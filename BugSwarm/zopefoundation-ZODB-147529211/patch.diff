diff --git a/.travis.yml b/.travis.yml
index 892c0001f2..bf3eb64664 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -1,32 +1,15 @@
+before_cache: [rm -f $HOME/.cache/pip/log/debug.log]
+cache:
+  directories: [$HOME/.cache/pip]
+dist: precise
+group: stable
+install: [travis_retry pip install -U pip==8.1.2, travis_retry pip install -U wheel==0.29.0,
+  travis_retry pip install -U manuel==1.8.0 zope.testing==4.5.0 zope.testrunner==4.5.1,
+  travis_retry pip install -U -e .]
 language: python
+notifications: {email: false}
+os: linux
+python: 3.5
+script: [zope-testrunner -u --test-path=src --auto-color --auto-progress, zope-testrunner
+    -f --test-path=src --auto-color --auto-progress]
 sudo: false
-python:
-    - pypy
-    - pypy3
-    - 2.7
-    - 3.3
-    - 3.4
-    - 3.5
-install:
-    # First install a newer pip so that it can use the wheel cache
-    # (only needed until travis upgrades pip to 7.x; note that the 3.5
-    # environment uses pip 7.1 by default).
-    - travis_retry pip install -U pip
-    # A newer wheel is also needed under Python 3, but only after we have
-    # a newer pip to take advantage of the cache.
-    - travis_retry pip install -U wheel
-    # Then start installing our deps so they can be cached. Note that use of --build-options / --global-options / --install-options
-    # disables the cache.
-    - travis_retry pip install -U manuel zope.testing zope.testrunner
-    - travis_retry pip install -U -e .
-script:
-    - zope-testrunner -u --test-path=src --auto-color --auto-progress
-    - zope-testrunner -f --test-path=src --auto-color --auto-progress
-notifications:
-    email: false
-# cache: pip seems not to work if `install` is replaced (https://github.com/travis-ci/travis-ci/issues/3239)
-cache:
-  directories:
-    - $HOME/.cache/pip
-before_cache:
-    - rm -f $HOME/.cache/pip/log/debug.log
diff --git a/XXX.rst b/XXX.rst
new file mode 100755
index 0000000000..e21bb37a3a
--- /dev/null
+++ b/XXX.rst
@@ -0,0 +1,14 @@
+Loose ends
+==========
+
+- BlobStorage no-longer works with FileStorage.  Since FileStorage
+  supports blobs on its own, so there's no reason to wrap a storage
+  with BlobStorage other than to test BlobStorage.
+
+  Amongst the choices:
+
+  - Make BlobStorage work with FileStorage.
+
+  - Test BlobStorage with MappingStorage, but that makes it impossible
+    to test some advanced features.
+
diff --git a/src/ZODB/DemoStorage.test b/src/ZODB/DemoStorage.test
index 866e28ed03..096498d049 100644
--- a/src/ZODB/DemoStorage.test
+++ b/src/ZODB/DemoStorage.test
@@ -206,7 +206,7 @@ Blob Support
 DemoStorage supports Blobs if the changes database supports blobs.
 
     >>> import ZODB.blob
-    >>> base = ZODB.blob.BlobStorage('base', FileStorage('base.fs'))
+    >>> base = FileStorage('base.fs', blob_dir='base')
     >>> db = DB(base)
     >>> conn = db.open()
     >>> conn.root()['blob'] = ZODB.blob.Blob()
@@ -215,10 +215,8 @@ DemoStorage supports Blobs if the changes database supports blobs.
     >>> transaction.commit()
     >>> db.close()
 
-    >>> base = ZODB.blob.BlobStorage('base',
-    ...                               FileStorage('base.fs', read_only=True))
-    >>> changes = ZODB.blob.BlobStorage('changes',
-    ...                                 FileStorage('changes.fs', create=True))
+    >>> base = FileStorage('base.fs', read_only=True, blob_dir='base')
+    >>> changes = FileStorage('changes.fs', blob_dir='changes', create=True)
     >>> storage = DemoStorage(base=base, changes=changes)
 
     >>> db = DB(storage)
diff --git a/src/ZODB/FileStorage/FileStorage.py b/src/ZODB/FileStorage/FileStorage.py
index 980174a21f..f273caa2a7 100644
--- a/src/ZODB/FileStorage/FileStorage.py
+++ b/src/ZODB/FileStorage/FileStorage.py
@@ -31,6 +31,7 @@
 from zope.interface import alsoProvides
 from zope.interface import implementer
 
+from .._compat import dumps
 from .. import utils
 
 from ZODB.blob import BlobStorageMixin
@@ -62,6 +63,7 @@
 from ZODB.POSException import ConflictError
 from ZODB.POSException import MultipleUndoErrors
 from ZODB.POSException import POSKeyError
+from ZODB.POSException import ReadConflictError
 from ZODB.POSException import ReadOnlyError
 from ZODB.POSException import StorageError
 from ZODB.POSException import StorageSystemError
@@ -417,6 +419,7 @@ def _restore_index(self):
 
     def close(self):
         self._file.close()
+        self._files.close()
         if hasattr(self,'_lock_file'):
             self._lock_file.close()
         try:
@@ -493,6 +496,21 @@ def loadBefore(self, oid, tid):
             else:
                 raise POSKeyError(oid)
 
+    def checkCurrentSerialInTransaction(self, oid, read_serial, transaction):
+        tbuf = self._tbuf(transaction)
+
+        with self._lock:
+            old = self._index_get(oid, 0)
+            committed_tid = z64
+            if old:
+                h = self._read_data_header(old, oid)
+                if read_serial == h.tid:
+                    return
+                committed_tid = h.tid
+
+            raise ReadConflictError(
+                oid=oid, serials=(committed_tid, read_serial))
+
     def store(self, oid, oldserial, data, version, transaction):
         if self._is_read_only:
             raise ReadOnlyError()
@@ -708,6 +726,7 @@ def tpc_finish(self, transaction, f=None):
                 finally:
                     self._vote_size -= tbuf.vote_size
                     self._commit_lock.release()
+                    transaction.set_data(self, None)
 
         return tid
 
@@ -772,100 +791,6 @@ def getTid(self, oid):
                 raise POSKeyError(oid)
             return h.tid
 
-    def _transactionalUndoRecord(self, tbuf, oid, pos, tid, pre):
-        """Get the undo information for a data record
-
-        'pos' points to the data header for 'oid' in the transaction
-        being undone.  'tid' refers to the transaction being undone.
-        'pre' is the 'prev' field of the same data header.
-
-        Return a 3-tuple consisting of a pickle, data pointer, and
-        current position.  If the pickle is true, then the data
-        pointer must be 0, but the pickle can be empty *and* the
-        pointer 0.
-        """
-
-        copy = True # Can we just copy a data pointer
-
-        # First check if it is possible to undo this record.
-        tpos = tbuf.index.get(oid, 0)
-        ipos = self._index.get(oid, 0)
-        tipos = tpos or ipos
-
-        if tipos != pos:
-            # The transaction being undone isn't current because:
-            # a) A later transaction was committed ipos != pos, or
-            # b) A change was made in the current transaction. This
-            #    could only be a previous undo in a multi-undo.
-            #    (We don't allow multiple data managers with the same
-            #    storage to participate in the same transaction.)
-            assert tipos > pos
-
-            # Get current data, as identified by tipos.  We'll use
-            # it to decide if and how we can undo in this case.
-            if tpos:
-                ctid, cdataptr, current_data = tbuf.undoDataInfo(oid, tpos)
-            else:
-                ctid, cdataptr, current_data = self._undoDataInfo(oid, ipos)
-
-            if cdataptr != pos:
-
-                # if cdataptr was == pos, then we'd be cool, because
-                # we're dealing with the same data.
-
-                # Because they aren't equal, we have to dig deeper
-
-                # Let's see if data to be undone and current data
-                # are the same. If not, we'll have to decide whether
-                # we should try conflict resolution.
-
-                try:
-                    data_to_be_undone = self._loadBack_impl(oid, pos)[0]
-                    if not current_data:
-                        current_data = self._loadBack_impl(oid, cdataptr)[0]
-
-                    if data_to_be_undone != current_data:
-                        # OK, so the current data is different from
-                        # the data being undone.  We can't just copy:
-                        copy = False
-
-                        if not pre:
-                            # The transaction we're undoing has no
-                            # previous state to merge with, so we
-                            # can't resolve a conflict.
-                            raise UndoError(
-                                "Can't undo an add transaction followed by"
-                                " conflicting transactions.", oid)
-                except KeyError:
-                    # LoadBack gave us a key error. Bail.
-                    raise UndoError("_loadBack() failed", oid)
-
-        # Return the data that should be written in the undo record.
-        if not pre:
-            # We're undoing object addition.  We're doing this because
-            # subsequent transactions has no net effect on the state
-            # (possibly because some of them were undos).
-            return "", 0, ipos
-
-        if copy:
-            # we can just copy our previous-record pointer forward
-            return "", pre, ipos
-
-        try:
-            pre_data = self._loadBack_impl(oid, pre)[0]
-        except KeyError:
-            # couldn't find oid; what's the real explanation for this?
-            raise UndoError("_loadBack() failed for %s", oid)
-
-        try:
-            data = self.tryToResolveConflict(
-                oid, ctid, tid, pre_data, current_data)
-            return data, 0, ipos
-        except ConflictError:
-            pass
-
-        raise UndoError("Some data were modified by a later transaction", oid)
-
     # undoLog() returns a description dict that includes an id entry.
     # The id is opaque to the client, but contains the transaction id.
     # The transactionalUndo() implementation does a simple linear
@@ -992,6 +917,100 @@ def _txn_undo_write(self, tpos, tbuf):
 
         return tindex
 
+    def _transactionalUndoRecord(self, tbuf, oid, pos, tid, pre):
+        """Get the undo information for a data record
+
+        'pos' points to the data header for 'oid' in the transaction
+        being undone.  'tid' refers to the transaction being undone.
+        'pre' is the 'prev' field of the same data header.
+
+        Return a 3-tuple consisting of a pickle, data pointer, and
+        current position.  If the pickle is true, then the data
+        pointer must be 0, but the pickle can be empty *and* the
+        pointer 0.
+        """
+
+        copy = True # Can we just copy a data pointer
+
+        # First check if it is possible to undo this record.
+        tpos = tbuf.index.get(oid, 0)
+        ipos = self._index.get(oid, 0)
+        tipos = tpos or ipos
+
+        if tipos != pos:
+            # The transaction being undone isn't current because:
+            # a) A later transaction was committed ipos != pos, or
+            # b) A change was made in the current transaction. This
+            #    could only be a previous undo in a multi-undo.
+            #    (We don't allow multiple data managers with the same
+            #    storage to participate in the same transaction.)
+            assert tipos > pos
+
+            # Get current data, as identified by tipos.  We'll use
+            # it to decide if and how we can undo in this case.
+            if tpos:
+                ctid, cdataptr, current_data = tbuf.undoDataInfo(oid, tpos)
+            else:
+                ctid, cdataptr, current_data = self._undoDataInfo(oid, ipos)
+
+            if cdataptr != pos:
+
+                # if cdataptr was == pos, then we'd be cool, because
+                # we're dealing with the same data.
+
+                # Because they aren't equal, we have to dig deeper
+
+                # Let's see if data to be undone and current data
+                # are the same. If not, we'll have to decide whether
+                # we should try conflict resolution.
+
+                try:
+                    data_to_be_undone = self._loadBack_impl(oid, pos)[0]
+                    if not current_data:
+                        current_data = self._loadBack_impl(oid, cdataptr)[0]
+
+                    if data_to_be_undone != current_data:
+                        # OK, so the current data is different from
+                        # the data being undone.  We can't just copy:
+                        copy = False
+
+                        if not pre:
+                            # The transaction we're undoing has no
+                            # previous state to merge with, so we
+                            # can't resolve a conflict.
+                            raise UndoError(
+                                "Can't undo an add transaction followed by"
+                                " conflicting transactions.", oid)
+                except KeyError:
+                    # LoadBack gave us a key error. Bail.
+                    raise UndoError("_loadBack() failed", oid)
+
+        # Return the data that should be written in the undo record.
+        if not pre:
+            # We're undoing object addition.  We're doing this because
+            # subsequent transactions has no net effect on the state
+            # (possibly because some of them were undos).
+            return "", 0, ipos
+
+        if copy:
+            # we can just copy our previous-record pointer forward
+            return "", pre, ipos
+
+        try:
+            pre_data = self._loadBack_impl(oid, pre)[0]
+        except KeyError:
+            # couldn't find oid; what's the real explanation for this?
+            raise UndoError("_loadBack() failed for %s", oid)
+
+        try:
+            data = self.tryToResolveConflict(
+                oid, ctid, tid, pre_data, current_data)
+            return data, 0, ipos
+        except ConflictError:
+            pass
+
+        raise UndoError("Some data were modified by a later transaction", oid)
+
     def history(self, oid, size=1, filter=None):
         with self._lock:
             r = []
@@ -2108,14 +2127,14 @@ def __init__(self, transaction, tid, status, tpos, fshelper):
             if len(ext) > 65535:
                 raise FileStorageError('too much extension data')
 
-        self.pos = tpos + self.tlen
+        self.pos = self.read_offset = tpos + self.tlen
 
         # blobs
         self.fshelper = fshelper
         self.blob_files = {} # oid -> blobfilename
 
     def store(self, oid, data, prev, resolved, back_pointer=z64):
-        h = DataHeader(oid, z64, prev, self.tpos, 0, len(data)).asString()
+        h = DataHeader(oid, z64, prev, self.tpos, 0, len(data or '')).asString()
         self.index[oid] = self.pos
         self._file.write(h)
         data = data or back_pointer
@@ -2135,6 +2154,12 @@ def storeblob(self, oid, blobfilename, serial=None):
             # Older store. Replace with newer
             remove_committed(self.blob_files[oid])
 
+        if os.path.dirname(blobfilename) != self.fshelper.temp_dir:
+            # We're storing from a savepoint.  Need to move to our tempdir
+            dest = utils.mktemp(self.fshelper.temp_dir, prefix='BUCSP')
+            rename_or_copy_blob(blobfilename, dest)
+            blobfilename = dest
+
         self.blob_files[oid] = blobfilename
 
     @property
@@ -2156,7 +2181,7 @@ def commit(self, tid, dest, tpos):
             th.ext = ext
             write(th.asString())
 
-            read_offset = self.tpos + self.tlen
+            read_offset = self.read_offset
             index = { oid: ipos - read_offset
                       for oid, ipos in self.index.items() }
 
@@ -2226,7 +2251,7 @@ def abort(self):
 
     def undoDataInfo(self, oid, pos):
         restore_pos = self._file.tell()
-        r = self._undoDataInfo(oid, pos)
+        r = self._undoDataInfo(oid, pos - self.read_offset)
         self._file.seek(restore_pos)
         return r
 
diff --git a/src/ZODB/FileStorage/tests.py b/src/ZODB/FileStorage/tests.py
index 5fe93c9347..f541d370d7 100644
--- a/src/ZODB/FileStorage/tests.py
+++ b/src/ZODB/FileStorage/tests.py
@@ -175,7 +175,8 @@ def _save_index():
     >>> index, pos, tid = fs._restore_index()
     >>> index.items() == fs._index.items()
     True
-    >>> pos, tid = fs._pos, fs._tid
+    >>> (pos, tid) == (fs._pos, fs._ltid)
+    True
 
 cleanup
 
diff --git a/src/ZODB/blob.py b/src/ZODB/blob.py
index e0d9017038..62e85e87be 100644
--- a/src/ZODB/blob.py
+++ b/src/ZODB/blob.py
@@ -352,7 +352,7 @@ class FilesystemHelper:
 
     def __init__(self, base_dir, layout_name='automatic'):
         self.base_dir = os.path.abspath(base_dir) + os.path.sep
-        self.temp_dir = os.path.join(base_dir, 'tmp')
+        self.temp_dir = os.path.join(self.base_dir, 'tmp')
 
         if layout_name == 'automatic':
             layout_name = auto_layout_select(base_dir)
diff --git a/src/ZODB/tests/testFileStorage.py b/src/ZODB/tests/testFileStorage.py
index 4be98c4e91..e8957acdba 100644
--- a/src/ZODB/tests/testFileStorage.py
+++ b/src/ZODB/tests/testFileStorage.py
@@ -286,7 +286,7 @@ def check_record_iternext(self):
             else:
                 self.assertNotEqual(next_oid, None)
 
-    def checkFlushAfterTruncate(self, fail=False):
+    def checkFlushAfterTruncate(self):
         r0 = self._dostore(z64)
         storage = self._storage
         t = transaction.Transaction()
@@ -301,21 +301,7 @@ def checkFlushAfterTruncate(self, fail=False):
         self._dostore(z64, r0, b'bar', 1)
         # In the case that read buffers were not invalidated, return value
         # is based on what was cached during the first load.
-        self.assertEqual(load_current(storage, z64)[0],
-                         b'foo' if fail else b'bar')
-
-    # We want to be sure that the above test detects any regression
-    # in the code it checks, because any bug here is like a time bomb: not
-    # obvious, hard to reproduce, with possible data corruption.
-    # It's even more important that FilePool.flush() is quite aggressive and
-    # we'd like to optimize it when Python gets an API to flush read buffers.
-    # Therefore, 'checkFlushAfterTruncate' is tested in turn by another unit
-    # test.
-    # On Windows, flushing explicitely is not (always?) necessary.
-    if sys.platform != 'win32':
-        def checkFlushNeededAfterTruncate(self):
-            self._storage._files.flush = lambda: None
-            self.checkFlushAfterTruncate(True)
+        self.assertEqual(load_current(storage, z64)[0], b'bar')
 
 class FileStorageHexTests(FileStorageTests):
 
diff --git a/src/ZODB/tests/testblob.py b/src/ZODB/tests/testblob.py
index ac0d23fa2e..a76796ca26 100644
--- a/src/ZODB/tests/testblob.py
+++ b/src/ZODB/tests/testblob.py
@@ -14,7 +14,7 @@
 from ZODB.blob import Blob
 from ZODB.blob import BushyLayout
 from ZODB.DB import DB
-from ZODB.FileStorage import FileStorage
+from ZODB.MappingStorage import MappingStorage
 from ZODB.tests.testConfig import ConfigTestBase
 from ZODB._compat import Pickler, Unpickler, _protocol
 
@@ -117,9 +117,7 @@ def testDeepCopyCanInvalidate(self):
         readers and writers values in cloned objects (see
         http://mail.zope.org/pipermail/zodb-dev/2008-August/012054.html)
         """
-        import ZODB.MappingStorage
-        database = DB(ZODB.blob.BlobStorage(
-            'blobs', ZODB.MappingStorage.MappingStorage()))
+        database = DB(ZODB.blob.BlobStorage('blobs', MappingStorage()))
         connection = database.open()
         root = connection.root()
         transaction.begin()
@@ -728,16 +726,6 @@ def setUp(test):
     test.globs['rmtree'] = zope.testing.setupstack.rmtree
 
 
-def setUpBlobAdaptedFileStorage(test):
-    setUp(test)
-
-    def create_storage(name='data', blob_dir=None):
-        if blob_dir is None:
-            blob_dir = '%s.bobs' % name
-        return ZODB.blob.BlobStorage(blob_dir, FileStorage('%s.fs' % name))
-
-    test.globs['create_storage'] = create_storage
-
 def storage_reusable_suite(prefix, factory,
                            test_blob_storage_recovery=False,
                            test_packing=False,
@@ -848,11 +836,12 @@ def test_suite():
             ]),
         ))
     suite.addTest(storage_reusable_suite(
-        'BlobAdaptedFileStorage',
+        'BlobAdaptedMappingStorage',
         lambda name, blob_dir:
-        ZODB.blob.BlobStorage(blob_dir, FileStorage('%s.fs' % name)),
-        test_blob_storage_recovery=True,
-        test_packing=True,
+        ZODB.blob.BlobStorage(blob_dir, MappingStorage()),
+        test_blob_storage_recovery=False,
+        test_packing=False,
+        test_undo=False,
         ))
 
     return suite
