diff --git a/doc/whats_new.rst b/doc/whats_new.rst
index 36c6cabd7971..42d6290a8cd9 100644
--- a/doc/whats_new.rst
+++ b/doc/whats_new.rst
@@ -131,6 +131,9 @@ Enhancements
    - Add option to show ``indicator features`` in the output of Imputer.
      By `Mani Teja`_.
 
+   - Reduce the memory usage for 32-bit float input arrays of :func:`utils.mean_variance_axis` and 
+     :func:`utils.incr_mean_variance_axis` by supporting cython fused types. By `YenChen Lin`_.
+
 Bug fixes
 .........
 
diff --git a/sklearn/cross_validation.py b/sklearn/cross_validation.py
index 8bf02c6340d3..5bf8e98338fb 100644
--- a/sklearn/cross_validation.py
+++ b/sklearn/cross_validation.py
@@ -51,6 +51,7 @@
            'LeavePOut',
            'ShuffleSplit',
            'StratifiedKFold',
+           'BinnedStratifiedKFold',
            'StratifiedShuffleSplit',
            'PredefinedSplit',
            'LabelShuffleSplit',
@@ -230,8 +231,8 @@ def __repr__(self):
         )
 
     def __len__(self):
-        return int(factorial(self.n) / factorial(self.n - self.p)
-                   / factorial(self.p))
+        return int(factorial(self.n) / factorial(self.n - self.p) /
+                   factorial(self.p))
 
 
 class _BaseKFold(with_metaclass(ABCMeta, _PartitionIterator)):
@@ -577,6 +578,150 @@ def __len__(self):
         return self.n_folds
 
 
+class BinnedStratifiedKFold(_BaseKFold):
+    """Binned Stratified K-Folds cross validation iterator for continuous data
+
+    Provides train/test indices to split data in train test sets
+    based on continuous input `y` of length `len_y`.
+    The input is binned into `ceil(len_y / n_folds)` classes
+    with equal number of members, except the middle class,
+    which receives the remainder of labels (of length `len_y % n_folds`).
+
+    This cross-validation object is a variation of KFold that
+    returns binned stratified folds. The folds are made by preserving
+    the percentage of samples for each class.
+
+    Read more in the :ref:`User Guide <cross_validation>`.
+
+    Parameters
+    ----------
+    y : array-like, [n_samples]
+        Samples to split in K folds.
+
+    n_folds : int, default=3
+        Number of folds. Must be at least 2.
+
+    shuffle : boolean, optional
+        Whether to shuffle each stratification of the data before splitting
+        into batches.
+
+    random_state : None, int or RandomState
+        When shuffle=True, pseudo-random number generator state used for
+        shuffling. If None, use default numpy RNG for shuffling.
+
+    Examples
+    --------
+    >>> from sklearn.cross_validation import BinnedStratifiedKFold
+    >>> y = np.arange(11.0)
+    >>> np.random.seed(0)
+    >>> np.random.shuffle(y)
+    >>> X = y + 0.1* np.random.randn(len(y))
+    >>> skf = BinnedStratifiedKFold(y, n_folds=3)
+    >>> len(skf)
+    3
+    >>> print(skf)  # doctest: +NORMALIZE_WHITESPACE
+    sklearn.cross_validation.BinnedStratifiedKFold(n=11, n_folds=3,
+            shuffle=False, random_state=None)
+    >>> indarr = np.zeros( len(y), dtype = bool)
+    >>> for train_index, test_index in skf:
+    ...    print("TRAIN:", train_index, "TEST:", test_index)
+    ...    X_train, X_test = X[train_index], X[test_index]
+    ...    y_train, y_test = y[train_index], y[test_index]
+    TRAIN: [ 1  2  3  4  5  8 10] TEST: [0 6 7 9]
+    TRAIN: [0 2 3 4 6 7 8 9] TEST: [ 1  5 10]
+    TRAIN: [ 0  1  5  6  7  9 10] TEST: [2 3 4 8]
+
+    Notes
+    -----
+    All the folds have size floor(n_samples / n_folds) or
+    floor(n_samples / n_folds) +1,
+    the length is assigned randomly (even if no shuffling is requested)
+    to balance the variance between folds.
+
+    See also
+    --------
+    StratifiedKFold -- stratified k-fold generator for classification data
+    """
+
+    def __init__(self, y, n_folds=3, shuffle=False,
+                 random_state=None):
+        self.random_state = random_state
+        super(BinnedStratifiedKFold, self).__init__(
+                len(y),
+                n_folds=n_folds, shuffle=shuffle, random_state=random_state
+                )
+        len_y = len(y)
+        yinds = np.arange(len_y)
+        "reorder the labels according to the ordering of `y`"
+        sorter0 = np.argsort(y)
+        yinds = yinds[sorter0]
+
+        self.n_classes = len_y // n_folds + int(len_y % n_folds != 0)
+
+        if len_y // n_folds > 1:
+            n_items_boundary_cls = n_folds * (len_y // n_folds // 2)
+            "assign lower `n_folds*(n_classes//2 )` labels to the lower class"
+            lowerclasses = yinds[:n_items_boundary_cls].reshape(-1, n_folds)
+            "assign upper `n_folds*(n_classes//2 )` labels to the upper class"
+            upperclasses = yinds[-n_items_boundary_cls:].reshape(-1, n_folds)
+            """assign the remainder labels to the middle class;
+            add -1 as a filling value;  shuffle"""
+            middleclasses = yinds[n_items_boundary_cls:-n_items_boundary_cls]
+            middleclasses = np.hstack([
+                    middleclasses,
+                    -np.ones(n_folds - len(middleclasses) % n_folds, dtype=int)
+                    ])
+            middleclasses = middleclasses.reshape(-1, n_folds)
+
+            rng = check_random_state(self.random_state)
+            rng.shuffle(middleclasses.T)
+            middleclasses = middleclasses.reshape(-1, n_folds)
+            self._test_masks = np.vstack([
+                        lowerclasses,
+                        middleclasses,
+                        upperclasses]).T
+            "to do : middle class rebalancing"
+        elif len_y > self.n_classes:
+            """put the lower half in one piece, and the rest into a ragged array;
+            the central values will remain unpaired
+            """
+            lowerclasses = yinds[:n_folds].reshape(-1, n_folds)
+            upperclasses = yinds[n_folds:]
+            upperclasses = np.hstack([
+                    upperclasses,
+                    -np.ones(n_folds - len(upperclasses) % n_folds, dtype=int)
+                    ])
+
+            self._test_masks = np.vstack([lowerclasses, upperclasses]).T
+
+        if shuffle:
+            rng.shuffle(self._test_masks)
+
+        "remove missing values from the middle class"
+        self._test_masks = [y[y != -1] for y in self._test_masks]
+        return
+
+    def _iter_test_masks(self):
+        indarr = np.zeros(self.n, dtype=bool)
+        for mask in self._test_masks:
+            indarr[:] = False
+            indarr[mask] = True
+            yield indarr
+
+    def __repr__(self):
+        return '%s.%s(n=%s, n_folds=%i, shuffle=%s, random_state=%s)' % (
+            self.__class__.__module__,
+            self.__class__.__name__,
+            self.n,
+            self.n_folds,
+            self.shuffle,
+            self.random_state,
+        )
+
+    def __len__(self):
+        return self.n_folds
+
+
 class LeaveOneLabelOut(_PartitionIterator):
     """Leave-One-Label_Out cross-validation iterator
 
diff --git a/sklearn/model_selection/__init__.py b/sklearn/model_selection/__init__.py
index caf0fe70ff49..fecc4dc524b5 100644
--- a/sklearn/model_selection/__init__.py
+++ b/sklearn/model_selection/__init__.py
@@ -2,6 +2,7 @@
 from ._split import KFold
 from ._split import LabelKFold
 from ._split import StratifiedKFold
+from ._split import BinnedStratifiedKFold
 from ._split import LeaveOneLabelOut
 from ._split import LeaveOneOut
 from ._split import LeavePLabelOut
@@ -40,6 +41,7 @@
            'RandomizedSearchCV',
            'ShuffleSplit',
            'StratifiedKFold',
+           'BinnedStratifiedKFold',
            'StratifiedShuffleSplit',
            'check_cv',
            'cross_val_predict',
diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py
index 143730e468cc..661fb3ebb81a 100644
--- a/sklearn/model_selection/_split.py
+++ b/sklearn/model_selection/_split.py
@@ -44,6 +44,7 @@
            'ShuffleSplit',
            'LabelShuffleSplit',
            'StratifiedKFold',
+           'BinnedStratifiedKFold',
            'StratifiedShuffleSplit',
            'PredefinedSplit',
            'train_test_split',
@@ -635,6 +636,164 @@ def split(self, X, y, labels=None):
         """
         return super(StratifiedKFold, self).split(X, y, labels)
 
+
+class BinnedStratifiedKFold(_BaseKFold):
+    """Stratified K-Folds cross-validator
+
+    Provides train/test indices to split data in train/test sets.
+
+    This cross-validation object is a variation of KFold that returns
+    stratified folds. The folds are made by preserving the percentage of
+    samples for each class.
+
+    Read more in the :ref:`User Guide <cross_validation>`.
+
+    Parameters
+    ----------
+    n_folds : int, default=3
+        Number of folds. Must be at least 2.
+
+    shuffle : boolean, optional
+        Whether to shuffle each stratification of the data before splitting
+        into batches.
+
+    random_state : None, int or RandomState
+        When shuffle=True, pseudo-random number generator state used for
+        shuffling. If None, use default numpy RNG for shuffling.
+
+    Examples
+    --------
+    >>> from sklearn.model_selection import BinnedStratifiedKFold
+    >>> y = np.arange(11.0)
+    >>> np.random.seed(0)
+    >>> np.random.shuffle(y)
+    >>> X = y + 0.1* np.random.randn(len(y))
+    >>> cv = BinnedStratifiedKFold(n_folds=3)
+    >>> skf = cv.split(y)
+    >>> print(cv)  # doctest: +NORMALIZE_WHITESPACE
+    BinnedStratifiedKFold(n_folds=3, random_state=None,
+    shuffle=False)
+    >>> indarr = np.zeros(len(y), dtype=bool)
+    >>> for train_index, test_index in skf:
+    ...    print("TRAIN:", train_index, "TEST:", test_index)
+    ...    X_train, X_test = X[train_index], X[test_index]
+    ...    y_train, y_test = y[train_index], y[test_index]
+    TRAIN: [ 1  2  3  4  5  8 10] TEST: [0 6 7 9]
+    TRAIN: [0 2 3 4 6 7 8 9] TEST: [ 1  5 10]
+    TRAIN: [ 0  1  5  6  7  9 10] TEST: [2 3 4 8]
+
+    Notes
+    -----
+    All the folds have size floor(n_samples / n_folds) or
+    floor(n_samples / n_folds) +1,
+    the length is assigned randomly (even if no shuffling is requested)
+    to balance the variance between folds.
+
+    See also
+    --------
+    StratifiedKFold -- stratified k-fold generator for classification data
+    """
+
+    def __init__(self, n_folds=3, shuffle=False, random_state=None):
+        super(BinnedStratifiedKFold, self).__init__(n_folds, shuffle,
+                                                    random_state)
+
+    def _make_test_folds(self, X, y=None, labels=None):
+        if y is None:
+            if hasattr(X, "shape") and \
+               (len(X.shape) == 1 or all(X.shape[1:] == 1)):
+                y = X
+            else:
+                raise ValueError("no y has been supplied; "
+                                 "first argument is not a valid y")
+        n_samples = len(y)
+        self.n_samples = n_samples
+        n_folds = self.n_folds
+        yinds = np.arange(n_samples)
+        "reorder the labels according to the ordering of `y`"
+        sorter0 = np.argsort(y)
+        yinds = yinds[sorter0]
+
+        self.n_classes = n_samples // n_folds + int(n_samples % n_folds != 0)
+
+        if n_samples // n_folds > 1:
+            n_items_boundary_cls = n_folds * (n_samples // n_folds // 2)
+            "assign lower `n_folds*(n_classes//2 )` labels to the lower class"
+            lowerclasses = yinds[:n_items_boundary_cls].reshape(-1, n_folds)
+            "assign upper `n_folds*(n_classes//2 )` labels to the upper class"
+            upperclasses = yinds[-n_items_boundary_cls:].reshape(-1, n_folds)
+            """assign the remainder labels to the middle class;
+            add -1 as a filling value;  shuffle"""
+            middleclasses = yinds[n_items_boundary_cls:-n_items_boundary_cls]
+            middleclasses = np.hstack([
+                    middleclasses,
+                    -np.ones(n_folds - len(middleclasses) % n_folds, dtype=int)
+                    ])
+            middleclasses = middleclasses.reshape(-1, n_folds)
+
+            rng = check_random_state(self.random_state)
+            rng.shuffle(middleclasses.T)
+            middleclasses = middleclasses.reshape(-1, n_folds)
+            self._test_masks = np.vstack([
+                        lowerclasses,
+                        middleclasses,
+                        upperclasses]).T
+            "to do : middle class rebalancing"
+        elif n_samples > self.n_classes:
+            """put the lower half in one piece, and the rest into a ragged array;
+            the central values will remain unpaired
+            """
+            lowerclasses = yinds[:n_folds].reshape(-1, n_folds)
+            upperclasses = yinds[n_folds:]
+            upperclasses = np.hstack([
+                    upperclasses,
+                    -np.ones(n_folds - len(upperclasses) % n_folds, dtype=int)
+                    ])
+
+            self._test_masks = np.vstack([lowerclasses, upperclasses]).T
+
+        if self.shuffle:
+            rng.shuffle(self._test_masks)
+        "remove missing values from the middle class"
+        self._test_masks = [y[y != -1] for y in self._test_masks]
+
+        test_folds = np.empty(n_samples,  dtype=np.int)
+        for nn, fold_masks in enumerate(self._test_masks):
+            test_folds[fold_masks] = nn
+        return test_folds
+
+    def _iter_test_masks(self, X, y=None, labels=None):
+        test_folds = self._make_test_folds(X, y)
+        for i in range(self.n_folds):
+            yield test_folds == i
+
+    def split(self, X, y=None, labels=None):
+        """Generate indices to split data into training and test set.
+
+        Parameters
+        ----------
+        X : array-like, shape (n_samples, n_features)
+            Training data, where n_samples is the number of samples
+            and n_features is the number of features.
+
+        y : array-like, shape (n_samples,)
+            The target variable for supervised learning problems.
+
+        labels : array-like, with shape (n_samples,), optional
+            Group labels for the samples used while splitting the dataset into
+            train/test set.
+
+        Returns
+        -------
+        train : ndarray
+            The training set indices for that split.
+
+        test : ndarray
+            The testing set indices for that split.
+        """
+        return super(BinnedStratifiedKFold, self).split(X, y, labels)
+
+
 class LeaveOneLabelOut(BaseCrossValidator):
     """Leave One Label Out cross-validator
 
@@ -1193,8 +1352,8 @@ def _validate_shuffle_split(n_samples, test_size, train_size):
     Validation helper to check if the test/test sizes are meaningful wrt to the
     size of the data (n_samples)
     """
-    if (test_size is not None and np.asarray(test_size).dtype.kind == 'i'
-            and test_size >= n_samples):
+    if (test_size is not None and np.asarray(test_size).dtype.kind == 'i' and
+            test_size >= n_samples):
         raise ValueError('test_size=%d should be smaller than the number of '
                          'samples %d' % (test_size, n_samples))
 
diff --git a/sklearn/model_selection/tests/test_split.py b/sklearn/model_selection/tests/test_split.py
index 69749f8e4c0a..11f184166498 100644
--- a/sklearn/model_selection/tests/test_split.py
+++ b/sklearn/model_selection/tests/test_split.py
@@ -29,6 +29,7 @@
 from sklearn.model_selection import cross_val_score
 from sklearn.model_selection import KFold
 from sklearn.model_selection import StratifiedKFold
+from sklearn.model_selection import BinnedStratifiedKFold
 from sklearn.model_selection import LabelKFold
 from sklearn.model_selection import LeaveOneOut
 from sklearn.model_selection import LeaveOneLabelOut
@@ -140,34 +141,27 @@ def test_cross_validator_with_default_params():
     X_1d = np.array([1, 2, 3, 4])
     y = np.array([1, 1, 2, 2])
     labels = np.array([1, 2, 3, 4])
-    loo = LeaveOneOut()
-    lpo = LeavePOut(p)
-    kf = KFold(n_folds)
-    skf = StratifiedKFold(n_folds)
-    lolo = LeaveOneLabelOut()
-    lopo = LeavePLabelOut(p)
-    ss = ShuffleSplit(random_state=0)
-    ps = PredefinedSplit([1, 1, 2, 2])  # n_splits = np of unique folds = 2
-
-    loo_repr = "LeaveOneOut()"
-    lpo_repr = "LeavePOut(p=2)"
-    kf_repr = "KFold(n_folds=2, random_state=None, shuffle=False)"
-    skf_repr = "StratifiedKFold(n_folds=2, random_state=None, shuffle=False)"
-    lolo_repr = "LeaveOneLabelOut()"
-    lopo_repr = "LeavePLabelOut(n_labels=2)"
-    ss_repr = ("ShuffleSplit(n_iter=10, random_state=0, test_size=0.1, "
-               "train_size=None)")
-    ps_repr = "PredefinedSplit(test_fold=array([1, 1, 2, 2]))"
+    cvs = [
+        (LeaveOneOut(), "LeaveOneOut()", n_samples),
+        (LeavePOut(p), "LeavePOut(p=%u)" % p, comb(n_samples, p) ),
+        (KFold(n_folds), "KFold(n_folds=2, random_state=None, shuffle=False)", n_folds),
+        (StratifiedKFold(n_folds), ("StratifiedKFold(n_folds=2, "
+                    "random_state=None, shuffle=False)"), n_folds),
+        (LeaveOneLabelOut(), "LeaveOneLabelOut()", n_unique_labels),
+        (LeavePLabelOut(p), "LeavePLabelOut(n_labels=%u)" % p, comb(n_unique_labels, p) ),
+        (ShuffleSplit(random_state=0), ("ShuffleSplit(n_iter=10, random_state=0, test_size=0.1, "
+                       "train_size=None)"), n_iter),
+        (PredefinedSplit([1, 1, 2, 2]), "PredefinedSplit(test_fold=array([1, 1, 2, 2]))", 2),
+          ]
+    # n_splits = np of unique folds = 2
 
     n_splits = [n_samples, comb(n_samples, p), n_folds, n_folds,
                 n_unique_labels, comb(n_unique_labels, p), n_iter, 2]
 
-    for i, (cv, cv_repr) in enumerate(zip(
-            [loo, lpo, kf, skf, lolo, lopo, ss, ps],
-            [loo_repr, lpo_repr, kf_repr, skf_repr, lolo_repr, lopo_repr,
-             ss_repr, ps_repr])):
+    for i, (cv, cv_repr, n_splits_ ) in enumerate(cvs):
+        print( cv, cv_repr, n_splits_ )
         # Test if get_n_splits works correctly
-        assert_equal(n_splits[i], cv.get_n_splits(X, y, labels))
+        assert_equal(n_splits_, cv.get_n_splits(X, y, labels))
 
         # Test if the cross-validator works as expected even if
         # the data is 1d
@@ -379,6 +373,110 @@ def test_stratifiedkfold_balance():
             assert_equal(np.sum(sizes), i)
 
 
+def test_binnedstratifiedkfold_balance():
+    for i in range(11, 17):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(i)
+        np.random.shuffle(y)
+        sizes = []
+
+        cv = BinnedStratifiedKFold(n_folds,
+                  shuffle=False, random_state=None)
+        bskf = cv.split(y)
+
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+        for  train_index, test_index in bskf:
+            sizes.append(
+                        len(test_index)
+                        )
+        assert_true((np.max(sizes) - np.min(sizes)) <= 1)
+        assert_equal(np.sum(sizes), i)
+
+
+def test_binnedstratifiedkfold_bin_spacing():
+    "check if the binned `y` falls into bins of equal size (+/- 1)"
+    for _ in range(10):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(30)
+        np.random.shuffle(y)
+
+        cv = BinnedStratifiedKFold(n_folds=n_folds, shuffle = False,
+                                   random_state=None)
+        bskf = cv.split(y)
+        #bins = np.percentile(y, np.arange(n_folds))
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+
+        for  train_index, test_index in bskf:
+            y_test = y[test_index]
+            hist_test, _ = np.histogram( y_test, bins = bins )
+            assert_true(all(abs(hist_test - np.mean(hist_test)) <= 1),
+                        msg = "y_test falls into bins of too ragged sizes")
+
+            y_train = y[train_index]
+            hist_train, _ = np.histogram( y_test, bins = bins )
+            assert_true(all(abs(hist_train - np.mean(hist_train)) <= 1),
+                        msg = "y_train falls into bins of too ragged sizes")
+
+
+def test_binnedstratifiedkfold_has_more_stable_distribution_moments_between_folds():
+    """check if BinnedStratifiedKFold performs on average better than KFold in terms of
+    lower between-fold variance of fold mean(y_test) and fold std(y_test)
+    """
+    binned_has_more_stable_std_list = []
+    binned_has_more_stable_mean_list = []
+
+    for trial in range(100):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(30)
+        np.random.shuffle(y)
+        ymeans_binned = []
+        ystds_binned = []
+
+        cv_bs = BinnedStratifiedKFold(n_folds=n_folds, shuffle = False,
+                                   random_state=None)
+        bskf = cv_bs.split(y)
+
+        cv = KFold(n_folds = n_folds,
+                        shuffle = True, random_state = None)
+        kf = cv.split(y)
+
+        #bins = np.percentile(y, np.arange(n_folds))
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+
+        for  train_index, test_index in bskf:
+            y_test = y[test_index]
+            ymeans_binned.append(y_test.mean())
+            ystds_binned.append(y_test.std())
+            hist_, _ = np.histogram(y[test_index], bins = bins)
+
+            assert_true(all(abs(hist_ - np.mean(hist_)) <= 1),
+                        msg="too ragged bins")
+
+        ymeans_regular = []
+        ystds_regular = []
+        for  train_index_reg, test_index_reg in kf:
+            ymeans_regular.append(y[test_index_reg].mean())
+            ystds_regular.append(y[test_index_reg].std())
+
+        binned_has_more_stable_std = np.std(ystds_regular) > np.std(ystds_binned)
+        binned_has_more_stable_std_list.append(binned_has_more_stable_std)
+
+        binned_has_more_stable_mean = np.std(ymeans_regular) > np.std(ymeans_binned)
+        binned_has_more_stable_mean_list.append(binned_has_more_stable_mean)
+
+    binned_has_more_stable_std_fraction = np.mean(binned_has_more_stable_std_list)
+    binned_has_more_stable_mean_fraction = np.mean(binned_has_more_stable_mean_list)
+
+    assert_greater( binned_has_more_stable_std_fraction, 0.5)
+    assert_greater( binned_has_more_stable_mean_fraction, 0.5)
+    print(" std(y_test) of BinnedStratifiedKFold was more stable than "
+          "one of KFold in\t%.2f%% cases" % \
+          (100.0*binned_has_more_stable_std_fraction))
+    print("mean(y_test) of BinnedStratifiedKFold was more stable than "
+          "one of KFold in\t%.2f%% cases" % \
+          (100.0*binned_has_more_stable_mean_fraction))
+
+
 def test_shuffle_kfold():
     # Check the indices are shuffled properly
     kf = KFold(3)
diff --git a/sklearn/tests/test_cross_validation.py b/sklearn/tests/test_cross_validation.py
index 027fe1ee458e..40d7a7e9260d 100644
--- a/sklearn/tests/test_cross_validation.py
+++ b/sklearn/tests/test_cross_validation.py
@@ -438,6 +438,109 @@ def test_label_kfold():
     assert_raises(ValueError, cval.LabelKFold, labels, n_folds=3)
 
 
+def test_binnedstratifiedkfold_balance():
+    for _ in range(10):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(30)
+        np.random.shuffle(y)
+        sizes = []
+
+        bskf = cval.BinnedStratifiedKFold(y, n_folds=n_folds,
+                                          shuffle = False, random_state=None)
+
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+        for  train_index, test_index in bskf:
+            sizes.append(
+                        len(test_index)
+                        )
+        assert_true((np.max(sizes) - np.min(sizes)) <= 1)
+        assert_equal(np.sum(sizes), bskf.n)
+
+
+def test_binnedstratifiedkfold_bin_spacing():
+    "check if the binned `y` falls into bins of equal size (+/- 1)"
+    for _ in range(10):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(30)
+        np.random.shuffle(y)
+
+        skf = cval.BinnedStratifiedKFold(y, n_folds=n_folds,
+                                         shuffle = False, random_state=None)
+
+        #bins = np.percentile(y, np.arange(n_folds))
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+
+        for  train_index, test_index in skf:
+            y_test = y[test_index]
+            hist_test, _ = np.histogram( y_test, bins = bins )
+            assert_true(all(abs(hist_test - np.mean(hist_test)) <= 1),
+                        msg = "y_test falls into bins of too ragged sizes")
+
+            y_train = y[train_index]
+            hist_train, _ = np.histogram( y_test, bins = bins )
+            assert_true(all(abs(hist_train - np.mean(hist_train)) <= 1),
+                        msg = "y_train falls into bins of too ragged sizes")
+
+
+def test_binnedstratifiedkfold_has_more_stable_distribution_moments_between_folds():
+    """check if BinnedStratifiedKFold performs on average better than KFold in terms of
+    lower between-fold variance of fold mean(y_test) and fold std(y_test)
+    """
+    binned_has_more_stable_std_list = []
+    binned_has_more_stable_mean_list = []
+
+    for trial in range(100):
+        n_folds = 2 + int(10*np.random.rand())
+        y = np.random.randn(30)
+        np.random.shuffle(y)
+        ymeans_binned = []
+        ystds_binned = []
+
+        skf = cval.BinnedStratifiedKFold(y, n_folds=n_folds,
+                                         shuffle = False, random_state=None)
+
+
+        kf = cval.KFold(len(y), n_folds = n_folds,
+                        shuffle = True, random_state = None)
+
+        #bins = np.percentile(y, np.arange(n_folds))
+        bins = np.array([np.percentile(y, q) for q in range(n_folds)])
+
+        for  train_index, test_index in skf:
+            y_test = y[test_index]
+            ymeans_binned.append(y_test.mean())
+            ystds_binned.append(y_test.std())
+            hist_, _ = np.histogram(y[test_index], bins = bins)
+
+            assert_true(all(abs(hist_ - np.mean(hist_)) <= 1),
+                        msg="too ragged bins")
+
+
+        ymeans_regular = []
+        ystds_regular = []
+        for  train_index_reg, test_index_reg in kf:
+            ymeans_regular.append(y[test_index_reg].mean())
+            ystds_regular.append(y[test_index_reg].std())
+
+        binned_has_more_stable_std = np.std(ystds_regular) > np.std(ystds_binned)
+        binned_has_more_stable_std_list.append(binned_has_more_stable_std)
+
+        binned_has_more_stable_mean = np.std(ymeans_regular) > np.std(ymeans_binned)
+        binned_has_more_stable_mean_list.append(binned_has_more_stable_mean)
+
+    binned_has_more_stable_std_fraction = np.mean(binned_has_more_stable_std_list)
+    binned_has_more_stable_mean_fraction = np.mean(binned_has_more_stable_mean_list)
+
+    assert_greater( binned_has_more_stable_std_fraction, 0.5)
+    assert_greater( binned_has_more_stable_mean_fraction, 0.5)
+    print(" std(y_test) of BinnedStratifiedKFold was more stable than "
+          "one of KFold in\t%.2f%% cases" % \
+          (100.0*binned_has_more_stable_std_fraction))
+    print("mean(y_test) of BinnedStratifiedKFold was more stable than "
+          "one of KFold in\t%.2f%% cases" % \
+          (100.0*binned_has_more_stable_mean_fraction))
+
+
 def test_shuffle_split():
     ss1 = cval.ShuffleSplit(10, test_size=0.2, random_state=0)
     ss2 = cval.ShuffleSplit(10, test_size=2, random_state=0)
diff --git a/sklearn/utils/sparsefuncs_fast.pyx b/sklearn/utils/sparsefuncs_fast.pyx
index ef978db49c1b..10c143ed5078 100644
--- a/sklearn/utils/sparsefuncs_fast.pyx
+++ b/sklearn/utils/sparsefuncs_fast.pyx
@@ -64,24 +64,36 @@ def csr_mean_variance_axis0(X):
         Feature-wise variances
 
     """
-    cdef unsigned int n_samples = X.shape[0]
-    cdef unsigned int n_features = X.shape[1]
+    if X.dtype != np.float32:
+        X = X.astype(np.float64)
+    return _csr_mean_variance_axis0(X.data, X.shape, X.indices)
 
-    cdef np.ndarray[DOUBLE, ndim=1, mode="c"] X_data
-    X_data = np.asarray(X.data, dtype=np.float64)     # might copy!
-    cdef np.ndarray[int, ndim=1] X_indices = X.indices
+
+def _csr_mean_variance_axis0(np.ndarray[floating, ndim=1, mode="c"] X_data,
+                             shape,
+                             np.ndarray[int, ndim=1] X_indices):
+    # Implement the function here since variables using fused types
+    # cannot be declared directly and can only be passed as function arguments
+    cdef unsigned int n_samples = shape[0]
+    cdef unsigned int n_features = shape[1]
 
     cdef unsigned int i
     cdef unsigned int non_zero = X_indices.shape[0]
     cdef unsigned int col_ind
-    cdef double diff
+    cdef floating diff
 
     # means[j] contains the mean of feature j
-    cdef np.ndarray[DOUBLE, ndim=1] means = np.zeros(n_features,
-                                                     dtype=np.float64)
-
+    cdef np.ndarray[floating, ndim=1] means
     # variances[j] contains the variance of feature j
-    cdef np.ndarray[DOUBLE, ndim=1] variances = np.zeros_like(means)
+    cdef np.ndarray[floating, ndim=1] variances
+
+    if floating is float:
+        dtype = np.float32
+    else:
+        dtype = np.float64
+
+    means = np.zeros(n_features, dtype=dtype)
+    variances = np.zeros_like(means, dtype=dtype)
 
     # counts[j] contains the number of samples where feature j is non-zero
     cdef np.ndarray[int, ndim=1] counts = np.zeros(n_features,
@@ -124,27 +136,38 @@ def csc_mean_variance_axis0(X):
         Feature-wise variances
 
     """
-    cdef unsigned int n_samples = X.shape[0]
-    cdef unsigned int n_features = X.shape[1]
+    if X.dtype != np.float32:
+        X = X.astype(np.float64)
+    return _csc_mean_variance_axis0(X.data, X.shape, X.indices, X.indptr)
+
 
-    cdef np.ndarray[DOUBLE, ndim=1] X_data
-    X_data = np.asarray(X.data, dtype=np.float64)     # might copy!
-    cdef np.ndarray[int, ndim=1] X_indices = X.indices
-    cdef np.ndarray[int, ndim=1] X_indptr = X.indptr
+def _csc_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
+                             shape,
+                             np.ndarray[int, ndim=1] X_indices,
+                             np.ndarray[int, ndim=1] X_indptr):
+    # Implement the function here since variables using fused types
+    # cannot be declared directly and can only be passed as function arguments
+    cdef unsigned int n_samples = shape[0]
+    cdef unsigned int n_features = shape[1]
 
     cdef unsigned int i
     cdef unsigned int j
     cdef unsigned int counts
     cdef unsigned int startptr
     cdef unsigned int endptr
-    cdef double diff
+    cdef floating diff
 
     # means[j] contains the mean of feature j
-    cdef np.ndarray[DOUBLE, ndim=1] means = np.zeros(n_features,
-                                                     dtype=np.float64)
-
+    cdef np.ndarray[floating, ndim=1] means
     # variances[j] contains the variance of feature j
-    cdef np.ndarray[DOUBLE, ndim=1] variances = np.zeros_like(means)
+    cdef np.ndarray[floating, ndim=1] variances
+    if floating is float:
+        dtype = np.float32
+    else:
+        dtype = np.float64
+
+    means = np.zeros(n_features, dtype=dtype)
+    variances = np.zeros_like(means, dtype=dtype)
 
     for i in xrange(n_features):
 
@@ -210,29 +233,58 @@ def incr_mean_variance_axis0(X, last_mean, last_var, unsigned long last_n):
     `utils.extmath._batch_mean_variance_update`.
 
     """
-    cdef unsigned long n_samples = X.shape[0]
-    cdef unsigned int n_features = X.shape[1]
+    if X.dtype != np.float32:
+        X = X.astype(np.float64)
+    return _incr_mean_variance_axis0(X.data, X.shape, X.indices, X.indptr,
+                                     X.format, last_mean, last_var, last_n)
+
+
+def _incr_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
+                              shape,
+                              np.ndarray[int, ndim=1] X_indices,
+                              np.ndarray[int, ndim=1] X_indptr,
+                              X_format,
+                              last_mean,
+                              last_var,
+                              unsigned long last_n):
+    # Implement the function here since variables using fused types
+    # cannot be declared directly and can only be passed as function arguments
+    cdef unsigned long n_samples = shape[0]
+    cdef unsigned int n_features = shape[1]
     cdef unsigned int i
 
     # last = stats until now
     # new = the current increment
     # updated = the aggregated stats
     # when arrays, they are indexed by i per-feature
-    cdef np.ndarray[DOUBLE, ndim=1] new_mean = np.zeros(n_features,
-                                                      dtype=np.float64)
-    cdef np.ndarray[DOUBLE, ndim=1] new_var = np.zeros_like(new_mean)
+    cdef np.ndarray[floating, ndim=1] new_mean
+    cdef np.ndarray[floating, ndim=1] new_var
+    cdef np.ndarray[floating, ndim=1] updated_mean
+    cdef np.ndarray[floating, ndim=1] updated_var
+    if floating is float:
+        dtype = np.float32
+    else:
+        dtype = np.float64
+
+    new_mean = np.zeros(n_features, dtype=dtype)
+    new_var = np.zeros_like(new_mean, dtype=dtype)
+    updated_mean = np.zeros_like(new_mean, dtype=dtype)
+    updated_var = np.zeros_like(new_mean, dtype=dtype)
+
     cdef unsigned long new_n
-    cdef np.ndarray[DOUBLE, ndim=1] updated_mean = np.zeros_like(new_mean)
-    cdef np.ndarray[DOUBLE, ndim=1] updated_var = np.zeros_like(new_mean)
     cdef unsigned long updated_n
-    cdef DOUBLE last_over_new_n
+    cdef floating last_over_new_n
 
     # Obtain new stats first
     new_n = n_samples
-    if isinstance(X, sp.csr_matrix):
-        new_mean, new_var = csr_mean_variance_axis0(X)
-    elif isinstance(X, sp.csc_matrix):
-        new_mean, new_var = csc_mean_variance_axis0(X)
+
+    if X_format == 'csr':
+        # X is a CSR matrix
+        new_mean, new_var = _csr_mean_variance_axis0(X_data, shape, X_indices)
+    else:
+        # X is a CSC matrix
+        new_mean, new_var = _csc_mean_variance_axis0(X_data, shape, X_indices,
+                                                     X_indptr)
 
     # First pass
     if last_n == 0:
diff --git a/sklearn/utils/tests/test_sparsefuncs.py b/sklearn/utils/tests/test_sparsefuncs.py
index f14628118170..2e989ab61068 100644
--- a/sklearn/utils/tests/test_sparsefuncs.py
+++ b/sklearn/utils/tests/test_sparsefuncs.py
@@ -30,29 +30,26 @@ def test_mean_variance_axis0():
     X_lil = sp.lil_matrix(X)
     X_lil[1, 0] = 0
     X[1, 0] = 0
-    X_csr = sp.csr_matrix(X_lil)
 
-    X_means, X_vars = mean_variance_axis(X_csr, axis=0)
-    assert_array_almost_equal(X_means, np.mean(X, axis=0))
-    assert_array_almost_equal(X_vars, np.var(X, axis=0))
+    assert_raises(TypeError, mean_variance_axis, X_lil, axis=0)
 
+    X_csr = sp.csr_matrix(X_lil)
     X_csc = sp.csc_matrix(X_lil)
-    X_means, X_vars = mean_variance_axis(X_csc, axis=0)
 
-    assert_array_almost_equal(X_means, np.mean(X, axis=0))
-    assert_array_almost_equal(X_vars, np.var(X, axis=0))
-    assert_raises(TypeError, mean_variance_axis, X_lil, axis=0)
+    expected_dtypes = [(np.float32, np.float32),
+                       (np.float64, np.float64),
+                       (np.int32, np.float64),
+                       (np.int64, np.float64)]
 
-    X = X.astype(np.float32)
-    X_csr = X_csr.astype(np.float32)
-    X_csc = X_csr.astype(np.float32)
-    X_means, X_vars = mean_variance_axis(X_csr, axis=0)
-    assert_array_almost_equal(X_means, np.mean(X, axis=0))
-    assert_array_almost_equal(X_vars, np.var(X, axis=0))
-    X_means, X_vars = mean_variance_axis(X_csc, axis=0)
-    assert_array_almost_equal(X_means, np.mean(X, axis=0))
-    assert_array_almost_equal(X_vars, np.var(X, axis=0))
-    assert_raises(TypeError, mean_variance_axis, X_lil, axis=0)
+    for input_dtype, output_dtype in expected_dtypes:
+        X_test = X.astype(input_dtype)
+        for X_sparse in (X_csr, X_csc):
+            X_sparse = X_sparse.astype(input_dtype)
+            X_means, X_vars = mean_variance_axis(X_sparse, axis=0)
+            assert_equal(X_means.dtype, output_dtype)
+            assert_equal(X_vars.dtype, output_dtype)
+            assert_array_almost_equal(X_means, np.mean(X_test, axis=0))
+            assert_array_almost_equal(X_vars, np.var(X_test, axis=0))
 
 
 def test_mean_variance_axis1():
@@ -64,29 +61,26 @@ def test_mean_variance_axis1():
     X_lil = sp.lil_matrix(X)
     X_lil[1, 0] = 0
     X[1, 0] = 0
-    X_csr = sp.csr_matrix(X_lil)
 
-    X_means, X_vars = mean_variance_axis(X_csr, axis=1)
-    assert_array_almost_equal(X_means, np.mean(X, axis=1))
-    assert_array_almost_equal(X_vars, np.var(X, axis=1))
+    assert_raises(TypeError, mean_variance_axis, X_lil, axis=1)
 
+    X_csr = sp.csr_matrix(X_lil)
     X_csc = sp.csc_matrix(X_lil)
-    X_means, X_vars = mean_variance_axis(X_csc, axis=1)
 
-    assert_array_almost_equal(X_means, np.mean(X, axis=1))
-    assert_array_almost_equal(X_vars, np.var(X, axis=1))
-    assert_raises(TypeError, mean_variance_axis, X_lil, axis=1)
+    expected_dtypes = [(np.float32, np.float32),
+                       (np.float64, np.float64),
+                       (np.int32, np.float64),
+                       (np.int64, np.float64)]
 
-    X = X.astype(np.float32)
-    X_csr = X_csr.astype(np.float32)
-    X_csc = X_csr.astype(np.float32)
-    X_means, X_vars = mean_variance_axis(X_csr, axis=1)
-    assert_array_almost_equal(X_means, np.mean(X, axis=1))
-    assert_array_almost_equal(X_vars, np.var(X, axis=1))
-    X_means, X_vars = mean_variance_axis(X_csc, axis=1)
-    assert_array_almost_equal(X_means, np.mean(X, axis=1))
-    assert_array_almost_equal(X_vars, np.var(X, axis=1))
-    assert_raises(TypeError, mean_variance_axis, X_lil, axis=1)
+    for input_dtype, output_dtype in expected_dtypes:
+        X_test = X.astype(input_dtype)
+        for X_sparse in (X_csr, X_csc):
+            X_sparse = X_sparse.astype(input_dtype)
+            X_means, X_vars = mean_variance_axis(X_sparse, axis=0)
+            assert_equal(X_means.dtype, output_dtype)
+            assert_equal(X_vars.dtype, output_dtype)
+            assert_array_almost_equal(X_means, np.mean(X_test, axis=0))
+            assert_array_almost_equal(X_vars, np.var(X_test, axis=0))
 
 
 def test_incr_mean_variance_axis():
@@ -132,34 +126,25 @@ def test_incr_mean_variance_axis():
         X = np.vstack(data_chunks)
         X_lil = sp.lil_matrix(X)
         X_csr = sp.csr_matrix(X_lil)
-        X_means, X_vars = mean_variance_axis(X_csr, axis)
-        X_means_incr, X_vars_incr, n_incr = \
-            incr_mean_variance_axis(X_csr, axis, last_mean, last_var, last_n)
-        assert_array_almost_equal(X_means, X_means_incr)
-        assert_array_almost_equal(X_vars, X_vars_incr)
-        assert_equal(X.shape[axis], n_incr)
-
         X_csc = sp.csc_matrix(X_lil)
-        X_means, X_vars = mean_variance_axis(X_csc, axis)
-        assert_array_almost_equal(X_means, X_means_incr)
-        assert_array_almost_equal(X_vars, X_vars_incr)
-        assert_equal(X.shape[axis], n_incr)
 
-        # All data but as float
-        X = X.astype(np.float32)
-        X_csr = X_csr.astype(np.float32)
-        X_means, X_vars = mean_variance_axis(X_csr, axis)
-        X_means_incr, X_vars_incr, n_incr = \
-            incr_mean_variance_axis(X_csr, axis, last_mean, last_var, last_n)
-        assert_array_almost_equal(X_means, X_means_incr)
-        assert_array_almost_equal(X_vars, X_vars_incr)
-        assert_equal(X.shape[axis], n_incr)
-
-        X_csc = X_csr.astype(np.float32)
-        X_means, X_vars = mean_variance_axis(X_csc, axis)
-        assert_array_almost_equal(X_means, X_means_incr)
-        assert_array_almost_equal(X_vars, X_vars_incr)
-        assert_equal(X.shape[axis], n_incr)
+        expected_dtypes = [(np.float32, np.float32),
+                           (np.float64, np.float64),
+                           (np.int32, np.float64),
+                           (np.int64, np.float64)]
+
+        for input_dtype, output_dtype in expected_dtypes:
+            for X_sparse in (X_csr, X_csc):
+                X_sparse = X_sparse.astype(input_dtype)
+                X_means, X_vars = mean_variance_axis(X_sparse, axis)
+                X_means_incr, X_vars_incr, n_incr = \
+                    incr_mean_variance_axis(X_sparse, axis, last_mean,
+                                            last_var, last_n)
+                assert_equal(X_means_incr.dtype, output_dtype)
+                assert_equal(X_vars_incr.dtype, output_dtype)
+                assert_array_almost_equal(X_means, X_means_incr)
+                assert_array_almost_equal(X_vars, X_vars_incr)
+                assert_equal(X.shape[axis], n_incr)
 
 
 def test_mean_variance_illegal_axis():
