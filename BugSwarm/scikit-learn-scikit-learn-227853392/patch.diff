diff --git a/sklearn/manifold/t_sne.py b/sklearn/manifold/t_sne.py
index 83d42c444f..b31f34d9ee 100755
--- a/sklearn/manifold/t_sne.py
+++ b/sklearn/manifold/t_sne.py
@@ -441,7 +441,7 @@ def trustworthiness(X, X_embedded, n_neighbors=5, precomputed=False):
     .. math::
 
         T(k) = 1 - \frac{2}{nk (2n - 3k - 1)} \sum^n_{i=1}
-            \sum_{j \in U^{(k)}_i (r(i, j) - k)}
+            \sum_{j \in U^{(k)}_i} (r(i, j) - k)
 
     where :math:`r(i, j)` is the rank of the embedded datapoint j
     according to the pairwise distances between the embedded datapoints,
diff --git a/sklearn/preprocessing/discretization.py b/sklearn/preprocessing/discretization.py
index 6058d5ae55..e2caa60e73 100755
--- a/sklearn/preprocessing/discretization.py
+++ b/sklearn/preprocessing/discretization.py
@@ -8,6 +8,7 @@
 
 from sklearn.base import BaseEstimator, TransformerMixin
 from sklearn.preprocessing.data import _transform_selected
+from sklearn.utils.fixes import isclose
 from sklearn.utils.validation import (
     check_array,
     check_is_fitted,
@@ -80,13 +81,13 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):
 
     Notes
     -----
-    Bin edges for feature `i` are defined as
+    Bin edges for feature ``i`` are defined as::
 
-    ```
-    np.concatenate([
-        -np.inf, offset_[i] + bin_width_[i] * np.arange(1, n_bins_[i]), np.inf
-    ])
-    ```
+      np.concatenate([
+        -np.inf,
+        offset_[i] + bin_width_[i] * np.arange(1, n_bins_[i]),
+        np.inf
+      ])
     """
 
     def __init__(self, n_bins=2, ignored_features=None):
@@ -114,9 +115,9 @@ def fit(self, X, y=None):
                                                n_features)
         self.transformed_features_ = np.delete(np.arange(n_features), ignored)
 
-        min = np.min(X, axis=0)
-        min[ignored] = 0
-        self.offset_ = min
+        offset = np.min(X, axis=0)
+        offset[ignored] = 0
+        self.offset_ = offset
 
         n_bins = self._check_n_bins(self.n_bins, n_features, ignored)
         n_bins[ignored] = 0
@@ -208,7 +209,7 @@ def _transform(self, X):
         # numeric instability. For these values, after normalizing into
         # [-1, n_bins] range, add 0.5 so they are binned correctly.
         with np.errstate(divide='ignore', invalid='ignore'):
-            needs_correction = np.isclose(np.mod(X, bin_width), bin_width)
+            needs_correction = isclose(np.mod(X, bin_width), bin_width)
             X /= bin_width
         X[needs_correction] += 0.5
         np.floor(X, out=X)
diff --git a/sklearn/utils/fixes.py b/sklearn/utils/fixes.py
index d789d5f525..0afb52ef03 100755
--- a/sklearn/utils/fixes.py
+++ b/sklearn/utils/fixes.py
@@ -207,6 +207,50 @@ def partition(a, kth, axis=-1, kind='introselect', order=None):
 
 
 if np_version < (1, 7):
+    # numpy.isclose was introduced in v 1.7.0
+    def isclose(a, b, rtol=1.e-5, atol=1.e-8, equal_nan=False):
+        def within_tol(x, y, atol, rtol):
+            with np.errstate(invalid='ignore'):
+                result = np.less_equal(abs(x-y), atol + rtol * abs(y))
+            if np.isscalar(a) and np.isscalar(b):
+                result = bool(result)
+            return result
+
+        x = np.array(a, copy=False, subok=True, ndmin=1)
+        y = np.array(b, copy=False, subok=True, ndmin=1)
+
+        # Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).
+        # This will cause casting of x later. Also, make sure to allow
+        # subclasses (e.g., for numpy.ma).
+        dt = np.core.multiarray.result_type(y, 1.)
+        y = np.array(y, dtype=dt, copy=False, subok=True)
+
+        xfin = np.isfinite(x)
+        yfin = np.isfinite(y)
+        if xfin.all() and yfin.all():
+            return within_tol(x, y, atol, rtol)
+        else:
+            finite = xfin & yfin
+            cond = np.zeros_like(finite, subok=True)
+            # Because we're using boolean indexing, x & y must be the same
+            # shape. Ideally, we'd just do x, y = broadcast_arrays(x, y). It's
+            # in lib.stride_tricks, though, so we can't import it here.
+            x = x * np.ones_like(cond)
+            y = y * np.ones_like(cond)
+            # Avoid subtraction with infinite/nan values...
+            cond[finite] = within_tol(x[finite], y[finite], atol, rtol)
+            # Check for equality of infinite values...
+            cond[~finite] = (x[~finite] == y[~finite])
+            if equal_nan:
+                # Make NaN == NaN
+                both_nan = np.isnan(x) & np.isnan(y)
+                cond[both_nan] = both_nan[both_nan]
+
+            if np.isscalar(a) and np.isscalar(b):
+                return bool(cond)
+            else:
+                return cond
+
     # Prior to 1.7.0, np.frombuffer wouldn't work for empty first arg.
     def frombuffer_empty(buf, dtype):
         if len(buf) == 0:
@@ -215,6 +259,7 @@ def frombuffer_empty(buf, dtype):
             return np.frombuffer(buf, dtype=dtype)
 else:
     frombuffer_empty = np.frombuffer
+    isclose = np.isclose
 
 
 if np_version < (1, 8):
