diff --git a/doc/index.rst b/doc/index.rst
index f855328e..565c0967 100644
--- a/doc/index.rst
+++ b/doc/index.rst
@@ -60,3 +60,5 @@ Module reference
    dump
    load
    hash
+   shelve
+   shelve_mmap
diff --git a/joblib/__init__.py b/joblib/__init__.py
index ba5a1b87..e4a741d1 100644
--- a/joblib/__init__.py
+++ b/joblib/__init__.py
@@ -121,9 +121,10 @@
 from .parallel import register_parallel_backend
 from .parallel import parallel_backend
 from .parallel import effective_n_jobs
+from .shelf import shelve, shelve_mmap
 
 
 __all__ = ['Memory', 'MemorizedResult', 'PrintTime', 'Logger', 'hash', 'dump',
            'load', 'Parallel', 'delayed', 'cpu_count', 'effective_n_jobs',
            'register_parallel_backend', 'parallel_backend',
-           'register_store_backend']
+           'register_store_backend', 'shelve', 'shelve_mmap']
diff --git a/joblib/memory.py b/joblib/memory.py
index 0f005dd3..fcae7714 100644
--- a/joblib/memory.py
+++ b/joblib/memory.py
@@ -741,21 +741,11 @@ def __repr__(self):
                                                      self.store_backend,))
 
 
-###############################################################################
-# class `Memory`
-###############################################################################
-class Memory(Logger):
-    """ A context object for caching a function's return value each time it
-        is called with the same input arguments.
-
-        All values are cached on the filesystem, in a deep directory
-        structure.
+class StoreBase(Logger):
+    """ Base class for context caching objects.
 
         see :ref:`memory_reference`
     """
-    # ------------------------------------------------------------------------
-    # Public interface
-    # ------------------------------------------------------------------------
 
     def __init__(self, location=None, backend='local', cachedir=None,
                  mmap_mode=None, compress=False, verbose=1, bytes_limit=None,
@@ -829,14 +819,66 @@ def __init__(self, location=None, backend='local', cachedir=None,
                               "cachedir value will be ignored.",
                               DeprecationWarning, stacklevel=2)
 
-        if isinstance(location, _basestring):
-            location = os.path.join(location, 'joblib')
-
         self.store_backend = _store_backend_factory(
-            backend, location, verbose=self._verbose,
-            backend_options=dict(compress=compress, mmap_mode=mmap_mode,
+            backend, self._location(location), verbose=self._verbose,
+            backend_options=dict(compress=compress,
+                                 mmap_mode=mmap_mode,
                                  **backend_options))
 
+    # ------------------------------------------------------------------------
+    # Public interface
+    # ------------------------------------------------------------------------
+
+    def clear(self, warn=True):
+        """Erase the complete cache directory."""
+        if warn:
+            self.warn('Flushing completely the cache')
+        if self.store_backend is not None:
+            self.store_backend.clear()
+
+    # ------------------------------------------------------------------------
+    # Private `object` interface
+    # ------------------------------------------------------------------------
+
+    def __repr__(self):
+        return '{0}(location={1})'.format(
+            self.__class__.__name__, (repr(None) if self.store_backend is None
+                                      else repr(self.store_backend)))
+
+    def __reduce__(self):
+        """ We don't store the timestamp when pickling, to avoid the hash
+            depending from it.
+            In addition, when unpickling, we run the __init__
+        """
+        # We need to remove 'joblib' from the end of cachedir
+        location = (repr(self.store_backend)[:-7]
+                    if self.store_backend is not None else None)
+        compress = self.store_backend.compress \
+            if self.store_backend is not None else False
+        return (self.__class__, (location, self.backend, self.mmap_mode,
+                                 compress, self._verbose))
+
+    def _location(self, location):
+        if isinstance(location, _basestring):
+            return os.path.join(location, self._root)
+        return location
+
+
+###############################################################################
+# class `Memory`
+###############################################################################
+class Memory(StoreBase):
+    """ A context object for caching a function's return value each time it
+        is called with the same input arguments.
+
+        All values are cached on the filesystem, in a deep directory
+        structure.
+
+        see :ref:`memory_reference`
+    """
+
+    _root = 'joblib'  # We don't want to break existing memory cache
+
     def cache(self, func=None, ignore=None, verbose=None, mmap_mode=False):
         """ Decorates the given function func to only compute its return
             value for input arguments not cached on disk.
@@ -880,19 +922,6 @@ def cache(self, func=None, ignore=None, verbose=None, mmap_mode=False):
                              ignore=ignore, verbose=verbose,
                              timestamp=self.timestamp)
 
-    def clear(self, warn=True):
-        """ Erase the complete cache directory.
-        """
-        if warn:
-            self.warn('Flushing completely the cache')
-        if self.store_backend is not None:
-            self.store_backend.clear()
-
-    def reduce_size(self):
-        """Remove cache elements to make cache size fit in ``bytes_limit``."""
-        if self.bytes_limit is not None and self.store_backend is not None:
-            self.store_backend.reduce_store_size(self.bytes_limit)
-
     def eval(self, func, *args, **kwargs):
         """ Eval function func with arguments `*args` and `**kwargs`,
             in the context of the memory.
@@ -906,24 +935,7 @@ def eval(self, func, *args, **kwargs):
             return func(*args, **kwargs)
         return self.cache(func)(*args, **kwargs)
 
-    # ------------------------------------------------------------------------
-    # Private `object` interface
-    # ------------------------------------------------------------------------
-
-    def __repr__(self):
-        return '{0}(location={1})'.format(
-            self.__class__.__name__, (repr(None) if self.store_backend is None
-                                      else repr(self.store_backend)))
-
-    def __reduce__(self):
-        """ We don't store the timestamp when pickling, to avoid the hash
-            depending from it.
-            In addition, when unpickling, we run the __init__
-        """
-        # We need to remove 'joblib' from the end of cachedir
-        location = (repr(self.store_backend)[:-7]
-                    if self.store_backend is not None else None)
-        compress = self.store_backend.compress \
-            if self.store_backend is not None else False
-        return (self.__class__, (location, self.backend, self.mmap_mode,
-                                 compress, self._verbose))
+    def reduce_size(self):
+        """Remove cache elements to make cache size fit in ``bytes_limit``."""
+        if self.bytes_limit is not None and self.store_backend is not None:
+            self.store_backend.reduce_store_size(self.bytes_limit)
diff --git a/joblib/shelf.py b/joblib/shelf.py
new file mode 100644
index 00000000..c684415e
--- /dev/null
+++ b/joblib/shelf.py
@@ -0,0 +1,226 @@
+"""
+A context object for temporary shelving arbitrary objects in a data store.
+"""
+
+# Copyright (c) 2018 Inria
+# License: BSD Style, 3 clauses.
+
+import os
+import tempfile
+import weakref
+import shutil
+
+from uuid import uuid4
+
+from .memory import StoreBase
+
+_active_shelf = None
+_active_shelf_mmap = None
+
+
+class JoblibShelfFuture():
+    """A Future-like object for keeping a reference on shelved objects."""
+
+    def __init__(self, data_id, shelf):
+        self._data_id = data_id
+        self._shelf = shelf
+
+    def result(self):
+        """Reloads the data from store and returns it.
+
+        Returns
+        -------
+            The reloaded data.
+        """
+        return self._shelf.store_backend.load_item([self._data_id])
+
+
+###############################################################################
+# class `JoblibShelf`
+###############################################################################
+class JoblibShelf(StoreBase):
+    """A context object for shelving an arbitrary object in a store."""
+
+    # The root of the shelf storage is built with current Python interpreter
+    # process ID
+    _root = 'joblib-shelf-{}'.format(os.getpid())
+    _futures = set()
+
+    def put(self, data):
+        """Put data on the shelf.
+
+        Parameters
+        ----------
+        data: any
+            The data to put on the shelf.
+
+        Returns:
+        --------
+            A future on the shelved data.
+
+        """
+        data_id = uuid4().hex
+        self.store_backend.dump_item([data_id], data)
+
+        future = JoblibShelfFuture(data_id, self)
+
+        def _collect(ref):
+            self._on_collect(data_id)
+        self._futures.add(weakref.ref(future, _collect))
+        return future
+
+    def _on_collect(self, data_id):
+        self.store_backend.clear_location(
+            os.path.join(self.store_backend.location, data_id))
+
+    def __del__(self):
+        # TODO: FIX self.clear()
+        shutil.rmtree(self.store_backend.location)
+
+
+def shelve(input_object):
+    """Shelves an arbitrary object and returns a future on it.
+
+    The input object can then be deleted at any time by the script to save
+    memory. The future, a light-weight object, can be used later to reload the
+    initial object.
+
+    During the life of the future, the input object is kept written on a store
+    (by default a file on a disk).
+    To retrieve the original input object later, use the ``result`` method of
+    the returned future, this call will reload the initial data from the disk
+    and return it.
+
+    Parameters
+    ----------
+    input_object: any
+        The input object to shelve.
+
+    Returns
+    -------
+        A future referencing the shelved object
+
+    Notes
+    -----
+        The content of the shelved object is effectively deleted from the store
+        only when no more reference on its future no longer exists.
+        When the interpreter process exits, all shelved objects are deleted
+        from the store.
+
+    Examples
+    --------
+
+        A simple example:
+
+        >>> from joblib import shelve
+        >>> input = "The object on the shelf"
+        >>> future = shelve(input)
+        >>> del input  # input object can now be removed from memory
+        >>> future  #doctest: +SKIP
+        <joblib.shelf.JoblibShelfFuture at 0x7fc15fad7a90>
+        >>> print(future.result())
+        The object on the shelf
+
+        Only the 'threading' backend of Parallel can be used with shelve:
+
+        >>> from joblib import shelve, Parallel, delayed
+        >>> def func(future):
+        ...     return future.result()**2
+        >>> r = Parallel(n_jobs=10, backend='threading')(
+        ...              delayed(func)(shelve(i)) for i in range(10))
+        >>> r
+        [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
+
+    """
+    global _active_shelf
+    if _active_shelf is None:
+        tmp_folder = os.environ.get('JOBLIB_TEMP_FOLDER',
+                                    tempfile.gettempdir())
+        _active_shelf = JoblibShelf(tmp_folder)
+
+    return _active_shelf.put(input_object)
+
+
+def shelve_mmap(input_array):
+    """Shelves an arbitrary object and returns a future.
+
+    The input array can then be deleted at any time to save memory. The
+    future, a light-weight object, can be used later to reload the initial
+    array.
+
+    The future returns a memmap only for input numpy arrays. On other types of
+    objects, it returns the initial object.
+
+    During the life of the future the content of the array is kept written on a
+    store (by default a file on a disk).
+    To retrieve the memmapped input array later, use the ``result`` method of
+    the future, this call will return a numpy memmap on the input array.
+
+    Parameters
+    ----------
+    input_array: any
+        The input numpy array to shelve.
+
+    Returns
+    -------
+        A future on the shelved array.
+
+    Notes
+    -----
+        The content of the shelved array is effectively deleted from the store
+        only when reference on its future no longer exists.
+        When the interpreter process exits, all shelved objects are deleted
+        from the store.
+
+    Examples
+    --------
+
+        A simple example:
+
+        >>> import numpy as np
+        >>> from joblib import shelve_mmap
+        >>> array = np.ones((10, 10))
+        >>> future = shelve_mmap(array)
+        >>> del array  # input array can now be removed from memory
+        >>> future  #doctest: +SKIP
+        <joblib.shelf.JoblibShelfFuture at 0x7fc15f1e7be0>
+        >>> future.result()
+        memmap([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
+                [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])
+
+        Only the 'threading' backend of Parallel can be used with shelve:
+
+        >>> import numpy as np
+        >>> from joblib import shelve, Parallel, delayed
+        >>> def f(future):
+        ...     return np.mean(future.result())
+        >>> array = np.random.random((10, 10))
+        >>> Parallel(n_jobs=10, backend='threading')(
+        ...          delayed(f)(shelve(i)) for i in array))  #doctest: +SKIP
+        [0.5224197461540009,
+         0.5529565351274045,
+         0.5685303248444292,
+         0.47138560341416086,
+         0.5606711476847496,
+         0.4467337319232188,
+         0.37955295459961974,
+         0.39589095750523356,
+         0.46805210613397985,
+         0.4432485635619462]
+
+    """
+    global _active_shelf_mmap
+    if _active_shelf_mmap is None:
+        tmp_folder = os.environ.get('JOBLIB_TEMP_FOLDER',
+                                    tempfile.gettempdir())
+        _active_shelf_mmap = JoblibShelf(tmp_folder, mmap_mode='r')
+
+    return _active_shelf_mmap.put(input_array)
diff --git a/joblib/test/test_shelf.py b/joblib/test/test_shelf.py
new file mode 100644
index 00000000..a2fecdba
--- /dev/null
+++ b/joblib/test/test_shelf.py
@@ -0,0 +1,149 @@
+"""
+Test the shelf module.
+"""
+
+# Copyright (c) 2018 Inria
+# License: BSD Style, 3 clauses.
+
+import os
+import os.path
+import gc
+
+from joblib.shelf import JoblibShelf, shelve, shelve_mmap
+from joblib.test.common import with_numpy, np
+from joblib.testing import parametrize
+
+
+@parametrize('data', [42, 2018.01, "some data",
+                      {'a': 1, 'b': 2}, [1, 2, 3, 4]])
+def test_shelve_with_standard_data(data):
+    future = shelve(data)
+    assert future.result() == data
+
+
+@with_numpy
+@parametrize('data', [42, 2018.01, "some data",
+                      {'a': 1, 'b': 2}, [1, 2, 3, 4]])
+def test_shelve_mmap_with_standard_data(data):
+    # no memmaping is possible with standard types
+    future = shelve_mmap(data)
+    assert not isinstance(future.result(), np.memmap)
+    assert future.result() == data
+
+
+@with_numpy
+def test_shelve_with_numpy():
+    data = np.random.random((5, 5))
+    future = shelve(data)
+    data_result = future.result()
+    np.testing.assert_array_equal(data_result, data)
+
+
+@with_numpy
+def test_shelve_mmap():
+    data = np.random.random((5, 5))
+    future = shelve_mmap(data)
+    data_result = future.result()
+    assert isinstance(data_result, np.memmap)
+
+
+@parametrize('data', [42, 2018.01, "some data",
+                      {'a': 1, 'b': 2}, [1, 2, 3, 4]])
+def test_shelved_data_directory(tmpdir, data):
+    shelf = JoblibShelf(location=tmpdir.strpath, verbose=10)
+    shelf_path = shelf.store_backend.location
+    future1 = shelf.put(data)
+    data_dir_path = os.path.join(shelf.store_backend.location,
+                                 future1._data_id)
+
+    # Check pickle file and parent directory exist (with the right name)
+    assert os.path.basename(data_dir_path) == future1._data_id
+    assert os.path.exists(data_dir_path)
+    assert os.path.exists(os.path.join(data_dir_path, 'output.pkl'))
+
+    # Check input data is correctly reloaded
+    assert future1.result() == data
+
+    # Add a second reference of the first future
+    future2 = future1
+
+    # Deleting future1 should not remove the cached directory
+    del future1
+    gc.collect()
+    assert os.path.exists(data_dir_path)
+
+    # Deleting future2 should remove the cached directory since it's the last
+    # reference on the initial future
+    del future2
+    gc.collect()
+    assert not os.path.exists(data_dir_path)
+
+    # Shelve the input data a second time
+    future3 = shelf.put(data)
+    data_dir_path = os.path.join(shelf.store_backend.location,
+                                 future3._data_id)
+
+    # Deleting the shelf should not remove the data on disk because the future
+    # still exists and have a reference on the shelf
+    del shelf
+    gc.collect()
+    assert os.path.exists(shelf_path)
+    assert os.path.exists(data_dir_path)
+
+    # Deleting the future now should remove the data on disk
+    del future3
+    gc.collect()
+    print(shelf_path)
+    assert not os.path.exists(shelf_path)
+    assert not os.path.exists(data_dir_path)
+
+
+@with_numpy
+def test_shelved_array_directory(tmpdir):
+    data = np.random.random((5, 5))
+    shelf = JoblibShelf(location=tmpdir.strpath, verbose=10)
+    shelf_path = shelf.store_backend.location
+    future1 = shelf.put(data)
+    data_dir_path = os.path.join(shelf.store_backend.location,
+                                 future1._data_id)
+
+    # Check pickle file and parent directory exist (with the right name)
+    assert os.path.basename(data_dir_path) == future1._data_id
+    assert os.path.exists(data_dir_path)
+    assert os.path.exists(os.path.join(data_dir_path, 'output.pkl'))
+
+    # Check input array is correctly reloaded
+    np.testing.assert_array_equal(future1.result(), data)
+
+    # Add a second reference of the first future
+    future2 = future1
+
+    # Deleting future1 should not remove the cached directory
+    del future1
+    gc.collect()
+    assert os.path.exists(data_dir_path)
+
+    # Deleting future2 should remove the cached directory since it's the last
+    # reference on the initial future
+    del future2
+    gc.collect()
+    assert not os.path.exists(data_dir_path)
+
+    # Shelve the input data a second time
+    future3 = shelf.put(data)
+    data_dir_path = os.path.join(shelf.store_backend.location,
+                                 future3._data_id)
+
+    # Deleting the shelf should not remove the data on disk because the future
+    # still exists and have a reference on the shelf
+    del shelf
+    gc.collect()
+    assert os.path.exists(shelf_path)
+    assert os.path.exists(data_dir_path)
+
+    # Deleting the future now should remove the data on disk
+    del future3
+    gc.collect()
+    print(shelf_path)
+    assert not os.path.exists(shelf_path)
+    assert not os.path.exists(data_dir_path)
