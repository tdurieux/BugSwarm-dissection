diff --git a/sklearn/mixture/gmm.py b/sklearn/mixture/gmm.py
index 001585c213..f064b2b9fd 100755
--- a/sklearn/mixture/gmm.py
+++ b/sklearn/mixture/gmm.py
@@ -211,7 +211,7 @@ class GaussianMixtureModel(DensityMixin, BaseEstimator):
     ...                       10 + np.random.randn(300, 1)))
     >>> g.fit(obs) # doctest: +NORMALIZE_WHITESPACE
     GaussianMixtureModel(covariance_type='diag', init_params='wmc',
-        min_covar=0.001, n_components=2, n_init=1, n_iter=100, params='wmc',
+        min_covar=0.001, n_components=2, n_init=1, n_iter=100, params=None,
         random_state=None, thresh=None, tol=0.001, verbose=0)
     >>> np.round(g.weights_, 2)
     array([ 0.75,  0.25])
@@ -229,7 +229,7 @@ class GaussianMixtureModel(DensityMixin, BaseEstimator):
     >>> # same), this time with an even split between the two modes.
     >>> g.fit(20 * [[0]] +  20 * [[10]]) # doctest: +NORMALIZE_WHITESPACE
     GaussianMixtureModel(covariance_type='diag', init_params='wmc',
-        min_covar=0.001, n_components=2, n_init=1, n_iter=100, params='wmc',
+        min_covar=0.001, n_components=2, n_init=1, n_iter=100, params=None,
         random_state=None, thresh=None, tol=0.001, verbose=0)
     >>> np.round(g.weights_, 2)
     array([ 0.5,  0.5])
@@ -238,7 +238,7 @@ class GaussianMixtureModel(DensityMixin, BaseEstimator):
 
     def __init__(self, n_components=1, covariance_type='diag',
                  random_state=None, thresh=None, tol=1e-3, min_covar=1e-3,
-                 n_iter=100, n_init=1, params='wmc', init_params='wmc',
+                 n_iter=100, n_init=1, params=None, init_params='wmc',
                  verbose=0):
         if thresh is not None:
             warnings.warn("'thresh' has been replaced by 'tol' in 0.16 "
@@ -261,7 +261,12 @@ def __init__(self, n_components=1, covariance_type='diag',
                              covariance_type)
 
         if n_init < 1:
-            raise ValueError('GMM estimation requires at least one run')
+            raise ValueError('The estimation requires at least one run')
+
+        if params is not None:
+            warnings.warn("The 'params' has been deprecated in 0.17 "
+                          "and will be removed in 0.19.",
+                          DeprecationWarning)
 
         self.weights_ = np.ones(self.n_components) / self.n_components
 
@@ -598,11 +603,11 @@ def _do_mstep(self, X, responsibilities, params, min_covar=0):
         weighted_X_sum = np.dot(responsibilities.T, X)
         inverse_weights = 1.0 / (weights[:, np.newaxis] + 10 * EPS)
 
-        if 'w' in params:
+        if params is None or 'w' in params:
             self.weights_ = (weights / (weights.sum() + 10 * EPS) + EPS)
-        if 'm' in params:
+        if params is None or 'm' in params:
             self.means_ = weighted_X_sum * inverse_weights
-        if 'c' in params:
+        if params is None or 'c' in params:
             covar_mstep_func = _covar_mstep_funcs[self.covariance_type]
             self.covars_ = covar_mstep_func(
                 self, X, responsibilities, weighted_X_sum, inverse_weights,
@@ -916,7 +921,7 @@ class GMM(GaussianMixtureModel):
     ...                       10 + np.random.randn(300, 1)))
     >>> g.fit(obs) # doctest: +NORMALIZE_WHITESPACE
     GMM(covariance_type='diag', init_params='wmc', min_covar=0.001,
-            n_components=2, n_init=1, n_iter=100, params='wmc',
+            n_components=2, n_init=1, n_iter=100, params=None,
             random_state=None, thresh=None, tol=0.001, verbose=0)
     >>> np.round(g.weights_, 2)
     array([ 0.75,  0.25])
@@ -934,7 +939,7 @@ class GMM(GaussianMixtureModel):
     >>> # same), this time with an even split between the two modes.
     >>> g.fit(20 * [[0]] +  20 * [[10]]) # doctest: +NORMALIZE_WHITESPACE
     GMM(covariance_type='diag', init_params='wmc', min_covar=0.001,
-            n_components=2, n_init=1, n_iter=100, params='wmc',
+            n_components=2, n_init=1, n_iter=100, params=None,
             random_state=None, thresh=None, tol=0.001, verbose=0)
     >>> np.round(g.weights_, 2)
     array([ 0.5,  0.5])
@@ -950,12 +955,6 @@ def __init__(self, n_components=1, covariance_type='diag',
                       "will be removed in 0.19. "
                       "Use the 'GaussianMixtureModel' class instead.",
                       DeprecationWarning)
-        if params is not None:
-            warnings.warn("The 'params' has been deprecated in 0.17 "
-                          "and will be removed in 0.19.",
-                          DeprecationWarning)
-        else:
-            params = 'wmc'
         super(GMM, self).__init__(n_components, covariance_type,
                                   random_state, thresh, tol, min_covar,
                                   n_iter, n_init, params, init_params, verbose)
