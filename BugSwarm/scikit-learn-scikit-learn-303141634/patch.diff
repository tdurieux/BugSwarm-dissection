diff --git a/.codecov.yml b/.codecov.yml
index 78a6c76891c5..2f73002107a0 100644
--- a/.codecov.yml
+++ b/.codecov.yml
@@ -1,4 +1,4 @@
-comment: off
+comment: false
 
 coverage:
   status:
diff --git a/build_tools/circle/build_doc.sh b/build_tools/circle/build_doc.sh
index b3f785254c2a..0be1dda05f04 100755
--- a/build_tools/circle/build_doc.sh
+++ b/build_tools/circle/build_doc.sh
@@ -109,7 +109,9 @@ conda update --yes --quiet conda
 conda create -n $CONDA_ENV_NAME --yes --quiet python numpy scipy \
   cython nose coverage matplotlib sphinx=1.6.2 pillow
 source activate testenv
-pip install sphinx-gallery numpydoc
+pip install sphinx-gallery
+# Use numpydoc master (for now)
+pip install git+https://github.com/numpy/numpydoc
 
 # Build and install scikit-learn in dev mode
 python setup.py develop
diff --git a/build_tools/travis/flake8_diff.sh b/build_tools/travis/flake8_diff.sh
index 84495b339a92..9781f7e6a5cc 100755
--- a/build_tools/travis/flake8_diff.sh
+++ b/build_tools/travis/flake8_diff.sh
@@ -137,12 +137,9 @@ check_files() {
 if [[ "$MODIFIED_FILES" == "no_match" ]]; then
     echo "No file outside sklearn/externals and doc/sphinxext/sphinx_gallery has been modified"
 else
-    # Default ignore PEP8 violations are from flake8 3.3.0
-    DEFAULT_IGNORED_PEP8=E121,E123,E126,E226,E24,E704,W503,W504
-    check_files "$(echo "$MODIFIED_FILES" | grep -v ^examples)" \
-           --ignore $DEFAULT_IGNORED_PEP8
-    # Examples are allowed to not have imports at top of file
+
+    check_files "$(echo "$MODIFIED_FILES" | grep -v ^examples)"
     check_files "$(echo "$MODIFIED_FILES" | grep ^examples)" \
-           --ignore $DEFAULT_IGNORED_PEP8 --ignore E402
+        --config ./examples/.flake8
 fi
 echo -e "No problem detected by flake8\n"
diff --git a/conftest.py b/conftest.py
index 25275e11aa1d..c4bed49c6df7 100644
--- a/conftest.py
+++ b/conftest.py
@@ -9,6 +9,6 @@
 # the doctests pass
 import numpy as np
 try:
-    np.set_printoptions(sign='legacy')
+    np.set_printoptions(legacy=True)
 except TypeError:
     pass
diff --git a/doc/datasets/index.rst b/doc/datasets/index.rst
index f9b400ba83e4..1316d596f50f 100644
--- a/doc/datasets/index.rst
+++ b/doc/datasets/index.rst
@@ -64,7 +64,7 @@ require to download any file from some external website.
    load_breast_cancer
 
 These datasets are useful to quickly illustrate the behavior of the
-various algorithms implemented in the scikit. They are however often too
+various algorithms implemented in scikit-learn. They are however often too
 small to be representative of real world machine learning tasks.
 
 .. _sample_images:
@@ -72,7 +72,7 @@ small to be representative of real world machine learning tasks.
 Sample images
 =============
 
-The scikit also embed a couple of sample JPEG images published under Creative
+Scikit-learn also embed a couple of sample JPEG images published under Creative
 Commons license by their authors. Those image can be useful to test algorithms
 and pipeline on 2D data.
 
diff --git a/doc/developers/contributing.rst b/doc/developers/contributing.rst
index 72e68bc45875..89875a480fa1 100644
--- a/doc/developers/contributing.rst
+++ b/doc/developers/contributing.rst
@@ -871,6 +871,8 @@ from high-level questions to a more detailed check-list.
   :ref:`contribute_documentation` section for more details), and are the plots
   instructive?
 
+:ref:`saved_replies` includes some frequent comments that reviewers may make.
+
 
 APIs of scikit-learn objects
 ============================
diff --git a/doc/developers/maintainer.rst b/doc/developers/maintainer.rst
index ff639d55009b..c645a5c71dbe 100644
--- a/doc/developers/maintainer.rst
+++ b/doc/developers/maintainer.rst
@@ -1,10 +1,10 @@
 Maintainer / core-developer information
 ========================================
 
-For more information see https://github.com/scikit-learn/scikit-learn/wiki/How-to-make-a-release
-
 Making a release
 ------------------
+For more information see https://github.com/scikit-learn/scikit-learn/wiki/How-to-make-a-release
+
 
 1. Update docs:
 
@@ -55,3 +55,27 @@ Making a release
 
 
 7. FOR FINAL RELEASE: Update the release date in What's New
+
+Travis Cron jobs
+----------------
+
+From `<https://docs.travis-ci.com/user/cron-jobs>`_: Travis CI cron jobs work
+similarly to the cron utility, they run builds at regular scheduled intervals
+independently of whether any commits were pushed to the repository. Cron jobs
+always fetch the most recent commit on a particular branch and build the project
+at that state. Cron jobs can run daily, weekly or monthly, which in practice
+means up to an hour after the selected time span, and you cannot set them to run
+at a specific time.
+
+For scikit-learn, Cron jobs are used for builds that we do not want to run in
+each PR. As an example the build with the dev versions of numpy and scipy is
+run as a Cron job. Most of the time when this numpy-dev build fail, it is
+related to a numpy change and not a scikit-learn one, so it would not make sense
+to blame the PR author for the Travis failure.
+
+The definition of what gets run in the Cron job is done in the .travis.yml
+config file, exactly the same way as the other Travis jobs. We use a ``if: type
+= cron`` filter in order for the build to be run only in Cron jobs.
+
+The branch targetted by the Cron job and the frequency of the Cron job is set
+via the web UI at https://www.travis-ci.org/scikit-learn/scikit-learn/settings.
diff --git a/doc/developers/performance.rst b/doc/developers/performance.rst
index 692e7ca1f99a..d3d6204ec328 100644
--- a/doc/developers/performance.rst
+++ b/doc/developers/performance.rst
@@ -94,7 +94,7 @@ loads and prepare you data and then use the IPython integrated profiler
 for interactively exploring the relevant part for the code.
 
 Suppose we want to profile the Non Negative Matrix Factorization module
-of the scikit. Let us setup a new IPython session and load the digits
+of scikit-learn. Let us setup a new IPython session and load the digits
 dataset and as in the :ref:`sphx_glr_auto_examples_classification_plot_digits_classification.py` example::
 
   In [1]: from sklearn.decomposition import NMF
diff --git a/doc/developers/tips.rst b/doc/developers/tips.rst
index bbf46965d379..57b1ddb243a5 100644
--- a/doc/developers/tips.rst
+++ b/doc/developers/tips.rst
@@ -72,6 +72,126 @@ following tricks can make debugging easier:
 
          pytest --pdbcls=IPython.terminal.debugger:TerminalPdb --capture no
 
+.. _saved_replies:
+
+Standard replies for reviewing
+------------------------------
+
+It may be helpful to store some of these in GitHub's `saved
+replies <https://github.com/settings/replies/>`_ for reviewing:
+
+.. highlight:: none
+
+..
+    Note that putting this content on a single line in a literal is the easiest way to make it copyable and wrapped on screen.
+
+Issue: You're welcome to update the docs
+    ::
+
+        Please feel free to offer a pull request updating the documentation if you feel it could be improved.
+
+Issue: Self-contained example for bug
+    ::
+
+        Please provide [self-contained example code](https://stackoverflow.com/help/mcve), including imports and data (if possible), so that other contributors can just run it and reproduce your issue. Ideally your example code should be minimal.
+
+Issue: Software versions
+    ::
+
+        To help diagnose your issue, could you please paste the output of:
+        ```py
+        import platform; print(platform.platform())
+        import sys; print("Python", sys.version)
+        import numpy; print("NumPy", numpy.__version__)
+        import scipy; print("SciPy", scipy.__version__)
+        import sklearn; print("Scikit-Learn", sklearn.__version__)
+        ```
+        ? Thanks.
+
+Issue: Code blocks
+    ::
+
+        Readability can be greatly improved if you [format](https://help.github.com/articles/creating-and-highlighting-code-blocks/) your code snippets and complete error messages appropriately. For example:
+
+            ```python
+            print(something)
+            ```
+        generates:
+        ```python
+        print(something)
+        ```
+        And:
+
+            ```pytb
+            Traceback (most recent call last):
+              File "<stdin>", line 1, in <module>
+            ImportError: No module named 'hello'
+            ```
+        generates:
+        ```pytb
+        Traceback (most recent call last):
+          File "<stdin>", line 1, in <module>
+        ImportError: No module named 'hello'
+        ```
+        You can edit your issue descriptions and comments at any time to improve readability. This helps maintainers a lot. Thanks!
+
+Issue/Comment: Linking to code
+    ::
+
+        Friendly advice: for clarity's sake, you can link to code like [this](https://help.github.com/articles/creating-a-permanent-link-to-a-code-snippet/).
+
+Issue/Comment: Linking to comments
+    ::
+
+        Please use links to comments, which make it a lot easier to see what you are referring to, rather than just linking to the issue. See [this](https://stackoverflow.com/questions/25163598/how-do-i-reference-a-specific-issue-comment-on-github) for more details.
+
+PR-NEW: Better description
+    ::
+
+        Thanks for the pull request! Please make the title of the PR descriptive so that we can easily recall the issue it is resolving. You should state what issue (or PR) it fixes/resolves in the description (see [here](http://scikit-learn.org/dev/developers/contributing.html#contributing-pull-requests)).
+
+PR-NEW: Fix #
+    ::
+
+        Please use "Fix #issueNumber" in your PR description (and you can do it more than once). This way the associated issue gets closed automatically when the PR is merged. For more details, look at [this](https://github.com/blog/1506-closing-issues-via-pull-requests).
+
+PR-NEW or Issue: Maintenance cost
+    ::
+
+        Every feature we include has a [maintenance cost](http://scikit-learn.org/dev/faq.html#why-are-you-so-selective-on-what-algorithms-you-include-in-scikit-learn). Our maintainers are mostly volunteers. For a new feature to be included, we need evidence that it is often useful and, ideally, [well-established](http://scikit-learn.org/dev/faq.html#what-are-the-inclusion-criteria-for-new-algorithms) in the literature or in practice. That doesn't stop you implementing it for yourself and publishing it in a separate repository, or even [scikit-learn-contrib](http://scikit-learn-contrib.github.io).
+
+PR-WIP: What's needed before merge?
+    ::
+
+        Please clarify (perhaps as a TODO list in the PR description) what work you believe still needs to be done before it can be reviewed for merge. When it is ready, please prefix the PR title with `[MRG]`.
+
+PR-WIP: Regression test needed
+    ::
+
+        Please add a [non-regression test](https://en.wikipedia.org/wiki/Non-regression_testing) that would fail at master but pass in this PR.
+
+PR-WIP: PEP8
+    ::
+
+        You have some [PEP8](https://www.python.org/dev/peps/pep-0008/) violations, whose details you can see in Travis CI. It might be worth configuring your code editor to check for such errors on the fly, so you can catch them before committing.
+
+PR-MRG: Patience
+    ::
+
+        Before merging, we generally require two core developers to agree that your pull request is desirable and ready. [Please be patient](http://scikit-learn.org/dev/faq.html#why-is-my-pull-request-not-getting-any-attention), as we mostly rely on volunteered time from busy core developers. (You are also welcome to help us out with [reviewing other PRs](http://scikit-learn.org/dev/developers/contributing.html#code-review-guidelines).)
+
+PR-MRG: Add to what's new
+    ::
+
+        Please add an entry to the change log at `doc/whats_new/v*.rst`. Like the other entries there, please reference this pull request with `:issue:` and credit yourself (and other contributors if applicable) with `:user:`.
+
+PR: Don't change unrelated
+    ::
+
+        Please do not change unrelated lines. It makes your contribution harder to review and may introduce merge conflicts to other pull requests.
+
+.. highlight:: default
+
 Debugging memory errors in Cython with valgrind
 ===============================================
 
diff --git a/doc/faq.rst b/doc/faq.rst
index fea4efa010c3..527850a8cbbe 100644
--- a/doc/faq.rst
+++ b/doc/faq.rst
@@ -86,6 +86,8 @@ arrays such as pandas DataFrame are also acceptable.
 For more information on loading your data files into these usable data 
 structures, please refer to :ref:`loading external datasets <external_datasets>`.
 
+.. _new_algorithms_inclusion_criteria:
+
 What are the inclusion criteria for new algorithms ?
 ----------------------------------------------------
 
@@ -108,9 +110,12 @@ proposed algorithm should outperform the methods that are already implemented
 in scikit-learn at least in some areas.
 
 Also note that your implementation need not be in scikit-learn to be used
-together with scikit-learn tools. You can implement your favorite algorithm in
-a scikit-learn compatible way, upload it to github and let us know. We will
-list it under :ref:`related_projects`.
+together with scikit-learn tools. You can implement your favorite algorithm
+in a scikit-learn compatible way, upload it to GitHub and let us know. We
+will be happy to list it under :ref:`related_projects`. If you already have
+a package on GitHub following the scikit-learn API, you may also be
+interested to look at `scikit-learn-contrib
+<http://scikit-learn-contrib.github.io>`_.
 
 .. _selectiveness:
 
@@ -123,8 +128,10 @@ The package relies on core developers using their free time to
 fix bugs, maintain code and review contributions.
 Any algorithm that is added needs future attention by the developers,
 at which point the original author might long have lost interest.
-Also see `this thread on the mailing list
-<https://sourceforge.net/p/scikit-learn/mailman/scikit-learn-general/thread/CAAkaFLWcBG+gtsFQzpTLfZoCsHMDv9UG5WaqT0LwUApte0TVzg@mail.gmail.com/#msg33104380>`_.
+See also :ref:`new_algorithms_inclusion_criteria`. For a great read about 
+long-term maintenance issues in open-source software, look at 
+`the Executive Summary of Roads and Bridges
+<https://www.fordfoundation.org/media/2976/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure.pdf#page=8>`_
 
 Why did you remove HMMs from scikit-learn?
 --------------------------------------------
diff --git a/doc/modules/dp-derivation.rst b/doc/modules/dp-derivation.rst
index 4509e0fa323b..0625884c279f 100644
--- a/doc/modules/dp-derivation.rst
+++ b/doc/modules/dp-derivation.rst
@@ -23,7 +23,7 @@ complex, or even more. For this reason we present here a full
 derivation of the inference algorithm and all the update and
 lower-bound equations. If you're not interested in learning how to
 derive similar algorithms yourself and you're not interested in
-changing/debugging the implementation in the scikit this document is
+changing/debugging the implementation in scikit-learn this document is
 not for you.
 
 The complexity of this implementation is linear in the number of
diff --git a/doc/modules/model_evaluation.rst b/doc/modules/model_evaluation.rst
index 9e266238f828..c7dea387e6b8 100644
--- a/doc/modules/model_evaluation.rst
+++ b/doc/modules/model_evaluation.rst
@@ -464,20 +464,19 @@ given binary ``y_true`` and ``y_pred``:
     There is no clear consensus on the definition of a balanced accuracy for the
     multiclass setting. Here are some definitions that can be found in the literature:
 
-    * Normalized class-wise accuracy average as described in [Guyon2015]_: for multi-class
-      classification problem, each sample is assigned the class with maximum prediction value.
-      The predictions are then binarized to compute the accuracy of each class on a
-      one-vs-rest fashion. The balanced accuracy is obtained by averaging the individual
-      accuracies over all classes and then normalized by the expected value of balanced
-      accuracy for random predictions (:math:`0.5` for binary classification, :math:`1/C`
-      for C-class classification problem).
-    * Macro-average recall as described in [Mosley2013]_ and [Kelleher2015]_: the recall
-      for each class is computed independently and the average is taken over all classes.
+    * Macro-average recall as described in [Mosley2013]_, [Kelleher2015]_ and [Guyon2015]_:
+      the recall for each class is computed independently and the average is taken over all classes.
+      In [Guyon2015]_, the macro-average recall is then adjusted to ensure that random predictions
+      have a score of :math:`0` while perfect predictions have a score of :math:`1`.
+      One can compute the macro-average recall using ``recall_score(average="macro")`` in :func:`recall_score`.
+    * Class balanced accuracy as described in [Mosley2013]_: the minimum between the precision
+      and the recall for each class is computed. Those values are then averaged over the total
+      number of classes to get the balanced accuracy.
+    * Balanced Accuracy as described in [Urbanowicz2015]_: the average of sensitivity and selectivity
+      is computed for each class and then averaged over total number of classes.
 
     Note that none of these different definitions are currently implemented within
-    the :func:`balanced_accuracy_score` function. However, the macro-averaged recall
-    is implemented in :func:`sklearn.metrics.recall_score`: set ``average`` parameter
-    to ``"macro"``.
+    the :func:`balanced_accuracy_score` function.
 
 .. topic:: References:
 
@@ -492,6 +491,8 @@ given binary ``y_true`` and ``y_pred``:
      Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples,
      and Case Studies <https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics>`_,
      2015.
+  .. [Urbanowicz2015] Urbanowicz R.J.,  Moore, J.H. `ExSTraCS 2.0: description and evaluation of a scalable learning
+     classifier system < https://doi.org/10.1007/s12065-015-0128-8>`_, Evol. Intel. (2015) 8: 89.
 
 .. _cohen_kappa:
 
diff --git a/doc/modules/model_persistence.rst b/doc/modules/model_persistence.rst
index 1efe4a8bcd52..d64657717ba7 100644
--- a/doc/modules/model_persistence.rst
+++ b/doc/modules/model_persistence.rst
@@ -13,7 +13,7 @@ security and maintainability issues when working with pickle serialization.
 Persistence example
 -------------------
 
-It is possible to save a model in the scikit by using Python's built-in
+It is possible to save a model in scikit-learn by using Python's built-in
 persistence model, namely `pickle <https://docs.python.org/2/library/pickle.html>`_::
 
   >>> from sklearn import svm
@@ -35,7 +35,7 @@ persistence model, namely `pickle <https://docs.python.org/2/library/pickle.html
   >>> y[0]
   0
 
-In the specific case of the scikit, it may be more interesting to use
+In the specific case of scikit-learn, it may be more interesting to use
 joblib's replacement of pickle (``joblib.dump`` & ``joblib.load``),
 which is more efficient on objects that carry large numpy arrays internally as
 is often the case for fitted scikit-learn estimators, but can only pickle to the
diff --git a/doc/presentations.rst b/doc/presentations.rst
index 8b5d3bdc897c..6fe17a69f462 100644
--- a/doc/presentations.rst
+++ b/doc/presentations.rst
@@ -37,7 +37,7 @@ Videos
   <http://videolectures.net/icml2010_varaquaux_scik/>`_ by `Gael Varoquaux`_ at
   ICML 2010
 
-    A three minute video from a very early stage of the scikit, explaining the
+    A three minute video from a very early stage of scikit-learn, explaining the
     basic idea and approach we are following.
 
 - `Introduction to statistical learning with scikit-learn <http://archive.org/search.php?query=scikit-learn>`_
diff --git a/doc/tutorial/basic/tutorial.rst b/doc/tutorial/basic/tutorial.rst
index 89600953a870..7c6058591b3e 100644
--- a/doc/tutorial/basic/tutorial.rst
+++ b/doc/tutorial/basic/tutorial.rst
@@ -209,7 +209,7 @@ example that you can run and study:
 Model persistence
 -----------------
 
-It is possible to save a model in the scikit by using Python's built-in
+It is possible to save a model in scikit-learn by using Python's built-in
 persistence model, namely `pickle <https://docs.python.org/2/library/pickle.html>`_::
 
   >>> from sklearn import svm
@@ -231,7 +231,7 @@ persistence model, namely `pickle <https://docs.python.org/2/library/pickle.html
   >>> y[0]
   0
 
-In the specific case of the scikit, it may be more interesting to use
+In the specific case of scikit-learn, it may be more interesting to use
 joblib's replacement of pickle (``joblib.dump`` & ``joblib.load``),
 which is more efficient on big data, but can only pickle to the disk
 and not to a string::
diff --git a/doc/tutorial/statistical_inference/settings.rst b/doc/tutorial/statistical_inference/settings.rst
index 1b1e477c5cfd..e3c4ca8fea21 100644
--- a/doc/tutorial/statistical_inference/settings.rst
+++ b/doc/tutorial/statistical_inference/settings.rst
@@ -12,7 +12,7 @@ list of multi-dimensional observations. We say that the first axis of
 these arrays is the **samples** axis, while the second is the
 **features** axis.
 
-.. topic:: A simple example shipped with the scikit: iris dataset
+.. topic:: A simple example shipped with scikit-learn: iris dataset
 
     ::
 
@@ -46,7 +46,7 @@ needs to be preprocessed in order to be used by scikit-learn.
         >>> plt.imshow(digits.images[-1], cmap=plt.cm.gray_r) #doctest: +SKIP
         <matplotlib.image.AxesImage object at ...>
 
-    To use this dataset with the scikit, we transform each 8x8 image into a
+    To use this dataset with scikit-learn, we transform each 8x8 image into a
     feature vector of length 64 ::
 
         >>> data = digits.images.reshape((digits.images.shape[0], -1))
diff --git a/doc/tutorial/statistical_inference/unsupervised_learning.rst b/doc/tutorial/statistical_inference/unsupervised_learning.rst
index 0ad16c180385..cef8fbe7809d 100644
--- a/doc/tutorial/statistical_inference/unsupervised_learning.rst
+++ b/doc/tutorial/statistical_inference/unsupervised_learning.rst
@@ -171,7 +171,7 @@ Connectivity-constrained clustering
 .....................................
 
 With agglomerative clustering, it is possible to specify which samples can be
-clustered together by giving a connectivity graph. Graphs in the scikit
+clustered together by giving a connectivity graph. Graphs in scikit-learn
 are represented by their adjacency matrix. Often, a sparse matrix is used.
 This can be useful, for instance, to retrieve connected regions (sometimes
 also referred to as connected components) when
diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst
index a01ffe41f975..58506cf8aa99 100644
--- a/doc/whats_new/v0.20.rst
+++ b/doc/whats_new/v0.20.rst
@@ -81,6 +81,10 @@ Classifiers and regressors
   ``inverse_func`` are the inverse of each other.
   :issue:`9399` by :user:`Guillaume Lemaitre <glemaitre>`.
 
+- Add `sample_weight` parameter to the fit method of
+  :class:`linear_model.BayesianRidge` for weighted linear regression.
+  :issue:`10111` by :user:`Peter St. John <pstjohn>`.
+
 Model evaluation and meta-estimators
 
 - A scorer based on :func:`metrics.brier_score_loss` is also available.
@@ -192,3 +196,10 @@ Cluster
 - Deprecate ``pooling_func`` unused parameter in
   :class:`cluster.AgglomerativeClustering`. :issue:`9875` by :user:`Kumar Ashutosh
   <thechargedneutron>`.
+
+Changes to estimator checks
+---------------------------
+
+- Allow tests in :func:`estimator_checks.check_estimator` to test functions
+  that accept pairwise data.
+  :issue:`9701` by :user:`Kyle Johnson <gkjohns>`
diff --git a/examples/.flake8 b/examples/.flake8
new file mode 100644
index 000000000000..703bf15e79bf
--- /dev/null
+++ b/examples/.flake8
@@ -0,0 +1,5 @@
+# Examples specific flake8 configuration
+
+[flake8]
+# Same ignore as project-wide plus E402 (imports not at top of file)
+ignore=E121,E123,E126,E24,E226,E704,W503,W504,E402
diff --git a/examples/README.txt b/examples/README.txt
index 6c084d956fa1..4f467efb61b7 100644
--- a/examples/README.txt
+++ b/examples/README.txt
@@ -1,6 +1,9 @@
 .. _general_examples:
 
+Examples
+========
+
 General examples
 ----------------
 
-General-purpose and introductory examples for the scikit.
+General-purpose and introductory examples for scikit-learn.
diff --git a/examples/applications/wikipedia_principal_eigenvector.py b/examples/applications/wikipedia_principal_eigenvector.py
index 175c10594440..3ef921bb3d05 100644
--- a/examples/applications/wikipedia_principal_eigenvector.py
+++ b/examples/applications/wikipedia_principal_eigenvector.py
@@ -23,7 +23,7 @@
     https://en.wikipedia.org/wiki/Power_iteration
 
 Here the computation is achieved thanks to Martinsson's Randomized SVD
-algorithm implemented in the scikit.
+algorithm implemented in scikit-learn.
 
 The graph data is fetched from the DBpedia dumps. DBpedia is an extraction
 of the latent structured data of the Wikipedia content.
diff --git a/examples/model_selection/plot_roc_crossval.py b/examples/model_selection/plot_roc_crossval.py
index eb4664049ee7..2dc7be549df8 100644
--- a/examples/model_selection/plot_roc_crossval.py
+++ b/examples/model_selection/plot_roc_crossval.py
@@ -24,7 +24,7 @@
 
 .. note::
 
-    See also :func:`sklearn.metrics.auc_score`,
+    See also :func:`sklearn.metrics.roc_auc_score`,
              :func:`sklearn.model_selection.cross_val_score`,
              :ref:`sphx_glr_auto_examples_model_selection_plot_roc.py`,
 
diff --git a/setup.cfg b/setup.cfg
index 378905311e17..02b3015e87f2 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -38,6 +38,10 @@ artifact_indexes=
     # https://ci.appveyor.com/project/sklearn-ci/scikit-learn/
     http://windows-wheels.scikit-learn.org/
 
+[flake8]
+# Default flake8 3.5 ignored flags
+ignore=E121,E123,E126,E226,E24,E704,W503,W504
+
 # Uncomment the following under windows to build using:
 # http://sourceforge.net/projects/mingw/
 
diff --git a/sklearn/__check_build/__init__.py b/sklearn/__check_build/__init__.py
index 5a4018789a77..6c1cdfd9fc7b 100644
--- a/sklearn/__check_build/__init__.py
+++ b/sklearn/__check_build/__init__.py
@@ -1,5 +1,5 @@
 """ Module to give helpful messages to the user that did not
-compile the scikit properly.
+compile scikit-learn properly.
 """
 import os
 
diff --git a/sklearn/__init__.py b/sklearn/__init__.py
index c45728106ad5..5f2278d1c8c3 100644
--- a/sklearn/__init__.py
+++ b/sklearn/__init__.py
@@ -127,7 +127,7 @@ def config_context(**new_config):
 
 if __SKLEARN_SETUP__:
     sys.stderr.write('Partial import of sklearn during the build process.\n')
-    # We are not importing the rest of the scikit during the build
+    # We are not importing the rest of scikit-learn during the build
     # process, as it may not be compiled yet
 else:
     from . import __check_build
diff --git a/sklearn/base.py b/sklearn/base.py
index 81c7e5dae7bc..6f59cea3c7ab 100644
--- a/sklearn/base.py
+++ b/sklearn/base.py
@@ -551,7 +551,6 @@ def is_classifier(estimator):
 def is_regressor(estimator):
     """Returns True if the given estimator is (probably) a regressor.
 
-
     Parameters
     ----------
     estimator : object
diff --git a/sklearn/decomposition/nmf.py b/sklearn/decomposition/nmf.py
index 8b3830470921..8c3a566ebb6e 100644
--- a/sklearn/decomposition/nmf.py
+++ b/sklearn/decomposition/nmf.py
@@ -114,8 +114,9 @@ def _beta_divergence(X, W, H, beta, square_root=False):
         X_data = X.ravel()
 
     # do not affect the zeros: here 0 ** (-1) = 0 and not infinity
-    WH_data = WH_data[X_data != 0]
-    X_data = X_data[X_data != 0]
+    indices = X_data > EPSILON
+    WH_data = WH_data[indices]
+    X_data = X_data[indices]
 
     # used to avoid division by zero
     WH_data[WH_data == 0] = EPSILON
diff --git a/sklearn/decomposition/tests/test_nmf.py b/sklearn/decomposition/tests/test_nmf.py
index 3ce53b550cb0..6692aa23d003 100644
--- a/sklearn/decomposition/tests/test_nmf.py
+++ b/sklearn/decomposition/tests/test_nmf.py
@@ -479,3 +479,18 @@ def test_nmf_decreasing():
                 if previous_loss is not None:
                     assert_greater(previous_loss, loss)
                 previous_loss = loss
+
+
+def test_nmf_underflow():
+    # Regression test for an underflow issue in _beta_divergence
+    rng = np.random.RandomState(0)
+    n_samples, n_features, n_components = 10, 2, 2
+    X = np.abs(rng.randn(n_samples, n_features)) * 10
+    W = np.abs(rng.randn(n_samples, n_components)) * 10
+    H = np.abs(rng.randn(n_components, n_features))
+
+    X[0, 0] = 0
+    ref = nmf._beta_divergence(X, W, H, beta=1.0)
+    X[0, 0] = 1e-323
+    res = nmf._beta_divergence(X, W, H, beta=1.0)
+    assert_almost_equal(res, ref)
diff --git a/sklearn/ensemble/bagging.py b/sklearn/ensemble/bagging.py
index 7ea3030bdf12..7c61488cb19b 100644
--- a/sklearn/ensemble/bagging.py
+++ b/sklearn/ensemble/bagging.py
@@ -459,13 +459,15 @@ class BaggingClassifier(BaseBagging, ClassifierMixin):
 
     max_samples : int or float, optional (default=1.0)
         The number of samples to draw from X to train each base estimator.
-            - If int, then draw `max_samples` samples.
-            - If float, then draw `max_samples * X.shape[0]` samples.
+
+        - If int, then draw `max_samples` samples.
+        - If float, then draw `max_samples * X.shape[0]` samples.
 
     max_features : int or float, optional (default=1.0)
         The number of features to draw from X to train each base estimator.
-            - If int, then draw `max_features` features.
-            - If float, then draw `max_features * X.shape[1]` features.
+
+        - If int, then draw `max_features` features.
+        - If float, then draw `max_features * X.shape[1]` features.
 
     bootstrap : boolean, optional (default=True)
         Whether samples are drawn with replacement.
@@ -827,13 +829,15 @@ class BaggingRegressor(BaseBagging, RegressorMixin):
 
     max_samples : int or float, optional (default=1.0)
         The number of samples to draw from X to train each base estimator.
-            - If int, then draw `max_samples` samples.
-            - If float, then draw `max_samples * X.shape[0]` samples.
+
+        - If int, then draw `max_samples` samples.
+        - If float, then draw `max_samples * X.shape[0]` samples.
 
     max_features : int or float, optional (default=1.0)
         The number of features to draw from X to train each base estimator.
-            - If int, then draw `max_features` features.
-            - If float, then draw `max_features * X.shape[1]` features.
+
+        - If int, then draw `max_features` features.
+        - If float, then draw `max_features * X.shape[1]` features.
 
     bootstrap : boolean, optional (default=True)
         Whether samples are drawn with replacement.
diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
index 2c155f11c628..31a82b9ce285 100644
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -1483,7 +1483,7 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
     loss_ : LossFunction
         The concrete ``LossFunction`` object.
 
-    init : BaseEstimator
+    init_ : BaseEstimator
         The estimator that provides the initial predictions.
         Set via the ``init`` argument or ``loss.init_estimator``.
 
@@ -1929,7 +1929,7 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
     loss_ : LossFunction
         The concrete ``LossFunction`` object.
 
-    init : BaseEstimator
+    init_ : BaseEstimator
         The estimator that provides the initial predictions.
         Set via the ``init`` argument or ``loss.init_estimator``.
 
diff --git a/sklearn/linear_model/bayes.py b/sklearn/linear_model/bayes.py
index a094eec0cd93..e754613cda38 100644
--- a/sklearn/linear_model/bayes.py
+++ b/sklearn/linear_model/bayes.py
@@ -11,7 +11,7 @@
 from scipy import linalg
 from scipy.linalg import pinvh
 
-from .base import LinearModel
+from .base import LinearModel, _rescale_data
 from ..base import RegressorMixin
 from ..utils.extmath import fast_logdet
 from ..utils import check_X_y
@@ -140,7 +140,7 @@ def __init__(self, n_iter=300, tol=1.e-3, alpha_1=1.e-6, alpha_2=1.e-6,
         self.copy_X = copy_X
         self.verbose = verbose
 
-    def fit(self, X, y):
+    def fit(self, X, y, sample_weight=None):
         """Fit the model
 
         Parameters
@@ -150,13 +150,25 @@ def fit(self, X, y):
         y : numpy array of shape [n_samples]
             Target values. Will be cast to X's dtype if necessary
 
+        sample_weight : numpy array of shape [n_samples]
+            Individual weights for each sample
+
+            .. versionadded:: 0.20
+               parameter *sample_weight* support to BayesianRidge.
+
         Returns
         -------
         self : returns an instance of self.
         """
         X, y = check_X_y(X, y, dtype=np.float64, y_numeric=True)
         X, y, X_offset_, y_offset_, X_scale_ = self._preprocess_data(
-            X, y, self.fit_intercept, self.normalize, self.copy_X)
+            X, y, self.fit_intercept, self.normalize, self.copy_X,
+            sample_weight=sample_weight)
+
+        if sample_weight is not None:
+            # Sample weight can be implemented via a simple rescaling.
+            X, y = _rescale_data(X, y, sample_weight)
+
         self.X_offset_ = X_offset_
         self.X_scale_ = X_scale_
         n_samples, n_features = X.shape
diff --git a/sklearn/linear_model/sag_fast.pyx b/sklearn/linear_model/sag_fast.pyx
index 81f39fbd805c..279af8f8ccc1 100644
--- a/sklearn/linear_model/sag_fast.pyx
+++ b/sklearn/linear_model/sag_fast.pyx
@@ -248,7 +248,7 @@ def sag(SequentialDataset dataset,
     ---------
     Schmidt, M., Roux, N. L., & Bach, F. (2013).
     Minimizing finite sums with the stochastic average gradient
-    https://hal.inria.fr/hal-00860051/PDF/sag_journal.pdf
+    https://hal.inria.fr/hal-00860051/document
     (section 4.3)
 
     Defazio, A., Bach, F., Lacoste-Julien, S. (2014),
diff --git a/sklearn/linear_model/stochastic_gradient.py b/sklearn/linear_model/stochastic_gradient.py
index 38caa51b5199..1cd37b953060 100644
--- a/sklearn/linear_model/stochastic_gradient.py
+++ b/sklearn/linear_model/stochastic_gradient.py
@@ -82,7 +82,7 @@ def set_params(self, *args, **kwargs):
     def fit(self, X, y):
         """Fit model."""
 
-    def _validate_params(self, set_max_iter=True):
+    def _validate_params(self, set_max_iter=True, for_partial_fit=False):
         """Validate input params. """
         if not isinstance(self.shuffle, bool):
             raise ValueError("shuffle must be either True or False")
@@ -120,14 +120,15 @@ def _validate_params(self, set_max_iter=True):
             self._tol = None
 
         elif self.tol is None and self.max_iter is None:
-            warnings.warn(
-                "max_iter and tol parameters have been added in %s in 0.19. If"
-                " both are left unset, they default to max_iter=5 and tol=None"
-                ". If tol is not None, max_iter defaults to max_iter=1000. "
-                "From 0.21, default max_iter will be 1000, "
-                "and default tol will be 1e-3." % type(self).__name__,
-                FutureWarning)
-            # Before 0.19, default was n_iter=5
+            if not for_partial_fit:
+                warnings.warn(
+                    "max_iter and tol parameters have been "
+                    "added in %s in 0.19. If both are left unset, "
+                    "they default to max_iter=5 and tol=None. "
+                    "If tol is not None, max_iter defaults to max_iter=1000. "
+                    "From 0.21, default max_iter will be 1000, and"
+                    " default tol will be 1e-3." % type(self), FutureWarning)
+                # Before 0.19, default was n_iter=5
             max_iter = 5
         else:
             max_iter = self.max_iter if self.max_iter is not None else 1000
@@ -539,7 +540,7 @@ def partial_fit(self, X, y, classes=None, sample_weight=None):
         -------
         self : returns an instance of self.
         """
-        self._validate_params()
+        self._validate_params(for_partial_fit=True)
         if self.class_weight in ['balanced']:
             raise ValueError("class_weight '{0}' is not supported for "
                              "partial_fit. In order to use 'balanced' weights,"
@@ -984,7 +985,7 @@ def partial_fit(self, X, y, sample_weight=None):
         -------
         self : returns an instance of self.
         """
-        self._validate_params()
+        self._validate_params(for_partial_fit=True)
         return self._partial_fit(X, y, self.alpha, C=1.0,
                                  loss=self.loss,
                                  learning_rate=self.learning_rate, max_iter=1,
diff --git a/sklearn/linear_model/tests/test_bayes.py b/sklearn/linear_model/tests/test_bayes.py
index 492f77d693a1..5337c0a19c5c 100644
--- a/sklearn/linear_model/tests/test_bayes.py
+++ b/sklearn/linear_model/tests/test_bayes.py
@@ -50,6 +50,21 @@ def test_bayesian_ridge_parameter():
     assert_almost_equal(rr_model.intercept_, br_model.intercept_)
 
 
+def test_bayesian_sample_weights():
+    # Test correctness of the sample_weights method
+    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])
+    y = np.array([1, 2, 3, 2, 0, 4, 5]).T
+    w = np.array([4, 3, 3, 1, 1, 2, 3]).T
+
+    # A Ridge regression model using an alpha value equal to the ratio of
+    # lambda_ and alpha_ from the Bayesian Ridge model must be identical
+    br_model = BayesianRidge(compute_score=True).fit(X, y, sample_weight=w)
+    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(
+        X, y, sample_weight=w)
+    assert_array_almost_equal(rr_model.coef_, br_model.coef_)
+    assert_almost_equal(rr_model.intercept_, br_model.intercept_)
+
+
 def test_toy_bayesian_ridge_object():
     # Test BayesianRidge on toy
     X = np.array([[1], [2], [6], [8], [10]])
diff --git a/sklearn/linear_model/tests/test_sgd.py b/sklearn/linear_model/tests/test_sgd.py
index d4552a9934cf..610b8b060aee 100644
--- a/sklearn/linear_model/tests/test_sgd.py
+++ b/sklearn/linear_model/tests/test_sgd.py
@@ -1194,9 +1194,9 @@ def test_tol_parameter():
 def test_future_and_deprecation_warnings():
     # Test that warnings are raised. Will be removed in 0.21
 
-    def init(max_iter=None, tol=None, n_iter=None):
+    def init(max_iter=None, tol=None, n_iter=None, for_partial_fit=False):
         sgd = SGDClassifier(max_iter=max_iter, tol=tol, n_iter=n_iter)
-        sgd._validate_params()
+        sgd._validate_params(for_partial_fit=for_partial_fit)
 
     # When all default values are used
     msg_future = "max_iter and tol parameters have been added in "
@@ -1211,6 +1211,9 @@ def init(max_iter=None, tol=None, n_iter=None):
     assert_no_warnings(init, None, 1e-3, None)
     assert_no_warnings(init, 100, 1e-3, None)
 
+    # Test that for_partial_fit will not throw warnings for max_iter or tol
+    assert_no_warnings(init, None, None, None, True)
+
 
 @ignore_warnings(category=(DeprecationWarning, FutureWarning))
 def test_tol_and_max_iter_default_values():
diff --git a/sklearn/manifold/spectral_embedding_.py b/sklearn/manifold/spectral_embedding_.py
index 4ae588d1ae6c..c1d0e2e5a75f 100644
--- a/sklearn/manifold/spectral_embedding_.py
+++ b/sklearn/manifold/spectral_embedding_.py
@@ -11,6 +11,7 @@
 from scipy.linalg import eigh
 from scipy.sparse.linalg import eigsh, lobpcg
 from scipy.sparse.csgraph import connected_components
+from scipy.sparse.csgraph import laplacian as csgraph_laplacian
 
 from ..base import BaseEstimator
 from ..externals import six
@@ -234,8 +235,8 @@ def spectral_embedding(adjacency, n_components=8, eigen_solver=None,
         warnings.warn("Graph is not fully connected, spectral embedding"
                       " may not work as expected.")
 
-    laplacian, dd = sparse.csgraph.laplacian(adjacency, normed=norm_laplacian,
-                                             return_diag=True)
+    laplacian, dd = csgraph_laplacian(adjacency, normed=norm_laplacian,
+                                      return_diag=True)
     if (eigen_solver == 'arpack' or eigen_solver != 'lobpcg' and
        (not sparse.isspmatrix(laplacian) or n_nodes < 5 * n_components)):
         # lobpcg used with eigen_solver='amg' has bugs for low number of nodes
diff --git a/sklearn/manifold/tests/test_spectral_embedding.py b/sklearn/manifold/tests/test_spectral_embedding.py
index ffca9c429a9b..dd746f2af259 100644
--- a/sklearn/manifold/tests/test_spectral_embedding.py
+++ b/sklearn/manifold/tests/test_spectral_embedding.py
@@ -3,6 +3,7 @@
 from numpy.testing import assert_array_equal
 
 from scipy import sparse
+from scipy.sparse import csgraph
 from scipy.linalg import eigh
 
 from sklearn.manifold.spectral_embedding_ import SpectralEmbedding
@@ -254,8 +255,8 @@ def test_spectral_embedding_unnormalized():
                                      drop_first=False)
 
     # Verify using manual computation with dense eigh
-    laplacian, dd = sparse.csgraph.laplacian(sims, normed=False,
-                                             return_diag=True)
+    laplacian, dd = csgraph.laplacian(sims, normed=False,
+                                      return_diag=True)
     _, diffusion_map = eigh(laplacian)
     embedding_2 = diffusion_map.T[:n_components] * dd
     embedding_2 = _deterministic_vector_sign_flip(embedding_2).T
diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py
index c79770de4ab8..6b445e1f2e18 100644
--- a/sklearn/metrics/cluster/supervised.py
+++ b/sklearn/metrics/cluster/supervised.py
@@ -651,7 +651,7 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
     See also
     --------
     adjusted_rand_score: Adjusted Rand Index
-    mutual_information_score: Mutual Information (not adjusted for chance)
+    mutual_info_score: Mutual Information (not adjusted for chance)
 
     Examples
     --------
diff --git a/sklearn/neighbors/regression.py b/sklearn/neighbors/regression.py
index bd2ffb9b8248..b13f16cfd399 100644
--- a/sklearn/neighbors/regression.py
+++ b/sklearn/neighbors/regression.py
@@ -9,6 +9,7 @@
 # License: BSD 3 clause (C) INRIA, University of Amsterdam
 
 import numpy as np
+from scipy.sparse import issparse
 
 from .base import _get_weights, _check_weights, NeighborsBase, KNeighborsMixin
 from .base import RadiusNeighborsMixin, SupervisedFloatMixin
@@ -139,6 +140,11 @@ def predict(self, X):
         y : array of int, shape = [n_samples] or [n_samples, n_outputs]
             Target values
         """
+        if issparse(X) and self.metric == 'precomputed':
+            raise ValueError(
+                "Sparse matrices not supported for prediction with "
+                "precomputed kernels. Densify your matrix."
+            )
         X = check_array(X, accept_sparse='csr')
 
         neigh_dist, neigh_ind = self.kneighbors(X)
diff --git a/sklearn/neighbors/tests/test_neighbors.py b/sklearn/neighbors/tests/test_neighbors.py
index 052c83c71d2e..ceb53412018b 100644
--- a/sklearn/neighbors/tests/test_neighbors.py
+++ b/sklearn/neighbors/tests/test_neighbors.py
@@ -2,7 +2,7 @@
 
 import numpy as np
 from scipy.sparse import (bsr_matrix, coo_matrix, csc_matrix, csr_matrix,
-                          dok_matrix, lil_matrix)
+                          dok_matrix, lil_matrix, issparse)
 
 from sklearn import metrics
 from sklearn import neighbors, datasets
@@ -731,10 +731,22 @@ def test_kneighbors_regressor_sparse(n_samples=40,
         knn = neighbors.KNeighborsRegressor(n_neighbors=n_neighbors,
                                             algorithm='auto')
         knn.fit(sparsemat(X), y)
+
+        knn_pre = neighbors.KNeighborsRegressor(n_neighbors=n_neighbors,
+                                                metric='precomputed')
+        knn_pre.fit(pairwise_distances(X, metric='euclidean'), y)
+
         for sparsev in SPARSE_OR_DENSE:
             X2 = sparsev(X)
             assert_true(np.mean(knn.predict(X2).round() == y) > 0.95)
 
+            X2_pre = sparsev(pairwise_distances(X, metric='euclidean'))
+            if issparse(sparsev(X2_pre)):
+                assert_raises(ValueError, knn_pre.predict, X2_pre)
+            else:
+                assert_true(
+                    np.mean(knn_pre.predict(X2_pre).round() == y) > 0.95)
+
 
 def test_neighbors_iris():
     # Sanity checks on the iris dataset
diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py
index 530f376c19fa..88f177436767 100644
--- a/sklearn/preprocessing/label.py
+++ b/sklearn/preprocessing/label.py
@@ -160,7 +160,7 @@ class LabelBinarizer(BaseEstimator, TransformerMixin):
     """Binarize labels in a one-vs-all fashion
 
     Several regression and binary classification algorithms are
-    available in the scikit. A simple way to extend these algorithms
+    available in scikit-learn. A simple way to extend these algorithms
     to the multi-class classification case is to use the so-called
     one-vs-all scheme.
 
@@ -393,7 +393,7 @@ def label_binarize(y, classes, neg_label=0, pos_label=1, sparse_output=False):
     """Binarize labels in a one-vs-all fashion
 
     Several regression and binary classification algorithms are
-    available in the scikit. A simple way to extend these algorithms
+    available in scikit-learn. A simple way to extend these algorithms
     to the multi-class classification case is to use the so-called
     one-vs-all scheme.
 
diff --git a/sklearn/preprocessing/tests/test_imputation.py b/sklearn/preprocessing/tests/test_imputation.py
index aa9cdf8aae7b..c3d8aa38cc69 100644
--- a/sklearn/preprocessing/tests/test_imputation.py
+++ b/sklearn/preprocessing/tests/test_imputation.py
@@ -530,4 +530,4 @@ def test_mice_additive_matrix():
                               n_burn_in=10,
                               verbose=True).fit(Xtr)
         Xts_est = imputer.fit_transform(Xts)
-        assert_array_almost_equal(Xts_filled, Xts_est, decimal=1)
+        assert_array_almost_equal(Xts_filled, Xts_est, decimal=0)
diff --git a/sklearn/semi_supervised/label_propagation.py b/sklearn/semi_supervised/label_propagation.py
index 10eebba86f04..e7917818a007 100644
--- a/sklearn/semi_supervised/label_propagation.py
+++ b/sklearn/semi_supervised/label_propagation.py
@@ -60,6 +60,7 @@
 import warnings
 import numpy as np
 from scipy import sparse
+from scipy.sparse import csgraph
 
 from ..base import BaseEstimator, ClassifierMixin
 from ..externals import six
@@ -514,7 +515,7 @@ def _build_graph(self):
             self.nn_fit = None
         n_samples = self.X_.shape[0]
         affinity_matrix = self._get_kernel(self.X_)
-        laplacian = sparse.csgraph.laplacian(affinity_matrix, normed=True)
+        laplacian = csgraph.laplacian(affinity_matrix, normed=True)
         laplacian = -laplacian
         if sparse.isspmatrix(laplacian):
             diag_mask = (laplacian.row == laplacian.col)
diff --git a/sklearn/tests/test_common.py b/sklearn/tests/test_common.py
index dde6f4c41c3f..908240cdaf02 100644
--- a/sklearn/tests/test_common.py
+++ b/sklearn/tests/test_common.py
@@ -77,7 +77,7 @@ def test_non_meta_estimators():
 
 def test_configure():
     # Smoke test the 'configure' step of setup, this tests all the
-    # 'configure' functions in the setup.pys in the scikit
+    # 'configure' functions in the setup.pys in scikit-learn
     cwd = os.getcwd()
     setup_path = os.path.abspath(os.path.join(sklearn.__path__[0], '..'))
     setup_filename = os.path.join(setup_path, 'setup.py')
diff --git a/sklearn/utils/estimator_checks.py b/sklearn/utils/estimator_checks.py
index da8a456d97c0..7316670fc1da 100644
--- a/sklearn/utils/estimator_checks.py
+++ b/sklearn/utils/estimator_checks.py
@@ -37,6 +37,7 @@
 
 from sklearn.base import (clone, TransformerMixin, ClusterMixin,
                           BaseEstimator, is_classifier, is_regressor)
+
 from sklearn.metrics import accuracy_score, adjusted_rand_score, f1_score
 
 from sklearn.random_projection import BaseRandomProjection
@@ -48,6 +49,8 @@
 from sklearn.exceptions import DataConversionWarning
 from sklearn.exceptions import SkipTestWarning
 from sklearn.model_selection import train_test_split
+from sklearn.metrics.pairwise import (rbf_kernel, linear_kernel,
+                                      pairwise_distances)
 
 from sklearn.utils import shuffle
 from sklearn.utils.fixes import signature
@@ -355,10 +358,56 @@ def _is_32bit():
     return struct.calcsize('P') * 8 == 32
 
 
+def _is_pairwise(estimator):
+    """Returns True if estimator has a _pairwise attribute set to True.
+
+    Parameters
+    ----------
+    estimator : object
+        Estimator object to test.
+
+    Returns
+    -------
+    out : bool
+        True if _pairwise is set to True and False otherwise.
+    """
+    return bool(getattr(estimator, "_pairwise", False))
+
+
+def _is_pairwise_metric(estimator):
+    """Returns True if estimator accepts pairwise metric.
+
+    Parameters
+    ----------
+    estimator : object
+        Estimator object to test.
+
+    Returns
+    -------
+    out : bool
+        True if _pairwise is set to True and False otherwise.
+    """
+    metric = getattr(estimator,  "metric", None)
+
+    return bool(metric == 'precomputed')
+
+
+def pairwise_estimator_convert_X(X, estimator, kernel=linear_kernel):
+
+    if _is_pairwise_metric(estimator):
+        return pairwise_distances(X, metric='euclidean')
+    if _is_pairwise(estimator):
+        return kernel(X, X)
+
+    return X
+
+
 def check_estimator_sparse_data(name, estimator_orig):
+
     rng = np.random.RandomState(0)
     X = rng.rand(40, 10)
     X[X < .8] = 0
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     X_csr = sparse.csr_matrix(X)
     y = (4 * rng.rand(40)).astype(np.int)
     # catch deprecation warnings
@@ -383,8 +432,8 @@ def check_estimator_sparse_data(name, estimator_orig):
             if hasattr(estimator, 'predict_proba'):
                 probs = estimator.predict_proba(X)
                 assert_equal(probs.shape, (X.shape[0], 4))
-        except TypeError as e:
-            if 'sparse' not in repr(e):
+        except (TypeError, ValueError) as e:
+            if 'sparse' not in repr(e).lower():
                 print("Estimator %s doesn't seem to fail gracefully on "
                       "sparse data: error message state explicitly that "
                       "sparse input is not supported if this is not the case."
@@ -405,7 +454,8 @@ def check_sample_weights_pandas_series(name, estimator_orig):
     if has_fit_parameter(estimator, "sample_weight"):
         try:
             import pandas as pd
-            X = pd.DataFrame([[1, 1], [1, 2], [1, 3], [2, 1], [2, 2], [2, 3]])
+            X = np.array([[1, 1], [1, 2], [1, 3], [2, 1], [2, 2], [2, 3]])
+            X = pd.DataFrame(pairwise_estimator_convert_X(X, estimator_orig))
             y = pd.Series([1, 1, 1, 2, 2, 2])
             weights = pd.Series([1] * 6)
             try:
@@ -426,7 +476,8 @@ def check_sample_weights_list(name, estimator_orig):
     if has_fit_parameter(estimator_orig, "sample_weight"):
         estimator = clone(estimator_orig)
         rnd = np.random.RandomState(0)
-        X = rnd.uniform(size=(10, 3))
+        X = pairwise_estimator_convert_X(rnd.uniform(size=(10, 3)),
+                                         estimator_orig)
         y = np.arange(10) % 3
         y = multioutput_estimator_convert_y_2d(estimator, y)
         sample_weight = [3] * 10
@@ -438,7 +489,8 @@ def check_sample_weights_list(name, estimator_orig):
 def check_dtype_object(name, estimator_orig):
     # check that estimators treat dtype object as numeric if possible
     rng = np.random.RandomState(0)
-    X = rng.rand(40, 10).astype(object)
+    X = pairwise_estimator_convert_X(rng.rand(40, 10), estimator_orig)
+    X = X.astype(object)
     y = (X[:, 0] * 4).astype(np.int)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -485,6 +537,8 @@ def check_dict_unchanged(name, estimator_orig):
     else:
         X = 2 * rnd.uniform(size=(20, 3))
 
+    X = pairwise_estimator_convert_X(X, estimator_orig)
+
     y = X[:, 0].astype(np.int)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -522,6 +576,7 @@ def check_dont_overwrite_parameters(name, estimator_orig):
     estimator = clone(estimator_orig)
     rnd = np.random.RandomState(0)
     X = 3 * rnd.uniform(size=(20, 3))
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = X[:, 0].astype(np.int)
     y = multioutput_estimator_convert_y_2d(estimator, y)
 
@@ -568,6 +623,7 @@ def check_fit2d_predict1d(name, estimator_orig):
     # check by fitting a 2d array and predicting with a 1d array
     rnd = np.random.RandomState(0)
     X = 3 * rnd.uniform(size=(20, 3))
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = X[:, 0].astype(np.int)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -621,6 +677,7 @@ def check_fit2d_1feature(name, estimator_orig):
     # informative message
     rnd = np.random.RandomState(0)
     X = 3 * rnd.uniform(size=(10, 1))
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = X[:, 0].astype(np.int)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -793,6 +850,7 @@ def check_pipeline_consistency(name, estimator_orig):
     X, y = make_blobs(n_samples=30, centers=[[0, 0, 0], [1, 1, 1]],
                       random_state=0, n_features=2, cluster_std=0.1)
     X -= X.min()
+    X = pairwise_estimator_convert_X(X, estimator_orig, kernel=rbf_kernel)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
     set_random_state(estimator)
@@ -817,6 +875,7 @@ def check_fit_score_takes_y(name, estimator_orig):
     # in fit and score so they can be used in pipelines
     rnd = np.random.RandomState(0)
     X = rnd.uniform(size=(10, 3))
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = np.arange(10) % 3
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -842,6 +901,7 @@ def check_fit_score_takes_y(name, estimator_orig):
 def check_estimators_dtypes(name, estimator_orig):
     rnd = np.random.RandomState(0)
     X_train_32 = 3 * rnd.uniform(size=(20, 5)).astype(np.float32)
+    X_train_32 = pairwise_estimator_convert_X(X_train_32, estimator_orig)
     X_train_64 = X_train_32.astype(np.float64)
     X_train_int_64 = X_train_32.astype(np.int64)
     X_train_int_32 = X_train_32.astype(np.int32)
@@ -887,7 +947,8 @@ def check_estimators_empty_data_messages(name, estimator_orig):
 def check_estimators_nan_inf(name, estimator_orig):
     # Checks that Estimator X's do not contain NaN or inf.
     rnd = np.random.RandomState(0)
-    X_train_finite = rnd.uniform(size=(10, 3))
+    X_train_finite = pairwise_estimator_convert_X(rnd.uniform(size=(10, 3)),
+                                                  estimator_orig)
     X_train_nan = rnd.uniform(size=(10, 3))
     X_train_nan[0, 0] = np.nan
     X_train_inf = rnd.uniform(size=(10, 3))
@@ -964,6 +1025,7 @@ def check_estimators_pickle(name, estimator_orig):
 
     # some estimators can't do features less than 0
     X -= X.min()
+    X = pairwise_estimator_convert_X(X, estimator_orig, kernel=rbf_kernel)
 
     estimator = clone(estimator_orig)
 
@@ -1138,6 +1200,7 @@ def check_classifiers_train(name, classifier_orig):
         classifier = clone(classifier_orig)
         if name in ['BernoulliNB', 'MultinomialNB', 'ComplementNB']:
             X -= X.min()
+        X = pairwise_estimator_convert_X(X, classifier_orig)
         set_random_state(classifier)
         # raises error on malformed input for fit
         with assert_raises(ValueError, msg="The classifer {} does not"
@@ -1159,11 +1222,18 @@ def check_classifiers_train(name, classifier_orig):
             assert_greater(accuracy_score(y, y_pred), 0.83)
 
         # raises error on malformed input for predict
-        with assert_raises(ValueError, msg="The classifier {} does not"
-                           " raise an error when the number of features "
-                           "in predict is different from the number of"
-                           " features in fit.".format(name)):
-            classifier.predict(X.T)
+        if _is_pairwise(classifier):
+            with assert_raises(ValueError, msg="The classifier {} does not"
+                               " raise an error when shape of X"
+                               "in predict is not equal to (n_test_samples,"
+                               "n_training_samples)".format(name)):
+                classifier.predict(X.reshape(-1, 1))
+        else:
+            with assert_raises(ValueError, msg="The classifier {} does not"
+                               " raise an error when the number of features "
+                               "in predict is different from the number of"
+                               " features in fit.".format(name)):
+                classifier.predict(X.T)
         if hasattr(classifier, "decision_function"):
             try:
                 # decision_function agrees with predict
@@ -1179,12 +1249,21 @@ def check_classifiers_train(name, classifier_orig):
                     assert_array_equal(np.argmax(decision, axis=1), y_pred)
 
                 # raises error on malformed input for decision_function
-                with assert_raises(ValueError, msg="The classifier {} does"
-                                   " not raise an error when the number of "
-                                   "features in decision_function is "
-                                   "different from the number of features"
-                                   " in fit.".format(name)):
-                    classifier.decision_function(X.T)
+                if _is_pairwise(classifier):
+                    with assert_raises(ValueError, msg="The classifier {} does"
+                                       " not raise an error when the  "
+                                       "shape of X in decision_function is "
+                                       "not equal to (n_test_samples, "
+                                       "n_training_samples) in fit."
+                                       .format(name)):
+                        classifier.decision_function(X.reshape(-1, 1))
+                else:
+                    with assert_raises(ValueError, msg="The classifier {} does"
+                                       " not raise an error when the number "
+                                       "of features in decision_function is "
+                                       "different from the number of features"
+                                       " in fit.".format(name)):
+                        classifier.decision_function(X.T)
             except NotImplementedError:
                 pass
         if hasattr(classifier, "predict_proba"):
@@ -1195,11 +1274,20 @@ def check_classifiers_train(name, classifier_orig):
             # check that probas for all classes sum to one
             assert_allclose(np.sum(y_prob, axis=1), np.ones(n_samples))
             # raises error on malformed input for predict_proba
-            with assert_raises(ValueError, msg="The classifier {} does not"
-                               " raise an error when the number of features "
-                               "in predict_proba is different from the number "
-                               "of features in fit.".format(name)):
-                classifier.predict_proba(X.T)
+            if _is_pairwise(classifier_orig):
+                with assert_raises(ValueError, msg="The classifier {} does not"
+                                   " raise an error when the shape of X"
+                                   "in predict_proba is not equal to "
+                                   "(n_test_samples, n_training_samples)."
+                                   .format(name)):
+                    classifier.predict_proba(X.reshape(-1, 1))
+            else:
+                with assert_raises(ValueError, msg="The classifier {} does not"
+                                   " raise an error when the number of "
+                                   "features in predict_proba is different "
+                                   "from the number of features in fit."
+                                   .format(name)):
+                    classifier.predict_proba(X.T)
             if hasattr(classifier, "predict_log_proba"):
                 # predict_log_proba is a transformation of predict_proba
                 y_log_prob = classifier.predict_log_proba(X)
@@ -1213,6 +1301,7 @@ def check_estimators_fit_returns_self(name, estimator_orig):
     X, y = make_blobs(random_state=0, n_samples=9, n_features=4)
     # some want non-negative input
     X -= X.min()
+    X = pairwise_estimator_convert_X(X, estimator_orig)
 
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
@@ -1260,7 +1349,7 @@ def check_supervised_y_2d(name, estimator_orig):
         # These only work on 2d, so this test makes no sense
         return
     rnd = np.random.RandomState(0)
-    X = rnd.uniform(size=(10, 3))
+    X = pairwise_estimator_convert_X(rnd.uniform(size=(10, 3)), estimator_orig)
     y = np.arange(10) % 3
     estimator = clone(estimator_orig)
     set_random_state(estimator)
@@ -1294,6 +1383,7 @@ def check_classifiers_classes(name, classifier_orig):
     # We need to make sure that we have non negative data, for things
     # like NMF
     X -= X.min() - .1
+    X = pairwise_estimator_convert_X(X, classifier_orig)
     y_names = np.array(["one", "two", "three"])[y]
 
     for y_names in [y_names, y_names.astype('O')]:
@@ -1325,7 +1415,7 @@ def check_classifiers_classes(name, classifier_orig):
 @ignore_warnings(category=(DeprecationWarning, FutureWarning))
 def check_regressors_int(name, regressor_orig):
     X, _ = _boston_subset()
-    X = X[:50]
+    X = pairwise_estimator_convert_X(X[:50], regressor_orig)
     rnd = np.random.RandomState(0)
     y = rnd.randint(3, size=X.shape[0])
     y = multioutput_estimator_convert_y_2d(regressor_orig, y)
@@ -1353,6 +1443,7 @@ def check_regressors_int(name, regressor_orig):
 @ignore_warnings(category=(DeprecationWarning, FutureWarning))
 def check_regressors_train(name, regressor_orig):
     X, y = _boston_subset()
+    X = pairwise_estimator_convert_X(X, regressor_orig)
     y = StandardScaler().fit_transform(y.reshape(-1, 1))  # X is already scaled
     y = y.ravel()
     regressor = clone(regressor_orig)
@@ -1429,6 +1520,12 @@ def check_class_weight_classifiers(name, classifier_orig):
         X, y = make_blobs(centers=n_centers, random_state=0, cluster_std=20)
         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,
                                                             random_state=0)
+
+        # can't use gram_if_pairwise() here, setting up gram matrix manually
+        if _is_pairwise(classifier_orig):
+            X_test = rbf_kernel(X_test, X_train)
+            X_train = rbf_kernel(X_train, X_train)
+
         n_centers = len(np.unique(y_train))
 
         if n_centers == 2:
@@ -1512,6 +1609,7 @@ def check_estimators_overwrite_params(name, estimator_orig):
     X, y = make_blobs(random_state=0, n_samples=9)
     # some want non-negative input
     X -= X.min()
+    X = pairwise_estimator_convert_X(X, estimator_orig, kernel=rbf_kernel)
     estimator = clone(estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator, y)
 
@@ -1586,6 +1684,7 @@ def check_sparsify_coefficients(name, estimator_orig):
 @ignore_warnings(category=DeprecationWarning)
 def check_classifier_data_not_an_array(name, estimator_orig):
     X = np.array([[3, 0], [0, 1], [0, 2], [1, 1], [1, 2], [2, 1]])
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = [1, 1, 1, 2, 2, 2]
     y = multioutput_estimator_convert_y_2d(estimator_orig, y)
     check_estimators_data_not_an_array(name, estimator_orig, X, y)
@@ -1594,6 +1693,7 @@ def check_classifier_data_not_an_array(name, estimator_orig):
 @ignore_warnings(category=DeprecationWarning)
 def check_regressor_data_not_an_array(name, estimator_orig):
     X, y = _boston_subset(n_samples=50)
+    X = pairwise_estimator_convert_X(X, estimator_orig)
     y = multioutput_estimator_convert_y_2d(estimator_orig, y)
     check_estimators_data_not_an_array(name, estimator_orig, X, y)
 
diff --git a/sklearn/utils/graph.py b/sklearn/utils/graph.py
index 610cd0ec9b4e..ab46121fbb09 100644
--- a/sklearn/utils/graph.py
+++ b/sklearn/utils/graph.py
@@ -11,6 +11,7 @@
 # License: BSD 3 clause
 
 from scipy import sparse
+from scipy.sparse import csgraph
 
 from .graph_shortest_path import graph_shortest_path  # noqa
 from .deprecation import deprecated
@@ -73,11 +74,11 @@ def single_source_shortest_path_length(graph, source, cutoff=None):
             "version 0.19 and will be removed in 0.21. Use "
             "scipy.sparse.csgraph.connected_components instead.")
 def connected_components(*args, **kwargs):
-    return sparse.csgraph.connected_components(*args, **kwargs)
+    return csgraph.connected_components(*args, **kwargs)
 
 
 @deprecated("sklearn.utils.graph.graph_laplacian was deprecated in version "
             "0.19 and will be removed in 0.21. Use "
             "scipy.sparse.csgraph.laplacian instead.")
 def graph_laplacian(*args, **kwargs):
-    return sparse.csgraph.laplacian(*args, **kwargs)
+    return csgraph.laplacian(*args, **kwargs)
diff --git a/sklearn/utils/tests/test_estimator_checks.py b/sklearn/utils/tests/test_estimator_checks.py
index 1b3a1ea7e597..2323f8a634eb 100644
--- a/sklearn/utils/tests/test_estimator_checks.py
+++ b/sklearn/utils/tests/test_estimator_checks.py
@@ -18,6 +18,8 @@
 from sklearn.cluster import MiniBatchKMeans
 from sklearn.decomposition import NMF
 from sklearn.linear_model import MultiTaskElasticNet
+from sklearn.svm import SVC
+from sklearn.neighbors import KNeighborsRegressor
 from sklearn.utils.validation import check_X_y, check_array
 
 
@@ -251,3 +253,16 @@ def __init__(self):
                         check_no_fit_attributes_set_in_init,
                         'estimator_name',
                         NonConformantEstimator)
+
+
+def test_check_estimator_pairwise():
+    # check that check_estimator() works on estimator with _pairwise
+    # kernel or  metric
+
+    # test precomputed kernel
+    est = SVC(kernel='precomputed')
+    check_estimator(est)
+
+    # test precomputed metric
+    est = KNeighborsRegressor(metric='precomputed')
+    check_estimator(est)
