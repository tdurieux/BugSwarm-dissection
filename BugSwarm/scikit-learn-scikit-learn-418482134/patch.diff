diff --git a/sklearn/ensemble/forest.py b/sklearn/ensemble/forest.py
index c15f61ab5e..125f48d5b0 100755
--- a/sklearn/ensemble/forest.py
+++ b/sklearn/ensemble/forest.py
@@ -965,7 +965,7 @@ class labels (multi-output problem).
                 min_impurity_decrease=0.0, min_impurity_split=None,
                 min_samples_leaf='deprecated', min_samples_split=2,
                 min_weight_fraction_leaf='deprecated', n_estimators=100,
-                n_jobs=1, oob_score=False, random_state=0, verbose=0,
+                n_jobs=None, oob_score=False, random_state=0, verbose=0,
                 warm_start=False)
     >>> print(clf.feature_importances_)
     [0.14205973 0.76664038 0.0282433  0.06305659]
@@ -1222,7 +1222,7 @@ class RandomForestRegressor(ForestRegressor):
                min_impurity_decrease=0.0, min_impurity_split=None,
                min_samples_leaf='deprecated', min_samples_split=2,
                min_weight_fraction_leaf='deprecated', n_estimators=100,
-               n_jobs=1, oob_score=False, random_state=0, verbose=0,
+               n_jobs=None, oob_score=False, random_state=0, verbose=0,
                warm_start=False)
     >>> print(regr.feature_importances_)
     [0.18146984 0.81473937 0.00145312 0.00233767]
diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
index 32d81f7e86..6e9cd843d5 100755
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -25,6 +25,7 @@
 
 from abc import ABCMeta
 from abc import abstractmethod
+import warnings
 
 from .base import BaseEnsemble
 from ..base import ClassifierMixin
@@ -1497,9 +1498,17 @@ def _fit_stages(self, X, y, y_pred, sample_weight, random_state,
         n_inbag = max(1, int(self.subsample * n_samples))
         loss_ = self.loss_
 
+        if self.min_weight_fraction_leaf != 'deprecated':
+            warnings.warn("'min_weight_fraction_leaf' is deprecated in 0.20 "
+                          "and will be fixed to a value of 0 in 0.22.",
+                          DeprecationWarning)
+            min_weight_fraction_leaf = self.min_weight_fraction_leaf
+        else:
+            min_weight_fraction_leaf = 0.
+
         # Set min_weight_leaf from min_weight_fraction_leaf
-        if self.min_weight_fraction_leaf != 0. and sample_weight is not None:
-            min_weight_leaf = (self.min_weight_fraction_leaf *
+        if min_weight_fraction_leaf != 0. and sample_weight is not None:
+            min_weight_leaf = (min_weight_fraction_leaf *
                                np.sum(sample_weight))
         else:
             min_weight_leaf = 0.
