diff --git a/doc/modules/pipeline.rst b/doc/modules/pipeline.rst
index e40ec3ecd8..9f10b6d6f1 100755
--- a/doc/modules/pipeline.rst
+++ b/doc/modules/pipeline.rst
@@ -42,7 +42,7 @@ is an estimator object::
     >>> clf # doctest: +NORMALIZE_WHITESPACE
     Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=None,
         whiten=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None,
-        coef0=0.0, degree=3, decision_function_shape=None, gamma=0.0,
+        coef0=0.0, decision_function_shape=None, degree=3, gamma=0.0,
         kernel='rbf', max_iter=-1, probability=False, random_state=None,
         shrinking=True, tol=0.001, verbose=False))])
 
diff --git a/doc/modules/svm.rst b/doc/modules/svm.rst
index 6563afea5c..ba28d77b49 100755
--- a/doc/modules/svm.rst
+++ b/doc/modules/svm.rst
@@ -77,7 +77,7 @@ n_features]`` holding the training samples, and an array y of class labels
     >>> clf = svm.SVC()
     >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE
     SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
-        degree=3, decision_function_shape=None, gamma=0.0, kernel='rbf',
+        decision_function_shape=None, degree=3, gamma=0.0, kernel='rbf',
         max_iter=-1, probability=False, random_state=None, shrinking=True,
         tol=0.001, verbose=False)
 
@@ -110,19 +110,27 @@ Multi-class classification
 :class:`SVC` and :class:`NuSVC` implement the "one-against-one"
 approach (Knerr et al., 1990) for multi- class classification. If
 ``n_class`` is the number of classes, then ``n_class * (n_class - 1) / 2``
-classifiers are constructed and each one trains data from two classes::
+classifiers are constructed and each one trains data from two classes.
+To provide a consistent interface with other classifiers, the
+``decision_function_shape`` option allows to aggregate the results of the
+"one-against-one" classifiers to a decision function of shape ``(n_samples,
+n_classes)``::
 
     >>> X = [[0], [1], [2], [3]]
     >>> Y = [0, 1, 2, 3]
-    >>> clf = svm.SVC()
+    >>> clf = svm.SVC(decision_function_shape='ovo')
     >>> clf.fit(X, Y) # doctest: +NORMALIZE_WHITESPACE
     SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
-        degree=3, decision_function_shape=None, gamma=0.0, kernel='rbf',
+        decision_function_shape='ovo', degree=3, gamma=0.0, kernel='rbf',
         max_iter=-1, probability=False, random_state=None, shrinking=True,
         tol=0.001, verbose=False)
     >>> dec = clf.decision_function([[1]])
     >>> dec.shape[1] # 4 classes: 4*3/2 = 6
     6
+    >>> clf.decision_function_shape = "ovr"
+    >>> dec = clf.decision_function([[1]])
+    >>> dec.shape[1] # 4 classes
+    4
 
 On the other hand, :class:`LinearSVC` implements "one-vs-the-rest"
 multi-class strategy, thus training n_class models. If there are only
diff --git a/doc/tutorial/basic/tutorial.rst b/doc/tutorial/basic/tutorial.rst
index 741684d3b3..fd6f9d6c84 100755
--- a/doc/tutorial/basic/tutorial.rst
+++ b/doc/tutorial/basic/tutorial.rst
@@ -286,7 +286,6 @@ Regression targets are cast to ``float64``, classification targets are
 maintained::
     >>> from sklearn import datasets
     >>> from sklearn.svm import SVC
-
     >>> iris = datasets.load_iris()
     >>> clf = SVC()
     >>> clf.fit(iris.data, iris.target)  # doctest: +NORMALIZE_WHITESPACE
diff --git a/examples/preprocessing/README.txt b/examples/preprocessing/README.txt
index c871e577e3..3a7784cf43 100755
--- a/examples/preprocessing/README.txt
+++ b/examples/preprocessing/README.txt
@@ -1,6 +1,6 @@
 .. _preprocessing_examples:
 
 Preprocessing
-------------
+-------------
 
 Examples concerning the :mod:`sklearn.preprocessing` module.
