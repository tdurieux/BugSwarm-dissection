diff --git a/build_tools/circle/build_doc.sh b/build_tools/circle/build_doc.sh
index 86231f8de4..e290b8ca93 100755
--- a/build_tools/circle/build_doc.sh
+++ b/build_tools/circle/build_doc.sh
@@ -92,6 +92,8 @@ else
     make_args=html
 fi
 
+make_args="SPHINXOPTS=-T $make_args"  # show full traceback on exception
+
 # Installing required system packages to support the rendering of math
 # notation in the HTML documentation
 sudo -E apt-get -yq update
diff --git a/doc/developers/tips.rst b/doc/developers/tips.rst
index 1388edd441..9e66174a7e 100755
--- a/doc/developers/tips.rst
+++ b/doc/developers/tips.rst
@@ -103,6 +103,11 @@ replies <https://github.com/settings/replies/>`_ for reviewing:
 ..
     Note that putting this content on a single line in a literal is the easiest way to make it copyable and wrapped on screen.
 
+Issue: Usage questions
+    ::
+
+        You're asking a usage question. The issue tracker is mainly for bugs and new features. For usage questions, it is recommended to try [Stack Overflow](https://stackoverflow.com/questions/tagged/scikit-learn) or [the Mailing List](https://mail.python.org/mailman/listinfo/scikit-learn).
+
 Issue: You're welcome to update the docs
     ::
 
diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst
index 27c9641dec..3a2d3d33ce 100755
--- a/doc/whats_new/v0.20.rst
+++ b/doc/whats_new/v0.20.rst
@@ -830,6 +830,12 @@ Misc
   indices should be rejected.
   :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.
 
+Preprocessing
+
+- In :class:`preprocessing.FunctionTransformer`, the default of ``validate``
+  will be from ``True`` to ``False`` in 0.22.
+  :issue:`10655` by :user:`Guillaume Lemaitre <glemaitre>`.
+
 Changes to estimator checks
 ---------------------------
 
diff --git a/sklearn/linear_model/passive_aggressive.py b/sklearn/linear_model/passive_aggressive.py
index dc48b7362b..6ad331772d 100755
--- a/sklearn/linear_model/passive_aggressive.py
+++ b/sklearn/linear_model/passive_aggressive.py
@@ -45,11 +45,6 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -57,6 +52,11 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
@@ -297,11 +297,6 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -309,6 +304,11 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
diff --git a/sklearn/linear_model/perceptron.py b/sklearn/linear_model/perceptron.py
index 64cbecef7e..1a01e1ba22 100755
--- a/sklearn/linear_model/perceptron.py
+++ b/sklearn/linear_model/perceptron.py
@@ -68,11 +68,6 @@ class Perceptron(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -80,6 +75,11 @@ class Perceptron(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
diff --git a/sklearn/linear_model/stochastic_gradient.py b/sklearn/linear_model/stochastic_gradient.py
index b46caa7d5f..34b4025d01 100755
--- a/sklearn/linear_model/stochastic_gradient.py
+++ b/sklearn/linear_model/stochastic_gradient.py
@@ -851,11 +851,6 @@ class SGDClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -863,6 +858,11 @@ class SGDClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
@@ -1460,11 +1460,6 @@ class SGDRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -1472,6 +1467,11 @@ class SGDRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     warm_start : bool, optional
         When set to True, reuse the solution of the previous call to fit as
         initialization, otherwise, just erase the previous solution.
diff --git a/sklearn/preprocessing/_function_transformer.py b/sklearn/preprocessing/_function_transformer.py
index f2a1290685..0c79543338 100755
--- a/sklearn/preprocessing/_function_transformer.py
+++ b/sklearn/preprocessing/_function_transformer.py
@@ -42,10 +42,16 @@ class FunctionTransformer(BaseEstimator, TransformerMixin):
 
     validate : bool, optional default=True
         Indicate that the input X array should be checked before calling
-        func. If validate is false, there will be no input validation.
-        If it is true, then X will be converted to a 2-dimensional NumPy
-        array or sparse matrix. If this conversion is not possible or X
-        contains NaN or infinity, an exception is raised.
+        ``func``. The possibilities are:
+
+        - If False, there is no input validation.
+        - If True, then X will be converted to a 2-dimensional NumPy array or
+          sparse matrix. If the conversion is not possible an exception is
+          raised.
+
+        .. deprecated:: 0.20
+           ``validate=True`` as default will be replaced by
+           ``validate=False`` in 0.22.
 
     accept_sparse : boolean, optional
         Indicate that func accepts a sparse matrix as input. If validate is
@@ -72,7 +78,7 @@ class FunctionTransformer(BaseEstimator, TransformerMixin):
         Dictionary of additional keyword arguments to pass to inverse_func.
 
     """
-    def __init__(self, func=None, inverse_func=None, validate=True,
+    def __init__(self, func=None, inverse_func=None, validate=None,
                  accept_sparse=False, pass_y='deprecated', check_inverse=True,
                  kw_args=None, inv_kw_args=None):
         self.func = func
@@ -84,6 +90,19 @@ def __init__(self, func=None, inverse_func=None, validate=True,
         self.kw_args = kw_args
         self.inv_kw_args = inv_kw_args
 
+    def _check_input(self, X):
+        # FIXME: Future warning to be removed in 0.22
+        if self.validate is None:
+            self._validate = True
+            warnings.warn("The default validate=True will be replaced by "
+                          "validate=False in 0.22.", FutureWarning)
+        else:
+            self._validate = self.validate
+
+        if self._validate:
+            return check_array(X, accept_sparse=self.accept_sparse)
+        return X
+
     def _check_inverse_transform(self, X):
         """Check that func and inverse_func are the inverse."""
         idx_selected = slice(None, None, max(1, X.shape[0] // 100))
@@ -111,8 +130,7 @@ def fit(self, X, y=None):
         -------
         self
         """
-        if self.validate:
-            X = check_array(X, self.accept_sparse)
+        X = self._check_input(X)
         if (self.check_inverse and not (self.func is None or
                                         self.inverse_func is None)):
             self._check_inverse_transform(X)
@@ -165,8 +183,7 @@ def inverse_transform(self, X, y='deprecated'):
                                kw_args=self.inv_kw_args)
 
     def _transform(self, X, y=None, func=None, kw_args=None):
-        if self.validate:
-            X = check_array(X, self.accept_sparse)
+        X = self._check_input(X)
 
         if func is None:
             func = _identity
diff --git a/sklearn/preprocessing/tests/test_function_transformer.py b/sklearn/preprocessing/tests/test_function_transformer.py
index 4d16645777..0bd57a8596 100755
--- a/sklearn/preprocessing/tests/test_function_transformer.py
+++ b/sklearn/preprocessing/tests/test_function_transformer.py
@@ -1,3 +1,4 @@
+import pytest
 import numpy as np
 from scipy import sparse
 
@@ -145,7 +146,8 @@ def test_check_inverse():
         trans = FunctionTransformer(func=np.sqrt,
                                     inverse_func=np.around,
                                     accept_sparse=accept_sparse,
-                                    check_inverse=True)
+                                    check_inverse=True,
+                                    validate=True)
         assert_warns_message(UserWarning,
                              "The provided functions are not strictly"
                              " inverse of each other. If you are sure you"
@@ -156,15 +158,38 @@ def test_check_inverse():
         trans = FunctionTransformer(func=np.expm1,
                                     inverse_func=np.log1p,
                                     accept_sparse=accept_sparse,
-                                    check_inverse=True)
+                                    check_inverse=True,
+                                    validate=True)
         Xt = assert_no_warnings(trans.fit_transform, X)
         assert_allclose_dense_sparse(X, trans.inverse_transform(Xt))
 
     # check that we don't check inverse when one of the func or inverse is not
     # provided.
     trans = FunctionTransformer(func=np.expm1, inverse_func=None,
-                                check_inverse=True)
+                                check_inverse=True, validate=True)
     assert_no_warnings(trans.fit, X_dense)
     trans = FunctionTransformer(func=None, inverse_func=np.expm1,
-                                check_inverse=True)
+                                check_inverse=True, validate=True)
     assert_no_warnings(trans.fit, X_dense)
+
+
+@pytest.mark.parametrize("validate, expected_warning",
+                         [(None, FutureWarning),
+                          (True, None),
+                          (False, None)])
+def test_function_transformer_future_warning(validate, expected_warning):
+    # FIXME: to be removed in 0.22
+    X = np.random.randn(100, 10)
+    transformer = FunctionTransformer(validate=validate)
+    with pytest.warns(expected_warning) as results:
+        transformer.fit_transform(X)
+    if expected_warning is None:
+        assert len(results) == 0
+
+
+def test_function_transformer_frame():
+    pd = pytest.importorskip('pandas')
+    X_df = pd.DataFrame(np.random.randn(100, 10))
+    transformer = FunctionTransformer(validate=False)
+    X_df_trans = transformer.fit_transform(X_df)
+    assert hasattr(X_df_trans, 'loc')
diff --git a/sklearn/tree/tree.py b/sklearn/tree/tree.py
index af216f1906..7105a86ce0 100755
--- a/sklearn/tree/tree.py
+++ b/sklearn/tree/tree.py
@@ -1152,7 +1152,7 @@ class ExtraTreeClassifier(DecisionTreeClassifier):
         The function to measure the quality of a split. Supported criteria are
         "gini" for the Gini impurity and "entropy" for the information gain.
 
-    splitter : string, optional (default="best")
+    splitter : string, optional (default="random")
         The strategy used to choose the split at each node. Supported
         strategies are "best" to choose the best split and "random" to choose
         the best random split.
@@ -1189,7 +1189,7 @@ class ExtraTreeClassifier(DecisionTreeClassifier):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    max_features : int, float, string or None, optional (default=None)
+    max_features : int, float, string or None, optional (default="auto")
         The number of features to consider when looking for the best split:
 
             - If int, then consider `max_features` features at each split.
@@ -1336,7 +1336,7 @@ class ExtraTreeRegressor(DecisionTreeRegressor):
         .. versionadded:: 0.18
            Mean Absolute Error (MAE) criterion.
 
-    splitter : string, optional (default="best")
+    splitter : string, optional (default="random")
         The strategy used to choose the split at each node. Supported
         strategies are "best" to choose the best split and "random" to choose
         the best random split.
@@ -1373,7 +1373,7 @@ class ExtraTreeRegressor(DecisionTreeRegressor):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    max_features : int, float, string or None, optional (default=None)
+    max_features : int, float, string or None, optional (default="auto")
         The number of features to consider when looking for the best split:
 
         - If int, then consider `max_features` features at each split.
