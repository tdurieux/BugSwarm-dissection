diff --git a/.gitignore b/.gitignore
index 04eb28083e..066707713b 100644
--- a/.gitignore
+++ b/.gitignore
@@ -19,6 +19,7 @@ dmypy.json
 # Packages
 *.egg
 *.egg-info
+*.eggs
 
 # IDEs
 .idea
@@ -33,3 +34,5 @@ htmlcov
 
 # pytest cache
 .pytest_cache/
+
+.tox
diff --git a/MANIFEST.in b/MANIFEST.in
index 30211b0fc3..7301cd59c1 100644
--- a/MANIFEST.in
+++ b/MANIFEST.in
@@ -3,5 +3,6 @@ recursive-include test-data *
 recursive-include extensions *
 recursive-include docs *
 include runtests.py
+include waiter.py
 include mypy_self_check.ini
 include LICENSE
diff --git a/README.md b/README.md
index aed360e517..be4cd3c597 100644
--- a/README.md
+++ b/README.md
@@ -1,8 +1,11 @@
+<img src="http://mypy-lang.org/static/mypy_light.svg" alt="mypy logo" width="300px"/>
+
 Mypy: Optional Static Typing for Python
 =======================================
 
 [![Build Status](https://api.travis-ci.org/python/mypy.svg?branch=master)](https://travis-ci.org/python/mypy)
 [![Chat at https://gitter.im/python/typing](https://badges.gitter.im/python/typing.svg)](https://gitter.im/python/typing?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
+[![Checked with mypy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)
 
 
 Got a question? Join us on Gitter!
@@ -108,7 +111,8 @@ Mypy can be integrated into popular IDEs:
 * Emacs: using [Flycheck](https://github.com/flycheck/) and [Flycheck-mypy](https://github.com/lbolla/emacs-flycheck-mypy)
 * Sublime Text: [SublimeLinter-contrib-mypy](https://github.com/fredcallaway/SublimeLinter-contrib-mypy)
 * Atom: [linter-mypy](https://atom.io/packages/linter-mypy)
-* PyCharm: PyCharm integrates [its own implementation of PEP 484](https://www.jetbrains.com/help/pycharm/2017.1/type-hinting-in-pycharm.html).
+* PyCharm: [mypy plugin](https://github.com/dropbox/mypy-PyCharm-plugin) (PyCharm integrates [its own implementation of PEP 484](https://www.jetbrains.com/help/pycharm/type-hinting-in-product.html))
+* VS Code: provides [basic integration](https://code.visualstudio.com/docs/python/linting#_mypy) with mypy.
 
 Mypy can also be integrated into [Flake8] using [flake8-mypy].
 
diff --git a/ROADMAP.md b/ROADMAP.md
index 76132e5f7f..e79790dfc5 100644
--- a/ROADMAP.md
+++ b/ROADMAP.md
@@ -8,17 +8,6 @@ core team member that nobody else is working on the same thing.
 **Note:** This doesnâ€™t include everything that the core team will work
 on, and everything is subject to change.
 
-- Make it possible to run mypy as a daemon to avoid reprocessing the
-  entire program on each run. This will improve performance
-  significantly. Even when using the incremental mode, processing a
-  large number of files is not cheap.
-
-- Provide much faster, reliable interactive feedback through
-  fine-grained incremental type checking, built on top of the daemon
-  mode.
-
-- Turn on `--strict-optional` by default.
-
 - Continue making error messages more useful and informative.
   ([issue](https://github.com/python/mypy/labels/topic-usability))
 
diff --git a/docs/source/additional_features.rst b/docs/source/additional_features.rst
index 44a98a4dd2..14b0ce2061 100644
--- a/docs/source/additional_features.rst
+++ b/docs/source/additional_features.rst
@@ -307,7 +307,7 @@ build::
 
 This flag adds extra information for the daemon to the cache. In
 order to use this extra information, you will also need to use the
-``--use-fine-grained-cache`` option with ``dymypy start`` or
+``--use-fine-grained-cache`` option with ``dmypy start`` or
 ``dmypy restart``. Example::
 
     $ dmypy start -- --use-fine-grained-cache <options...>
diff --git a/docs/source/basics.rst b/docs/source/basics.rst
deleted file mode 100644
index b4cf68c035..0000000000
--- a/docs/source/basics.rst
+++ /dev/null
@@ -1,189 +0,0 @@
-Basics
-======
-
-This chapter introduces some core concepts of mypy, including function
-annotations, the ``typing`` module and library stubs. Read it carefully,
-as the rest of documentation may not make much sense otherwise.
-
-Function signatures
-*******************
-
-A function without a type annotation is considered dynamically typed:
-
-.. code-block:: python
-
-   def greeting(name):
-       return 'Hello, {}'.format(name)
-
-You can declare the signature of a function using the Python 3
-annotation syntax (Python 2 is discussed later in :ref:`python2`).
-This makes the function statically typed, and that causes type
-checker report type errors within the function.
-
-Here's a version of the above function that is statically typed and
-will be type checked:
-
-.. code-block:: python
-
-   def greeting(name: str) -> str:
-       return 'Hello, {}'.format(name)
-
-If a function does not explicitly return a value we give the return
-type as ``None``. Using a ``None`` result in a statically typed
-context results in a type check error:
-
-.. code-block:: python
-
-   def p() -> None:
-       print('hello')
-
-   a = p()   # Type check error: p has None return value
-
-Arguments with default values can be annotated as follows:
-
-.. code-block:: python
-
-   def greeting(name: str, prefix: str = 'Mr.') -> str:
-      return 'Hello, {} {}'.format(name, prefix)
-
-Running mypy
-************
-
-You can type check a program by using the ``mypy`` tool, which is
-basically a linter -- it checks your program for errors without actually
-running it::
-
-   $ mypy program.py
-
-All errors reported by mypy are essentially warnings that you are free
-to ignore, if you so wish.
-
-The next chapter explains how to download and install mypy:
-:ref:`getting-started`.
-
-More command line options are documented in :ref:`command-line`.
-
-.. note::
-
-   Depending on how mypy is configured, you may have to run mypy like
-   this::
-
-     $ python3 -m mypy program.py
-
-The typing module
-*****************
-
-The ``typing`` module contains many definitions that are useful in
-statically typed code. You typically use ``from ... import`` to import
-them (we'll explain ``Iterable`` later in this document):
-
-.. code-block:: python
-
-   from typing import Iterable
-
-   def greet_all(names: Iterable[str]) -> None:
-       for name in names:
-           print('Hello, {}'.format(name))
-
-For brevity, we often omit the ``typing`` import in code examples, but
-mypy will give an error if you use definitions such as ``Iterable``
-without first importing them.
-
-Mixing dynamic and static typing
-********************************
-
-Mixing dynamic and static typing within a single file is often
-useful. For example, if you are migrating existing Python code to
-static typing, it may be easiest to do this incrementally, such as by
-migrating a few functions at a time. Also, when prototyping a new
-feature, you may decide to first implement the relevant code using
-dynamic typing and only add type signatures later, when the code is
-more stable.
-
-.. code-block:: python
-
-   def f():
-       1 + 'x'  # No static type error (dynamically typed)
-
-   def g() -> None:
-       1 + 'x'  # Type check error (statically typed)
-
-.. note::
-
-   The earlier stages of mypy, known as the semantic analysis, may
-   report errors even for dynamically typed functions. However, you
-   should not rely on this, as this may change in the future.
-
-.. _library-stubs:
-
-Library stubs and the Typeshed repo
-***********************************
-
-In order to type check code that uses library modules such as those
-included in the Python standard library, you need to have library
-*stubs*. A library stub defines a skeleton of the public interface
-of the library, including classes, variables and functions and
-their types, but dummy function bodies.
-
-For example, consider this code:
-
-.. code-block:: python
-
-  x = chr(4)
-
-Without a library stub, the type checker would have no way of
-inferring the type of ``x`` and checking that the argument to ``chr``
-has a valid type. Mypy incorporates the `typeshed
-<https://github.com/python/typeshed>`_ project, which contains library
-stubs for the Python builtins and the standard library. The stub for
-the builtins contains a definition like this for ``chr``:
-
-.. code-block:: python
-
-    def chr(code: int) -> str: ...
-
-In stub files we don't care about the function bodies, so we use
-an ellipsis instead.  That ``...`` is three literal dots!
-
-Mypy complains if it can't find a stub (or a real module) for a
-library module that you import. You can create a stub easily; here is
-an overview:
-
-* Write a stub file for the library and store it as a ``.pyi`` file in
-  the same directory as the library module.
-* Alternatively, put your stubs (``.pyi`` files) in a directory
-  reserved for stubs (e.g., ``myproject/stubs``). In this case you
-  have to set the environment variable ``MYPYPATH`` to refer to the
-  directory.  For example::
-
-    $ export MYPYPATH=~/work/myproject/stubs
-
-Use the normal Python file name conventions for modules, e.g. ``csv.pyi``
-for module ``csv``. Use a subdirectory with ``__init__.pyi`` for packages.
-
-If a directory contains both a ``.py`` and a ``.pyi`` file for the
-same module, the ``.pyi`` file takes precedence. This way you can
-easily add annotations for a module even if you don't want to modify
-the source code. This can be useful, for example, if you use 3rd party
-open source libraries in your program (and there are no stubs in
-typeshed yet).
-
-That's it! Now you can access the module in mypy programs and type check
-code that uses the library. If you write a stub for a library module,
-consider making it available for other programmers that use mypy
-by contributing it back to the typeshed repo.
-
-There is more information about creating stubs in the
-`mypy wiki <https://github.com/python/mypy/wiki/Creating-Stubs-For-Python-Modules>`_.
-The following sections explain the kinds of type annotations you can use
-in your programs and stub files.
-
-.. note::
-
-   You may be tempted to point ``MYPYPATH`` to the standard library or
-   to the ``site-packages`` directory where your 3rd party packages
-   are installed. This is almost always a bad idea -- you will likely
-   get tons of error messages about code you didn't write and that
-   mypy can't analyze all that well yet, and in the worst case
-   scenario mypy may crash due to some construct in a 3rd party
-   package that it didn't expect.
diff --git a/docs/source/cheat_sheet.rst b/docs/source/cheat_sheet.rst
index aec927b59e..efd140c93d 100644
--- a/docs/source/cheat_sheet.rst
+++ b/docs/source/cheat_sheet.rst
@@ -3,7 +3,8 @@
 Type hints cheat sheet (Python 2)
 =================================
 
-This document is a quick cheat sheet showing how the `PEP 484 <https://www.python.org/dev/peps/pep-0484/>`_ type
+This document is a quick cheat sheet showing how the
+`PEP 484 <https://www.python.org/dev/peps/pep-0484/>`_ type
 language represents various common types in Python 2.
 
 .. note::
@@ -21,35 +22,32 @@ Built-in types
 
    from typing import List, Set, Dict, Tuple, Text, Optional
 
-   # For simple built-in types, just use the name of the type.
-   x = 1 # type: int
-   x = 1.0 # type: float
-   x = True # type: bool
-   x = "test" # type: str
-   x = u"test" # type: unicode
+   # For simple built-in types, just use the name of the type
+   x = 1  # type: int
+   x = 1.0  # type: float
+   x = True  # type: bool
+   x = "test"  # type: str
+   x = u"test"  # type: unicode
 
    # For collections, the name of the type is capitalized, and the
-   # name of the type inside the collection is in brackets.
-   x = [1] # type: List[int]
-   x = set([6, 7]) # type: Set[int]
+   # name of the type inside the collection is in brackets
+   x = [1]  # type: List[int]
+   x = {6, 7}  # type: Set[int]
 
-   # Empty Tuple types are a bit special
-   x = ()  # type: Tuple[()]
+   # For mappings, we need the types of both keys and values
+   x = {'field': 2.0}  # type: Dict[str, float]
 
-   # For mappings, we need the types of both keys and values.
-   x = dict(field=2.0) # type: Dict[str, float]
+   # For tuples, we specify the types of all the elements
+   x = (3, "yes", 7.5)  # type: Tuple[int, str, float]
 
-   # For tuples, we specify the types of all the elements.
-   x = (3, "yes", 7.5) # type: Tuple[int, str, float]
+   # For textual data, use Text
+   # ("Text" means  "unicode" in Python 2 and "str" in Python 3)
+   x = [u"one", u"two"]  # type: List[Text]
 
-   # For textual data, use Text.
-   # This is `unicode` in Python 2 and `str` in Python 3.
-   x = ["string", u"unicode"] # type: List[Text]
-
-   # Use Optional for values that could be None.
-   input_str = f() # type: Optional[str]
-   if input_str is not None:
-      print input_str
+   # Use Optional[] for values that could be None
+   x = some_function()  # type: Optional[str]
+   if x is not None:
+      print x
 
 
 Functions
@@ -57,9 +55,9 @@ Functions
 
 .. code-block:: python
 
-   from typing import Callable, Iterable
+   from typing import Callable, Iterable, Union, Optional, List
 
-   # This is how you annotate a function definition.
+   # This is how you annotate a function definition
    def stringify(num):
        # type: (int) -> str
        """Your function docstring goes here after the type definition."""
@@ -70,29 +68,31 @@ Functions
    def greet_world(): # type: () -> None
        print "Hello, world!"
 
-   # And here's how you specify multiple arguments.
+   # And here's how you specify multiple arguments
    def plus(num1, num2):
        # type: (int, int) -> int
        return num1 + num2
 
-   # Add type annotations for kwargs as though they were positional args.
+   # Add type annotations for arguments with default values as though they
+   # had no defaults
    def f(num1, my_float=3.5):
        # type: (int, float) -> float
        return num1 + my_float
 
    # An argument can be declared positional-only by giving it a name
-   # starting with two underscores:
+   # starting with two underscores
    def quux(__x):
        # type: (int) -> None
        pass
+
    quux(3)  # Fine
    quux(__x=3)  # Error
 
-   # This is how you annotate a function value.
-   x = f # type: Callable[[int, float], float]
+   # This is how you annotate a callable (function) value
+   x = f  # type: Callable[[int, float], float]
 
    # A generator function that yields ints is secretly just a function that
-   # returns an iterable (see below) of ints, so that's how we annotate it.
+   # returns an iterable (see below) of ints, so that's how we annotate it
    def f(n):
        # type: (int) -> Iterable[int]
        i = 0
@@ -100,7 +100,7 @@ Functions
            yield i
            i += 1
 
-   # There's alternative syntax for functions with many arguments.
+   # There's an alternative syntax for functions with many arguments
    def send_email(address,     # type: Union[str, List[str]]
                   sender,      # type: str
                   cc,          # type: Optional[List[str]]
@@ -109,7 +109,7 @@ Functions
                   body=None    # type: List[str]
                   ):
        # type: (...) -> bool
-        <code>
+       <code>
 
 
 When you're puzzled or when things are complicated
@@ -117,59 +117,63 @@ When you're puzzled or when things are complicated
 
 .. code-block:: python
 
-   from typing import Union, Any, cast
+   from typing import Union, Any, List, Optional, cast
 
    # To find out what type mypy infers for an expression anywhere in
-   # your program, wrap it in reveal_type.  Mypy will print an error
+   # your program, wrap it in reveal_type().  Mypy will print an error
    # message with the type; remove it again before running the code.
-   reveal_type(1) # -> error: Revealed type is 'builtins.int'
+   reveal_type(1) # -> Revealed type is 'builtins.int'
 
-   # Use Union when something could be one of a few types.
-   x = [3, 5, "test", "fun"] # type: List[Union[int, str]]
+   # Use Union when something could be one of a few types
+   x = [3, 5, "test", "fun"]  # type: List[Union[int, str]]
 
    # Use Any if you don't know the type of something or it's too
-   # dynamic to write a type for.
-   x = mystery_function() # type: Any
+   # dynamic to write a type for
+   x = mystery_function()  # type: Any
+
+   # If you initialize a variable with an empty container or "None"
+   # you may have to help mypy a bit by providing a type annotation
+   x = []  # type: List[str]
+   x = None  # type: Optional[str]
 
-   # This is how to deal with varargs.
-   # This makes each positional arg and each keyword arg a 'str'.
+   # This makes each positional arg and each keyword arg a "str"
    def call(self, *args, **kwargs):
-            # type: (*str, **str) -> str
-            request = make_request(*args, **kwargs)
-            return self.do_api_query(request)
-   
-   # Use `ignore` to suppress type-checking on a given line, when your
-   # code confuses mypy or runs into an outright bug in mypy.
-   # Good practice is to comment every `ignore` with a bug link
+       # type: (*str, **str) -> str
+       request = make_request(*args, **kwargs)
+       return self.do_api_query(request)
+
+   # Use a "type: ignore" comment to suppress errors on a given line,
+   # when your code confuses mypy or runs into an outright bug in mypy.
+   # Good practice is to comment every "ignore" with a bug link
    # (in mypy, typeshed, or your own code) or an explanation of the issue.
    x = confusing_function() # type: ignore # https://github.com/python/mypy/issues/1167
 
-   # cast is a helper function for mypy that allows for guidance of how to convert types.
-   # it does not cast at runtime
+   # "cast" is a helper function that lets you override the inferred
+   # type of an expression. It's only for mypy -- there's no runtime check.
    a = [4]
-   b = cast(List[int], a)  # passes fine
-   c = cast(List[str], a)  # passes fine (no runtime check)
-   reveal_type(c)  # -> error: Revealed type is 'builtins.list[builtins.str]'
-   print(c)  # -> [4] the object is not cast
-
-   # if you want dynamic attributes on your class, have it override __setattr__ or __getattr__
-   # in a stub or in your source code.
-   # __setattr__ allows for dynamic assignment to names
-   # __getattr__ allows for dynamic access to names
+   b = cast(List[int], a)  # Passes fine
+   c = cast(List[str], a)  # Passes fine (no runtime check)
+   reveal_type(c)  # -> Revealed type is 'builtins.list[builtins.str]'
+   print c  # -> [4]; the object is not cast
+
+   # If you want dynamic attributes on your class, have it override "__setattr__"
+   # or "__getattr__" in a stub or in your source code.
+   #
+   # "__setattr__" allows for dynamic assignment to names
+   # "__getattr__" allows for dynamic access to names
    class A:
-       # this will allow assignment to any A.x, if x is the same type as `value`
+       # This will allow assignment to any A.x, if x is the same type as "value"
+       # (use "value: Any" to allow arbitrary types)
        def __setattr__(self, name, value):
            # type: (str, int) -> None
            ...
-   a.foo = 42  # works
-   a.bar = 'Ex-parrot'  # fails type checking
 
-   # TODO: explain "Need type annotation for variable" when
-   # initializing with None or an empty container
+   a.foo = 42  # Works
+   a.bar = 'Ex-parrot'  # Fails type checking
 
 
-Standard duck types
-*******************
+Standard "duck types"
+*********************
 
 In typical Python code, many functions that can take a list or a dict
 as an argument only need their argument to be somehow "list-like" or
@@ -181,23 +185,28 @@ that are common in idiomatic Python are standardized.
 
    from typing import Mapping, MutableMapping, Sequence, Iterable
 
-   # Use Iterable for generic iterables (anything usable in `for`),
-   # and Sequence where a sequence (supporting `len` and `__getitem__`) is required.
+   # Use Iterable for generic iterables (anything usable in "for"),
+   # and Sequence where a sequence (supporting "len" and "__getitem__") is
+   # required
    def f(iterable_of_ints):
        # type: (Iterable[int]) -> List[str]
        return [str(x) for x in iterator_of_ints]
+
    f(range(1, 3))
 
-   # Mapping describes a dict-like object (with `__getitem__`) that we won't mutate,
-   # and MutableMapping one (with `__setitem__`) that we might.
+   # Mapping describes a dict-like object (with "__getitem__") that we won't
+   # mutate, and MutableMapping one (with "__setitem__") that we might
    def f(my_dict):
        # type: (Mapping[int, str]) -> List[int]
        return list(my_dict.keys())
+
    f({3: 'yes', 4: 'no'})
+
    def f(my_mapping):
        # type: (MutableMapping[int, str]) -> Set[str]
        my_dict[5] = 'maybe'
        return set(my_dict.values())
+
    f({3: 'yes', 4: 'no'})
 
 
@@ -207,43 +216,36 @@ Classes
 .. code-block:: python
 
    class MyClass(object):
-
-       # For instance methods, omit `self`.
+       # For instance methods, omit type for "self"
        def my_method(self, num, str1):
            # type: (int, str) -> str
            return num * str1
 
-       # The __init__ method doesn't return anything, so it gets return
-       # type None just like any other method that doesn't return anything.
+       # The "__init__" method doesn't return anything, so it gets return
+       # type "None" just like any other method that doesn't return anything
        def __init__(self):
            # type: () -> None
            pass
 
-   # User-defined classes are written with just their own names.
-   x = MyClass() # type: MyClass
+   # User-defined classes are valid as types in annotations
+   x = MyClass()  # type: MyClass
 
 
-Other stuff
-***********
+Miscellaneous
+*************
 
 .. code-block:: python
 
    import sys
-   # typing.Match describes regex matches from the re module.
+   import re
    from typing import Match, AnyStr, IO
-   x = re.match(r'[0-9]+', "15") # type: Match[str]
 
-   # Use AnyStr for functions that should accept any kind of string
-   # without allowing different kinds of strings to mix.
-   def concat(a, b):
-       # type: (AnyStr, AnyStr) -> AnyStr
-       return a + b
-   concat(u"foo", u"bar")  # type: unicode
-   concat(b"foo", b"bar")  # type: bytes
+   # "typing.Match" describes regex matches from the re module
+   x = re.match(r'[0-9]+', "15")  # type: Match[str]
 
    # Use IO[] for functions that should accept or return any
-   # object that comes from an open() call. The IO[] does not
-   # distinguish between reading, writing or other modes.
+   # object that comes from an open() call (IO[] does not
+   # distinguish between reading, writing or other modes)
    def get_sys_IO(mode='w'):
        # type: (str) -> IO[str]
        if mode == 'w':
@@ -252,6 +254,3 @@ Other stuff
            return sys.stdin
        else:
            return sys.stdout
-
-   # TODO: add TypeVar and a simple generic function
-
diff --git a/docs/source/cheat_sheet_py3.rst b/docs/source/cheat_sheet_py3.rst
index cbd1ab266e..d3988bb49e 100644
--- a/docs/source/cheat_sheet_py3.rst
+++ b/docs/source/cheat_sheet_py3.rst
@@ -3,8 +3,9 @@
 Type hints cheat sheet (Python 3)
 =================================
 
-This document is a quick cheat sheet showing how the `PEP 484 <https://www.python.org/dev/peps/pep-0484/>`_ type
-language represents various common types in Python 3. Unless otherwise noted, the syntax is valid on all versions of Python 3.
+This document is a quick cheat sheet showing how the
+`PEP 484 <https://www.python.org/dev/peps/pep-0484/>`_ type
+annotation notation represents various common types in Python 3.
 
 .. note::
 
@@ -14,6 +15,33 @@ language represents various common types in Python 3. Unless otherwise noted, th
    annotation, and show the inferred types.
 
 
+Variables
+*********
+
+Python 3.6 introduced a syntax for annotating variables in
+`PEP 526 <https://www.python.org/dev/peps/pep-0526/>`_ and
+we use it in most examples.
+
+.. code-block:: python
+
+   # This is how you declare the type of a variable type in Python 3.6
+   x: int = 1
+
+   # In Python 3.5 and earlier you can use a type comment instead
+   # (equivalent to the previous definition)
+   x = 1  # type: int
+
+   # You don't need to initialize a variable to annotate it
+   a: int  # Ok (no value at runtime until assigned)
+
+   # The latter is useful in conditional branches
+   child: bool
+   if age < 18:
+       child = True
+   else:
+       child = False
+
+
 Built-in types
 **************
 
@@ -21,188 +49,151 @@ Built-in types
 
    from typing import List, Set, Dict, Tuple, Text, Optional, AnyStr
 
-   # For simple built-in types, just use the name of the type.
-   x = 1  # type: int
-   x = 1.0  # type: float
-   x = True  # type: bool
-   x = "test"  # type: str
-   x = u"test"  # type: str
-   x = b"test"  # type: bytes
+   # For simple built-in types, just use the name of the type
+   x: int = 1
+   x: float = 1.0
+   x: bool = True
+   x: str = "test"
+   x: str = u"test"
+   x: bytes = b"test"
 
    # For collections, the name of the type is capitalized, and the
-   # name of the type inside the collection is in brackets.
-   x = [1]  # type: List[int]
-   x = {6, 7}  # type: Set[int]
-
-   # Empty Tuple types are a bit special
-   x = ()  # type: Tuple[()]
-
-   # For mappings, we need the types of both keys and values.
-   x = {'field': 2.0}  # type: Dict[str, float]
+   # name of the type inside the collection is in brackets
+   x: List[int] = [1]
+   x: Set[int] = {6, 7}
 
-   # For tuples, we specify the types of all the elements.
-   x = (3, "yes", 7.5)  # type: Tuple[int, str, float]
+   # Same as above, but with type comment syntax
+   x = [1]  # type: List[int]
 
-   # For textual data, use Text.
-   # This is `unicode` in Python 2 and `str` in Python 3.
-   x = ["string", u"unicode"]  # type: List[Text]
+   # For mappings, we need the types of both keys and values
+   x: Dict[str, float] = {'field': 2.0}
 
+   # For tuples, we specify the types of all the elements
+   x: Tuple[int, str, float] = (3, "yes", 7.5)
 
+   # For textual data, use Text if you care about Python 2 compatibility
+   # ("Text" means "unicode" in Python 2 and "str" in Python 3)
+   x: List[Text] = ["string", u"unicode"]
 
-   # Use Optional for values that could be None.
-   input_str = f()  # type: Optional[str]
-   if input_str is not None:
-      print(input_str)
+   # Use Optional[] for values that could be None
+   x: Optional[str] = some_function()
+   if x is not None:
+       print(x)
 
 
 Functions
 *********
 
-Python 3 introduces an annotation syntax for function declarations in `PEP 3107 <https://www.python.org/dev/peps/pep-3107/>`_.
+Python 3 supports an annotation syntax for function declarations.
 
 .. code-block:: python
 
    from typing import Callable, Iterable, Union, Optional, List
 
-   # This is how you annotate a function definition.
+   # This is how you annotate a function definition
    def stringify(num: int) -> str:
        return str(num)
-       
-   # And here's how you specify multiple arguments.
+
+   # And here's how you specify multiple arguments
    def plus(num1: int, num2: int) -> int:
        return num1 + num2
 
-   # Add type annotations for kwargs as though they were positional args.
+   # Add default value for an argument after the type annotation
    def f(num1: int, my_float: float = 3.5) -> float:
        return num1 + my_float
 
-   # An argument can be declared positional-only by giving it a name
-   # starting with two underscores:
-   def quux(__x: int) -> None:
-       pass
-   quux(3)  # Fine
-   quux(__x=3)  # Error
-
-   # This is how you annotate a function value.
-   x = f # type: Callable[[int, float], float]
+   # This is how you annotate a callable (function) value
+   x: Callable[[int, float], float] = f
 
    # A generator function that yields ints is secretly just a function that
-   # returns an iterable (see below) of ints, so that's how we annotate it.
+   # returns an iterable (see below) of ints, so that's how we annotate it
    def f(n: int) -> Iterable[int]:
        i = 0
        while i < n:
            yield i
            i += 1
 
-   # For a function with many arguments, you can of course split it over multiple lines
+   # You can of course split a function annotation over multiple lines
    def send_email(address: Union[str, List[str]],
                   sender: str,
                   cc: Optional[List[str]],
                   bcc: Optional[List[str]],
                   subject='',
-                  body: List[str] = None
+                  body: Optional[List[str]] = None
                   ) -> bool:
-       
        ...
 
-Coroutines and asyncio
-**********************
-
-See :ref:`async-and-await` for the full detail on typing coroutines and asynchronous code.
-
-.. code-block:: python
-
-   import asyncio
-   from typing import Generator, Any
-
-   # A generator-based coroutine created with @asyncio.coroutine should have a
-   # return type of Generator[Any, None, T], where T is the type it returns.
-   @asyncio.coroutine
-   def countdown34(tag: str, count: int) -> Generator[Any, None, str]:
-       while count > 0:
-           print('T-minus {} ({})'.format(count, tag))
-           yield from asyncio.sleep(0.1)
-           count -= 1
-       return "Blastoff!"
-
-   # mypy currently does not support converting functions into generator-based
-   # coroutines in Python 3.4, so you need to add a 'yield' to make it
-   # typecheck.
-   @asyncio.coroutine
-   def async1(obj: object) -> Generator[None, None, str]:
-       if False:
-           yield
-       return "placeholder"
+   # An argument can be declared positional-only by giving it a name
+   # starting with two underscores:
+   def quux(__x: int) -> None:
+       pass
 
-   # A Python 3.5+ coroutine is typed like a normal function.
-   async def countdown35(tag: str, count: int) -> str:
-       while count > 0:
-           print('T-minus {} ({})'.format(count, tag))
-           await asyncio.sleep(0.1)
-           count -= 1
-       return "Blastoff!"
+   quux(3)  # Fine
+   quux(__x=3)  # Error
 
-   async def async2(obj: object) -> str:
-       return "placeholder"
 
 When you're puzzled or when things are complicated
 **************************************************
 
 .. code-block:: python
 
-   from typing import Union, Any, List, cast
+   from typing import Union, Any, List, Optional, cast
 
    # To find out what type mypy infers for an expression anywhere in
-   # your program, wrap it in reveal_type.  Mypy will print an error
+   # your program, wrap it in reveal_type().  Mypy will print an error
    # message with the type; remove it again before running the code.
-   reveal_type(1)  # -> error: Revealed type is 'builtins.int'
+   reveal_type(1)  # -> Revealed type is 'builtins.int'
 
-   # Use Union when something could be one of a few types.
-   x = [3, 5, "test", "fun"]  # type: List[Union[int, str]]
+   # Use Union when something could be one of a few types
+   x: List[Union[int, str]] = [3, 5, "test", "fun"]
 
    # Use Any if you don't know the type of something or it's too
-   # dynamic to write a type for.
-   x = mystery_function()  # type: Any
+   # dynamic to write a type for
+   x: Any = mystery_function()
 
-   # This is how to deal with varargs.
-   # This makes each positional arg and each keyword arg a 'str'.
+   # If you initialize a variable with an empty container or "None"
+   # you may have to help mypy a bit by providing a type annotation
+   x: List[str] = []
+   x: Optional[str] = None
+
+   # This makes each positional arg and each keyword arg a "str"
    def call(self, *args: str, **kwargs: str) -> str:
-            request = make_request(*args, **kwargs)
-            return self.do_api_query(request)
+       request = make_request(*args, **kwargs)
+       return self.do_api_query(request)
 
-   # Use `ignore` to suppress type-checking on a given line, when your
-   # code confuses mypy or runs into an outright bug in mypy.
-   # Good practice is to comment every `ignore` with a bug link
+   # Use a "type: ignore" comment to suppress errors on a given line,
+   # when your code confuses mypy or runs into an outright bug in mypy.
+   # Good practice is to comment every "ignore" with a bug link
    # (in mypy, typeshed, or your own code) or an explanation of the issue.
-   x = confusing_function()  # type: ignore # https://github.com/python/mypy/issues/1167
+   x = confusing_function()  # type: ignore  # https://github.com/python/mypy/issues/1167
 
-   # cast is a helper function for mypy that allows for guidance of how to convert types.
-   # it does not cast at runtime
+   # "cast" is a helper function that lets you override the inferred
+   # type of an expression. It's only for mypy -- there's no runtime check.
    a = [4]
-   b = cast(List[int], a)  # passes fine
-   c = cast(List[str], a)  # passes fine (no runtime check)
-   reveal_type(c)  # -> error: Revealed type is 'builtins.list[builtins.str]'
-   print(c)  # -> [4] the object is not cast
-
-   # if you want dynamic attributes on your class, have it override __setattr__ or __getattr__
-   # in a stub or in your source code.
-   # __setattr__ allows for dynamic assignment to names
-   # __getattr__ allows for dynamic access to names
+   b = cast(List[int], a)  # Passes fine
+   c = cast(List[str], a)  # Passes fine (no runtime check)
+   reveal_type(c)  # -> Revealed type is 'builtins.list[builtins.str]'
+   print(c)  # -> [4]; the object is not cast
+
+   # If you want dynamic attributes on your class, have it override "__setattr__"
+   # or "__getattr__" in a stub or in your source code.
+   #
+   # "__setattr__" allows for dynamic assignment to names
+   # "__getattr__" allows for dynamic access to names
    class A:
-       # this will allow assignment to any A.x, if x is the same type as `value`
+       # This will allow assignment to any A.x, if x is the same type as "value"
+       # (use "value: Any" to allow arbitrary types)
        def __setattr__(self, name: str, value: int) -> None: ...
-       # this will allow access to any A.x, if x is compatible with the return type
-       def __getattr__(self, name: str) -> int: ...
-   a.foo = 42  # works
-   a.bar = 'Ex-parrot'  # fails type checking
 
+       # This will allow access to any A.x, if x is compatible with the return type
+       def __getattr__(self, name: str) -> int: ...
 
-   # TODO: explain "Need type annotation for variable" when
-   # initializing with None or an empty container
+   a.foo = 42  # Works
+   a.bar = 'Ex-parrot'  # Fails type checking
 
 
-Standard duck types
-*******************
+Standard "duck types"
+*********************
 
 In typical Python code, many functions that can take a list or a dict
 as an argument only need their argument to be somehow "list-like" or
@@ -214,20 +205,25 @@ that are common in idiomatic Python are standardized.
 
    from typing import Mapping, MutableMapping, Sequence, Iterable, List, Set
 
-   # Use Iterable for generic iterables (anything usable in `for`),
-   # and Sequence where a sequence (supporting `len` and `__getitem__`) is required.
-   def f(iterable_of_ints: Iterable[int]) -> List[str]:
-       return [str(x) for x in iterable_of_ints]
+   # Use Iterable for generic iterables (anything usable in "for"),
+   # and Sequence where a sequence (supporting "len" and "__getitem__") is
+   # required
+   def f(ints: Iterable[int]) -> List[str]:
+       return [str(x) for x in ints]
+
    f(range(1, 3))
 
-   # Mapping describes a dict-like object (with `__getitem__`) that we won't mutate,
-   # and MutableMapping one (with `__setitem__`) that we might.
-   def f(my_dict: Mapping[int, str])-> List[int]:
+   # Mapping describes a dict-like object (with "__getitem__") that we won't
+   # mutate, and MutableMapping one (with "__setitem__") that we might
+   def f(my_dict: Mapping[int, str]) -> List[int]:
        return list(my_dict.keys())
+
    f({3: 'yes', 4: 'no'})
+
    def f(my_mapping: MutableMapping[int, str]) -> Set[str]:
        my_mapping[5] = 'maybe'
        return set(my_mapping.values())
+
    f({3: 'yes', 4: 'no'})
 
 
@@ -237,43 +233,69 @@ Classes
 .. code-block:: python
 
    class MyClass:
-       # The __init__ method doesn't return anything, so it gets return
-       # type None just like any other method that doesn't return anything.
+       # You can optionally declare instance variables in the class body
+       attr: int
+       # This is an instance variable with a default value
+       charge_percent: int = 100
+
+       # The "__init__" method doesn't return anything, so it gets return
+       # type "None" just like any other method that doesn't return anything
        def __init__(self) -> None:
            ...
-       # For instance methods, omit `self`.
+
+       # For instance methods, omit type for "self"
        def my_method(self, num: int, str1: str) -> str:
            return num * str1
 
+   # User-defined classes are valid as types in annotations
+   x: MyClass = MyClass()
+
+   # You can use the ClassVar annotation to declare a class variable
+   class Car:
+       seats: ClassVar[int] = 4
+       passengers: ClassVar[List[str]]
+
+   # You can also declare the type of an attribute in "__init__"
+   class Box:
+       def __init__(self) -> None:
+           self.items: List[str] = []
+
+
+Coroutines and asyncio
+**********************
+
+See :ref:`async-and-await` for the full detail on typing coroutines and asynchronous code.
+
+.. code-block:: python
 
+   import asyncio
+   from typing import Generator, Any
 
-   # User-defined classes are written with just their own names.
-   x = MyClass() # type: MyClass
+   # A coroutine is typed like a normal function
+   async def countdown35(tag: str, count: int) -> str:
+       while count > 0:
+           print('T-minus {} ({})'.format(count, tag))
+           await asyncio.sleep(0.1)
+           count -= 1
+       return "Blastoff!"
 
 
-Other stuff
-***********
+Miscellaneous
+*************
 
 .. code-block:: python
 
    import sys
    import re
-   # typing.Match describes regex matches from the re module.
    from typing import Match, AnyStr, IO
-   x = re.match(r'[0-9]+', "15")  # type: Match[str]
 
-   # You can use AnyStr to indicate that any string type will work
-   # but not to mix types
-   def full_name(first: AnyStr, last: AnyStr) -> AnyStr:
-       return first+last
-   full_name('Jon','Doe')  # same str ok
-   full_name(b'Bill', b'Bit')  # same binary ok
-   full_name(b'Terry', 'Trouble')  # different str types, fails
+   # "typing.Match" describes regex matches from the re module
+   x: Match[str] = re.match(r'[0-9]+', "15")
 
    # Use IO[] for functions that should accept or return any
-   # object that comes from an open() call. The IO[] does not
-   # distinguish between reading, writing or other modes.
-   def get_sys_IO(mode='w') -> IO[str]:
+   # object that comes from an open() call (IO[] does not
+   # distinguish between reading, writing or other modes)
+   def get_sys_IO(mode: str = 'w') -> IO[str]:
        if mode == 'w':
            return sys.stdout
        elif mode == 'r':
@@ -281,69 +303,15 @@ Other stuff
        else:
            return sys.stdout
 
-   # forward references are useful if you want to reference a class before it is designed
-   
-   def f(foo: A) -> int:  # this will fail
+   # Forward references are useful if you want to reference a class before
+   # it is defined
+   def f(foo: A) -> int:  # This will fail
        ...
-   
+
    class A:
        ...
-       
-   # however, using the string 'A', it will pass as long as there is a class of that name later on
-   def f(foo: 'A') -> int:
-       ...
-
-   # TODO: add TypeVar and a simple generic function
-
-Variable Annotation in Python 3.6 with PEP 526
-**********************************************
 
-Python 3.6 brings new syntax for annotating variables with `PEP 526 <https://www.python.org/dev/peps/pep-0526/>`_.
-Mypy brings limited support for PEP 526 annotations.
-
-
-.. code-block:: python
-
-   # annotation is similar to arguments to functions
-   name: str = "Eric Idle"
-   
-   # class instances can be annotated as follows
-   mc : MyClass = MyClass()
-   
-   # tuple packing can be done as follows
-   tu: Tuple[str, ...] = ('a', 'b', 'c')
-   
-   # annotations are not checked at runtime
-   year: int = '1972'  # error in type checking, but works at runtime
-   
-   # these are all equivalent
-   hour = 24 # type: int
-   hour: int; hour = 24
-   hour: int = 24
-   
-   # you do not (!) need to initialize a variable to annotate it
-   a: int # ok for type checking and runtime
-   
-   # which is useful in conditional branches
-   child: bool
-   if age < 18:
-       child = True
-   else:
-       child = False
-   
-   # annotations for classes are for instance variables (those created in __init__ or __new__)
-   class Battery:
-       charge_percent: int = 100  # this is an instance variable with a default value
-       capacity: int  # an instance variable without a default
-       
-   # you can use the ClassVar annotation to make the variable a class variable instead of an instance variable.
-   class Car:
-       seats: ClassVar[int] = 4
-       passengers: ClassVar[List[str]]
-       
-    # You can also declare the type of an attribute in __init__
-    class Box:
-        def __init__(self) -> None:
-            self.items: List[str] = []
-   
-Please see :ref:`python-36` for more on mypy's compatibility with Python 3.6's new features.
+   # If you use the string literal 'A', it will pass as long as there is a
+   # class of that name later on in the file
+   def f(foo: 'A') -> int:  # Ok
+       ...
diff --git a/docs/source/common_issues.rst b/docs/source/common_issues.rst
index 253f4fc630..a93b79c135 100644
--- a/docs/source/common_issues.rst
+++ b/docs/source/common_issues.rst
@@ -417,7 +417,7 @@ understand how mypy handles a particular piece of code. Example:
    reveal_type((1, 'hello'))  # Revealed type is 'Tuple[builtins.int, builtins.str]'
 
 You can also use ``reveal_locals()`` at any line in a file
-to see the types of all local varaibles at once. Example:
+to see the types of all local variables at once. Example:
 
 .. code-block:: python
 
@@ -561,7 +561,6 @@ the protocol definition:
        x = 42
    fun(C())  # OK
 
-
 Dealing with conflicting names
 ------------------------------
 
@@ -589,3 +588,16 @@ renaming the method, a work-around is to use an alias:
            ...
        def register(self, path: bytes_):
            ...
+
+I need a mypy bug fix that hasn't been released yet
+---------------------------------------------------
+
+You can install the latest development version of mypy from source. Clone the
+`mypy repository on GitHub <https://github.com/python/mypy>`_, and then run
+``pip install`` locally:
+
+.. code-block:: text
+
+    git clone --recurse-submodules https://github.com/python/mypy.git
+    cd mypy
+    sudo python3 -m pip install --upgrade .
diff --git a/docs/source/config_file.rst b/docs/source/config_file.rst
index 698d8fefed..82dd7961a4 100644
--- a/docs/source/config_file.rst
+++ b/docs/source/config_file.rst
@@ -183,7 +183,7 @@ overridden by the pattern sections matching the module name.
   Used in conjunction with ``follow_imports=skip``, this can be used
   to suppress the import of a module from ``typeshed``, replacing it
   with `Any`.
-  Used in conjuncation with ``follow_imports=error``, this can be used
+  Used in conjunction with ``follow_imports=error``, this can be used
   to make any use of a particular ``typeshed`` module an error.
 
 - ``ignore_missing_imports`` (Boolean, default False) suppress error
diff --git a/docs/source/existing_code.rst b/docs/source/existing_code.rst
new file mode 100644
index 0000000000..df1eb75ddb
--- /dev/null
+++ b/docs/source/existing_code.rst
@@ -0,0 +1,179 @@
+.. _existing-code:
+
+Using mypy with an existing codebase
+====================================
+
+This section explains how to get started using mypy with an existing,
+significant codebase that has little or no type annotations. If you are
+a beginner, you can skip this section.
+
+These steps will get you started with mypy on an existing codebase:
+
+1. Start small -- get a clean mypy build for some files, with few
+   annotations
+
+2. Write a mypy runner script to ensure consistent results
+
+3. Run mypy in Continuous Integration to prevent type errors
+
+4. Gradually annotate commonly imported modules
+
+5. Write annotations as you modify existing code and write new code
+
+6. Use MonkeyType or PyAnnotate to automatically annotate legacy code
+
+We discuss all of these points in some detail below, and a few optional
+follow-up steps.
+
+Start small
+-----------
+
+If your codebase is large, pick a subset of your codebase (say, 5,000
+to 50,000 lines) and run mypy only on this subset at first,
+*without any annotations*. This shouldn't take more than a day or two
+to implement, so you start enjoying benefits soon.
+
+You'll likely need to fix some mypy errors, either by inserting
+annotations requested by mypy or by adding ``# type: ignore``
+comments to silence errors you don't want to fix now.
+
+In particular, mypy often generates errors about modules that it can't
+find or that don't have stub files:
+
+.. code-block:: text
+
+    core/config.py:7: error: Cannot find module named 'frobnicate'
+    core/model.py:9: error: Cannot find module named 'acme'
+    ...
+
+This is normal, and you can easily ignore these errors. For example,
+here we ignore an error about a third-party module ``frobnicate`` that
+doesn't have stubs using ``# type: ignore``:
+
+.. code-block:: python
+
+   import frobnicate  # type: ignore
+   ...
+   frobnicate.initialize()  # OK (but not checked)
+
+You can also use a mypy configuration file, which is convenient if
+there are a large number of errors to ignore. For example, to disable
+errors about importing ``frobnicate`` and ``acme`` everywhere in your
+codebase, use a config like this:
+
+.. code-block:: text
+
+   [mypy-frobnicate.*]
+   ignore_missing_imports = True
+
+   [mypy-acme.*]
+   ignore_missing_imports = True
+
+You can add multiple sections for different modules that should be
+ignored.
+
+If your config file is named ``mypy.ini``, this is how you run mypy:
+
+.. code-block:: text
+
+   mypy --config-file mypy.ini mycode/
+
+If you get a large number of errors, you may want to ignore all errors
+about missing imports.  This can easily cause problems later on and
+hide real errors, and it's only recommended as a last resort.
+For more details, look :ref:`here <follow-imports>`.
+
+Mypy follows imports by default. This can result in a few files passed
+on the command line causing mypy to process a large number of imported
+files, resulting in lots of errors you don't want to deal with at the
+moment. There is a config file option to disable this behavior, but
+since this can hide errors, it's not recommended for most users.
+
+Mypy runner script
+------------------
+
+Introduce a mypy runner script that runs mypy, so that every developer
+will use mypy consistently. Here are some things you may want to do in
+the script:
+
+* Ensure that the correct version of mypy is installed.
+
+* Specify mypy config file or command-line options.
+
+* Provide set of files to type check. You may want to implement
+  inclusion and exclusion filters for full control of the file
+  list.
+
+Continuous Integration
+----------------------
+
+Once you have a clean mypy run and a runner script for a part
+of your codebase, set up your Continuous Integration (CI) system to
+run mypy to ensure that developers won't introduce bad annotations.
+A simple CI script could look something like this:
+
+.. code-block:: text
+
+    python3 -m pip install mypy==0.600  # Pinned version avoids surprises
+    scripts/mypy  # Runs with the correct options
+
+Annotate widely imported modules
+--------------------------------
+
+Most projects have some widely imported modules, such as utilities or
+model classes. It's a good idea to annotate these pretty early on,
+since this allows code using these modules to be type checked more
+effectively. Since mypy supports gradual typing, it's okay to leave
+some of these modules unannotated. The more you annotate, the more
+useful mypy will be, but even a little annotation coverage is useful.
+
+Write annotations as you go
+---------------------------
+
+Now you are ready to include type annotations in your development
+workflows. Consider adding something like these in your code style
+conventions:
+
+1. Developers should add annotations for any new code.
+2. It's also encouraged to write annotations when you modify existing code.
+
+This way you'll gradually increase annotation coverage in your
+codebase without much effort.
+
+Automate annotation of legacy code
+----------------------------------
+
+There are tools for automatically adding draft annotations
+based on type profiles collected at runtime.  Tools include
+`MonkeyType <https://github.com/Instagram/MonkeyType>`_
+(Python 3) and `PyAnnotate <https://github.com/dropbox/pyannotate>`_
+(type comments only).
+
+A simple approach is to collect types from test runs. This may work
+well if your test coverage is good (and if your tests aren't very
+slow).
+
+Another approach is to enable type collection for a small, random
+fraction of production network requests.  This clearly requires more
+care, as type collection could impact the reliability or the
+performance of your service.
+
+Speed up mypy runs
+------------------
+
+You can use :ref:`mypy daemon <mypy_daemon>` to get much faster
+incremental mypy runs. The larger your project is, the more useful
+this will be.  If your project has at least 100,000 lines of code or
+so, you may also want to set up :ref:`remote caching <remote-cache>`
+for further speedups.
+
+Introduce stricter options
+--------------------------
+
+Mypy is very configurable. Once you get started with static typing,
+you may want to explore the various
+strictness options mypy provides to
+catch more bugs. For example, you can ask mypy to require annotations
+for all functions in certain modules to avoid accidentally introducing
+code that won't be type checked. Refer to :ref:`command-line` for the
+details.
diff --git a/docs/source/getting_started.rst b/docs/source/getting_started.rst
index 6294c497a1..64524d99ce 100644
--- a/docs/source/getting_started.rst
+++ b/docs/source/getting_started.rst
@@ -1,31 +1,209 @@
-.. _getting-started:
-
 Getting started
 ===============
 
-Installation
-************
+This chapter introduces some core concepts of mypy, including function
+annotations, the ``typing`` module and library stubs. Read it carefully,
+as the rest of documentation may not make much sense otherwise.
+
+Installing mypy
+***************
 
 Mypy requires Python 3.4 or later to run.  Once you've
 `installed Python 3 <https://www.python.org/downloads/>`_,
-you can install mypy with:
+you can install mypy using pip:
 
 .. code-block:: text
 
-    $ python3 -m pip install mypy
+    python3 -m pip install mypy
 
 Note that even though you need Python 3 to run ``mypy``, type checking
-Python 2 code is fully supported, as discussed in :ref:`python2`.
+Python 2 code is fully supported, as discussed later in :ref:`python2`.
+
+Running mypy
+************
 
-Installing from source
-**********************
+You can type check a program by using the ``mypy`` tool, which is
+basically a linter -- it checks your program for errors without actually
+running it::
 
-To install mypy from source, clone the
-`mypy repository on GitHub <https://github.com/python/mypy>`_ and then run
-``pip install`` locally:
+   $ mypy program.py
 
-.. code-block:: text
+All errors reported by mypy are essentially warnings that you are free
+to ignore, if you so wish.
+
+.. note::
+
+   Depending on how mypy is configured, you may have to run mypy like
+   this::
+
+     $ python3 -m mypy program.py
+
+If you haven't added any type annotations to your program yet, you
+should add some first, as mypy won't report many errors in unannotated
+functions. Don't worry if you aren't familiar with type annotations --
+we'll discuss them in detail in much of the rest of this guide.
+
+Mypy supports many command line options that you can use to tweak how
+mypy behaves.  They are documented in :ref:`command-line`.
+
+Function signatures
+*******************
+
+A function without a type annotation is considered *dynamically typed* by
+mypy:
+
+.. code-block:: python
+
+   def greeting(name):
+       return 'Hello, {}'.format(name)
+
+You can declare the signature of a function using the Python 3
+annotation syntax (Python 2 is discussed later in :ref:`python2`).
+This makes the function statically typed, which causes mypy to
+report type errors within the function.
+
+Here's a version of the above function that is statically typed and
+will be type checked:
+
+.. code-block:: python
+
+   def greeting(name: str) -> str:
+       return 'Hello, {}'.format(name)
+
+Now mypy will reject the following call, since the argument has an
+incompatible type:
+
+.. code-block:: python
+
+   def greeting(name: str) -> str:
+       return 'Hello, {}'.format(name)
+
+   greeting(b'Alice')  # Argument 1 to "greeting" has incompatible type "bytes"; expected "str"
+
+If a function does not explicitly return a value we give the return
+type as ``None``. Using a ``None`` result in a statically typed
+context results in a type check error:
+
+.. code-block:: python
+
+   def p() -> None:
+       print('hello')
+
+   a = p()  # Error: "p" does not return a value
+
+Arguments with default values can be annotated as follows:
+
+.. code-block:: python
+
+   def greeting(name: str, excited: bool = False) -> str:
+       message = 'Hello, {}'.format(name)
+       if excited:
+           message += '!!!'
+       return message
+
+Mixing dynamic and static typing within a single file is often
+useful. For example, if you are migrating existing Python code to
+static typing, it may be easiest to do this incrementally, such as by
+migrating a few functions at a time. Also, when prototyping a new
+feature, you may decide to first implement the relevant code using
+dynamic typing and only add type signatures later, when the code is
+more stable.
+
+.. code-block:: python
+
+   def f():
+       1 + 'x'  # No static type error (dynamically typed)
+
+   def g() -> None:
+       1 + 'x'  # Type check error (statically typed)
+
+.. note::
+
+   The earlier stages of mypy, known as the semantic analysis, may
+   report errors even for dynamically typed functions. However, you
+   should not rely on this, as this may change in the future.
+
+The typing module
+*****************
+
+The ``typing`` module contains many definitions that are useful in
+statically typed code. You typically use ``from ... import`` to import
+them (we'll explain ``Iterable`` later in this document):
+
+.. code-block:: python
+
+   from typing import Iterable
+
+   def greet_all(names: Iterable[str]) -> None:
+       for name in names:
+           print('Hello, {}'.format(name))
+
+For brevity, we often omit the ``typing`` import in code examples, but
+mypy will give an error if you use definitions such as ``Iterable``
+without first importing them.
+
+.. _stubs-intro:
+
+Library stubs and typeshed
+**************************
+
+Mypy uses library *stubs* to type check code interacting with library
+modules, including the Python standard library. A library stub defines
+a skeleton of the public interface of the library, including classes,
+variables and functions, and their types. Mypy ships with stubs from
+the `typeshed <https://github.com/python/typeshed>`_ project, which
+contains library stubs for the Python builtins, the standard library,
+and selected third-party packages.
+
+For example, consider this code:
+
+.. code-block:: python
+
+  x = chr(4)
+
+Without a library stub, mypy would have no way of inferring the type of ``x``
+and checking that the argument to ``chr`` has a valid type.
+
+Mypy complains if it can't find a stub (or a real module) for a
+library module that you import. Some modules ship with stubs that mypy
+can automatically find, or you can install a 3rd party module with
+additional stubs (see :ref:`installed-packages` for details).  You can
+also :ref:`create stubs <stub-files>` easily. We discuss ways of
+silencing complaints about missing stubs in :ref:`existing-code`.
+
+Next steps
+**********
+
+If you are in a hurry and don't want to read lots of documentation
+before getting started, here are some pointers to quick learning
+resources:
+
+* Read the :ref:`mypy cheatsheet <cheat-sheet-py3>` (also for
+  :ref:`Python 2 <cheat-sheet-py2>`).
+
+* Read :ref:`existing-code` if you have a significant existing
+  codebase without many type annotations.
+
+* Read the `blog post <http://blog.zulip.org/2016/10/13/static-types-in-python-oh-mypy/>`_
+  about the Zulip project's experiences with adopting mypy.
+
+* If you prefer watching talks instead of reading, here are
+  some ideas:
+
+  * Carl Meyer:
+    `Type Checked Python in the Real World <https://www.youtube.com/watch?v=pMgmKJyWKn8>`_
+    (PyCon 2018)
+
+  * Greg Price:
+    `Clearer Code at Scale: Static Types at Zulip and Dropbox <https://www.youtube.com/watch?v=0c46YHS3RY8>`_
+    (PyCon 2018)
+
+* Look at :ref:`solutions to common issues <common_issues>` with mypy if
+  you encounter problems.
+
+* You can ask questions about mypy in the
+  `mypy issue tracker <https://github.com/python/mypy/issues>`_ and
+  typing `Gitter chat <https://gitter.im/python/typing>`_.
 
-    $ git clone --recurse-submodules https://github.com/python/mypy.git
-    $ cd mypy
-    $ sudo python3 -m pip install --upgrade .
+You can also continue reading this document and skip sections that
+aren't relevant for you. You don't need to read sections in order.
diff --git a/docs/source/index.rst b/docs/source/index.rst
index 71a3a94669..00e9746184 100644
--- a/docs/source/index.rst
+++ b/docs/source/index.rst
@@ -13,8 +13,8 @@ Mypy is a static type checker for Python 3 and Python 2.7.
    :caption: First steps
 
    introduction
-   basics
    getting_started
+   existing_code
 
 .. toctree::
    :maxdepth: 2
@@ -27,15 +27,17 @@ Mypy is a static type checker for Python 3 and Python 2.7.
    :maxdepth: 2
    :caption: Type system reference
 
-   python2
    builtin_types
    type_inference_and_annotations
    kinds_of_types
    class_basics
    protocols
+   metaclasses
+   python2
    dynamic_typing
    casts
    duck_type_compatibility
+   stubs
    generics
    more_types
 
diff --git a/docs/source/introduction.rst b/docs/source/introduction.rst
index d84027ae07..9b427ffd20 100644
--- a/docs/source/introduction.rst
+++ b/docs/source/introduction.rst
@@ -13,8 +13,8 @@ Using the Python 3 function annotation syntax (using the
 a comment-based annotation syntax for Python 2 code, you will be able to
 efficiently annotate your code and use mypy to check the code for common
 errors. Mypy has a powerful and easy-to-use type system with modern features
-such as type inference, generics, function types, tuple types, and
-union types.
+such as type inference, generics, callable types, tuple types,
+union types, and structural subtyping.
 
 As a developer, you decide how to use mypy in your workflow. You can always
 escape to dynamic typing as mypy's approach to static typing doesn't restrict
diff --git a/docs/source/kinds_of_types.rst b/docs/source/kinds_of_types.rst
index 596e0711a3..26de4cffa7 100644
--- a/docs/source/kinds_of_types.rst
+++ b/docs/source/kinds_of_types.rst
@@ -346,7 +346,7 @@ This also works for attributes defined within methods:
 
 As a special case, you can use a non-optional type when initializing an
 attribute to ``None`` inside a class body *and* using a type comment,
-since when using a type comment, an initializer is syntacticaly required,
+since when using a type comment, an initializer is syntactically required,
 and ``None`` is used as a dummy, placeholder initializer:
 
 .. code-block:: python
diff --git a/docs/source/metaclasses.rst b/docs/source/metaclasses.rst
new file mode 100644
index 0000000000..f71f48520a
--- /dev/null
+++ b/docs/source/metaclasses.rst
@@ -0,0 +1,106 @@
+.. _metaclasses:
+
+Metaclasses
+===========
+
+A `metaclass <https://docs.python.org/3/reference/datamodel.html#metaclasses>`_
+is a class that describes the construction and behavior of other classes,
+similarly to how classes describe the construction and behavior of objects.
+The default metaclass is ``type``, but it's possible to use other metaclasses.
+Metaclasses allows one to create "a different kind of class", such as Enums,
+NamedTuples and singletons.
+
+Mypy has some special understanding of ``ABCMeta`` and ``EnumMeta``.
+
+.. _defining:
+
+Defining a metaclass
+********************
+
+.. code-block:: python
+
+    class M(type):
+        pass
+
+    class A(metaclass=M):
+        pass
+
+In Python 2, the syntax for defining a metaclass is different:
+
+.. code-block:: python
+
+    class A(object):
+        __metaclass__ = M
+
+Mypy also supports using the `six <https://pythonhosted.org/six/#six.with_metaclass>`_
+library to define metaclass in a portable way:
+
+.. code-block:: python
+
+    import six
+
+    class A(six.with_metaclass(M)):
+        pass
+
+    @six.add_metaclass(M)
+    class C(object):
+        pass
+
+.. _examples:
+
+Metaclass usage example
+***********************
+
+Mypy supports the lookup of attributes in the metaclass:
+
+.. code-block:: python
+
+    from typing import Type, TypeVar, ClassVar
+    T = TypeVar('T')
+
+    class M(type):
+        count: ClassVar[int] = 0
+
+        def make(cls: Type[T]) -> T:
+            M.count += 1
+            return cls()
+
+    class A(metaclass=M):
+        pass
+
+    a: A = A.make()  # make() is looked up at M; the result is an object of type A
+    print(A.count)
+
+    class B(A):
+        pass
+
+    b: B = B.make()  # metaclasses are inherited
+    print(B.count + " objects were created")  # Error: Unsupported operand types for + ("int" and "str")
+
+.. _limitations:
+
+Gotchas and limitations of metaclass support
+********************************************
+
+Note that metaclasses pose some requirements on the inheritance structure,
+so it's better not to combine metaclasses and class hierarchies:
+
+.. code-block:: python
+
+    class M1(type): pass
+    class M2(type): pass
+
+    class A1(metaclass=M1): pass
+    class A2(metaclass=M2): pass
+
+    class B1(A1, metaclass=M2): pass  # Mypy Error: Inconsistent metaclass structure for 'B1'
+    # At runtime the above definition raises an exception
+    # TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
+
+    # Same runtime error as in B1, but mypy does not catch it yet
+    class B12(A1, A2): pass
+
+* Mypy does not understand dynamically-computed metaclasses,
+  such as ``class A(metaclass=f()): ...``
+* Mypy does not and cannot understand arbitrary metaclass code.
+* Mypy only recognizes subclasses of ``type`` as potential metaclasses.
diff --git a/docs/source/mypy_daemon.rst b/docs/source/mypy_daemon.rst
index 8eb8091284..9b97a027bc 100644
--- a/docs/source/mypy_daemon.rst
+++ b/docs/source/mypy_daemon.rst
@@ -36,24 +36,23 @@ Basic usage
 ***********
 
 The client utility ``dmypy`` is used to control the mypy daemon.
-Use ``dmypy start -- <flags>`` to start the daemon. You can use almost
-arbitrary mypy flags after ``--``.  The daemon will always run on the
-current host. Example::
+Use ``dmypy run -- <flags> <files>`` to typecheck a set of files
+(or directories). This will launch the daemon if it is not running.
+You can use almost arbitrary mypy flags after ``--``.  The daemon
+will always run on the current host. Example::
 
-    dmypy start -- --follow-imports=skip
+    dmypy run -- --follow-imports=error prog.py pkg1/ pkg2/
 
 .. note::
-   You'll need to use either the ``--follow-imports=skip`` or the
-   ``--follow-imports=error`` option with dmypy because the current
+   You'll need to use either the ``--follow-imports=error`` or the
+   ``--follow-imports=skip`` option with dmypy because the current
    implementation can't follow imports.
    See :ref:`follow-imports` for details on how these work.
    You can also define these using a
    :ref:`configuration file <config-file>`.
 
-The daemon will not type check anything when it's started.
-Use ``dmypy check <files>`` to check some files (or directories)::
-
-    dmypy check prog.py pkg1/ pkg2/
+``dmypy run`` will automatically restart the daemon if the
+configuration or mypy version changes.
 
 You need to provide all files or directories you want to type check
 (other than stubs) as arguments. This is a result of the
@@ -68,19 +67,30 @@ you have a large codebase.
 Additional features
 *******************
 
-You have precise control over the lifetime of the daemon process:
+While ``dmypy run`` is sufficient for most uses, some workflows
+(ones using :ref:`remote caching <remote-cache>`, perhaps),
+require more precise control over the lifetime of the daemon process:
+
+* ``dmypy stop`` stops the daemon.
 
-* ``dymypy stop`` stops the daemon.
+* ``dmypy start -- <flags>`` starts the daemon but does not check any files.
+  You can use almost arbitrary mypy flags after ``--``.
 
 * ``dmypy restart -- <flags>`` restarts the daemon. The flags are the same
   as with ``dmypy start``. This is equivalent to a stop command followed
   by a start.
 
-* Use ``dmypy start --timeout SECONDS -- <flags>`` (or
-  ``dmypy restart --timeout SECONDS -- <flags>``) to automatically
+* Use ``dmypy run --timeout SECONDS -- <flags>`` (or
+  ``start`` or ``restart``) to automatically
   shut down the daemon after inactivity. By default, the daemon runs
   until it's explicitly stopped.
 
+* ``dmypy check <files>`` checks a set of files using an already
+  running daemon.
+
+* ``dmypy status`` checks whether a daemon is running. It prints a
+  diagnostic and exits with ``0`` if there is a running daemon.
+
 Use ``dmypy --help`` for help on additional commands and command-line
 options not discussed here, and ``dmypy <command> --help`` for help on
 command-specific options.
@@ -88,8 +98,8 @@ command-specific options.
 Limitations
 ***********
 
-* You have to use either the ``--follow-imports=skip`` or
-  the ``--follow-imports=error`` option because of an implementation
+* You have to use either the ``--follow-imports=error`` or
+  the ``--follow-imports=skip`` option because of an implementation
   limitation. This can be defined
   through the command line or through a
   :ref:`configuration file <config-file>`.
diff --git a/docs/source/revision_history.rst b/docs/source/revision_history.rst
index e90be133e3..1ad6d33636 100644
--- a/docs/source/revision_history.rst
+++ b/docs/source/revision_history.rst
@@ -4,6 +4,17 @@ Revision history
 List of major changes (the `Mypy Blog <http://mypy-lang.blogspot.com/>`_ contains more
 detailed release notes):
 
+- June 2018
+    * Publish ``mypy`` version 0.610 on PyPI.
+
+      * Major overhaul of documentation.
+
+      * Add the ``dmypy run`` command to the :ref:`daemon <mypy_daemon>`.
+
+      * Partially revert the prior changes to section pattern semantics in
+        configuration files
+        (:ref:`docs <config-file>` and :ref:`more docs <per-module-flags>`).
+
 - May 2018
     * Publish ``mypy`` version 0.600 on PyPI.
 
@@ -180,7 +191,7 @@ detailed release notes):
 - November 2016
     * Publish ``mypy-lang`` version 0.4.6 on PyPI.
 
-    * Add :ref:`getting-started`.
+    * Add Getting started.
 
     * Add :ref:`generic-methods-and-generic-self` (experimental).
 
@@ -268,7 +279,7 @@ detailed release notes):
     * Document Python 2 support.
 
 - Nov 2015
-    Add :ref:`library-stubs`.
+    Add :ref:`stubs-intro`.
 
 - Jun 2015
     Remove ``Undefined`` and ``Dynamic``, as they are not in PEP 484.
diff --git a/docs/source/stubs.rst b/docs/source/stubs.rst
new file mode 100644
index 0000000000..f363835aff
--- /dev/null
+++ b/docs/source/stubs.rst
@@ -0,0 +1,78 @@
+.. _stub-files:
+
+Stub files
+==========
+
+Mypy uses stub files stored in the
+`typeshed <https://github.com/python/typeshed>`_ repository to determine
+the types of standard library and third-party library functions, classes,
+and other definitions. You can also create your own stubs that will be
+used to type check your code. The basic properties of stubs were introduced
+back in :ref:`stubs-intro`.
+
+Creating a stub
+***************
+
+Here is an overview of how to create a stub file:
+
+* Write a stub file for the library (or an arbitrary module) and store it as
+  a ``.pyi`` file in the same directory as the library module.
+* Alternatively, put your stubs (``.pyi`` files) in a directory
+  reserved for stubs (e.g., ``myproject/stubs``). In this case you
+  have to set the environment variable ``MYPYPATH`` to refer to the
+  directory.  For example::
+
+    $ export MYPYPATH=~/work/myproject/stubs
+
+Use the normal Python file name conventions for modules, e.g. ``csv.pyi``
+for module ``csv``. Use a subdirectory with ``__init__.pyi`` for packages.
+
+If a directory contains both a ``.py`` and a ``.pyi`` file for the
+same module, the ``.pyi`` file takes precedence. This way you can
+easily add annotations for a module even if you don't want to modify
+the source code. This can be useful, for example, if you use 3rd party
+open source libraries in your program (and there are no stubs in
+typeshed yet).
+
+That's it! Now you can access the module in mypy programs and type check
+code that uses the library. If you write a stub for a library module,
+consider making it available for other programmers that use mypy
+by contributing it back to the typeshed repo.
+
+There is more information about creating stubs in the
+`mypy wiki <https://github.com/python/mypy/wiki/Creating-Stubs-For-Python-Modules>`_.
+The following sections explain the kinds of type annotations you can use
+in your programs and stub files.
+
+.. note::
+
+   You may be tempted to point ``MYPYPATH`` to the standard library or
+   to the ``site-packages`` directory where your 3rd party packages
+   are installed. This is almost always a bad idea -- you will likely
+   get tons of error messages about code you didn't write and that
+   mypy can't analyze all that well yet, and in the worst case
+   scenario mypy may crash due to some construct in a 3rd party
+   package that it didn't expect.
+
+Stub file syntax
+****************
+
+Stub files are written in normal Python 3 syntax, but generally
+leaving out runtime logic like variable initializers, function bodies,
+and default arguments, or replacing them with ellipses.
+
+In this example, each ellipsis ``...`` is literally written in the
+stub file as three dots:
+
+.. code-block:: python
+
+    x: int
+
+    def afunc(code: str) -> int: ...
+    def afunc(a: int, b: int = ...) -> int: ...
+
+.. note::
+
+    The ellipsis ``...`` is also used with a different meaning in
+    :ref:`callable types <callable-types>` and :ref:`tuple types
+    <tuple-types>`.
diff --git a/docs/source/type_inference_and_annotations.rst b/docs/source/type_inference_and_annotations.rst
index 117e8ecf6a..080b491af8 100644
--- a/docs/source/type_inference_and_annotations.rst
+++ b/docs/source/type_inference_and_annotations.rst
@@ -216,27 +216,3 @@ to be annotated with a starred type:
     p, q, *rs = 1, 2  # type: int, int, *List[int]
 
 Here, the type of ``rs`` is set to ``List[int]``.
-
-Types in stub files
-*******************
-
-:ref:`Stub files <library-stubs>` are written in normal Python 3
-syntax, but generally leaving out runtime logic like variable
-initializers, function bodies, and default arguments, or replacing them
-with ellipses.
-
-In this example, each ellipsis ``...`` is literally written in the
-stub file as three dots:
-
-.. code-block:: python
-
-    x: int
-
-    def afunc(code: str) -> int: ...
-    def afunc(a: int, b: int = ...) -> int: ...
-
-.. note::
-
-    The ellipsis ``...`` is also used with a different meaning in
-    :ref:`callable types <callable-types>` and :ref:`tuple types
-    <tuple-types>`.
diff --git a/extensions/mypy_extensions.py b/extensions/mypy_extensions.py
index c711e0023a..056b1bf7c6 100644
--- a/extensions/mypy_extensions.py
+++ b/extensions/mypy_extensions.py
@@ -46,7 +46,7 @@ def __new__(cls, name, bases, ns, total=True):
         # This method is called directly when TypedDict is subclassed,
         # or via _typeddict_new when TypedDict is instantiated. This way
         # TypedDict supports all three syntaxes described in its docstring.
-        # Subclasses and instanes of TypedDict return actual dictionaries
+        # Subclasses and instances of TypedDict return actual dictionaries
         # via _dict_new.
         ns['__new__'] = _typeddict_new if name == 'TypedDict' else _dict_new
         tp_dict = super(_TypedDictMeta, cls).__new__(cls, name, (dict,), ns)
diff --git a/mypy/applytype.py b/mypy/applytype.py
index db93c468f2..e1d81218b2 100644
--- a/mypy/applytype.py
+++ b/mypy/applytype.py
@@ -1,4 +1,4 @@
-from typing import List, Dict, Sequence, Optional
+from typing import Dict, Sequence, Optional
 
 import mypy.subtypes
 from mypy.sametypes import is_same_type
diff --git a/mypy/binder.py b/mypy/binder.py
index 0cba54fd03..15c728d54b 100644
--- a/mypy/binder.py
+++ b/mypy/binder.py
@@ -354,7 +354,7 @@ def frame_context(self, *, can_skip: bool, fall_through: int = 1,
         continue_frame and 'continue' statements.
 
         If try_frame is true, then execution is allowed to jump at any
-        point within the newly created frame (or its descendents) to
+        point within the newly created frame (or its descendants) to
         its parent (i.e., to the frame that was on top before this
         call to frame_context).
 
diff --git a/mypy/build.py b/mypy/build.py
index 1992cecca4..6a31f1f89b 100644
--- a/mypy/build.py
+++ b/mypy/build.py
@@ -26,18 +26,14 @@
 import subprocess
 import sys
 import time
-from os.path import dirname, basename
+from os.path import dirname
 import errno
 
 from typing import (AbstractSet, Any, cast, Dict, Iterable, Iterator, List,
                     Mapping, NamedTuple, Optional, Set, Tuple, Union, Callable)
-# Can't use TYPE_CHECKING because it's not in the Python 3.5.1 stdlib
-MYPY = False
-if MYPY:
-    from typing import Deque
 
 from mypy import sitepkgs
-from mypy.nodes import (MODULE_REF, MypyFile, Node, ImportBase, Import, ImportFrom, ImportAll)
+from mypy.nodes import (MypyFile, ImportBase, Import, ImportFrom, ImportAll)
 from mypy.semanal_pass1 import SemanticAnalyzerPass1
 from mypy.semanal import SemanticAnalyzerPass2, apply_semantic_analyzer_patches
 from mypy.semanal_pass3 import SemanticAnalyzerPass3
@@ -74,10 +70,6 @@
 Graph = Dict[str, 'State']
 
 
-def getmtime(name: str) -> int:
-    return int(os.path.getmtime(name))
-
-
 # TODO: Get rid of BuildResult.  We might as well return a BuildManager.
 class BuildResult:
     """The result of a successful build.
@@ -230,7 +222,12 @@ def compute_lib_path(sources: List[BuildSource],
         # to the lib_path
         # TODO: Don't do this in some cases; for motivation see see
         # https://github.com/python/mypy/issues/4195#issuecomment-341915031
-        lib_path.appendleft(os.getcwd())
+        if options.bazel:
+            dir = '.'
+        else:
+            dir = os.getcwd()
+        if dir not in lib_path:
+            lib_path.appendleft(dir)
 
     # Prepend a config-defined mypy path.
     lib_path.extendleft(options.mypy_path)
@@ -687,6 +684,31 @@ def maybe_swap_for_shadow_path(self, path: str) -> str:
     def get_stat(self, path: str) -> os.stat_result:
         return self.fscache.stat(self.maybe_swap_for_shadow_path(path))
 
+    def getmtime(self, path: str) -> int:
+        """Return a file's mtime; but 0 in bazel mode.
+
+        (Bazel's distributed cache doesn't like filesystem metadata to
+        end up in output files.)
+        """
+        if self.options.bazel:
+            return 0
+        else:
+            return int(os.path.getmtime(path))
+
+    def normpath(self, path: str) -> str:
+        """Convert path to absolute; but to relative in bazel mode.
+
+        (Bazel's distributed cache doesn't like filesystem metadata to
+        end up in output files.)
+        """
+        # TODO: Could we always use relpath?  (A worry in non-bazel
+        # mode would be that a moved file may change its full module
+        # name without changing its size, mtime or hash.)
+        if self.options.bazel:
+            return os.path.relpath(path)
+        else:
+            return os.path.abspath(path)
+
     def all_imported_modules_in_file(self,
                                      file: MypyFile) -> List[Tuple[int, str, int]]:
         """Find all reachable import statements in a file.
@@ -1094,7 +1116,7 @@ def get_cache_names(id: str, path: str, manager: BuildManager) -> Tuple[str, str
 
     Args:
       id: module ID
-      path: module path (used to recognize packages)
+      path: module path
       cache_dir: cache directory
       pyversion: Python version (major, minor)
 
@@ -1102,6 +1124,9 @@ def get_cache_names(id: str, path: str, manager: BuildManager) -> Tuple[str, str
       A tuple with the file names to be used for the meta JSON, the
       data JSON, and the fine-grained deps JSON, respectively.
     """
+    pair = manager.options.cache_map.get(path)
+    if pair is not None:
+        return (pair[0], pair[1], None)
     prefix = _cache_dir_prefix(manager, id)
     is_package = os.path.basename(path).startswith('__init__.py')
     if is_package:
@@ -1232,22 +1257,23 @@ def validate_meta(meta: Optional[CacheMeta], id: str, path: Optional[str],
         manager.log('Metadata abandoned for {}: errors were previously ignored'.format(id))
         return None
 
+    bazel = manager.options.bazel
     assert path is not None, "Internal error: meta was provided without a path"
     # Check data_json; assume if its mtime matches it's good.
     # TODO: stat() errors
-    data_mtime = getmtime(meta.data_json)
+    data_mtime = manager.getmtime(meta.data_json)
     if data_mtime != meta.data_mtime:
         manager.log('Metadata abandoned for {}: data cache is modified'.format(id))
         return None
     deps_mtime = None
     if manager.options.cache_fine_grained:
         assert meta.deps_json
-        deps_mtime = getmtime(meta.deps_json)
+        deps_mtime = manager.getmtime(meta.deps_json)
         if deps_mtime != meta.deps_mtime:
             manager.log('Metadata abandoned for {}: deps cache is modified'.format(id))
             return None
 
-    path = os.path.abspath(path)
+    path = manager.normpath(path)
     try:
         st = manager.get_stat(path)
     except OSError:
@@ -1272,12 +1298,14 @@ def validate_meta(meta: Optional[CacheMeta], id: str, path: Optional[str],
     fine_grained_cache = manager.use_fine_grained_cache()
 
     size = st.st_size
-    if size != meta.size and not fine_grained_cache:
+    # Bazel ensures the cache is valid.
+    if size != meta.size and not bazel and not fine_grained_cache:
         manager.log('Metadata abandoned for {}: file {} has different size'.format(id, path))
         return None
 
-    mtime = int(st.st_mtime)
-    if mtime != meta.mtime or path != meta.path:
+    # Bazel ensures the cache is valid.
+    mtime = 0 if bazel else int(st.st_mtime)
+    if not bazel and (mtime != meta.mtime or path != meta.path):
         try:
             source_hash = manager.fscache.md5(path)
         except (OSError, UnicodeDecodeError, DecodeError):
@@ -1317,7 +1345,7 @@ def validate_meta(meta: Optional[CacheMeta], id: str, path: Optional[str],
                 meta_str = json.dumps(meta_dict, indent=2, sort_keys=True)
             else:
                 meta_str = json.dumps(meta_dict)
-            meta_json, _, _2 = get_cache_names(id, path, manager)
+            meta_json, _, _ = get_cache_names(id, path, manager)
             manager.log('Updating mtime for {}: file {}, meta {}, mtime {}'
                         .format(id, path, meta_json, meta.mtime))
             atomic_write(meta_json, meta_str, '\n')  # Ignore errors, it's just an optimization.
@@ -1373,12 +1401,20 @@ def write_cache(id: str, path: str, tree: MypyFile,
       corresponding to the metadata that was written (the latter may
       be None if the cache could not be written).
     """
-    # Obtain file paths
-    path = os.path.abspath(path)
+    # For Bazel we use relative paths and zero mtimes.
+    bazel = manager.options.bazel
+
+    # Obtain file paths.
+    path = manager.normpath(path)
     meta_json, data_json, deps_json = get_cache_names(id, path, manager)
     manager.log('Writing {} {} {} {} {}'.format(
         id, path, meta_json, data_json, deps_json))
 
+    # Update tree.path so that in bazel mode it's made relative (since
+    # sometimes paths leak out).
+    if bazel:
+        tree.path = path
+
     # Make sure directory for cache files exists
     parent = os.path.dirname(data_json)
     assert os.path.dirname(meta_json) == parent
@@ -1390,7 +1426,8 @@ def write_cache(id: str, path: str, tree: MypyFile,
 
     # Obtain and set up metadata
     try:
-        os.makedirs(parent, exist_ok=True)
+        if parent:
+            os.makedirs(parent, exist_ok=True)
         st = manager.get_stat(path)
     except OSError as err:
         manager.log("Cannot get stat for {}: {}".format(path, err))
@@ -1405,10 +1442,11 @@ def write_cache(id: str, path: str, tree: MypyFile,
         return interface_hash, None
 
     # Write data cache file, if applicable
+    # Note that for Bazel we don't record the data file's mtime.
     if old_interface_hash == interface_hash:
         # If the interface is unchanged, the cached data is guaranteed
         # to be equivalent, and we only need to update the metadata.
-        data_mtime = getmtime(data_json)
+        data_mtime = manager.getmtime(data_json)
         manager.trace("Interface for {} is unchanged".format(id))
     else:
         manager.trace("Interface for {} has changed".format(id))
@@ -1425,7 +1463,7 @@ def write_cache(id: str, path: str, tree: MypyFile,
             # Both have the effect of slowing down the next run a
             # little bit due to an out-of-date cache file.
             return interface_hash, None
-        data_mtime = getmtime(data_json)
+        data_mtime = manager.getmtime(data_json)
 
     deps_mtime = None
     if deps_json:
@@ -1433,9 +1471,9 @@ def write_cache(id: str, path: str, tree: MypyFile,
         if not atomic_write(deps_json, deps_str, '\n'):
             manager.log("Error writing deps JSON file {}".format(deps_json))
             return interface_hash, None
-        deps_mtime = getmtime(deps_json)
+        deps_mtime = manager.getmtime(deps_json)
 
-    mtime = int(st.st_mtime)
+    mtime = 0 if bazel else int(st.st_mtime)
     size = st.st_size
     options = manager.options.clone_for_module(id)
     assert source_hash is not None
@@ -1475,7 +1513,7 @@ def delete_cache(id: str, path: str, manager: BuildManager) -> None:
     This avoids inconsistent states with cache files from different mypy runs,
     see #4043 for an example.
     """
-    path = os.path.abspath(path)
+    path = manager.normpath(path)
     cache_paths = get_cache_names(id, path, manager)
     manager.log('Deleting {} {} {}'.format(id, path, " ".join(x for x in cache_paths if x)))
 
diff --git a/mypy/checker.py b/mypy/checker.py
index 5d2cf5009f..feedc5a820 100644
--- a/mypy/checker.py
+++ b/mypy/checker.py
@@ -2017,7 +2017,8 @@ def check_multi_assignment_from_iterable(self, lvalues: List[Lvalue], rvalue_typ
             item_type = self.iterable_item_type(cast(Instance, rvalue_type))
             for lv in lvalues:
                 if isinstance(lv, StarExpr):
-                    self.check_assignment(lv.expr, self.temp_node(rvalue_type, context),
+                    items_type = self.named_generic_type('builtins.list', [item_type])
+                    self.check_assignment(lv.expr, self.temp_node(items_type, context),
                                           infer_lvalue_type)
                 else:
                     self.check_assignment(lv, self.temp_node(item_type, context),
@@ -2176,12 +2177,12 @@ def check_simple_assignment(self, lvalue_type: Optional[Type], rvalue: Expressio
 
     def check_member_assignment(self, instance_type: Type, attribute_type: Type,
                                 rvalue: Expression, context: Context) -> Tuple[Type, bool]:
-        """Type member assigment.
+        """Type member assignment.
 
         This defers to check_simple_assignment, unless the member expression
         is a descriptor, in which case this checks descriptor semantics as well.
 
-        Return the inferred rvalue_type and whether to infer anything about the attribute type
+        Return the inferred rvalue_type and whether to infer anything about the attribute type.
         """
         # Descriptors don't participate in class-attribute access
         if ((isinstance(instance_type, FunctionLike) and instance_type.is_type_obj()) or
@@ -3245,7 +3246,7 @@ def enter_partial_types(self, *, is_function: bool = False,
         if not self.current_node_deferred:
             for var, context in partial_types.items():
                 # If we require local partial types, there are a few exceptions where
-                # we fall back to inferring just "None" as the type from a None initaliazer:
+                # we fall back to inferring just "None" as the type from a None initializer:
                 #
                 # 1. If all happens within a single function this is acceptable, since only
                 #    the topmost function is a separate target in fine-grained incremental mode.
diff --git a/mypy/checkexpr.py b/mypy/checkexpr.py
index 69c72198e3..09aca5fedf 100644
--- a/mypy/checkexpr.py
+++ b/mypy/checkexpr.py
@@ -156,7 +156,7 @@ def analyze_ref_expr(self, e: RefExpr, lvalue: bool = False) -> Type:
             result = function_type(node, self.named_type('builtins.function'))
         elif isinstance(node, OverloadedFuncDef) and node.type is not None:
             # node.type is None when there are multiple definitions of a function
-            # and it's decorated by somthing that is not typing.overload
+            # and it's decorated by something that is not typing.overload
             result = node.type
         elif isinstance(node, TypeInfo):
             # Reference to a type object.
@@ -536,7 +536,7 @@ def check_call(self, callee: Type, args: List[Expression],
                 if specified
             arg_messages: TODO
             callable_name: Fully-qualified name of the function/method to call,
-                or None if unavaiable (examples: 'builtins.open', 'typing.Mapping.get')
+                or None if unavailable (examples: 'builtins.open', 'typing.Mapping.get')
             object_type: If callable_name refers to a method, the type of the object
                 on which the method is being called
         """
@@ -1195,8 +1195,34 @@ def plausible_overload_call_targets(self,
                                         arg_kinds: List[int],
                                         arg_names: Optional[Sequence[Optional[str]]],
                                         overload: Overloaded) -> List[CallableType]:
-        """Returns all overload call targets that having matching argument counts."""
+        """Returns all overload call targets that having matching argument counts.
+
+        If the given args contains a star-arg (*arg or **kwarg argument), this method
+        will ensure all star-arg overloads appear at the start of the list, instead
+        of their usual location.
+
+        The only exception is if the starred argument is something like a Tuple or a
+        NamedTuple, which has a definitive "shape". If so, we don't move the corresponding
+        alternative to the front since we can infer a more precise match using the original
+        order."""
+
+        def has_shape(typ: Type) -> bool:
+            # TODO: Once https://github.com/python/mypy/issues/5198 is fixed,
+            #       add 'isinstance(typ, TypedDictType)' somewhere below.
+            return (isinstance(typ, TupleType)
+                    or (isinstance(typ, Instance) and typ.type.is_named_tuple))
+
         matches = []  # type: List[CallableType]
+        star_matches = []  # type: List[CallableType]
+
+        args_have_var_arg = False
+        args_have_kw_arg = False
+        for kind, typ in zip(arg_kinds, arg_types):
+            if kind == ARG_STAR and not has_shape(typ):
+                args_have_var_arg = True
+            if kind == ARG_STAR2 and not has_shape(typ):
+                args_have_kw_arg = True
+
         for typ in overload.items():
             formal_to_actual = map_actuals_to_formals(arg_kinds, arg_names,
                                                       typ.arg_kinds, typ.arg_names,
@@ -1204,9 +1230,14 @@ def plausible_overload_call_targets(self,
 
             if self.check_argument_count(typ, arg_types, arg_kinds, arg_names,
                                          formal_to_actual, None, None):
-                matches.append(typ)
+                if args_have_var_arg and typ.is_var_arg:
+                    star_matches.append(typ)
+                elif args_have_kw_arg and typ.is_kw_arg:
+                    star_matches.append(typ)
+                else:
+                    matches.append(typ)
 
-        return matches
+        return star_matches + matches
 
     def infer_overload_return_type(self,
                                    plausible_targets: List[CallableType],
@@ -1238,7 +1269,9 @@ def infer_overload_return_type(self,
         for typ in plausible_targets:
             overload_messages = self.msg.clean_copy()
             prev_messages = self.msg
+            assert self.msg is self.chk.msg
             self.msg = overload_messages
+            self.chk.msg = overload_messages
             try:
                 # Passing `overload_messages` as the `arg_messages` parameter doesn't
                 # seem to reliably catch all possible errors.
@@ -1253,6 +1286,7 @@ def infer_overload_return_type(self,
                     callable_name=callable_name,
                     object_type=object_type)
             finally:
+                self.chk.msg = prev_messages
                 self.msg = prev_messages
 
             is_match = not overload_messages.is_errors()
@@ -1270,15 +1304,20 @@ def infer_overload_return_type(self,
             return None
         elif any_causes_overload_ambiguity(matches, return_types, arg_types, arg_kinds, arg_names):
             # An argument of type or containing the type 'Any' caused ambiguity.
-            # We infer a type of 'Any'
-            return self.check_call(callee=AnyType(TypeOfAny.special_form),
-                                   args=args,
-                                   arg_kinds=arg_kinds,
-                                   arg_names=arg_names,
-                                   context=context,
-                                   arg_messages=arg_messages,
-                                   callable_name=callable_name,
-                                   object_type=object_type)
+            if all(is_subtype(ret_type, return_types[-1]) for ret_type in return_types[:-1]):
+                # The last match is a supertype of all the previous ones, so it's safe
+                # to return that inferred type.
+                return return_types[-1], inferred_types[-1]
+            else:
+                # We give up and return 'Any'.
+                return self.check_call(callee=AnyType(TypeOfAny.special_form),
+                                       args=args,
+                                       arg_kinds=arg_kinds,
+                                       arg_names=arg_names,
+                                       context=context,
+                                       arg_messages=arg_messages,
+                                       callable_name=callable_name,
+                                       object_type=object_type)
         else:
             # Success! No ambiguity; return the first match.
             return return_types[0], inferred_types[0]
@@ -2831,7 +2870,7 @@ def visit_enum_call_expr(self, e: EnumCallExpr) -> Type:
                 if not isinstance(typ, AnyType):
                     var = e.info.names[name].node
                     if isinstance(var, Var):
-                        # Inline TypeCheker.set_inferred_type(),
+                        # Inline TypeChecker.set_inferred_type(),
                         # without the lvalue.  (This doesn't really do
                         # much, since the value attribute is defined
                         # to have type Any in the typeshed stub.)
@@ -3174,16 +3213,20 @@ def any_causes_overload_ambiguity(items: List[CallableType],
             matching_formals_unfiltered = [(item_idx, lookup[arg_idx])
                                            for item_idx, lookup in enumerate(actual_to_formal)
                                            if lookup[arg_idx]]
+
+            matching_returns = []
             matching_formals = []
             for item_idx, formals in matching_formals_unfiltered:
-                if len(formals) > 1:
-                    # An actual maps to multiple formals -- give up as too
-                    # complex, just assume it overlaps.
-                    return True
-                matching_formals.append((item_idx, items[item_idx].arg_types[formals[0]]))
-            if (not all_same_types(t for _, t in matching_formals) and
-                    not all_same_types(items[idx].ret_type
-                                       for idx, _ in matching_formals)):
+                matched_callable = items[item_idx]
+                matching_returns.append(matched_callable.ret_type)
+
+                # Note: if an actual maps to multiple formals of differing types within
+                # a single callable, then we know at least one of those formals must be
+                # a different type then the formal(s) in some other callable.
+                # So it's safe to just append everything to the same list.
+                for formal in formals:
+                    matching_formals.append(matched_callable.arg_types[formal])
+            if not all_same_types(matching_formals) and not all_same_types(matching_returns):
                 # Any maps to multiple different types, and the return types of these items differ.
                 return True
     return False
diff --git a/mypy/checkmember.py b/mypy/checkmember.py
index 2c80ab0a32..99298c04fd 100644
--- a/mypy/checkmember.py
+++ b/mypy/checkmember.py
@@ -17,7 +17,7 @@
 from mypy.expandtype import expand_type_by_instance, expand_type, freshen_function_type_vars
 from mypy.infer import infer_type_arguments
 from mypy.typevars import fill_typevars
-from mypy.plugin import Plugin, AttributeContext
+from mypy.plugin import AttributeContext
 from mypy import messages
 from mypy import subtypes
 from mypy import meet
@@ -299,7 +299,7 @@ def analyze_var(name: str, var: Var, itype: Instance, info: TypeInfo, node: Cont
 
     This is conceptually part of analyze_member_access and the arguments are similar.
 
-    itype is the class object in which var is dedined
+    itype is the class object in which var is defined
     original_type is the type of E in the expression E.var
     """
     # Found a member variable.
diff --git a/mypy/constraints.py b/mypy/constraints.py
index 67d42cf8c9..ec5d4725b8 100644
--- a/mypy/constraints.py
+++ b/mypy/constraints.py
@@ -2,7 +2,6 @@
 
 from typing import Iterable, List, Optional, Sequence
 
-from mypy import experiments
 from mypy.types import (
     CallableType, Type, TypeVisitor, UnboundType, AnyType, NoneTyp, TypeVarType, Instance,
     TupleType, TypedDictType, UnionType, Overloaded, ErasedType, PartialType, DeletedType,
diff --git a/mypy/dmypy.py b/mypy/dmypy.py
index 76fcd5a9cc..a6a97e28c0 100644
--- a/mypy/dmypy.py
+++ b/mypy/dmypy.py
@@ -14,7 +14,7 @@
 import sys
 import time
 
-from typing import Any, Callable, Dict, List, Mapping, Optional, Sequence, Tuple, TypeVar
+from typing import Any, Callable, Dict, Mapping, Optional, Tuple
 
 from mypy.dmypy_util import STATUS_FILE, receive
 from mypy.util import write_junit_xml
diff --git a/mypy/dmypy_server.py b/mypy/dmypy_server.py
index 8899db97db..aaf1046736 100644
--- a/mypy/dmypy_server.py
+++ b/mypy/dmypy_server.py
@@ -6,8 +6,6 @@
 to enable fine-grained incremental reprocessing of changes.
 """
 
-import gc
-import io
 import json
 import os
 import shutil
@@ -24,7 +22,6 @@
 from mypy.find_sources import create_source_list, InvalidSourceList
 from mypy.server.update import FineGrainedBuildManager
 from mypy.dmypy_util import STATUS_FILE, receive
-from mypy.gclogger import GcLogger
 from mypy.fscache import FileSystemCache
 from mypy.fswatcher import FileSystemWatcher, FileData
 from mypy.options import Options
@@ -172,14 +169,14 @@ def serve(self) -> None:
                             resp = {'error': "Command is not a string"}
                         else:
                             command = data.pop('command')
-                        try:
-                            resp = self.run_command(command, data)
-                        except Exception:
-                            # If we are crashing, report the crash to the client
-                            tb = traceback.format_exception(*sys.exc_info())  # type: ignore
-                            resp = {'error': "Daemon crashed!\n" + "".join(tb)}
-                            conn.sendall(json.dumps(resp).encode('utf8'))
-                            raise
+                            try:
+                                resp = self.run_command(command, data)
+                            except Exception:
+                                # If we are crashing, report the crash to the client
+                                tb = traceback.format_exception(*sys.exc_info())
+                                resp = {'error': "Daemon crashed!\n" + "".join(tb)}
+                                conn.sendall(json.dumps(resp).encode('utf8'))
+                                raise
                     try:
                         conn.sendall(json.dumps(resp).encode('utf8'))
                     except OSError as err:
@@ -195,7 +192,7 @@ def serve(self) -> None:
             shutil.rmtree(self.sock_directory)
             exc_info = sys.exc_info()
             if exc_info[0] and exc_info[0] is not SystemExit:
-                traceback.print_exception(*exc_info)  # type: ignore
+                traceback.print_exception(*exc_info)
 
     def create_listening_socket(self) -> socket.socket:
         """Create the socket and set it up for listening."""
diff --git a/mypy/erasetype.py b/mypy/erasetype.py
index a22728016f..eeae6a2a93 100644
--- a/mypy/erasetype.py
+++ b/mypy/erasetype.py
@@ -3,9 +3,8 @@
 from mypy.types import (
     Type, TypeVisitor, UnboundType, AnyType, NoneTyp, TypeVarId, Instance, TypeVarType,
     CallableType, TupleType, TypedDictType, UnionType, Overloaded, ErasedType, PartialType,
-    DeletedType, TypeTranslator, TypeList, UninhabitedType, TypeType, TypeOfAny
+    DeletedType, TypeTranslator, UninhabitedType, TypeType, TypeOfAny
 )
-from mypy import experiments
 
 
 def erase_type(typ: Type) -> Type:
diff --git a/mypy/errors.py b/mypy/errors.py
index f2d4da76ba..24fd16dcbb 100644
--- a/mypy/errors.py
+++ b/mypy/errors.py
@@ -506,7 +506,7 @@ def remove_duplicates(self, errors: List[Tuple[Optional[str], int, int, str, str
             while (j >= 0 and errors[j][0] == errors[i][0] and
                     errors[j][1] == errors[i][1]):
                 if (errors[j][3] == errors[i][3] and
-                        # Allow duplicate notes in overload conficts reporting
+                        # Allow duplicate notes in overload conflicts reporting.
                         not (errors[i][3] == 'note' and
                              errors[i][4].strip() in allowed_duplicates
                              or errors[i][4].strip().startswith('def ')) and
diff --git a/mypy/expandtype.py b/mypy/expandtype.py
index 937ed8b73a..d4cd0d12d1 100644
--- a/mypy/expandtype.py
+++ b/mypy/expandtype.py
@@ -3,7 +3,7 @@
 from mypy.types import (
     Type, Instance, CallableType, TypeVisitor, UnboundType, AnyType,
     NoneTyp, TypeVarType, Overloaded, TupleType, TypedDictType, UnionType,
-    ErasedType, TypeList, PartialType, DeletedType, UninhabitedType, TypeType, TypeVarId,
+    ErasedType, PartialType, DeletedType, UninhabitedType, TypeType, TypeVarId,
     FunctionLike, TypeVarDef
 )
 
diff --git a/mypy/exprtotype.py b/mypy/exprtotype.py
index 0e1fcef5f7..9146c30381 100644
--- a/mypy/exprtotype.py
+++ b/mypy/exprtotype.py
@@ -3,7 +3,7 @@
 from mypy.nodes import (
     Expression, NameExpr, MemberExpr, IndexExpr, TupleExpr,
     ListExpr, StrExpr, BytesExpr, UnicodeExpr, EllipsisExpr, CallExpr,
-    ARG_POS, ARG_NAMED, get_member_expr_fullname
+    get_member_expr_fullname
 )
 from mypy.fastparse import parse_type_comment
 from mypy.types import (
@@ -32,7 +32,7 @@ def expr_to_unanalyzed_type(expr: Expression, _parent: Optional[Expression] = No
     The result is not semantically analyzed. It can be UnboundType or TypeList.
     Raise TypeTranslationError if the expression cannot represent a type.
     """
-    # The `parent` paremeter is used in recursive calls to provide context for
+    # The `parent` parameter is used in recursive calls to provide context for
     # understanding whether an CallableArgument is ok.
     name = None  # type: Optional[str]
     if isinstance(expr, NameExpr):
diff --git a/mypy/fastparse.py b/mypy/fastparse.py
index ad673e96d8..972cb9796a 100644
--- a/mypy/fastparse.py
+++ b/mypy/fastparse.py
@@ -2,7 +2,7 @@
 import sys
 
 from typing import (
-    Tuple, Union, TypeVar, Callable, Sequence, Optional, Any, cast, List, Set, overload
+    Tuple, Union, TypeVar, Callable, Sequence, Optional, Any, cast, List, overload
 )
 from mypy.sharedparse import (
     special_function_elide_names, argument_elide_name,
@@ -29,7 +29,6 @@
     TypeOfAny
 )
 from mypy import defaults
-from mypy import experiments
 from mypy import messages
 from mypy.errors import Errors
 from mypy.options import Options
diff --git a/mypy/fastparse2.py b/mypy/fastparse2.py
index 7d3cff2cc9..db151f0472 100644
--- a/mypy/fastparse2.py
+++ b/mypy/fastparse2.py
@@ -11,13 +11,13 @@
 
 The reason why this file is not easily merged with mypy.fastparse despite the large amount
 of redundancy is because the Python 2 AST and the Python 3 AST nodes belong to two completely
-different class heirarchies, which made it difficult to write a shared visitor between the
+different class hierarchies, which made it difficult to write a shared visitor between the
 two in a typesafe way.
 """
 from functools import wraps
 import sys
 
-from typing import Tuple, Union, TypeVar, Callable, Sequence, Optional, Any, cast, List, Set
+from typing import Tuple, Union, TypeVar, Callable, Sequence, Optional, Any, cast, List
 from mypy.sharedparse import (
     special_function_elide_names, argument_elide_name,
 )
@@ -28,7 +28,7 @@
     DelStmt, BreakStmt, ContinueStmt, PassStmt, GlobalDecl,
     WhileStmt, ForStmt, IfStmt, TryStmt, WithStmt,
     TupleExpr, GeneratorExpr, ListComprehension, ListExpr, ConditionalExpr,
-    DictExpr, SetExpr, NameExpr, IntExpr, StrExpr, BytesExpr, UnicodeExpr,
+    DictExpr, SetExpr, NameExpr, IntExpr, StrExpr, UnicodeExpr,
     FloatExpr, CallExpr, SuperExpr, MemberExpr, IndexExpr, SliceExpr, OpExpr,
     UnaryExpr, LambdaExpr, ComparisonExpr, DictionaryComprehension,
     SetComprehension, ComplexExpr, EllipsisExpr, YieldExpr, Argument,
@@ -38,7 +38,6 @@
 from mypy.types import (
     Type, CallableType, AnyType, UnboundType, EllipsisType, TypeOfAny
 )
-from mypy import experiments
 from mypy import messages
 from mypy.errors import Errors
 from mypy.fastparse import TypeConverter, parse_type_comment
diff --git a/mypy/find_sources.py b/mypy/find_sources.py
index fd489fbbeb..c054586d3a 100644
--- a/mypy/find_sources.py
+++ b/mypy/find_sources.py
@@ -143,6 +143,8 @@ def get_init_file(self, dir: str) -> Optional[str]:
             f = os.path.join(dir, '__init__' + ext)
             if self.fscache.isfile(f):
                 return f
+            if ext == '.py' and self.fscache.init_under_package_root(f):
+                return f
         return None
 
 
diff --git a/mypy/fixup.py b/mypy/fixup.py
index fa7edd40a4..75621e640f 100644
--- a/mypy/fixup.py
+++ b/mypy/fixup.py
@@ -5,12 +5,11 @@
 from mypy.nodes import (
     MypyFile, SymbolNode, SymbolTable, SymbolTableNode,
     TypeInfo, FuncDef, OverloadedFuncDef, Decorator, Var,
-    TypeVarExpr, ClassDef, Block,
-    LDEF, MDEF, GDEF, TYPE_ALIAS
+    TypeVarExpr, ClassDef, Block, TYPE_ALIAS
 )
 from mypy.types import (
-    CallableType, EllipsisType, Instance, Overloaded, TupleType, TypedDictType,
-    TypeList, TypeVarType, UnboundType, UnionType, TypeVisitor,
+    CallableType, Instance, Overloaded, TupleType, TypedDictType,
+    TypeVarType, UnboundType, UnionType, TypeVisitor,
     TypeType, NOT_READY
 )
 from mypy.visitor import NodeVisitor
diff --git a/mypy/fscache.py b/mypy/fscache.py
index 9b89144e76..3f1f9e5775 100644
--- a/mypy/fscache.py
+++ b/mypy/fscache.py
@@ -28,17 +28,22 @@
 advantage of the benefits.
 """
 
-import functools
 import hashlib
 import os
 import stat
-from typing import Dict, List, Tuple
+from typing import Dict, List, Set
 
 
 class FileSystemCache:
     def __init__(self) -> None:
+        # The package root is not flushed with the caches.
+        # It is set by set_package_root() below.
+        self.package_root = []  # type: List[str]
         self.flush()
 
+    def set_package_root(self, package_root: List[str]) -> None:
+        self.package_root = package_root
+
     def flush(self) -> None:
         """Start another transaction and empty all caches."""
         self.stat_cache = {}  # type: Dict[str, os.stat_result]
@@ -49,6 +54,7 @@ def flush(self) -> None:
         self.read_cache = {}  # type: Dict[str, bytes]
         self.read_error_cache = {}  # type: Dict[str, Exception]
         self.hash_cache = {}  # type: Dict[str, str]
+        self.fake_package_cache = set()  # type: Set[str]
 
     def stat(self, path: str) -> os.stat_result:
         if path in self.stat_cache:
@@ -58,6 +64,11 @@ def stat(self, path: str) -> os.stat_result:
         try:
             st = os.stat(path)
         except OSError as err:
+            if self.init_under_package_root(path):
+                try:
+                    return self._fake_init(path)
+                except OSError:
+                    pass
             # Take a copy to get rid of associated traceback and frame objects.
             # Just assigning to __traceback__ doesn't free them.
             self.stat_error_cache[path] = copy_os_error(err)
@@ -65,9 +76,88 @@ def stat(self, path: str) -> os.stat_result:
         self.stat_cache[path] = st
         return st
 
+    def init_under_package_root(self, path: str) -> bool:
+        """Is this path an __init__.py under a package root?
+
+        This is used to detect packages that don't contain __init__.py
+        files, which is needed to support Bazel.  The function should
+        only be called for non-existing files.
+
+        It will return True if it refers to a __init__.py file that
+        Bazel would create, so that at runtime Python would think the
+        directory containing it is a package.  For this to work you
+        must pass one or more package roots using the --package-root
+        flag.
+
+        As an exceptional case, any directory that is a package root
+        itself will not be considered to contain a __init__.py file.
+        This is different from the rules Bazel itself applies, but is
+        necessary for mypy to properly distinguish packages from other
+        directories.
+
+        See https://docs.bazel.build/versions/master/be/python.html,
+        where this behavior is described under legacy_create_init.
+        """
+        if not self.package_root:
+            return False
+        dirname, basename = os.path.split(path)
+        if basename != '__init__.py':
+            return False
+        try:
+            st = self.stat(dirname)
+        except OSError:
+            return False
+        else:
+            if not stat.S_ISDIR(st.st_mode):
+                return False
+        ok = False
+        drive, path = os.path.splitdrive(path)  # Ignore Windows drive name
+        path = os.path.normpath(path)
+        for root in self.package_root:
+            if path.startswith(root):
+                if path == root + basename:
+                    # A package root itself is never a package.
+                    ok = False
+                    break
+                else:
+                    ok = True
+        return ok
+
+    def _fake_init(self, path: str) -> os.stat_result:
+        """Prime the cache with a fake __init__.py file.
+
+        This makes code that looks for path believe an empty file by
+        that name exists.  Should only be called after
+        init_under_package_root() returns True.
+        """
+        dirname, basename = os.path.split(path)
+        assert basename == '__init__.py', path
+        assert not os.path.exists(path), path  # Not cached!
+        dirname = os.path.normpath(dirname)
+        st = self.stat(dirname)  # May raise OSError
+        # Get stat result as a sequence so we can modify it.
+        # (Alas, typeshed's os.stat_result is not a sequence yet.)
+        tpl = tuple(st)  # type: ignore
+        seq = list(tpl)  # type: List[float]
+        seq[stat.ST_MODE] = stat.S_IFREG | 0o444
+        seq[stat.ST_INO] = 1
+        seq[stat.ST_NLINK] = 1
+        seq[stat.ST_SIZE] = 0
+        tpl = tuple(seq)
+        st = os.stat_result(tpl)
+        self.stat_cache[path] = st
+        # Make listdir() and read() also pretend this file exists.
+        self.fake_package_cache.add(dirname)
+        return st
+
     def listdir(self, path: str) -> List[str]:
+        path = os.path.normpath(path)
         if path in self.listdir_cache:
-            return self.listdir_cache[path]
+            res = self.listdir_cache[path]
+            # Check the fake cache.
+            if path in self.fake_package_cache and '__init__.py' not in res:
+                res.append('__init__.py')  # Updates the result as well as the cache
+            return res
         if path in self.listdir_error_cache:
             raise copy_os_error(self.listdir_error_cache[path])
         try:
@@ -77,6 +167,9 @@ def listdir(self, path: str) -> List[str]:
             self.listdir_error_cache[path] = copy_os_error(err)
             raise err
         self.listdir_cache[path] = results
+        # Check the fake cache.
+        if path in self.fake_package_cache and '__init__.py' not in results:
+            results.append('__init__.py')
         return results
 
     def isfile(self, path: str) -> bool:
@@ -133,12 +226,19 @@ def read(self, path: str) -> bytes:
         # earlier instant than the mtime reported by self.stat().
         self.stat(path)
 
-        try:
-            with open(path, 'rb') as f:
-                data = f.read()
-        except Exception as err:
-            self.read_error_cache[path] = err
-            raise
+        dirname, basename = os.path.split(path)
+        dirname = os.path.normpath(dirname)
+        # Check the fake cache.
+        if basename == '__init__.py' and dirname in self.fake_package_cache:
+            data = b''
+        else:
+            try:
+                with open(path, 'rb') as f:
+                    data = f.read()
+            except OSError as err:
+                self.read_error_cache[path] = err
+                raise
+
         md5hash = hashlib.md5(data).hexdigest()
         self.read_cache[path] = data
         self.hash_cache[path] = md5hash
diff --git a/mypy/indirection.py b/mypy/indirection.py
index 8f503a4b55..d9c171fc45 100644
--- a/mypy/indirection.py
+++ b/mypy/indirection.py
@@ -1,10 +1,6 @@
 from typing import Dict, Iterable, List, Optional, Set
-from abc import abstractmethod
 
-from mypy.visitor import NodeVisitor
 from mypy.types import SyntheticTypeVisitor
-from mypy.nodes import MODULE_REF
-import mypy.nodes as nodes
 import mypy.types as types
 from mypy.util import split_module_names
 
diff --git a/mypy/join.py b/mypy/join.py
index 0206bfba13..fed988bba1 100644
--- a/mypy/join.py
+++ b/mypy/join.py
@@ -1,11 +1,11 @@
 """Calculation of the least upper bound types (joins)."""
 
 from collections import OrderedDict
-from typing import cast, List, Optional
+from typing import List, Optional
 
 from mypy.types import (
     Type, AnyType, NoneTyp, TypeVisitor, Instance, UnboundType, TypeVarType, CallableType,
-    TupleType, TypedDictType, ErasedType, TypeList, UnionType, FunctionLike, Overloaded,
+    TupleType, TypedDictType, ErasedType, UnionType, FunctionLike, Overloaded,
     PartialType, DeletedType, UninhabitedType, TypeType, true_or_false, TypeOfAny
 )
 from mypy.maptype import map_instance_to_supertype
diff --git a/mypy/main.py b/mypy/main.py
index bc6a21e1aa..2b0243b945 100644
--- a/mypy/main.py
+++ b/mypy/main.py
@@ -9,13 +9,13 @@
 import sys
 import time
 
-from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple, Callable
+from typing import Any, Dict, List, Mapping, Optional, Tuple, Callable
 
 from mypy import build
 from mypy import defaults
 from mypy import experiments
 from mypy import util
-from mypy.build import BuildSource, BuildResult, PYTHON_EXTENSIONS
+from mypy.build import BuildSource, BuildResult
 from mypy.find_sources import create_source_list, InvalidSourceList
 from mypy.fscache import FileSystemCache
 from mypy.errors import CompileError
@@ -148,8 +148,7 @@ def type_check_only(sources: List[BuildSource], bin_dir: Optional[str],
                        fscache=fscache)
 
 
-FOOTER = """environment variables:
-MYPYPATH     additional module search path"""
+FOOTER = "environment variables: Define MYPYPATH for additional module search path entries."
 
 
 class SplitNamespace(argparse.Namespace):
@@ -303,7 +302,11 @@ def process_options(args: List[str],
                     server_options: bool = False,
                     fscache: Optional[FileSystemCache] = None,
                     ) -> Tuple[List[BuildSource], Options]:
-    """Parse command line arguments."""
+    """Parse command line arguments.
+
+    If a FileSystemCache is passed in, and package_root options are given,
+    call fscache.set_package_root() to set the cache's package root.
+    """
 
     parser = argparse.ArgumentParser(prog='mypy', epilog=FOOTER,
                                      fromfile_prefix_chars='@',
@@ -318,23 +321,26 @@ def add_invertible_flag(flag: str,
                             default: bool,
                             dest: Optional[str] = None,
                             help: str,
-                            strict_flag: bool = False
+                            strict_flag: bool = False,
+                            group: Optional[argparse._ActionsContainer] = None
                             ) -> None:
         if inverse is None:
             inverse = invert_flag_name(flag)
+        if group is None:
+            group = parser
 
         if help is not argparse.SUPPRESS:
             help += " (inverse: {})".format(inverse)
 
-        arg = parser.add_argument(flag,
-                                  action='store_false' if default else 'store_true',
-                                  dest=dest,
-                                  help=help)
+        arg = group.add_argument(flag,
+                                 action='store_false' if default else 'store_true',
+                                 dest=dest,
+                                 help=help)
         dest = arg.dest
-        arg = parser.add_argument(inverse,
-                                  action='store_true' if default else 'store_false',
-                                  dest=dest,
-                                  help=argparse.SUPPRESS)
+        arg = group.add_argument(inverse,
+                                 action='store_true' if default else 'store_false',
+                                 dest=dest,
+                                 help=argparse.SUPPRESS)
         if strict_flag:
             assert dest is not None
             strict_flag_names.append(flag)
@@ -347,125 +353,248 @@ def add_invertible_flag(flag: str,
     parser.add_argument('-v', '--verbose', action='count', dest='verbosity',
                         help="more verbose messages")
     parser.add_argument('-V', '--version', action='version',
-                        version='%(prog)s ' + __version__)
-    parser.add_argument('--python-version', type=parse_version, metavar='x.y',
-                        help='use Python x.y', dest='special-opts:python_version')
-    parser.add_argument('--python-executable', action='store', metavar='EXECUTABLE',
-                        help="Python executable used for finding PEP 561 compliant installed"
-                             " packages and stubs", dest='special-opts:python_executable')
-    parser.add_argument('--no-site-packages', action='store_true',
-                        dest='special-opts:no_executable',
-                        help="Do not search for installed PEP 561 compliant packages")
-    parser.add_argument('--platform', action='store', metavar='PLATFORM',
-                        help="typecheck special-cased code for the given OS platform "
-                             "(defaults to sys.platform)")
-    parser.add_argument('-2', '--py2', dest='python_version', action='store_const',
-                        const=defaults.PYTHON2_VERSION, help="use Python 2 mode")
-    parser.add_argument('--ignore-missing-imports', action='store_true',
-                        help="silently ignore imports of missing modules")
-    parser.add_argument('--follow-imports', choices=['normal', 'silent', 'skip', 'error'],
-                        default='normal', help="how to treat imports (default normal)")
-    parser.add_argument('--disallow-any-unimported', default=False, action='store_true',
-                        help="disallow Any types resulting from unfollowed imports")
-    parser.add_argument('--disallow-any-expr', default=False, action='store_true',
-                        help='disallow all expressions that have type Any')
-    parser.add_argument('--disallow-any-decorated', default=False, action='store_true',
-                        help='disallow functions that have Any in their signature '
-                             'after decorator transformation')
-    parser.add_argument('--disallow-any-explicit', default=False, action='store_true',
-                        help='disallow explicit Any in type positions')
-    parser.add_argument('--disallow-any-generics', default=False, action='store_true',
-                        help='disallow usage of generic types that do not specify explicit '
-                             'type parameters')
+                        version='%(prog)s ' + __version__,
+                        help="show program's version number and exit")
+
+    config_group = parser.add_argument_group(
+        title='config file',
+        description="Use a config file instead of command line arguments.")
+    config_group.add_argument(
+        '--config-file',
+        help="configuration file, must have a [mypy] section "
+             "(defaults to {})".format(', '.join(defaults.CONFIG_FILES)))
+    add_invertible_flag('--warn-unused-configs', default=False, strict_flag=True,
+                        help="warn about unused '[mypy-<pattern>]' config sections",
+                        group=config_group)
+
+    imports_group = parser.add_argument_group(
+        title='import discovery',
+        description="Configure how imports are discovered and followed.")
+    imports_group.add_argument(
+        '--ignore-missing-imports', action='store_true',
+        help="silently ignore imports of missing modules")
+    imports_group.add_argument(
+        '--follow-imports', choices=['normal', 'silent', 'skip', 'error'],
+        default='normal', help="how to treat imports (default normal)")
+    imports_group.add_argument(
+        '--python-executable', action='store', metavar='EXECUTABLE',
+        help="Python executable used for finding PEP 561 compliant installed"
+             " packages and stubs",
+        dest='special-opts:python_executable')
+    imports_group.add_argument(
+        '--no-site-packages', action='store_true',
+        dest='special-opts:no_executable',
+        help="do not search for installed PEP 561 compliant packages")
+
+    platform_group = parser.add_argument_group(
+        title='platform configuration',
+        description="Type check code assuming certain runtime conditions.")
+    platform_group.add_argument(
+        '--python-version', type=parse_version, metavar='x.y',
+        help='type check code assuming it will be running on Python x.y',
+        dest='special-opts:python_version')
+    platform_group.add_argument(
+        '-2', '--py2', dest='python_version', action='store_const',
+        const=defaults.PYTHON2_VERSION,
+        help="use Python 2 mode (same as --python-version 2.7)")
+    platform_group.add_argument(
+        '--platform', action='store', metavar='PLATFORM',
+        help="type check special-cased code for the given OS platform "
+             "(defaults to sys.platform)")
+    platform_group.add_argument(
+        '--always-true', metavar='NAME', action='append', default=[],
+        help="additional variable to be considered True (may be repeated)")
+    platform_group.add_argument(
+        '--always-false', metavar='NAME', action='append', default=[],
+        help="additional variable to be considered False (may be repeated)")
+
+    disallow_any_group = parser.add_argument_group(
+        title='Any type restrictions',
+        description="Disallow the use of the 'Any' type under certain conditions.")
+    disallow_any_group.add_argument(
+        '--disallow-any-unimported', default=False, action='store_true',
+        help="disallow Any types resulting from unfollowed imports")
+    add_invertible_flag('--disallow-subclassing-any', default=False, strict_flag=True,
+                        help="disallow subclassing values of type 'Any' when defining classes",
+                        group=disallow_any_group)
+    disallow_any_group.add_argument(
+        '--disallow-any-expr', default=False, action='store_true',
+        help='disallow all expressions that have type Any')
+    disallow_any_group.add_argument(
+        '--disallow-any-decorated', default=False, action='store_true',
+        help='disallow functions that have Any in their signature '
+             'after decorator transformation')
+    disallow_any_group.add_argument(
+        '--disallow-any-explicit', default=False, action='store_true',
+        help='disallow explicit Any in type positions')
+    disallow_any_group.add_argument(
+        '--disallow-any-generics', default=False, action='store_true',
+        help='disallow usage of generic types that do not specify explicit '
+             'type parameters')
+
+    untyped_group = parser.add_argument_group(
+        title='untyped definitions and calls',
+        description="Configure how untyped definitions and calls are handled.")
     add_invertible_flag('--disallow-untyped-calls', default=False, strict_flag=True,
                         help="disallow calling functions without type annotations"
-                        " from functions with type annotations")
+                        " from functions with type annotations",
+                        group=untyped_group)
     add_invertible_flag('--disallow-untyped-defs', default=False, strict_flag=True,
                         help="disallow defining functions without type annotations"
-                        " or with incomplete type annotations")
+                        " or with incomplete type annotations",
+                        group=untyped_group)
     add_invertible_flag('--disallow-incomplete-defs', default=False, strict_flag=True,
-                        help="disallow defining functions with incomplete type annotations")
+                        help="disallow defining functions with incomplete type annotations",
+                        group=untyped_group)
     add_invertible_flag('--check-untyped-defs', default=False, strict_flag=True,
-                        help="type check the interior of functions without type annotations")
-    add_invertible_flag('--disallow-subclassing-any', default=False, strict_flag=True,
-                        help="disallow subclassing values of type 'Any' when defining classes")
+                        help="type check the interior of functions without type annotations",
+                        group=untyped_group)
     add_invertible_flag('--warn-incomplete-stub', default=False,
                         help="warn if missing type annotation in typeshed, only relevant with"
-                        " --check-untyped-defs enabled")
-    add_invertible_flag('--disallow-untyped-decorators', default=False, strict_flag=True,
-                        help="disallow decorating typed functions with untyped decorators")
+                             " --check-untyped-defs enabled",
+                        group=untyped_group)
+
+    none_group = parser.add_argument_group(
+        title='None and Optional handling',
+        description="Adjust how values of type 'None' are handled.")
+    add_invertible_flag('--no-implicit-optional', default=False, strict_flag=True,
+                        help="don't assume arguments with default values of None are Optional",
+                        group=none_group)
+    none_group.add_argument(
+        '--strict-optional', action='store_true',
+        help=argparse.SUPPRESS)
+    none_group.add_argument(
+        '--no-strict-optional', action='store_false', dest='strict_optional',
+        help="disable strict Optional checks (inverse: --strict-optional)")
+    none_group.add_argument(
+        '--strict-optional-whitelist', metavar='GLOB', nargs='*',
+        help="suppress strict Optional errors in all but the provided files; "
+             "implies --strict-optional (may suppress certain other errors "
+             "in non-whitelisted files)")
+
+    lint_group = parser.add_argument_group(
+        title='warnings',
+        description="Detect code that is sound but redundant or problematic.")
     add_invertible_flag('--warn-redundant-casts', default=False, strict_flag=True,
-                        help="warn about casting an expression to its inferred type")
+                        help="warn about casting an expression to its inferred type",
+                        group=lint_group)
     add_invertible_flag('--no-warn-no-return', dest='warn_no_return', default=True,
-                        help="do not warn about functions that end without returning")
+                        help="do not warn about functions that end without returning",
+                        group=lint_group)
     add_invertible_flag('--warn-return-any', default=False, strict_flag=True,
                         help="warn about returning values of type Any"
-                             " from non-Any typed functions")
+                             " from non-Any typed functions",
+                        group=lint_group)
     add_invertible_flag('--warn-unused-ignores', default=False, strict_flag=True,
-                        help="warn about unneeded '# type: ignore' comments")
-    add_invertible_flag('--warn-unused-configs', default=False, strict_flag=True,
-                        help="warn about unused '[mypy-<pattern>]' config sections")
+                        help="warn about unneeded '# type: ignore' comments",
+                        group=lint_group)
+
+    strictness_group = parser.add_argument_group(
+        title='other strictness checks',
+        description="Other miscellaneous strictness checks.")
+    add_invertible_flag('--disallow-untyped-decorators', default=False, strict_flag=True,
+                        help="disallow decorating typed functions with untyped decorators",
+                        group=strictness_group)
+
+    incremental_group = parser.add_argument_group(
+        title='incremental mode',
+        description="Adjust how mypy incrementally type checks and caches modules.")
+    incremental_group.add_argument(
+        '-i', '--incremental', action='store_true',
+        help=argparse.SUPPRESS)
+    incremental_group.add_argument(
+        '--no-incremental', action='store_false', dest='incremental',
+        help="disable module cache (inverse: --incremental)")
+    incremental_group.add_argument(
+        '--cache-dir', action='store', metavar='DIR',
+        help="store module cache info in the given folder in incremental mode "
+             "(defaults to '{}')".format(defaults.CACHE_DIR))
+    incremental_group.add_argument(
+        '--cache-fine-grained', action='store_true',
+        help="include fine-grained dependency information in the cache for the mypy daemon")
+    incremental_group.add_argument(
+        '--quick-and-dirty', action='store_true',
+        help="use cache even if dependencies out of date (implies --incremental)")
+    incremental_group.add_argument(
+        '--skip-version-check', action='store_true',
+        help="allow using cache written by older mypy version")
+
+    internals_group = parser.add_argument_group(
+        title='mypy internals',
+        description="Debug and customize mypy internals.")
+    internals_group.add_argument(
+        '--pdb', action='store_true', help="invoke pdb on fatal error")
+    internals_group.add_argument(
+        '--show-traceback', '--tb', action='store_true',
+        help="show traceback on fatal error")
+    internals_group.add_argument(
+        '--custom-typing', metavar='MODULE', dest='custom_typing_module',
+        help="use a custom typing module")
+    internals_group.add_argument(
+        '--custom-typeshed-dir', metavar='DIR',
+        help="use the custom typeshed in DIR")
+    internals_group.add_argument(
+        '--shadow-file', nargs=2, metavar=('SOURCE_FILE', 'SHADOW_FILE'),
+        dest='shadow_file', action='append',
+        help="when encountering SOURCE_FILE, read and type check "
+             "the contents of SHADOW_FILE instead.")
+
+    error_group = parser.add_argument_group(
+        title='error reporting',
+        description="Adjust the amount of detail shown in error messages.")
     add_invertible_flag('--show-error-context', default=False,
                         dest='show_error_context',
-                        help='Precede errors with "note:" messages explaining context')
-    add_invertible_flag('--no-implicit-optional', default=False, strict_flag=True,
-                        help="don't assume arguments with default values of None are Optional")
-    parser.add_argument('-i', '--incremental', action='store_true',
-                        help=argparse.SUPPRESS)
-    parser.add_argument('--no-incremental', action='store_false', dest='incremental',
-                        help="disable module cache, (inverse: --incremental)")
-    parser.add_argument('--quick-and-dirty', action='store_true',
-                        help="use cache even if dependencies out of date "
-                        "(implies --incremental)")
-    parser.add_argument('--cache-dir', action='store', metavar='DIR',
-                        help="store module cache info in the given folder in incremental mode "
-                        "(defaults to '{}')".format(defaults.CACHE_DIR))
-    parser.add_argument('--cache-fine-grained', action='store_true',
-                        help="include fine-grained dependency information in the cache")
-    parser.add_argument('--skip-version-check', action='store_true',
-                        help="allow using cache written by older mypy version")
-    parser.add_argument('--strict-optional', action='store_true',
-                        help=argparse.SUPPRESS)
-    parser.add_argument('--no-strict-optional', action='store_false', dest='strict_optional',
-                        help="disable strict Optional checks (inverse: --strict-optional)")
-    parser.add_argument('--strict-optional-whitelist', metavar='GLOB', nargs='*',
-                        help="suppress strict Optional errors in all but the provided files "
-                        "(experimental -- read documentation before using!).  "
-                        "Implies --strict-optional.  Has the undesirable side-effect of "
-                        "suppressing other errors in non-whitelisted files.")
-    parser.add_argument('--always-true', metavar='NAME', action='append', default=[],
-                        help="Additional variable to be considered True (may be repeated)")
-    parser.add_argument('--always-false', metavar='NAME', action='append', default=[],
-                        help="Additional variable to be considered False (may be repeated)")
-    parser.add_argument('--junit-xml', help="write junit.xml to the given file")
-    parser.add_argument('--pdb', action='store_true', help="invoke pdb on fatal error")
-    parser.add_argument('--show-traceback', '--tb', action='store_true',
-                        help="show traceback on fatal error")
-    parser.add_argument('--stats', action='store_true', dest='dump_type_stats', help="dump stats")
-    parser.add_argument('--inferstats', action='store_true', dest='dump_inference_stats',
-                        help="dump type inference stats")
-    parser.add_argument('--custom-typing', metavar='MODULE', dest='custom_typing_module',
-                        help="use a custom typing module")
-    parser.add_argument('--custom-typeshed-dir', metavar='DIR',
-                        help="use the custom typeshed in DIR")
-    parser.add_argument('--scripts-are-modules', action='store_true',
-                        help="Script x becomes module x instead of __main__")
-    parser.add_argument('--config-file',
-                        help="Configuration file, must have a [mypy] section "
-                        "(defaults to {})".format(', '.join(defaults.CONFIG_FILES)))
+                        help='precede errors with "note:" messages explaining context',
+                        group=error_group)
     add_invertible_flag('--show-column-numbers', default=False,
-                        help="Show column numbers in error messages")
-    parser.add_argument('--find-occurrences', metavar='CLASS.MEMBER',
-                        dest='special-opts:find_occurrences',
-                        help="print out all usages of a class member (experimental)")
-    strict_help = "Strict mode. Enables the following flags: {}".format(
+                        help="show column numbers in error messages",
+                        group=error_group)
+
+    analysis_group = parser.add_argument_group(
+        title='extra analysis',
+        description="Extract additional information and analysis.")
+    analysis_group.add_argument(
+        '--stats', action='store_true', dest='dump_type_stats', help=argparse.SUPPRESS)
+    analysis_group.add_argument(
+        '--inferstats', action='store_true', dest='dump_inference_stats',
+        help=argparse.SUPPRESS)
+    analysis_group.add_argument(
+        '--find-occurrences', metavar='CLASS.MEMBER',
+        dest='special-opts:find_occurrences',
+        help="print out all usages of a class member (experimental)")
+
+    strict_help = "strict mode; enables the following flags: {}".format(
         ", ".join(strict_flag_names))
-    parser.add_argument('--strict', action='store_true', dest='special-opts:strict',
-                        help=strict_help)
-    parser.add_argument('--shadow-file', nargs=2, metavar=('SOURCE_FILE', 'SHADOW_FILE'),
-                        dest='shadow_file', action='append',
-                        help="When encountering SOURCE_FILE, read and typecheck "
-                             "the contents of SHADOW_FILE instead.")
+    strictness_group.add_argument(
+        '--strict', action='store_true', dest='special-opts:strict',
+        help=strict_help)
+
+    report_group = parser.add_argument_group(
+        title='report generation',
+        description='Generate a report in the specified format.')
+    for report_type in sorted(reporter_classes):
+        report_group.add_argument('--%s-report' % report_type.replace('_', '-'),
+                                  metavar='DIR',
+                                  dest='special-opts:%s_report' % report_type)
+
+    other_group = parser.add_argument_group(
+        title='miscellaneous',
+        description="Other miscellaneous flags.")
+    other_group.add_argument(
+        '--junit-xml', help="write junit.xml to the given file")
+    other_group.add_argument(
+        '--scripts-are-modules', action='store_true',
+        help="script x becomes module x instead of __main__")
+
+    if server_options:
+        # TODO: This flag is superfluous; remove after a short transition (2018-03-16)
+        other_group.add_argument(
+            '--experimental', action='store_true', dest='fine_grained_incremental',
+            help="enable fine-grained incremental mode")
+        other_group.add_argument(
+            '--use-fine-grained-cache', action='store_true',
+            help="use the cache in fine-grained incremental mode")
+
     # hidden options
     # --debug-cache will disable any cache-related compressions/optimizations,
     # which will make the cache writing process output pretty-printed JSON (which
@@ -480,6 +609,19 @@ def add_invertible_flag(flag: str,
     # --local-partial-types disallows partial types spanning module top level and a function
     # (implicitly defined in fine-grained incremental mode)
     parser.add_argument('--local-partial-types', action='store_true', help=argparse.SUPPRESS)
+    # --bazel changes some behaviors for use with Bazel (https://bazel.build).
+    parser.add_argument('--bazel', action='store_true', help=argparse.SUPPRESS)
+    # --package-root adds a directory below which directories are considered
+    # packages even without __init__.py.  May be repeated.
+    parser.add_argument('--package-root', metavar='ROOT', action='append', default=[],
+                        help=argparse.SUPPRESS)
+    # --cache-map FILE ... gives a mapping from source files to cache files.
+    # Each triple of arguments is a source file, a cache meta file, and a cache data file.
+    # Modules not mentioned in the file will go through cache_dir.
+    # Must be followed by another flag or by '--' (and then only file args may follow).
+    parser.add_argument('--cache-map', nargs='+', dest='special-opts:cache_map',
+                        help=argparse.SUPPRESS)
+
     # deprecated options
     parser.add_argument('--disallow-any', dest='special-opts:disallow_any',
                         help=argparse.SUPPRESS)
@@ -502,22 +644,8 @@ def add_invertible_flag(flag: str,
     parser.add_argument('--no-fast-parser', action='store_true',
                         dest='special-opts:no_fast_parser',
                         help=argparse.SUPPRESS)
-    if server_options:
-        # TODO: This flag is superfluous; remove after a short transition (2018-03-16)
-        parser.add_argument('--experimental', action='store_true', dest='fine_grained_incremental',
-                            help="enable fine-grained incremental mode")
-        parser.add_argument('--use-fine-grained-cache', action='store_true',
-                            help="use the cache in fine-grained incremental mode")
-
-    report_group = parser.add_argument_group(
-        title='report generation',
-        description='Generate a report in the specified format.')
-    for report_type in sorted(reporter_classes):
-        report_group.add_argument('--%s-report' % report_type.replace('_', '-'),
-                                  metavar='DIR',
-                                  dest='special-opts:%s_report' % report_type)
 
-    code_group = parser.add_argument_group(title='How to specify the code to type check')
+    code_group = parser.add_argument_group(title='specifying which code to type check')
     code_group.add_argument('-m', '--module', action='append', metavar='MODULE',
                             default=[],
                             dest='special-opts:modules',
@@ -633,6 +761,14 @@ def add_invertible_flag(flag: str,
             report_dir = val
             options.report_dirs[report_type] = report_dir
 
+    # Process --package-root.
+    if options.package_root:
+        process_package_roots(fscache, parser, options)
+
+    # Process --cache-map.
+    if special_opts.cache_map:
+        process_cache_map(parser, special_opts, options)
+
     # Let quick_and_dirty imply incremental.
     if options.quick_and_dirty:
         options.incremental = True
@@ -666,6 +802,63 @@ def add_invertible_flag(flag: str,
         return targets, options
 
 
+def process_package_roots(fscache: Optional[FileSystemCache],
+                          parser: argparse.ArgumentParser,
+                          options: Options) -> None:
+    """Validate and normalize package_root."""
+    if fscache is None:
+        parser.error("--package-root does not work here (no fscache)")
+    assert fscache is not None  # Since mypy doesn't know parser.error() raises.
+    # Do some stuff with drive letters to make Windows happy (esp. tests).
+    current_drive, _ = os.path.splitdrive(os.getcwd())
+    dot = os.curdir
+    dotslash = os.curdir + os.sep
+    dotdotslash = os.pardir + os.sep
+    trivial_paths = {dot, dotslash}
+    package_root = []
+    for root in options.package_root:
+        if os.path.isabs(root):
+            parser.error("Package root cannot be absolute: %r" % root)
+        drive, root = os.path.splitdrive(root)
+        if drive and drive != current_drive:
+            parser.error("Package root must be on current drive: %r" % (drive + root))
+        # Empty package root is always okay.
+        if root:
+            root = os.path.relpath(root)  # Normalize the heck out of it.
+            if root.startswith(dotdotslash):
+                parser.error("Package root cannot be above current directory: %r" % root)
+            if root in trivial_paths:
+                root = ''
+            elif not root.endswith(os.sep):
+                root = root + os.sep
+        package_root.append(root)
+    options.package_root = package_root
+    # Pass the package root on the the filesystem cache.
+    fscache.set_package_root(package_root)
+
+
+def process_cache_map(parser: argparse.ArgumentParser,
+                      special_opts: argparse.Namespace,
+                      options: Options) -> None:
+    """Validate cache_map and copy into options.cache_map."""
+    n = len(special_opts.cache_map)
+    if n % 3 != 0:
+        parser.error("--cache-map requires one or more triples (see source)")
+    for i in range(0, n, 3):
+        source, meta_file, data_file = special_opts.cache_map[i:i + 3]
+        if source in options.cache_map:
+            parser.error("Duplicate --cache-map source %s)" % source)
+        if not source.endswith('.py') and not source.endswith('.pyi'):
+            parser.error("Invalid --cache-map source %s (triple[0] must be *.py[i])" % source)
+        if not meta_file.endswith('.meta.json'):
+            parser.error("Invalid --cache-map meta_file %s (triple[1] must be *.meta.json)" %
+                         meta_file)
+        if not data_file.endswith('.data.json'):
+            parser.error("Invalid --cache-map data_file %s (triple[2] must be *.data.json)" %
+                         data_file)
+        options.cache_map[source] = (meta_file, data_file)
+
+
 # For most options, the type of the default value set in options.py is
 # sufficient, and we don't have to do anything here.  This table
 # exists to specify types for values initialized to None or container
@@ -683,6 +876,7 @@ def add_invertible_flag(flag: str,
     'plugins': lambda s: [p.strip() for p in s.split(',')],
     'always_true': lambda s: [p.strip() for p in s.split(',')],
     'always_false': lambda s: [p.strip() for p in s.split(',')],
+    'package_root': lambda s: [p.strip() for p in s.split(',')],
 }
 
 
diff --git a/mypy/meet.py b/mypy/meet.py
index 0d44d80820..32772f4801 100644
--- a/mypy/meet.py
+++ b/mypy/meet.py
@@ -1,11 +1,10 @@
 from collections import OrderedDict
-from typing import List, Optional, cast, Tuple
+from typing import List, Optional, Tuple
 
 from mypy.join import is_similar_callables, combine_similar_callables, join_type_list
-from mypy.sametypes import is_same_type
 from mypy.types import (
     Type, AnyType, TypeVisitor, UnboundType, NoneTyp, TypeVarType, Instance, CallableType,
-    TupleType, TypedDictType, ErasedType, TypeList, UnionType, PartialType, DeletedType,
+    TupleType, TypedDictType, ErasedType, UnionType, PartialType, DeletedType,
     UninhabitedType, TypeType, TypeOfAny
 )
 from mypy.subtypes import is_equivalent, is_subtype, is_protocol_implementation
diff --git a/mypy/memprofile.py b/mypy/memprofile.py
index 1e2a3e7a8f..81d2a6aafd 100644
--- a/mypy/memprofile.py
+++ b/mypy/memprofile.py
@@ -7,7 +7,7 @@
 from collections import defaultdict
 import gc
 import sys
-from typing import List, Dict, Set, Iterable, Tuple, cast
+from typing import List, Dict, Iterable, Tuple, cast
 
 from mypy.nodes import FakeInfo, Node
 from mypy.types import Type
diff --git a/mypy/nodes.py b/mypy/nodes.py
index 61d86df0c5..2ec8859a8a 100644
--- a/mypy/nodes.py
+++ b/mypy/nodes.py
@@ -1298,27 +1298,7 @@ def accept(self, visitor: ExpressionVisitor[T]) -> T:
         return visitor.visit_name_expr(self)
 
     def serialize(self) -> JsonDict:
-        # TODO: Find out where and why NameExpr is being serialized (if at all).
         assert False, "Serializing NameExpr: %s" % (self,)
-        return {'.class': 'NameExpr',
-                'kind': self.kind,
-                'node': None if self.node is None else self.node.serialize(),
-                'fullname': self.fullname,
-                'is_new_def': self.is_new_def,
-                'is_inferred_def': self.is_inferred_def,
-                'name': self.name,
-                }
-
-    @classmethod
-    def deserialize(cls, data: JsonDict) -> 'NameExpr':
-        assert data['.class'] == 'NameExpr'
-        ret = NameExpr(data['name'])
-        ret.kind = data['kind']
-        ret.node = None if data['node'] is None else SymbolNode.deserialize(data['node'])
-        ret.fullname = data['fullname']
-        ret.is_new_def = data['is_new_def']
-        ret.is_inferred_def = data['is_inferred_def']
-        return ret
 
 
 class MemberExpr(RefExpr):
@@ -2223,7 +2203,7 @@ def protocol_members(self) -> List[str]:
         # Protocol members are names of all attributes/methods defined in a protocol
         # and in all its supertypes (except for 'object').
         members = set()  # type: Set[str]
-        assert self.mro, "This property can be only acessed after MRO is (re-)calculated"
+        assert self.mro, "This property can be only accessed after MRO is (re-)calculated"
         for base in self.mro[:-1]:  # we skip "object" since everyone implements it
             if base.is_protocol:
                 for name in base.names:
@@ -2390,7 +2370,7 @@ def deserialize(cls, data: JsonDict) -> 'TypeInfo':
         # not be loaded until after a class in the mro has changed its
         # bases, which causes the mro to change. If we recomputed our
         # mro, we would compute the *new* mro, which leaves us with no
-        # way to detact that the mro has changed! Thus we need to make
+        # way to detect that the mro has changed! Thus we need to make
         # sure to load the original mro so that once the class is
         # rechecked, it can tell that the mro has changed.
         ti._mro_refs = data['mro']
diff --git a/mypy/options.py b/mypy/options.py
index bb95ff1af2..4a248b9fe7 100644
--- a/mypy/options.py
+++ b/mypy/options.py
@@ -3,7 +3,7 @@
 import pprint
 import sys
 
-from typing import Dict, List, Mapping, MutableMapping, Optional, Pattern, Set, Tuple
+from typing import Dict, List, Mapping, Optional, Pattern, Set, Tuple
 
 from mypy import defaults
 
@@ -47,7 +47,7 @@ class Options:
     }
 
     OPTIONS_AFFECTING_CACHE = ((PER_MODULE_OPTIONS |
-                                {"quick_and_dirty", "platform"})
+                                {"quick_and_dirty", "platform", "bazel"})
                                - {"debug_cache"})
 
     def __init__(self) -> None:
@@ -193,6 +193,12 @@ def __init__(self) -> None:
         self.dump_deps = False
         # If True, partial types can't span a module top level and a function
         self.local_partial_types = False
+        # Some behaviors are changed when using Bazel (https://bazel.build).
+        self.bazel = False
+        # List of package roots -- directories under these are packages even
+        # if they don't have __init__.py.
+        self.package_root = []  # type: List[str]
+        self.cache_map = {}  # type: Dict[str, Tuple[str, str]]
 
     def snapshot(self) -> object:
         """Produce a comparable snapshot of this Option"""
diff --git a/mypy/parse.py b/mypy/parse.py
index d845138727..149a0bbb61 100644
--- a/mypy/parse.py
+++ b/mypy/parse.py
@@ -1,4 +1,4 @@
-from typing import List, Tuple, Set, cast, Union, Optional
+from typing import Union, Optional
 
 from mypy.errors import Errors
 from mypy.options import Options
diff --git a/mypy/plugin.py b/mypy/plugin.py
index 75b3708575..f6bd02f923 100644
--- a/mypy/plugin.py
+++ b/mypy/plugin.py
@@ -4,7 +4,6 @@
 from functools import partial
 from typing import Callable, List, Tuple, Optional, NamedTuple, TypeVar, Dict
 
-import mypy.plugins.attrs
 from mypy.nodes import (
     Expression, StrExpr, IntExpr, UnaryExpr, Context, DictExpr, ClassDef,
     TypeInfo, SymbolTableNode, MypyFile
@@ -302,13 +301,18 @@ def get_method_hook(self, fullname: str
 
     def get_class_decorator_hook(self, fullname: str
                                  ) -> Optional[Callable[[ClassDefContext], None]]:
-        if fullname in mypy.plugins.attrs.attr_class_makers:
-            return mypy.plugins.attrs.attr_class_maker_callback
-        elif fullname in mypy.plugins.attrs.attr_dataclass_makers:
+        from mypy.plugins import attrs
+        from mypy.plugins import dataclasses
+
+        if fullname in attrs.attr_class_makers:
+            return attrs.attr_class_maker_callback
+        elif fullname in attrs.attr_dataclass_makers:
             return partial(
-                mypy.plugins.attrs.attr_class_maker_callback,
+                attrs.attr_class_maker_callback,
                 auto_attribs_default=True
             )
+        elif fullname in dataclasses.dataclass_makers:
+            return dataclasses.dataclass_class_maker_callback
         return None
 
 
diff --git a/mypy/plugins/attrs.py b/mypy/plugins/attrs.py
index 4a7d97f3d2..028b86ca85 100644
--- a/mypy/plugins/attrs.py
+++ b/mypy/plugins/attrs.py
@@ -11,6 +11,9 @@
     is_class_var, TempNode, Decorator, MemberExpr, Expression, FuncDef, Block,
     PassStmt, SymbolTableNode, MDEF, JsonDict, OverloadedFuncDef
 )
+from mypy.plugins.common import (
+    _get_argument, _get_bool_argument, _get_decorator_bool_argument
+)
 from mypy.types import (
     Type, AnyType, TypeOfAny, CallableType, NoneTyp, TypeVarDef, TypeVarType,
     Overloaded, Instance, UnionType, FunctionLike
@@ -53,7 +56,7 @@ def argument(self, ctx: 'mypy.plugin.ClassDefContext') -> Argument:
         init_type = self.info[self.name].type
 
         if self.converter_name:
-            # When a converter is set the init_type is overriden by the first argument
+            # When a converter is set the init_type is overridden by the first argument
             # of the converter method.
             converter = lookup_qualified_stnode(ctx.api.modules, self.converter_name, True)
             if not converter:
@@ -237,11 +240,12 @@ def _analyze_class(ctx: 'mypy.plugin.ClassDefContext', auto_attribs: bool) -> Li
     # attributes for all classes have been read, because subclasses can override parents.
     last_default = False
     for attribute in attributes:
-        if attribute.init and not attribute.has_default and last_default:
-            ctx.api.fail(
-                "Non-default attributes not allowed after default attributes.",
-                attribute.context)
-        last_default = attribute.has_default
+        if attribute.init:
+            if not attribute.has_default and last_default:
+                ctx.api.fail(
+                    "Non-default attributes not allowed after default attributes.",
+                    attribute.context)
+            last_default |= attribute.has_default
 
     return attributes
 
@@ -468,67 +472,6 @@ def _add_init(ctx: 'mypy.plugin.ClassDefContext', attributes: List[Attribute],
                 func_type.arg_types[0] = ctx.api.class_type(ctx.cls.info)
 
 
-def _get_decorator_bool_argument(
-        ctx: 'mypy.plugin.ClassDefContext',
-        name: str,
-        default: bool) -> bool:
-    """Return the bool argument for the decorator.
-
-    This handles both @attr.s(...) and @attr.s
-    """
-    if isinstance(ctx.reason, CallExpr):
-        return _get_bool_argument(ctx, ctx.reason, name, default)
-    else:
-        return default
-
-
-def _get_bool_argument(ctx: 'mypy.plugin.ClassDefContext', expr: CallExpr,
-                       name: str, default: bool) -> bool:
-    """Return the boolean value for an argument to a call or the default if it's not found."""
-    attr_value = _get_argument(expr, name)
-    if attr_value:
-        ret = ctx.api.parse_bool(attr_value)
-        if ret is None:
-            ctx.api.fail('"{}" argument must be True or False.'.format(name), expr)
-            return default
-        return ret
-    return default
-
-
-def _get_argument(call: CallExpr, name: str) -> Optional[Expression]:
-    """Return the expression for the specific argument."""
-    # To do this we use the CallableType of the callee to find the FormalArgument,
-    # then walk the actual CallExpr looking for the appropriate argument.
-    #
-    # Note: I'm not hard-coding the index so that in the future we can support other
-    # attrib and class makers.
-    callee_type = None
-    if (isinstance(call.callee, RefExpr)
-            and isinstance(call.callee.node, (Var, FuncBase))
-            and call.callee.node.type):
-        callee_node_type = call.callee.node.type
-        if isinstance(callee_node_type, Overloaded):
-            # We take the last overload.
-            callee_type = callee_node_type.items()[-1]
-        elif isinstance(callee_node_type, CallableType):
-            callee_type = callee_node_type
-
-    if not callee_type:
-        return None
-
-    argument = callee_type.argument_by_name(name)
-    if not argument:
-        return None
-    assert argument.name
-
-    for i, (attr_name, attr_value) in enumerate(zip(call.arg_names, call.args)):
-        if argument.pos is not None and not attr_name and i == argument.pos:
-            return attr_value
-        if attr_name == argument.name:
-            return attr_value
-    return None
-
-
 class MethodAdder:
     """Helper to add methods to a TypeInfo.
 
diff --git a/mypy/plugins/common.py b/mypy/plugins/common.py
new file mode 100644
index 0000000000..28bfbb038a
--- /dev/null
+++ b/mypy/plugins/common.py
@@ -0,0 +1,110 @@
+from typing import List, Optional
+
+from mypy.nodes import (
+    ARG_POS, MDEF, Argument, Block, CallExpr, Expression, FuncBase,
+    FuncDef, PassStmt, RefExpr, SymbolTableNode, Var
+)
+from mypy.plugin import ClassDefContext
+from mypy.semanal import set_callable_name
+from mypy.types import CallableType, Overloaded, Type, TypeVarDef
+from mypy.typevars import fill_typevars
+
+
+def _get_decorator_bool_argument(
+        ctx: ClassDefContext,
+        name: str,
+        default: bool,
+) -> bool:
+    """Return the bool argument for the decorator.
+
+    This handles both @decorator(...) and @decorator.
+    """
+    if isinstance(ctx.reason, CallExpr):
+        return _get_bool_argument(ctx, ctx.reason, name, default)
+    else:
+        return default
+
+
+def _get_bool_argument(ctx: ClassDefContext, expr: CallExpr,
+                       name: str, default: bool) -> bool:
+    """Return the boolean value for an argument to a call or the
+    default if it's not found.
+    """
+    attr_value = _get_argument(expr, name)
+    if attr_value:
+        ret = ctx.api.parse_bool(attr_value)
+        if ret is None:
+            ctx.api.fail('"{}" argument must be True or False.'.format(name), expr)
+            return default
+        return ret
+    return default
+
+
+def _get_argument(call: CallExpr, name: str) -> Optional[Expression]:
+    """Return the expression for the specific argument."""
+    # To do this we use the CallableType of the callee to find the FormalArgument,
+    # then walk the actual CallExpr looking for the appropriate argument.
+    #
+    # Note: I'm not hard-coding the index so that in the future we can support other
+    # attrib and class makers.
+    callee_type = None
+    if (isinstance(call.callee, RefExpr)
+            and isinstance(call.callee.node, (Var, FuncBase))
+            and call.callee.node.type):
+        callee_node_type = call.callee.node.type
+        if isinstance(callee_node_type, Overloaded):
+            # We take the last overload.
+            callee_type = callee_node_type.items()[-1]
+        elif isinstance(callee_node_type, CallableType):
+            callee_type = callee_node_type
+
+    if not callee_type:
+        return None
+
+    argument = callee_type.argument_by_name(name)
+    if not argument:
+        return None
+    assert argument.name
+
+    for i, (attr_name, attr_value) in enumerate(zip(call.arg_names, call.args)):
+        if argument.pos is not None and not attr_name and i == argument.pos:
+            return attr_value
+        if attr_name == argument.name:
+            return attr_value
+    return None
+
+
+def _add_method(
+        ctx: ClassDefContext,
+        name: str,
+        args: List[Argument],
+        return_type: Type,
+        self_type: Optional[Type] = None,
+        tvar_def: Optional[TypeVarDef] = None,
+) -> None:
+    """Adds a new method to a class.
+    """
+    info = ctx.cls.info
+    self_type = self_type or fill_typevars(info)
+    function_type = ctx.api.named_type('__builtins__.function')
+
+    args = [Argument(Var('self'), self_type, None, ARG_POS)] + args
+    arg_types, arg_names, arg_kinds = [], [], []
+    for arg in args:
+        assert arg.type_annotation, 'All arguments must be fully typed.'
+        arg_types.append(arg.type_annotation)
+        arg_names.append(arg.variable.name())
+        arg_kinds.append(arg.kind)
+
+    signature = CallableType(arg_types, arg_kinds, arg_names, return_type, function_type)
+    if tvar_def:
+        signature.variables = [tvar_def]
+
+    func = FuncDef(name, args, Block([PassStmt()]))
+    func.info = info
+    func.type = set_callable_name(signature, func)
+    func._fullname = info.fullname() + '.' + name
+    func.line = info.line
+
+    info.names[name] = SymbolTableNode(MDEF, func)
+    info.defn.defs.body.append(func)
diff --git a/mypy/plugins/dataclasses.py b/mypy/plugins/dataclasses.py
new file mode 100644
index 0000000000..9dba62558b
--- /dev/null
+++ b/mypy/plugins/dataclasses.py
@@ -0,0 +1,322 @@
+from collections import OrderedDict
+from typing import Dict, List, Set, Tuple
+
+from mypy.nodes import (
+    ARG_OPT, ARG_POS, MDEF, Argument, AssignmentStmt, CallExpr,
+    Context, Decorator, Expression, FuncDef, JsonDict, NameExpr,
+    SymbolTableNode, TempNode, TypeInfo, Var,
+)
+from mypy.plugin import ClassDefContext
+from mypy.plugins.common import _add_method, _get_decorator_bool_argument
+from mypy.types import (
+    CallableType, Instance, NoneTyp, TypeVarDef, TypeVarType,
+)
+
+# The set of decorators that generate dataclasses.
+dataclass_makers = {
+    'dataclass',
+    'dataclasses.dataclass',
+}
+
+
+class DataclassAttribute:
+    def __init__(
+            self,
+            name: str,
+            is_in_init: bool,
+            is_init_var: bool,
+            has_default: bool,
+            line: int,
+            column: int,
+    ) -> None:
+        self.name = name
+        self.is_in_init = is_in_init
+        self.is_init_var = is_init_var
+        self.has_default = has_default
+        self.line = line
+        self.column = column
+
+    def to_argument(self, info: TypeInfo) -> Argument:
+        return Argument(
+            variable=self.to_var(info),
+            type_annotation=info[self.name].type,
+            initializer=None,
+            kind=ARG_OPT if self.has_default else ARG_POS,
+        )
+
+    def to_var(self, info: TypeInfo) -> Var:
+        return Var(self.name, info[self.name].type)
+
+    def serialize(self) -> JsonDict:
+        return {
+            'name': self.name,
+            'is_in_init': self.is_in_init,
+            'is_init_var': self.is_init_var,
+            'has_default': self.has_default,
+            'line': self.line,
+            'column': self.column,
+        }
+
+    @classmethod
+    def deserialize(cls, info: TypeInfo, data: JsonDict) -> 'DataclassAttribute':
+        return cls(**data)
+
+
+class DataclassTransformer:
+    def __init__(self, ctx: ClassDefContext) -> None:
+        self._ctx = ctx
+
+    def transform(self) -> None:
+        """Apply all the necessary transformations to the underlying
+        dataclass so as to ensure it is fully type checked according
+        to the rules in PEP 557.
+        """
+        ctx = self._ctx
+        info = self._ctx.cls.info
+        attributes = self.collect_attributes()
+        decorator_arguments = {
+            'init': _get_decorator_bool_argument(self._ctx, 'init', True),
+            'eq': _get_decorator_bool_argument(self._ctx, 'eq', True),
+            'order': _get_decorator_bool_argument(self._ctx, 'order', False),
+            'frozen': _get_decorator_bool_argument(self._ctx, 'frozen', False),
+        }
+
+        if decorator_arguments['init']:
+            _add_method(
+                ctx,
+                '__init__',
+                args=[attr.to_argument(info) for attr in attributes if attr.is_in_init],
+                return_type=NoneTyp(),
+            )
+            for stmt in self._ctx.cls.defs.body:
+                # Fix up the types of classmethods since, by default,
+                # they will be based on the parent class' init.
+                if isinstance(stmt, Decorator) and stmt.func.is_class:
+                    func_type = stmt.func.type
+                    if isinstance(func_type, CallableType):
+                        func_type.arg_types[0] = self._ctx.api.class_type(self._ctx.cls.info)
+
+        # Add an eq method, but only if the class doesn't already have one.
+        if decorator_arguments['eq'] and info.get('__eq__') is None:
+            for method_name in ['__eq__', '__ne__']:
+                # The TVar is used to enforce that "other" must have
+                # the same type as self (covariant).  Note the
+                # "self_type" parameter to _add_method.
+                obj_type = ctx.api.named_type('__builtins__.object')
+                cmp_tvar_def = TypeVarDef('T', 'T', 1, [], obj_type)
+                cmp_other_type = TypeVarType(cmp_tvar_def)
+                cmp_return_type = ctx.api.named_type('__builtins__.bool')
+
+                _add_method(
+                    ctx,
+                    method_name,
+                    args=[Argument(Var('other', cmp_other_type), cmp_other_type, None, ARG_POS)],
+                    return_type=cmp_return_type,
+                    self_type=cmp_other_type,
+                    tvar_def=cmp_tvar_def,
+                )
+
+        # Add <, >, <=, >=, but only if the class has an eq method.
+        if decorator_arguments['order']:
+            if not decorator_arguments['eq']:
+                ctx.api.fail('eq must be True if order is True', ctx.cls)
+
+            for method_name in ['__lt__', '__gt__', '__le__', '__ge__']:
+                # Like for __eq__ and __ne__, we want "other" to match
+                # the self type.
+                obj_type = ctx.api.named_type('__builtins__.object')
+                order_tvar_def = TypeVarDef('T', 'T', 1, [], obj_type)
+                order_other_type = TypeVarType(order_tvar_def)
+                order_return_type = ctx.api.named_type('__builtins__.bool')
+                order_args = [
+                    Argument(Var('other', order_other_type), order_other_type, None, ARG_POS)
+                ]
+
+                existing_method = info.get(method_name)
+                if existing_method is not None:
+                    assert existing_method.node
+                    ctx.api.fail(
+                        'You may not have a custom %s method when order=True' % method_name,
+                        existing_method.node,
+                    )
+
+                _add_method(
+                    ctx,
+                    method_name,
+                    args=order_args,
+                    return_type=order_return_type,
+                    self_type=order_other_type,
+                    tvar_def=order_tvar_def,
+                )
+
+        if decorator_arguments['frozen']:
+            self._freeze(attributes)
+
+        # Remove init-only vars from the class.
+        for attr in attributes:
+            if attr.is_init_var:
+                del info.names[attr.name]
+
+        info.metadata['dataclass'] = {
+            'attributes': OrderedDict((attr.name, attr.serialize()) for attr in attributes),
+            'frozen': decorator_arguments['frozen'],
+        }
+
+    def collect_attributes(self) -> List[DataclassAttribute]:
+        """Collect all attributes declared in the dataclass and its parents.
+
+        All assignments of the form
+
+          a: SomeType
+          b: SomeOtherType = ...
+
+        are collected.
+        """
+        # First, collect attributes belonging to the current class.
+        ctx = self._ctx
+        cls = self._ctx.cls
+        attrs = []  # type: List[DataclassAttribute]
+        known_attrs = set()  # type: Set[str]
+        for stmt in cls.defs.body:
+            # Any assignment that doesn't use the new type declaration
+            # syntax can be ignored out of hand.
+            if not (isinstance(stmt, AssignmentStmt) and stmt.new_syntax):
+                continue
+
+            # a: int, b: str = 1, 'foo' is not supported syntax so we
+            # don't have to worry about it.
+            lhs = stmt.lvalues[0]
+            if not isinstance(lhs, NameExpr):
+                continue
+
+            node = cls.info.names[lhs.name].node
+            assert isinstance(node, Var)
+
+            # x: ClassVar[int] is ignored by dataclasses.
+            if node.is_classvar:
+                continue
+
+            # x: InitVar[int] is turned into x: int and is removed from the class.
+            is_init_var = False
+            if (
+                    isinstance(node.type, Instance) and
+                    node.type.type.fullname() == 'dataclasses.InitVar'
+            ):
+                is_init_var = True
+                node.type = node.type.args[0]
+
+            has_field_call, field_args = _collect_field_args(stmt.rvalue)
+
+            is_in_init_param = field_args.get('init')
+            if is_in_init_param is None:
+                is_in_init = True
+            else:
+                is_in_init = bool(ctx.api.parse_bool(is_in_init_param))
+
+            has_default = False
+            # Ensure that something like x: int = field() is rejected
+            # after an attribute with a default.
+            if has_field_call:
+                has_default = 'default' in field_args or 'default_factory' in field_args
+
+            # All other assignments are already type checked.
+            elif not isinstance(stmt.rvalue, TempNode):
+                has_default = True
+
+            known_attrs.add(lhs.name)
+            attrs.append(DataclassAttribute(
+                name=lhs.name,
+                is_in_init=is_in_init,
+                is_init_var=is_init_var,
+                has_default=has_default,
+                line=stmt.line,
+                column=stmt.column,
+            ))
+
+        # Next, collect attributes belonging to any class in the MRO
+        # as long as those attributes weren't already collected.  This
+        # makes it possible to overwrite attributes in subclasses.
+        super_attrs = []
+        init_method = cls.info.get_method('__init__')
+        for info in cls.info.mro[1:-1]:
+            if 'dataclass' not in info.metadata:
+                continue
+
+            for name, data in info.metadata['dataclass']['attributes'].items():
+                if name not in known_attrs:
+                    attr = DataclassAttribute.deserialize(info, data)
+                    if attr.is_init_var and isinstance(init_method, FuncDef):
+                        # InitVars are removed from classes so, in order for them to be inherited
+                        # properly, we need to re-inject them into subclasses' sym tables here.
+                        # To do that, we look 'em up from the parents' __init__.  These variables
+                        # are subsequently removed from the sym table at the end of
+                        # DataclassTransformer.transform.
+                        for arg, arg_name in zip(init_method.arguments, init_method.arg_names):
+                            if arg_name == attr.name:
+                                cls.info.names[attr.name] = SymbolTableNode(MDEF, arg.variable)
+
+                    known_attrs.add(name)
+                    super_attrs.append(attr)
+
+        all_attrs = super_attrs + attrs
+
+        # Ensure that arguments without a default don't follow
+        # arguments that have a default.
+        found_default = False
+        for attr in all_attrs:
+            # If we find any attribute that is_in_init but that
+            # doesn't have a default after one that does have one,
+            # then that's an error.
+            if found_default and attr.is_in_init and not attr.has_default:
+                ctx.api.fail(
+                    'Attributes without a default cannot follow attributes with one',
+                    Context(line=attr.line, column=attr.column),
+                )
+
+            found_default = found_default or attr.has_default
+
+        return all_attrs
+
+    def _freeze(self, attributes: List[DataclassAttribute]) -> None:
+        """Converts all attributes to @property methods in order to
+        emulate frozen classes.
+        """
+        info = self._ctx.cls.info
+        for attr in attributes:
+            sym_node = info.names.get(attr.name)
+            if sym_node is not None:
+                var = sym_node.node
+                assert isinstance(var, Var)
+                var.is_property = True
+            else:
+                var = attr.to_var(info)
+                var.info = info
+                var.is_property = True
+                var._fullname = info.fullname() + '.' + var.name()
+                info.names[var.name()] = SymbolTableNode(MDEF, var)
+
+
+def dataclass_class_maker_callback(ctx: ClassDefContext) -> None:
+    """Hooks into the class typechecking process to add support for dataclasses.
+    """
+    transformer = DataclassTransformer(ctx)
+    transformer.transform()
+
+
+def _collect_field_args(expr: Expression) -> Tuple[bool, Dict[str, Expression]]:
+    """Returns a tuple where the first value represents whether or not
+    the expression is a call to dataclass.field and the second is a
+    dictionary of the keyword arguments that field() was called with.
+    """
+    if (
+            isinstance(expr, CallExpr) and
+            isinstance(expr.callee, NameExpr) and
+            expr.callee.fullname == 'dataclasses.field'
+    ):
+        # field() only takes keyword arguments.
+        args = {}
+        for name, arg in zip(expr.arg_names, expr.args):
+            assert name is not None
+            args[name] = arg
+        return True, args
+    return False, {}
diff --git a/mypy/sametypes.py b/mypy/sametypes.py
index cba80e1ef8..b382c632ff 100644
--- a/mypy/sametypes.py
+++ b/mypy/sametypes.py
@@ -3,7 +3,7 @@
 from mypy.types import (
     Type, UnboundType, AnyType, NoneTyp, TupleType, TypedDictType,
     UnionType, CallableType, TypeVarType, Instance, TypeVisitor, ErasedType,
-    TypeList, Overloaded, PartialType, DeletedType, UninhabitedType, TypeType
+    Overloaded, PartialType, DeletedType, UninhabitedType, TypeType
 )
 
 
diff --git a/mypy/semanal.py b/mypy/semanal.py
index b241cb047a..e7678d0e67 100644
--- a/mypy/semanal.py
+++ b/mypy/semanal.py
@@ -44,18 +44,18 @@
     ImportFrom, ImportAll, Block, LDEF, NameExpr, MemberExpr,
     IndexExpr, TupleExpr, ListExpr, ExpressionStmt, ReturnStmt,
     RaiseStmt, AssertStmt, OperatorAssignmentStmt, WhileStmt,
-    ForStmt, BreakStmt, ContinueStmt, IfStmt, TryStmt, WithStmt, DelStmt, PassStmt,
+    ForStmt, BreakStmt, ContinueStmt, IfStmt, TryStmt, WithStmt, DelStmt,
     GlobalDecl, SuperExpr, DictExpr, CallExpr, RefExpr, OpExpr, UnaryExpr,
     SliceExpr, CastExpr, RevealExpr, TypeApplication, Context, SymbolTable,
     SymbolTableNode, TVAR, ListComprehension, GeneratorExpr,
-    LambdaExpr, MDEF, FuncBase, Decorator, SetExpr, TypeVarExpr, NewTypeExpr,
+    LambdaExpr, MDEF, Decorator, SetExpr, TypeVarExpr,
     StrExpr, BytesExpr, PrintStmt, ConditionalExpr, PromoteExpr,
-    ComparisonExpr, StarExpr, ARG_POS, ARG_NAMED, ARG_NAMED_OPT, type_aliases,
-    YieldFromExpr, NamedTupleExpr, TypedDictExpr, NonlocalDecl, SymbolNode,
+    ComparisonExpr, StarExpr, ARG_POS, ARG_NAMED, type_aliases,
+    YieldFromExpr, NamedTupleExpr, NonlocalDecl, SymbolNode,
     SetComprehension, DictionaryComprehension, TYPE_ALIAS, TypeAliasExpr,
-    YieldExpr, ExecStmt, Argument, BackquoteExpr, ImportBase, AwaitExpr,
-    IntExpr, FloatExpr, UnicodeExpr, EllipsisExpr, TempNode, EnumCallExpr, ImportedName,
-    COVARIANT, CONTRAVARIANT, INVARIANT, UNBOUND_IMPORTED, LITERAL_YES, ARG_OPT, nongen_builtins,
+    YieldExpr, ExecStmt, BackquoteExpr, ImportBase, AwaitExpr,
+    IntExpr, FloatExpr, UnicodeExpr, TempNode, ImportedName,
+    COVARIANT, CONTRAVARIANT, INVARIANT, UNBOUND_IMPORTED, LITERAL_YES, nongen_builtins,
     collections_type_aliases, get_member_expr_fullname, REVEAL_TYPE, REVEAL_LOCALS
 )
 from mypy.literals import literal
@@ -66,9 +66,9 @@
 from mypy.errors import Errors, report_internal_error
 from mypy.messages import CANNOT_ASSIGN_TO_TYPE, MessageBuilder
 from mypy.types import (
-    FunctionLike, UnboundType, TypeVarDef, TypeType, TupleType, UnionType, StarType, function_type,
-    TypedDictType, NoneTyp, CallableType, Overloaded, Instance, Type, TypeVarType, AnyType,
-    TypeTranslator, TypeOfAny, TypeVisitor, UninhabitedType, ErasedType, DeletedType
+    FunctionLike, UnboundType, TypeVarDef, TupleType, UnionType, StarType, function_type,
+    CallableType, Overloaded, Instance, Type, AnyType,
+    TypeTranslator, TypeOfAny
 )
 from mypy.nodes import implicit_module_attrs
 from mypy.typeanal import (
@@ -81,9 +81,8 @@
 from mypy.options import Options
 from mypy import experiments
 from mypy.plugin import Plugin, ClassDefContext, SemanticAnalyzerPluginInterface
-from mypy import join
 from mypy.util import get_prefix, correct_relative_import
-from mypy.semanal_shared import SemanticAnalyzerInterface, set_callable_name, PRIORITY_FALLBACKS
+from mypy.semanal_shared import SemanticAnalyzerInterface, set_callable_name
 from mypy.scope import Scope
 from mypy.semanal_namedtuple import NamedTupleAnalyzer, NAMEDTUPLE_PROHIBITED_NAMES
 from mypy.semanal_typeddict import TypedDictAnalyzer
@@ -585,7 +584,7 @@ def _visit_overloaded_func_def(self, defn: OverloadedFuncDef) -> None:
 
         if not defn.items:
             # It was not any kind of overload def after all. We've visited the
-            # redfinitions already.
+            # redefinitions already.
             return
 
         if self.type and not self.is_func_scope():
@@ -862,7 +861,7 @@ def setup_type_promotion(self, defn: ClassDef) -> None:
             if isinstance(decorator, CallExpr):
                 analyzed = decorator.analyzed
                 if isinstance(analyzed, PromoteExpr):
-                    # _promote class decorator (undocumented faeture).
+                    # _promote class decorator (undocumented feature).
                     promote_target = analyzed.type
         if not promote_target:
             promotions = (TYPE_PROMOTIONS_PYTHON3 if self.options.python_version[0] >= 3
diff --git a/mypy/semanal_pass1.py b/mypy/semanal_pass1.py
index 7e2e911940..12da48e928 100644
--- a/mypy/semanal_pass1.py
+++ b/mypy/semanal_pass1.py
@@ -13,7 +13,7 @@
 definitions, as these look like regular assignments until we are able to
 bind names, which only happens in pass 2.
 
-This pass also infers the reachability of certain if staments, such as
+This pass also infers the reachability of certain if statements, such as
 those with platform checks.
 """
 
@@ -32,7 +32,6 @@
 from mypy.options import Options
 from mypy.sametypes import is_same_type
 from mypy.visitor import NodeVisitor
-from mypy.util import correct_relative_import
 
 
 class SemanticAnalyzerPass1(NodeVisitor[None]):
diff --git a/mypy/semanal_pass3.py b/mypy/semanal_pass3.py
index 6b70025ed2..947afc0c79 100644
--- a/mypy/semanal_pass3.py
+++ b/mypy/semanal_pass3.py
@@ -10,8 +10,7 @@
 """
 
 from collections import OrderedDict
-from contextlib import contextmanager
-from typing import Dict, List, Callable, Optional, Union, Set, cast, Tuple, Iterator
+from typing import Dict, List, Callable, Optional, Union, cast, Tuple
 
 from mypy import messages, experiments
 from mypy.nodes import (
@@ -77,6 +76,7 @@ def visit_file(self, file_node: MypyFile, fnam: str, options: Options,
     def refresh_partial(self, node: Union[MypyFile, FuncItem, OverloadedFuncDef],
                         patches: List[Tuple[int, Callable[[], None]]]) -> None:
         """Refresh a stale target in fine-grained incremental mode."""
+        self.options = self.sem.options
         self.patches = patches
         if isinstance(node, MypyFile):
             self.recurse_into_functions = False
@@ -204,7 +204,7 @@ def visit_decorator(self, dec: Decorator) -> None:
             sig = find_fixed_callable_return(dec.decorators[0])
             if sig:
                 # The outermost decorator always returns the same kind of function,
-                # so we know that this is the type of the decoratored function.
+                # so we know that this is the type of the decorated function.
                 orig_sig = function_type(dec.func, self.builtin_type('function'))
                 sig.name = orig_sig.items()[0].name
                 dec.var.type = sig
diff --git a/mypy/server/astdiff.py b/mypy/server/astdiff.py
index 30b449c9f3..e525496163 100644
--- a/mypy/server/astdiff.py
+++ b/mypy/server/astdiff.py
@@ -50,16 +50,16 @@ class level -- these are handled at attribute level (say, 'mod.Cls.method'
   fine-grained dependencies.
 """
 
-from typing import Set, List, TypeVar, Dict, Tuple, Optional, Sequence, Union
+from typing import Set, Dict, Tuple, Optional, Sequence, Union
 
 from mypy.nodes import (
-    SymbolTable, SymbolTableNode, TypeInfo, Var, MypyFile, SymbolNode, Decorator, TypeVarExpr,
+    SymbolTable, TypeInfo, Var, SymbolNode, Decorator, TypeVarExpr,
     OverloadedFuncDef, FuncItem, MODULE_REF, TYPE_ALIAS, UNBOUND_IMPORTED, TVAR
 )
 from mypy.types import (
-    Type, TypeVisitor, UnboundType, TypeList, AnyType, NoneTyp, UninhabitedType,
+    Type, TypeVisitor, UnboundType, AnyType, NoneTyp, UninhabitedType,
     ErasedType, DeletedType, Instance, TypeVarType, CallableType, TupleType, TypedDictType,
-    UnionType, Overloaded, PartialType, TypeType, function_type
+    UnionType, Overloaded, PartialType, TypeType
 )
 from mypy.util import get_prefix
 
diff --git a/mypy/server/astmerge.py b/mypy/server/astmerge.py
index 7ab4fd7283..15f4ee1302 100644
--- a/mypy/server/astmerge.py
+++ b/mypy/server/astmerge.py
@@ -4,7 +4,7 @@
 we build a new AST from the updated source. However, other parts of the program
 may have direct references to parts of the old AST (namely, those nodes exposed
 in the module symbol table). The merge operation changes the identities of new
-AST nodes that have a correspondance in the old AST to the old ones so that
+AST nodes that have a correspondence in the old AST to the old ones so that
 existing cross-references in other modules will continue to point to the correct
 nodes. Also internal cross-references within the new AST are replaced. AST nodes
 that aren't externally visible will get new, distinct object identities. This
@@ -15,7 +15,7 @@
 translation when looking up references (which would be hard to retrofit).
 
 The AST merge operation is performed after semantic analysis. Semantic
-analysis has to deal with potentionally multiple aliases to certain AST
+analysis has to deal with potentially multiple aliases to certain AST
 nodes (in particular, MypyFile nodes). Type checking assumes that we
 don't have multiple variants of a single AST node visible to the type
 checker.
@@ -28,7 +28,7 @@
 
 * If a function is replaced with another function with an identical signature,
   call sites continue to point to the same object (by identity) and don't need
-  to be reprocessed. Similary, if a class is replaced with a class that is
+  to be reprocessed. Similarly, if a class is replaced with a class that is
   sufficiently similar (MRO preserved, etc.), class references don't need any
   processing. A typical incremental update to a file only changes a few
   externally visible things in a module, and this means that often only few
@@ -48,7 +48,7 @@
 from typing import Dict, List, cast, TypeVar, Optional
 
 from mypy.nodes import (
-    Node, MypyFile, SymbolTable, Block, AssignmentStmt, NameExpr, MemberExpr, RefExpr, TypeInfo,
+    MypyFile, SymbolTable, Block, AssignmentStmt, NameExpr, MemberExpr, RefExpr, TypeInfo,
     FuncDef, ClassDef, NamedTupleExpr, SymbolNode, Var, Statement, SuperExpr, NewTypeExpr,
     OverloadedFuncDef, LambdaExpr, TypedDictExpr, EnumCallExpr, FuncBase, TypeAliasExpr, CallExpr,
     CastExpr,
diff --git a/mypy/server/deps.py b/mypy/server/deps.py
index f3df6fdb7b..f006b3d7f3 100644
--- a/mypy/server/deps.py
+++ b/mypy/server/deps.py
@@ -11,7 +11,7 @@
 function or method, or a module top level), a class, or a trigger (for
 recursively triggering other triggers).
 
-Here's an example represention of a simple dependency map (in format
+Here's an example representation of a simple dependency map (in format
 "<trigger> -> locations"):
 
   <m.A.g> -> m.f
@@ -90,9 +90,9 @@ class 'mod.Cls'. This can also refer to an attribute inherited from a
     Node, Expression, MypyFile, FuncDef, ClassDef, AssignmentStmt, NameExpr, MemberExpr, Import,
     ImportFrom, CallExpr, CastExpr, TypeVarExpr, TypeApplication, IndexExpr, UnaryExpr, OpExpr,
     ComparisonExpr, GeneratorExpr, DictionaryComprehension, StarExpr, PrintStmt, ForStmt, WithStmt,
-    TupleExpr, ListExpr, OperatorAssignmentStmt, DelStmt, YieldFromExpr, Decorator, Block,
+    TupleExpr, OperatorAssignmentStmt, DelStmt, YieldFromExpr, Decorator, Block,
     TypeInfo, FuncBase, OverloadedFuncDef, RefExpr, SuperExpr, Var, NamedTupleExpr, TypedDictExpr,
-    LDEF, MDEF, GDEF, FuncItem, TypeAliasExpr, NewTypeExpr, ImportAll, EnumCallExpr, AwaitExpr,
+    LDEF, MDEF, GDEF, TypeAliasExpr, NewTypeExpr, ImportAll, EnumCallExpr, AwaitExpr,
     op_methods, reverse_op_methods, ops_with_inplace_method, unary_op_methods
 )
 from mypy.traverser import TraverserVisitor
@@ -499,7 +499,7 @@ def process_global_ref_expr(self, o: RefExpr) -> None:
 
         # If this is a reference to a type, generate a dependency to its
         # constructor.
-        # TODO: avoid generating spurious dependencies for isinstancce checks,
+        # TODO: avoid generating spurious dependencies for isinstance checks,
         # except statements, class attribute reference, etc, if perf problem.
         typ = self.type_map.get(o)
         if isinstance(typ, FunctionLike) and typ.is_type_obj():
@@ -509,7 +509,7 @@ def process_global_ref_expr(self, o: RefExpr) -> None:
 
     def visit_name_expr(self, o: NameExpr) -> None:
         if o.kind == LDEF:
-            # We don't track depdendencies to local variables, since they
+            # We don't track dependencies to local variables, since they
             # aren't externally visible.
             return
         if o.kind == MDEF:
diff --git a/mypy/server/mergecheck.py b/mypy/server/mergecheck.py
index aab591b813..c1dde80d22 100644
--- a/mypy/server/mergecheck.py
+++ b/mypy/server/mergecheck.py
@@ -2,7 +2,7 @@
 
 from typing import Dict, List, Tuple
 
-from mypy.nodes import SymbolNode, Var, Decorator, OverloadedFuncDef, FuncDef
+from mypy.nodes import SymbolNode, Var, Decorator, FuncDef
 from mypy.server.objgraph import get_reachable_graph, get_path
 
 
diff --git a/mypy/server/objgraph.py b/mypy/server/objgraph.py
index b8ebd5a8e2..1ccfdbc26e 100644
--- a/mypy/server/objgraph.py
+++ b/mypy/server/objgraph.py
@@ -1,8 +1,7 @@
 """Find all objects reachable from a root object."""
 
-from collections import deque
 from collections.abc import Iterable
-from typing import List, Dict, Iterator, Optional, Tuple, Mapping
+from typing import List, Dict, Iterator, Tuple, Mapping
 import weakref
 import types
 
diff --git a/mypy/server/update.py b/mypy/server/update.py
index 19569486c8..541049b258 100644
--- a/mypy/server/update.py
+++ b/mypy/server/update.py
@@ -112,27 +112,23 @@
 test cases (test-data/unit/fine-grained*.test).
 """
 
-import os
 import time
-import os.path
 from typing import (
-    Dict, List, Set, Tuple, Iterable, Union, Optional, Mapping, NamedTuple, Callable,
+    Dict, List, Set, Tuple, Iterable, Union, Optional, NamedTuple, Callable,
     Sequence
 )
 
 from mypy.build import (
-    BuildManager, State, BuildSource, BuildResult, Graph, load_graph, module_not_found,
-    process_fresh_modules,
-    PRI_INDIRECT, DEBUG_FINE_GRAINED,
+    BuildManager, State, BuildSource, BuildResult, Graph, load_graph,
+    process_fresh_modules, DEBUG_FINE_GRAINED,
 )
 from mypy.checker import DeferredNode
-from mypy.errors import Errors, CompileError
+from mypy.errors import CompileError
 from mypy.nodes import (
-    MypyFile, FuncDef, TypeInfo, Expression, SymbolNode, Var, FuncBase, ClassDef, Decorator,
-    Import, ImportFrom, OverloadedFuncDef, SymbolTable, LambdaExpr
+    MypyFile, FuncDef, TypeInfo, SymbolNode, Decorator,
+    OverloadedFuncDef, SymbolTable, LambdaExpr
 )
 from mypy.options import Options
-from mypy.types import Type
 from mypy.fscache import FileSystemCache
 from mypy.semanal import apply_semantic_analyzer_patches
 from mypy.server.astdiff import (
@@ -331,7 +327,7 @@ def update_module(self,
         # its tree loaded so that we can snapshot it for comparison.
         ensure_trees_loaded(manager, graph, [module])
 
-        # Record symbol table snaphot of old version the changed module.
+        # Record symbol table snapshot of old version the changed module.
         old_snapshots = {}  # type: Dict[str, Dict[str, SnapshotItem]]
         if module in manager.modules:
             snapshot = snapshot_symbol_table(module, manager.modules[module].names)
@@ -446,7 +442,7 @@ def update_module_isolated(module: str,
                            force_removed: bool) -> UpdateResult:
     """Build a new version of one changed module only.
 
-    Don't propagate changes to elsewhere in the program. Raise CompleError on
+    Don't propagate changes to elsewhere in the program. Raise CompileError on
     encountering a blocking error.
 
     Args:
@@ -852,8 +848,9 @@ def key(node: DeferredNode) -> int:
 
     nodes = sorted(nodeset, key=key)
 
-    # TODO: ignore_all argument to set_file_ignored_lines
-    manager.errors.set_file_ignored_lines(file_node.path, file_node.ignored_lines)
+    options = graph[module_id].options
+    manager.errors.set_file_ignored_lines(
+        file_node.path, file_node.ignored_lines, options.ignore_errors)
 
     targets = set()
     for node in nodes:
@@ -871,7 +868,6 @@ def key(node: DeferredNode) -> int:
 
     # Second pass of semantic analysis. We don't redo the first pass, because it only
     # does local things that won't go stale.
-    options = graph[module_id].options
     for deferred in nodes:
         with semantic_analyzer.file_context(
                 file_node=file_node,
diff --git a/mypy/sharedparse.py b/mypy/sharedparse.py
index 48bd98a3ff..d2e4fed5fa 100644
--- a/mypy/sharedparse.py
+++ b/mypy/sharedparse.py
@@ -104,4 +104,4 @@ def special_function_elide_names(name: str) -> bool:
 
 
 def argument_elide_name(name: Optional[str]) -> bool:
-    return name is not None and name.startswith("__")
+    return name is not None and name.startswith("__") and not name.endswith("__")
diff --git a/mypy/solve.py b/mypy/solve.py
index c1243b71e0..3331f263cc 100644
--- a/mypy/solve.py
+++ b/mypy/solve.py
@@ -3,14 +3,12 @@
 from typing import List, Dict, Optional
 from collections import defaultdict
 
-from mypy.types import Type, NoneTyp, AnyType, UninhabitedType, TypeVarId, TypeOfAny
+from mypy.types import Type, AnyType, UninhabitedType, TypeVarId, TypeOfAny
 from mypy.constraints import Constraint, SUPERTYPE_OF
 from mypy.join import join_types
 from mypy.meet import meet_types
 from mypy.subtypes import is_subtype
 
-from mypy import experiments
-
 
 def solve_constraints(vars: List[TypeVarId], constraints: List[Constraint],
                       strict: bool =True) -> List[Optional[Type]]:
diff --git a/mypy/stats.py b/mypy/stats.py
index eb7e5d4c05..c2af203204 100644
--- a/mypy/stats.py
+++ b/mypy/stats.py
@@ -1,11 +1,10 @@
 """Utilities for calculating and reporting statistics about types."""
 
-import cgi
 import os.path
 import typing
 
 from collections import Counter
-from typing import Dict, List, cast, Tuple, Optional
+from typing import Dict, List, cast, Optional
 
 from mypy.traverser import TraverserVisitor
 from mypy.typeanal import collect_all_inner_types
diff --git a/mypy/strconv.py b/mypy/strconv.py
index 8814e29e79..74982ca8eb 100644
--- a/mypy/strconv.py
+++ b/mypy/strconv.py
@@ -3,7 +3,7 @@
 import re
 import os
 
-from typing import Any, List, Tuple, Optional, Union, Sequence, Dict
+from typing import Any, List, Tuple, Optional, Union, Sequence
 
 from mypy.util import short_type, IdMapper
 import mypy.nodes
diff --git a/mypy/stubgen.py b/mypy/stubgen.py
index 9e12576c1b..070476d020 100755
--- a/mypy/stubgen.py
+++ b/mypy/stubgen.py
@@ -48,7 +48,7 @@
 from collections import defaultdict
 
 from typing import (
-    Any, List, Dict, Tuple, Iterable, Iterator, Mapping, Optional, NamedTuple, Set, Union, cast
+    Any, List, Dict, Tuple, Iterable, Iterator, Mapping, Optional, NamedTuple, Set, cast
 )
 
 import mypy.build
@@ -63,11 +63,11 @@
     IfStmt, ReturnStmt, ImportAll, ImportFrom, Import, FuncDef, FuncBase, TempNode,
     ARG_POS, ARG_STAR, ARG_STAR2, ARG_NAMED, ARG_NAMED_OPT,
 )
-from mypy.stubgenc import parse_all_signatures, find_unique_signatures, generate_stub_for_c_module
-from mypy.stubutil import is_c_module, write_header
+from mypy.stubgenc import generate_stub_for_c_module
+from mypy.stubutil import is_c_module, write_header, parse_all_signatures, find_unique_signatures
 from mypy.options import Options as MypyOptions
 from mypy.types import (
-    Type, TypeStrVisitor, AnyType, CallableType,
+    Type, TypeStrVisitor, CallableType,
     UnboundType, NoneTyp, TupleType, TypeList,
 )
 from mypy.visitor import NodeVisitor
@@ -998,7 +998,7 @@ def usage(exit_nonzero: bool=True) -> None:
                           respect __all__)
           --include-private
                           generate stubs for objects and members considered private
-                          (single leading undescore and no trailing underscores)
+                          (single leading underscore and no trailing underscores)
           --doc-dir PATH  use .rst documentation in PATH (this may result in
                           better stubs in some cases; consider setting this to
                           DIR/Python-X.Y.Z/Doc/library)
diff --git a/mypy/stubgenc.py b/mypy/stubgenc.py
index 435e725c95..d6e4a004dd 100644
--- a/mypy/stubgenc.py
+++ b/mypy/stubgenc.py
@@ -9,10 +9,7 @@
 from typing import List, Dict, Tuple, Optional
 from types import ModuleType
 
-from mypy.stubutil import (
-    parse_all_signatures, find_unique_signatures, is_c_module, write_header,
-    infer_sig_from_docstring
-)
+from mypy.stubutil import is_c_module, write_header, infer_sig_from_docstring
 
 
 def generate_stub_for_c_module(module_name: str,
diff --git a/mypy/stubutil.py b/mypy/stubutil.py
index 93153f2464..efe16c9d3c 100644
--- a/mypy/stubutil.py
+++ b/mypy/stubutil.py
@@ -1,7 +1,7 @@
 import re
 import sys
 
-from typing import Any, Optional, Tuple, Sequence, MutableSequence, List, MutableMapping, IO
+from typing import Optional, Tuple, Sequence, MutableSequence, List, MutableMapping, IO
 from types import ModuleType
 
 
diff --git a/mypy/subtypes.py b/mypy/subtypes.py
index 3f05e3dec6..551c92a2df 100644
--- a/mypy/subtypes.py
+++ b/mypy/subtypes.py
@@ -1,10 +1,10 @@
-from typing import List, Optional, Dict, Callable, Tuple, Iterator, Set, Union, cast
+from typing import List, Optional, Callable, Tuple, Iterator, Set, Union, cast
 from contextlib import contextmanager
 
 from mypy.types import (
     Type, AnyType, UnboundType, TypeVisitor, FormalArgument, NoneTyp, function_type,
     Instance, TypeVarType, CallableType, TupleType, TypedDictType, UnionType, Overloaded,
-    ErasedType, TypeList, PartialType, DeletedType, UninhabitedType, TypeType, is_named_instance,
+    ErasedType, PartialType, DeletedType, UninhabitedType, TypeType, is_named_instance,
     FunctionLike, TypeOfAny
 )
 import mypy.applytype
@@ -609,7 +609,7 @@ def is_callable_compatible(left: CallableType, right: CallableType,
         The two calls are similar in that they both check the function arguments in
         the same direction: they both run `is_subtype(argument_from_g, argument_from_f)`.
 
-        However, the two calls differ in which direction they check things likee
+        However, the two calls differ in which direction they check things like
         keyword arguments. For example, suppose f and g are defined like so:
 
             def f(x: int, *y: int) -> int: ...
diff --git a/mypy/test/data.py b/mypy/test/data.py
index 0318e93c4c..cfc6430fb5 100644
--- a/mypy/test/data.py
+++ b/mypy/test/data.py
@@ -249,7 +249,20 @@ def runtest(self) -> None:
             pytest.skip()
         suite = self.parent.obj()
         suite.setup()
-        suite.run_case(self)
+        try:
+            suite.run_case(self)
+        except Exception:
+            # As a debugging aid, support copying the contents of the tmp directory somewhere
+            save_dir = self.config.getoption('--save-failures-to', None)  # type: Optional[str]
+            if save_dir:
+                assert self.tmpdir is not None
+                target_dir = os.path.join(save_dir, os.path.basename(self.tmpdir.name))
+                print("Copying data from test {} to {}".format(self.name, target_dir))
+                if not os.path.isabs(target_dir):
+                    assert self.old_cwd
+                    target_dir = os.path.join(self.old_cwd, target_dir)
+                shutil.copytree(self.tmpdir.name, target_dir)
+            raise
 
     def setup(self) -> None:
         self.old_cwd = os.getcwd()
@@ -578,6 +591,8 @@ def pytest_addoption(parser: Any) -> None:
     group.addoption('--update-data', action='store_true', default=False,
                     help='Update test data to reflect actual output'
                          ' (supported only for certain tests)')
+    group.addoption('--save-failures-to', default=None,
+                    help='Copy the temp directories from failing tests to a target directory')
     group.addoption('--mypy-verbose', action='count',
                     help='Set the verbose flag when creating mypy Options')
 
diff --git a/mypy/test/testcheck.py b/mypy/test/testcheck.py
index 9f9a3e6090..855cd471a3 100644
--- a/mypy/test/testcheck.py
+++ b/mypy/test/testcheck.py
@@ -2,24 +2,21 @@
 
 import os
 import re
-import shutil
 import sys
 
-from typing import Dict, List, Optional, Set, Tuple
+from typing import Dict, List, Set, Tuple
 
-from mypy import build, defaults
+from mypy import build
 from mypy.build import BuildSource, Graph
 from mypy.test.config import test_temp_dir
-from mypy.test.data import DataDrivenTestCase, DataSuite, FileOperation, UpdateFile, DeleteFile
+from mypy.test.data import DataDrivenTestCase, DataSuite, FileOperation, UpdateFile
 from mypy.test.helpers import (
     assert_string_arrays_equal, normalize_error_messages, assert_module_equivalence,
     retry_on_error, update_testcase_output, parse_options,
     copy_and_fudge_mtime
 )
 from mypy.errors import CompileError
-from mypy.options import Options
 
-from mypy import experiments
 
 # List of files that contain test case descriptions.
 typecheck_files = [
@@ -77,6 +74,7 @@
     'check-custom-plugin.test',
     'check-default-plugin.test',
     'check-attr.test',
+    'check-dataclasses.test',
 ]
 
 
diff --git a/mypy/test/testcmdline.py b/mypy/test/testcmdline.py
index 2a8b25687a..2eb944e135 100644
--- a/mypy/test/testcmdline.py
+++ b/mypy/test/testcmdline.py
@@ -58,6 +58,13 @@ def test_python_cmdline(testcase: DataDrivenTestCase) -> None:
     outb = process.stdout.read()
     # Split output into lines.
     out = [s.rstrip('\n\r') for s in str(outb, 'utf8').splitlines()]
+
+    if "PYCHARM_HOSTED" in os.environ:
+        pos = next((p for p, i in enumerate(out) if i.startswith('pydev debugger: ')), None)
+        if pos is not None:
+            del out[pos]  # the attaching debugger message itself
+            del out[pos]  # plus the extra new line added
+
     result = process.wait()
     # Remove temp file.
     os.remove(program_path)
diff --git a/mypy/test/testerrorstream.py b/mypy/test/testerrorstream.py
index 1659f934a2..3df1f27eb6 100644
--- a/mypy/test/testerrorstream.py
+++ b/mypy/test/testerrorstream.py
@@ -1,16 +1,12 @@
 """Tests for mypy incremental error output."""
-from typing import List, Callable, Optional
+from typing import List
 
-import os
-
-from mypy import defaults, build
+from mypy import build
 from mypy.test.helpers import assert_string_arrays_equal
 from mypy.test.data import DataDrivenTestCase, DataSuite
 from mypy.build import BuildSource
 from mypy.errors import CompileError
 from mypy.options import Options
-from mypy.nodes import CallExpr, StrExpr
-from mypy.types import Type
 
 
 class ErrorStreamSuite(DataSuite):
diff --git a/mypy/test/testfinegrained.py b/mypy/test/testfinegrained.py
index 101bb1ff2a..884404c481 100644
--- a/mypy/test/testfinegrained.py
+++ b/mypy/test/testfinegrained.py
@@ -15,13 +15,12 @@
 import os
 import re
 
-from typing import List, Set, Tuple, Optional, cast
+from typing import List, cast
 
 from mypy import build
-from mypy.build import BuildManager, BuildSource
+from mypy.build import BuildSource
 from mypy.errors import CompileError
 from mypy.options import Options
-from mypy.server.update import FineGrainedBuildManager
 from mypy.test.config import test_temp_dir
 from mypy.test.data import (
     DataDrivenTestCase, DataSuite, UpdateFile
diff --git a/mypy/test/testmerge.py b/mypy/test/testmerge.py
index 24ad912120..08f102e179 100644
--- a/mypy/test/testmerge.py
+++ b/mypy/test/testmerge.py
@@ -5,22 +5,20 @@
 from typing import List, Tuple, Dict, Optional
 
 from mypy import build
-from mypy.build import BuildManager, BuildSource, BuildResult, State, Graph
+from mypy.build import BuildSource, BuildResult
 from mypy.defaults import PYTHON3_VERSION
-from mypy.errors import Errors, CompileError
+from mypy.errors import CompileError
 from mypy.nodes import (
     Node, MypyFile, SymbolTable, SymbolTableNode, TypeInfo, Expression, Var, TypeVarExpr,
     UNBOUND_IMPORTED
 )
 from mypy.options import Options
-from mypy.server.astmerge import merge_asts
 from mypy.server.subexpr import get_subexpressions
 from mypy.server.update import FineGrainedBuildManager
-from mypy.strconv import StrConv, indent
+from mypy.strconv import StrConv
 from mypy.test.config import test_temp_dir
 from mypy.test.data import DataDrivenTestCase, DataSuite
 from mypy.test.helpers import assert_string_arrays_equal, normalize_error_messages
-from mypy.test.testtypegen import ignore_node
 from mypy.types import TypeStrVisitor, Type
 from mypy.util import short_type, IdMapper
 
diff --git a/mypy/test/testpep561.py b/mypy/test/testpep561.py
index 5432a53722..01a168ec97 100644
--- a/mypy/test/testpep561.py
+++ b/mypy/test/testpep561.py
@@ -6,7 +6,7 @@
 from unittest import TestCase, main
 
 import mypy.api
-from mypy.build import FindModuleCache, _get_site_packages_dirs
+from mypy.build import _get_site_packages_dirs
 from mypy.test.config import package_path
 from mypy.test.helpers import run_command
 from mypy.util import try_find_python2_interpreter
diff --git a/mypy/test/testtransform.py b/mypy/test/testtransform.py
index af34b927e4..9c12a8028c 100644
--- a/mypy/test/testtransform.py
+++ b/mypy/test/testtransform.py
@@ -1,7 +1,6 @@
 """Identity AST transform test cases"""
 
 import os.path
-from typing import List
 
 from mypy import build
 from mypy.build import BuildSource
diff --git a/mypy/test/testtypegen.py b/mypy/test/testtypegen.py
index 5a9ace1b3b..3336b1b541 100644
--- a/mypy/test/testtypegen.py
+++ b/mypy/test/testtypegen.py
@@ -2,7 +2,7 @@
 
 import re
 
-from typing import Set, List
+from typing import Set
 
 from mypy import build
 from mypy.build import BuildSource
diff --git a/mypy/traverser.py b/mypy/traverser.py
index d4060852fe..5c894de736 100644
--- a/mypy/traverser.py
+++ b/mypy/traverser.py
@@ -17,7 +17,7 @@
 class TraverserVisitor(NodeVisitor[None]):
     """A parse tree visitor that traverses the parse tree during visiting.
 
-    It does not peform any actions outside the traversal. Subclasses
+    It does not perform any actions outside the traversal. Subclasses
     should override visit methods to perform actions during
     traversal. Calling the superclass method allows reusing the
     traversal implementation.
diff --git a/mypy/treetransform.py b/mypy/treetransform.py
index 140d514e41..c9c83f98c2 100644
--- a/mypy/treetransform.py
+++ b/mypy/treetransform.py
@@ -94,7 +94,7 @@ def visit_func_def(self, node: FuncDef) -> FuncDef:
 
         # These contortions are needed to handle the case of recursive
         # references inside the function being transformed.
-        # Set up placholder nodes for references within this function
+        # Set up placeholder nodes for references within this function
         # to other functions defined inside it.
         # Don't create an entry for this function itself though,
         # since we want self-references to point to the original
@@ -584,7 +584,7 @@ def types(self, types: List[Type]) -> List[Type]:
 class FuncMapInitializer(TraverserVisitor):
     """This traverser creates mappings from nested FuncDefs to placeholder FuncDefs.
 
-    The placholders will later be replaced with transformed nodes.
+    The placeholders will later be replaced with transformed nodes.
     """
 
     def __init__(self, transformer: TransformVisitor) -> None:
diff --git a/mypy/tvar_scope.py b/mypy/tvar_scope.py
index e4931fd684..639c89da80 100644
--- a/mypy/tvar_scope.py
+++ b/mypy/tvar_scope.py
@@ -1,5 +1,5 @@
 from typing import Optional, Dict, Union
-from mypy.types import TypeVarDef, TypeVarId
+from mypy.types import TypeVarDef
 from mypy.nodes import TypeVarExpr, SymbolTableNode
 
 
diff --git a/mypy/typeanal.py b/mypy/typeanal.py
index 70c0766d53..9e878109a3 100644
--- a/mypy/typeanal.py
+++ b/mypy/typeanal.py
@@ -1,6 +1,5 @@
 """Semantic analysis of types"""
 
-from abc import abstractmethod
 from collections import OrderedDict
 from typing import Callable, List, Optional, Set, Tuple, Iterator, TypeVar, Iterable, Dict, Union
 
@@ -16,15 +15,14 @@
     Type, UnboundType, TypeVarType, TupleType, TypedDictType, UnionType, Instance, AnyType,
     CallableType, NoneTyp, DeletedType, TypeList, TypeVarDef, TypeVisitor, SyntheticTypeVisitor,
     StarType, PartialType, EllipsisType, UninhabitedType, TypeType, get_typ_args, set_typ_args,
-    CallableArgument, get_type_vars, TypeQuery, union_items, TypeOfAny, ForwardRef, Overloaded,
-    TypeTranslator
+    CallableArgument, get_type_vars, TypeQuery, union_items, TypeOfAny, ForwardRef, Overloaded
 )
 
 from mypy.nodes import (
     TVAR, TYPE_ALIAS, UNBOUND_IMPORTED, TypeInfo, Context, SymbolTableNode, Var, Expression,
     IndexExpr, RefExpr, nongen_builtins, check_arg_names, check_arg_kinds, ARG_POS, ARG_NAMED,
     ARG_OPT, ARG_NAMED_OPT, ARG_STAR, ARG_STAR2, TypeVarExpr, FuncDef, CallExpr, NameExpr,
-    Decorator, Node, ImportedName, type_aliases
+    Decorator, ImportedName, type_aliases
 )
 from mypy.tvar_scope import TypeVarScope
 from mypy.exprtotype import expr_to_unanalyzed_type, TypeTranslationError
diff --git a/mypy/types.py b/mypy/types.py
index c461f8070d..92dc4d731b 100644
--- a/mypy/types.py
+++ b/mypy/types.py
@@ -269,7 +269,7 @@ def accept(self, visitor: 'TypeVisitor[T]') -> T:
         return visitor.visit_type_list(self)
 
     def serialize(self) -> JsonDict:
-        assert False, "Sythetic types don't serialize"
+        assert False, "Synthetic types don't serialize"
 
 
 _dummy = object()  # type: Any
@@ -837,7 +837,7 @@ def max_fixed_args(self) -> int:
     def max_possible_positional_args(self) -> int:
         """Returns maximum number of positional arguments this method could possibly accept.
 
-        This takes into acount *arg and **kwargs but excludes keyword-only args."""
+        This takes into account *arg and **kwargs but excludes keyword-only args."""
         if self.is_var_arg or self.is_kw_arg:
             return sys.maxsize
         blacklist = (ARG_NAMED, ARG_NAMED_OPT)
@@ -1257,7 +1257,7 @@ def accept(self, visitor: 'TypeVisitor[T]') -> T:
         return visitor.visit_star_type(self)
 
     def serialize(self) -> JsonDict:
-        assert False, "Sythetic types don't serialize"
+        assert False, "Synthetic types don't serialize"
 
 
 class UnionType(Type):
@@ -1712,7 +1712,7 @@ def visit_overloaded(self, t: Overloaded) -> Type:
             if isinstance(new, CallableType):
                 items.append(new)
             else:
-                raise RuntimeError('CallableType expectected, but got {}'.format(type(new)))
+                raise RuntimeError('CallableType expected, but got {}'.format(type(new)))
         return Overloaded(items=items)
 
     def visit_type_type(self, t: TypeType) -> Type:
@@ -2096,7 +2096,7 @@ def callable_type(fdef: mypy.nodes.FuncItem, fallback: Instance,
 
 
 def get_typ_args(tp: Type) -> List[Type]:
-    """Get all type arguments from a parameterizable Type."""
+    """Get all type arguments from a parametrizable Type."""
     if not isinstance(tp, (Instance, UnionType, TupleType, CallableType)):
         return []
     typ_args = (tp.args if isinstance(tp, Instance) else
@@ -2106,7 +2106,7 @@ def get_typ_args(tp: Type) -> List[Type]:
 
 
 def set_typ_args(tp: Type, new_args: List[Type], line: int = -1, column: int = -1) -> Type:
-    """Return a copy of a parameterizable Type with arguments set to new_args."""
+    """Return a copy of a parametrizable Type with arguments set to new_args."""
     if isinstance(tp, Instance):
         return Instance(tp.type, new_args, line, column)
     if isinstance(tp, TupleType):
diff --git a/mypy/typestate.py b/mypy/typestate.py
index 1077d9a754..337aac21d7 100644
--- a/mypy/typestate.py
+++ b/mypy/typestate.py
@@ -131,7 +131,7 @@ def _snapshot_protocol_deps(cls) -> Dict[str, Set[str]]:
 
         The first kind is generated immediately per-module in deps.py (see also an example there
         for motivation why it is needed). While two other kinds are generated here after all
-        modules are type checked anf we have recorded all the subtype checks. To understand these
+        modules are type checked and we have recorded all the subtype checks. To understand these
         two kinds, consider a simple example:
 
             class A:
diff --git a/mypy/util.py b/mypy/util.py
index 8222bfe6c6..35aa5ccc3e 100644
--- a/mypy/util.py
+++ b/mypy/util.py
@@ -2,9 +2,8 @@
 
 import re
 import subprocess
-import hashlib
 from xml.sax.saxutils import escape
-from typing import TypeVar, List, Tuple, Optional, Sequence, Dict
+from typing import TypeVar, List, Tuple, Optional, Dict
 
 
 T = TypeVar('T')
diff --git a/mypy/version.py b/mypy/version.py
index 4b5034f252..f65568834b 100644
--- a/mypy/version.py
+++ b/mypy/version.py
@@ -1,7 +1,7 @@
 import os
 from mypy import git
 
-__version__ = '0.610+dev'
+__version__ = '0.620+dev'
 base_version = __version__
 
 mypy_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
diff --git a/mypy/visitor.py b/mypy/visitor.py
index 97a05dc72a..1bb941e4cb 100644
--- a/mypy/visitor.py
+++ b/mypy/visitor.py
@@ -1,7 +1,7 @@
 """Generic abstract syntax tree node visitor"""
 
 from abc import abstractmethod
-from typing import Dict, TypeVar, Generic
+from typing import TypeVar, Generic
 
 if False:
     # break import cycle only needed for mypy
diff --git a/pytest.ini b/pytest.ini
index 808f581b63..621ac41315 100644
--- a/pytest.ini
+++ b/pytest.ini
@@ -20,4 +20,5 @@ python_classes =
 python_functions =
 
 # always run in parallel (requires pytest-xdist, see test-requirements.txt)
-addopts = -nauto --cov-append --cov-report=
+addopts = -nauto
+
diff --git a/setup.cfg b/setup.cfg
index cfc72fbd89..a853f2ac0e 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -25,7 +25,8 @@ exclude =
   typeshed/*,
   # during runtests.py flake8 might be started when there's still examples in the temp dir
   tmp-test-dirs/*
-
+  .tox
+  .eggs
 
 # Things to ignore:
 #   E251: spaces around default arg value (against our style)
diff --git a/test-data/unit/check-attr.test b/test-data/unit/check-attr.test
index d403848c04..9851509dad 100644
--- a/test-data/unit/check-attr.test
+++ b/test-data/unit/check-attr.test
@@ -844,3 +844,16 @@ class A:
     x: int = attr.ib(factory=list)  # E: Incompatible types in assignment (expression has type "List[T]", variable has type "int")
     y: str = attr.ib(factory=my_factory) # E: Incompatible types in assignment (expression has type "int", variable has type "str")
 [builtins fixtures/list.pyi]
+
+[case testAttrsDefaultAndInit]
+import attr
+
+@attr.s
+class C:
+   a = attr.ib(init=False, default=42)
+   b = attr.ib()  # Ok because previous attribute is init=False
+   c = attr.ib(default=44)
+   d = attr.ib(init=False)  # Ok because this attribute is init=False
+   e = attr.ib()  # E: Non-default attributes not allowed after default attributes.
+
+[builtins fixtures/bool.pyi]
diff --git a/test-data/unit/check-dataclasses.test b/test-data/unit/check-dataclasses.test
new file mode 100644
index 0000000000..aa8bad16f5
--- /dev/null
+++ b/test-data/unit/check-dataclasses.test
@@ -0,0 +1,432 @@
+[case testDataclassesBasic]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Person:
+    name: str
+    age: int
+
+    def summary(self):
+        return "%s is %d years old." % (self.name, self.age)
+
+reveal_type(Person)  # E: Revealed type is 'def (name: builtins.str, age: builtins.int) -> __main__.Person'
+Person('John', 32)
+Person('Jonh', 21, None)  # E: Too many arguments for "Person"
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesBasicInheritance]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Mammal:
+    age: int
+
+@dataclass
+class Person(Mammal):
+    name: str
+
+    def summary(self):
+        return "%s is %d years old." % (self.name, self.age)
+
+reveal_type(Person)  # E: Revealed type is 'def (age: builtins.int, name: builtins.str) -> __main__.Person'
+Mammal(10)
+Person(32, 'John')
+Person(21, 'Jonh', None)  # E: Too many arguments for "Person"
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesDeepInheritance]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    a: int
+
+@dataclass
+class B(A):
+    b: int
+
+@dataclass
+class C(B):
+    c: int
+
+@dataclass
+class D(C):
+    d: int
+
+reveal_type(A)  # E: Revealed type is 'def (a: builtins.int) -> __main__.A'
+reveal_type(B)  # E: Revealed type is 'def (a: builtins.int, b: builtins.int) -> __main__.B'
+reveal_type(C)  # E: Revealed type is 'def (a: builtins.int, b: builtins.int, c: builtins.int) -> __main__.C'
+reveal_type(D)  # E: Revealed type is 'def (a: builtins.int, b: builtins.int, c: builtins.int, d: builtins.int) -> __main__.D'
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesOverriding]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Mammal:
+    age: int
+
+@dataclass
+class Person(Mammal):
+    name: str
+    age: int
+
+reveal_type(Person)  # E: Revealed type is 'def (name: builtins.str, age: builtins.int) -> __main__.Person'
+Person('John', 32)
+Person('John', 21, None)  # E: Too many arguments for "Person"
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesFreezing]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass(frozen=True)
+class Person:
+    name: str
+
+john = Person('John')
+john.name = 'Ben'  # E: Property "name" defined in "Person" is read-only
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesFields]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+
+@dataclass
+class Person:
+    name: str
+    age: int = field(default=0, init=False)
+
+reveal_type(Person)  # E: Revealed type is 'def (name: builtins.str) -> __main__.Person'
+john = Person('John')
+john.age = 'invalid'  # E: Incompatible types in assignment (expression has type "str", variable has type "int")
+john.age = 24
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesBadInit]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+
+@dataclass
+class Person:
+    name: str
+    age: int = field(init=None)  # E: No overload variant of "field" matches argument type "None"
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesMultiInit]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+from typing import List
+
+@dataclass
+class Person:
+    name: str
+    age: int = field(init=False)
+    friend_names: List[str] = field(init=True)
+    enemy_names: List[str]
+
+reveal_type(Person)  # E: Revealed type is 'def (name: builtins.str, friend_names: builtins.list[builtins.str], enemy_names: builtins.list[builtins.str]) -> __main__.Person'
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesMultiInitDefaults]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+from typing import List, Optional
+
+@dataclass
+class Person:
+    name: str
+    age: int = field(init=False)
+    friend_names: List[str] = field(init=True)
+    enemy_names: List[str]
+    nickname: Optional[str] = None
+
+reveal_type(Person)  # E: Revealed type is 'def (name: builtins.str, friend_names: builtins.list[builtins.str], enemy_names: builtins.list[builtins.str], nickname: Union[builtins.str, None] =) -> __main__.Person'
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesDefaults]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Application:
+    name: str = 'Unnamed'
+    rating: int = 0
+
+reveal_type(Application)  # E: Revealed type is 'def (name: builtins.str =, rating: builtins.int =) -> __main__.Application'
+app = Application()
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesDefaultFactories]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+
+@dataclass
+class Application:
+    name: str = 'Unnamed'
+    rating: int = field(default_factory=int)
+    rating_count: int = field()  # E: Attributes without a default cannot follow attributes with one
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesDefaultFactoryTypeChecking]
+# flags: --python-version 3.6
+from dataclasses import dataclass, field
+
+@dataclass
+class Application:
+    name: str = 'Unnamed'
+    rating: int = field(default_factory=str)  # E: Incompatible types in assignment (expression has type "str", variable has type "int")
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesDefaultOrdering]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Application:
+    name: str = 'Unnamed'
+    rating: int  # E: Attributes without a default cannot follow attributes with one
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesClassmethods]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Application:
+    name: str
+
+    @classmethod
+    def parse(cls, request: str) -> "Application":
+        return cls(name='...')
+
+app = Application.parse('')
+
+[builtins fixtures/list.pyi]
+[builtins fixtures/classmethod.pyi]
+
+[case testDataclassesClassVars]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+from typing import ClassVar
+
+@dataclass
+class Application:
+  name: str
+
+  COUNTER: ClassVar[int] = 0
+
+reveal_type(Application)  # E: Revealed type is 'def (name: builtins.str) -> __main__.Application'
+application = Application("example")
+application.COUNTER = 1  # E: Cannot assign to class variable "COUNTER" via instance
+Application.COUNTER = 1
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassEquality]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Application:
+  name: str
+  rating: int
+
+app1 = Application("example-1", 5)
+app2 = Application("example-2", 5)
+app1 == app2
+app1 != app2
+app1 == None  # E: Unsupported operand types for == ("Application" and "None")
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassCustomEquality]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass
+class Application:
+  name: str
+  rating: int
+
+  def __eq__(self, other: 'Application') -> bool:
+     ...
+
+app1 = Application("example-1", 5)
+app2 = Application("example-2", 5)
+app1 == app2
+app1 != app2  # E: Unsupported left operand type for != ("Application")
+app1 == None  # E: Unsupported operand types for == ("Application" and "None")
+
+class SpecializedApplication(Application):
+  ...
+
+app1 == SpecializedApplication("example-3", 5)
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassOrdering]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass(order=True)
+class Application:
+  name: str
+  rating: int
+
+app1 = Application('example-1', 5)
+app2 = Application('example-2', 5)
+app1 < app2
+app1 > app2
+app1 <= app2
+app1 >= app2
+app1 < 5  # E: Unsupported operand types for < ("Application" and "int")
+app1 > 5  # E: Unsupported operand types for > ("Application" and "int")
+app1 <= 5  # E: Unsupported operand types for <= ("Application" and "int")
+app1 >= 5  # E: Unsupported operand types for >= ("Application" and "int")
+
+class SpecializedApplication(Application):
+  ...
+
+app3 = SpecializedApplication('example-3', 5)
+app1 < app3
+app1 > app3
+app1 <= app3
+app1 >= app3
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassOrderingWithoutEquality]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass(eq=False, order=True)  # E: eq must be True if order is True
+class Application:
+   ...
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassOrderingWithCustomMethods]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+
+@dataclass(order=True)
+class Application:
+  def __lt__(self, other: 'Application') -> bool: # E: You may not have a custom __lt__ method when order=True
+    ...
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassDefaultsInheritance]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+from typing import Optional
+
+@dataclass(order=True)
+class Application:
+  id: Optional[int]
+  name: str
+
+@dataclass
+class SpecializedApplication(Application):
+  rating: int = 0
+
+reveal_type(SpecializedApplication)  # E: Revealed type is 'def (id: Union[builtins.int, None], name: builtins.str, rating: builtins.int =) -> __main__.SpecializedApplication'
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassGenerics]
+# flags: --python-version 3.6
+from dataclasses import dataclass
+from typing import Generic, List, Optional, TypeVar
+
+T = TypeVar('T')
+
+@dataclass
+class A(Generic[T]):
+  x: T
+  y: T
+  z: List[T]
+
+  def foo(self) -> List[T]:
+    return [self.x, self.y]
+
+  def bar(self) -> T:
+    return self.z[0]
+
+  def problem(self) -> T:
+    return self.z  # E: Incompatible return value type (got "List[T]", expected "T")
+
+reveal_type(A)  # E: Revealed type is 'def [T] (x: T`1, y: T`1, z: builtins.list[T`1]) -> __main__.A[T`1]'
+A(1, 2, ["a", "b"])  # E: Cannot infer type argument 1 of "A"
+a = A(1, 2, [1, 2])
+reveal_type(a)  # E: Revealed type is '__main__.A[builtins.int*]'
+reveal_type(a.x)  # E: Revealed type is 'builtins.int*'
+reveal_type(a.y)  # E: Revealed type is 'builtins.int*'
+reveal_type(a.z)  # E: Revealed type is 'builtins.list[builtins.int*]'
+s: str = a.bar()  # E: Incompatible types in assignment (expression has type "int", variable has type "str")
+
+[builtins fixtures/list.pyi]
+
+[case testDataclassesForwardRefs]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+  b: 'B'
+
+@dataclass
+class B:
+  x: int
+
+reveal_type(A)  # E: Revealed type is 'def (b: __main__.B) -> __main__.A'
+A(b=B(42))
+A(b=42)  # E: Argument "b" to "A" has incompatible type "int"; expected "B"
+
+[builtins fixtures/list.pyi]
+
+
+[case testDataclassesInitVars]
+from dataclasses import InitVar, dataclass
+
+@dataclass
+class Application:
+  name: str
+  database_name: InitVar[str]
+
+reveal_type(Application)  # E: Revealed type is 'def (name: builtins.str, database_name: builtins.str) -> __main__.Application'
+app = Application("example", 42)  # E: Argument 2 to "Application" has incompatible type "int"; expected "str"
+app = Application("example", "apps")
+app.name
+app.database_name  # E: "Application" has no attribute "database_name"
+
+
+@dataclass
+class SpecializedApplication(Application):
+  rating: int
+
+reveal_type(SpecializedApplication)  # E: Revealed type is 'def (name: builtins.str, database_name: builtins.str, rating: builtins.int) -> __main__.SpecializedApplication'
+app = SpecializedApplication("example", "apps", "five")  # E: Argument 3 to "SpecializedApplication" has incompatible type "str"; expected "int"
+app = SpecializedApplication("example", "apps", 5)
+app.name
+app.rating
+app.database_name  # E: "SpecializedApplication" has no attribute "database_name"
+
+[builtins fixtures/list.pyi]
diff --git a/test-data/unit/check-functions.test b/test-data/unit/check-functions.test
index a00d1fc81c..3b900ee5f5 100644
--- a/test-data/unit/check-functions.test
+++ b/test-data/unit/check-functions.test
@@ -2073,25 +2073,18 @@ h(7) # E: Cannot call function of unknown type
 
 [case testPositionalOnlyArg]
 def f(__a: int) -> None: pass
+def g(__a__: int) -> None: pass
 
 f(1)
 f(__a=1) # E: Unexpected keyword argument "__a" for "f"
 
-[builtins fixtures/bool.pyi]
-[out]
-main:1: note: "f" defined here
-
-[case testPositionalOnlyArgFastparse]
-
-
-def f(__a: int) -> None: pass
-
-f(1)
-f(__a=1) # E: Unexpected keyword argument "__a" for "f"
+g(1)
+# Argument names that also end with __ are not positional-only.
+g(__a__=1)
 
 [builtins fixtures/bool.pyi]
 [out]
-main:3: note: "f" defined here
+main:1: note: "f" defined here
 
 [case testMagicMethodPositionalOnlyArg]
 class A(object):
diff --git a/test-data/unit/check-incremental.test b/test-data/unit/check-incremental.test
index 1c1871922b..f7a55c9308 100644
--- a/test-data/unit/check-incremental.test
+++ b/test-data/unit/check-incremental.test
@@ -4362,6 +4362,321 @@ import b
 [stale]
 [rechecked b]
 
+[case testIncrementalDataclassesSubclassingCached]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    e: str = 'e'
+
+a = B(5, [5], 'foo')
+a.a = 6
+a._b = [2]
+a.c = 'yo'
+a._d = 22
+a.e = 'hi'
+
+[file a.py]
+from dataclasses import dataclass, field
+from typing import ClassVar, List
+
+@dataclass
+class A:
+    a: int
+    _b: List[int]
+    c: str = '18'
+    _d: int = field(default=False)
+    E = 7
+    F: ClassVar[int] = 22
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+
+[case testIncrementalDataclassesSubclassingCachedType]
+import b
+
+[file b.py]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    pass
+
+[file b.py.2]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    pass
+
+reveal_type(B)
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    x: int
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+tmp/b.py:8: error: Revealed type is 'def (x: builtins.int) -> b.B'
+
+[case testIncrementalDataclassesArguments]
+import b
+
+[file b.py]
+from a import Frozen, NoInit, NoCmp
+
+[file b.py.2]
+from a import Frozen, NoInit, NoCmp
+
+f = Frozen(5)
+f.x = 6
+
+g = NoInit()
+
+Frozen(1) < Frozen(2)
+Frozen(1) <= Frozen(2)
+Frozen(1) > Frozen(2)
+Frozen(1) >= Frozen(2)
+
+NoCmp(1) < NoCmp(2)
+NoCmp(1) <= NoCmp(2)
+NoCmp(1) > NoCmp(2)
+NoCmp(1) >= NoCmp(2)
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass(frozen=True, order=True)
+class Frozen:
+    x: int
+
+@dataclass(init=False)
+class NoInit:
+    x: int
+
+@dataclass(order=False)
+class NoCmp:
+    x: int
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+tmp/b.py:4: error: Property "x" defined in "Frozen" is read-only
+tmp/b.py:13: error: Unsupported left operand type for < ("NoCmp")
+tmp/b.py:14: error: Unsupported left operand type for <= ("NoCmp")
+tmp/b.py:15: error: Unsupported left operand type for > ("NoCmp")
+tmp/b.py:16: error: Unsupported left operand type for >= ("NoCmp")
+
+[case testIncrementalDataclassesDunder]
+import b
+
+[file b.py]
+from a import A
+
+[file b.py.2]
+from a import A
+
+reveal_type(A)
+reveal_type(A.__eq__)
+reveal_type(A.__ne__)
+reveal_type(A.__lt__)
+reveal_type(A.__le__)
+reveal_type(A.__gt__)
+reveal_type(A.__ge__)
+
+A(1) < A(2)
+A(1) <= A(2)
+A(1) > A(2)
+A(1) >= A(2)
+A(1) == A(2)
+A(1) != A(2)
+
+A(1) < 1
+A(1) <= 1
+A(1) > 1
+A(1) >= 1
+A(1) == 1
+A(1) != 1
+
+1 < A(1)
+1 <= A(1)
+1 > A(1)
+1 >= A(1)
+1 == A(1)
+1 != A(1)
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass(order=True)
+class A:
+    a: int
+
+[builtins fixtures/attr.pyi]
+[out1]
+[out2]
+tmp/b.py:3: error: Revealed type is 'def (a: builtins.int) -> a.A'
+tmp/b.py:4: error: Revealed type is 'def (builtins.object, builtins.object) -> builtins.bool'
+tmp/b.py:5: error: Revealed type is 'def (builtins.object, builtins.object) -> builtins.bool'
+tmp/b.py:6: error: Revealed type is 'def [T] (self: T`1, other: T`1) -> builtins.bool'
+tmp/b.py:7: error: Revealed type is 'def [T] (self: T`1, other: T`1) -> builtins.bool'
+tmp/b.py:8: error: Revealed type is 'def [T] (self: T`1, other: T`1) -> builtins.bool'
+tmp/b.py:9: error: Revealed type is 'def [T] (self: T`1, other: T`1) -> builtins.bool'
+tmp/b.py:18: error: Unsupported operand types for < ("A" and "int")
+tmp/b.py:19: error: Unsupported operand types for <= ("A" and "int")
+tmp/b.py:20: error: Unsupported operand types for > ("A" and "int")
+tmp/b.py:21: error: Unsupported operand types for >= ("A" and "int")
+tmp/b.py:25: error: Unsupported operand types for > ("A" and "int")
+tmp/b.py:26: error: Unsupported operand types for >= ("A" and "int")
+tmp/b.py:27: error: Unsupported operand types for < ("A" and "int")
+tmp/b.py:28: error: Unsupported operand types for <= ("A" and "int")
+
+[case testIncrementalDataclassesSubclassModified]
+from b import B
+B(5, 'foo')
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    x: int
+
+[file b.py]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    y: str
+
+[file b.py.2]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    y: int
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+main:2: error: Argument 2 to "B" has incompatible type "str"; expected "int"
+[rechecked b]
+
+[case testIncrementalDataclassesSubclassModifiedErrorFirst]
+from b import B
+B(5, 'foo')
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    x: int
+
+[file b.py]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    y: int
+
+[file b.py.2]
+from a import A
+from dataclasses import dataclass
+
+@dataclass
+class B(A):
+    y: str
+
+[builtins fixtures/list.pyi]
+[out1]
+main:2: error: Argument 2 to "B" has incompatible type "str"; expected "int"
+
+[out2]
+[rechecked b]
+
+[case testIncrementalDataclassesThreeFiles]
+from c import C
+C(5, 'foo', True)
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    a: int
+
+[file b.py]
+from dataclasses import dataclass
+
+@dataclass
+class B:
+    b: str
+
+[file b.py.2]
+from dataclasses import dataclass
+
+@dataclass
+class B:
+    b: str
+    c: str
+
+[file c.py]
+from a import A
+from b import B
+from dataclasses import dataclass
+
+@dataclass
+class C(A, B):
+    c: bool
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+tmp/c.py:7: error: Incompatible types in assignment (expression has type "bool", base class "B" defined the type as "str")
+
+[case testIncrementalDataclassesThreeRuns]
+from a import A
+A(5)
+
+[file a.py]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    a: int
+
+[file a.py.2]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    a: str
+
+[file a.py.3]
+from dataclasses import dataclass
+
+@dataclass
+class A:
+    a: int = 6
+
+[builtins fixtures/list.pyi]
+[out1]
+[out2]
+main:2: error: Argument 1 to "A" has incompatible type "int"; expected "str"
+[out3]
+
 [case testParentPatchingMess]
 # flags: --ignore-missing-imports --follow-imports=skip
 # cmd: mypy -m d d.k d.k.a d.k.v t
@@ -4428,3 +4743,14 @@ class C:
 [out]
 [out2]
 main:5: error: Incompatible types in assignment (expression has type "str", variable has type "int")
+
+[case testBazelFlagIgnoresFileChanges]
+-- Since the initial run wrote a cache file, the second run ignores the source
+# flags: --bazel
+from a import f
+f()
+[file a.py]
+def f(): pass
+[file a.py.2]
+[out]
+[out2]
diff --git a/test-data/unit/check-overloading.test b/test-data/unit/check-overloading.test
index f48ce84dc3..589b04b49e 100644
--- a/test-data/unit/check-overloading.test
+++ b/test-data/unit/check-overloading.test
@@ -1276,7 +1276,7 @@ def f(x: object) -> object: ...
 def f(x): pass
 
 a: Any
-reveal_type(f(a))  # E: Revealed type is 'Any'
+reveal_type(f(a))  # E: Revealed type is 'builtins.object'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument2]
 from typing import overload, Any
@@ -1288,7 +1288,7 @@ def f(x: float) -> float: ...
 def f(x): pass
 
 a: Any
-reveal_type(f(a))  # E: Revealed type is 'Any'
+reveal_type(f(a))  # E: Revealed type is 'builtins.float'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument3]
 from typing import overload, Any
@@ -1312,16 +1312,17 @@ def f(x: object, y: int, z: str) -> object: ...
 def f(x): pass
 
 a: Any
-# Any causes ambiguity
-reveal_type(f(a, 1, ''))  # E: Revealed type is 'Any'
+# Any causes ambiguity; we fall back to returning object since it's a
+# supertype of int
+reveal_type(f(a, 1, ''))  # E: Revealed type is 'builtins.object'
 # Any causes no ambiguity
 reveal_type(f(1, a, a))  # E: Revealed type is 'builtins.int'
 reveal_type(f('', a, a))  # E: Revealed type is 'builtins.object'
 # Like above, but use keyword arguments.
-reveal_type(f(y=1, z='', x=a))  # E: Revealed type is 'Any'
+reveal_type(f(y=1, z='', x=a))  # E: Revealed type is 'builtins.object'
 reveal_type(f(y=a, z='', x=1))  # E: Revealed type is 'builtins.int'
 reveal_type(f(z='', x=1, y=a))  # E: Revealed type is 'builtins.int'
-reveal_type(f(z='', x=a, y=1))  # E: Revealed type is 'Any'
+reveal_type(f(z='', x=a, y=1))  # E: Revealed type is 'builtins.object'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument5]
 from typing import overload, Any, Union
@@ -1333,7 +1334,7 @@ def f(x: Union[int, float]) -> float: ...
 def f(x): pass
 
 a: Any
-reveal_type(f(a))  # E: Revealed type is 'Any'
+reveal_type(f(a))  # E: Revealed type is 'builtins.float'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument6]
 from typing import overload, Any
@@ -1343,7 +1344,7 @@ def f(x: int, y: int) -> int: ...
 @overload
 def f(x: float, y: int, z: str) -> float: ...
 @overload
-def f(x: object, y: int, z: str, a: None) -> object: ...
+def f(x: object, y: int, z: str, a: None) -> str: ...
 def f(x): pass
 
 a: Any
@@ -1352,7 +1353,7 @@ reveal_type(f(*a))  # E: Revealed type is 'Any'
 reveal_type(f(a, *a))  # E: Revealed type is 'Any'
 reveal_type(f(1, *a))  # E: Revealed type is 'Any'
 reveal_type(f(1.1, *a))  # E: Revealed type is 'Any'
-reveal_type(f('', *a))  # E: Revealed type is 'builtins.object'
+reveal_type(f('', *a))  # E: Revealed type is 'builtins.str'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument7]
 from typing import overload, Any
@@ -1363,9 +1364,15 @@ def f(x: int, y: int, z: int) -> int: ...
 def f(x: object, y: int, z: int) -> object: ...
 def f(x): pass
 
+@overload
+def g(x: int, y: int, z: int) -> int: ...
+@overload
+def g(x: object, y: int, z: str) -> object: ...
+def g(x): pass
+
 a: Any
-# TODO: We could infer 'int' here
-reveal_type(f(1, *a))  # E: Revealed type is 'Any'
+reveal_type(f(1, *a))  # E: Revealed type is 'builtins.int'
+reveal_type(g(1, *a))  # E: Revealed type is 'builtins.object'
 
 [case testOverloadWithOverlappingItemsAndAnyArgument8]
 from typing import overload, Any
@@ -1381,6 +1388,62 @@ a: Any
 reveal_type(f(a, 1, 1)) # E: Revealed type is 'builtins.str'
 reveal_type(f(1, *a))  # E: Revealed type is 'builtins.str'
 
+[case testOverloadWithOverlappingItemsAndAnyArgument9]
+from typing import overload, Any, List
+
+@overload
+def f(x: List[int]) -> List[int]: ...
+@overload
+def f(x: List[Any]) -> List[Any]: ...
+def f(x): pass
+
+a: Any
+b: List[Any]
+c: List[str]
+d: List[int]
+reveal_type(f(a)) # E: Revealed type is 'builtins.list[Any]'
+reveal_type(f(b))  # E: Revealed type is 'builtins.list[Any]'
+reveal_type(f(c))  # E: Revealed type is 'builtins.list[Any]'
+reveal_type(f(d))  # E: Revealed type is 'builtins.list[builtins.int]'
+
+[builtins fixtures/list.pyi]
+
+[case testOverloadWithOverlappingItemsAndAnyArgument10]
+from typing import overload, Any
+
+@overload
+def f(*, x: int = 3, y: int = 3) -> int: ...  # E: Overloaded function signatures 1 and 2 overlap with incompatible return types
+@overload
+def f(**kwargs: str) -> str: ...
+def f(*args, **kwargs): pass
+
+# Checking an overload flagged as unsafe is a bit weird, but this is the
+# cleanest way to make sure 'Any' ambiguity checks work correctly with
+# keyword arguments.
+a: Any
+i: int
+reveal_type(f(x=a, y=i))  # E: Revealed type is 'builtins.int'
+reveal_type(f(y=a))       # E: Revealed type is 'Any'
+reveal_type(f(x=a, y=a))  # E: Revealed type is 'Any'
+
+[builtins fixtures/dict.pyi]
+
+[case testOverloadWithOverlappingItemsAndAnyArgument11]
+from typing import overload, Any, Dict
+
+@overload
+def f(x: int = 3, **kwargs: int) -> int: ...
+@overload
+def f(**kwargs: str) -> str: ...
+def f(*args, **kwargs): pass
+
+a: Dict[str, Any]
+i: int
+reveal_type(f(x=i, **a))  # E: Revealed type is 'builtins.int'
+reveal_type(f(**a))       # E: Revealed type is 'Any'
+
+[builtins fixtures/dict.pyi]
+
 [case testOverloadOnOverloadWithType]
 from typing import Any, Type, TypeVar, overload
 from mod import MyInt
@@ -1944,6 +2007,235 @@ def foo2(x: str, *, y: str, z: str) -> str: ...
 
 [builtins fixtures/dict.pyi]
 
+[case testOverloadVarargInputAndVarargDefinition]
+from typing import overload, List
+
+class A: ...
+class B: ...
+class C: ...
+
+@overload
+def foo(x: int) -> A: ...
+@overload
+def foo(x: int, y: int) -> B: ...
+@overload
+def foo(x: int, y: int, z: int, *args: int) -> C: ...
+def foo(*args): pass
+
+reveal_type(foo(1))        # E: Revealed type is '__main__.A'
+reveal_type(foo(1, 2))     # E: Revealed type is '__main__.B'
+reveal_type(foo(1, 2, 3))  # E: Revealed type is '__main__.C'
+
+reveal_type(foo(*[1]))        # E: Revealed type is '__main__.C'
+reveal_type(foo(*[1, 2]))     # E: Revealed type is '__main__.C'
+reveal_type(foo(*[1, 2, 3]))  # E: Revealed type is '__main__.C'
+
+x: List[int]
+reveal_type(foo(*x))  # E: Revealed type is '__main__.C'
+
+y: List[str]
+foo(*y)  # E: No overload variant of "foo" matches argument type "List[str]"
+[builtins fixtures/list.pyi]
+
+[case testOverloadMultipleVarargDefinition]
+from typing import overload, List, Any
+
+class A: ...
+class B: ...
+class C: ...
+class D: ...
+
+@overload
+def foo(x: int) -> A: ...
+@overload
+def foo(x: int, y: int) -> B: ...
+@overload
+def foo(x: int, y: int, z: int, *args: int) -> C: ...
+@overload
+def foo(*x: str) -> D: ...
+def foo(*args): pass
+
+reveal_type(foo(*[1, 2]))      # E: Revealed type is '__main__.C'
+reveal_type(foo(*["a", "b"]))  # E: Revealed type is '__main__.D'
+
+x: List[Any]
+reveal_type(foo(*x))  # E: Revealed type is 'Any'
+[builtins fixtures/list.pyi]
+
+[case testOverloadMultipleVarargDefinitionComplex]
+from typing import TypeVar, overload, Any, Callable
+
+T1 = TypeVar('T1')
+T2 = TypeVar('T2')
+T3 = TypeVar('T3')
+
+@overload
+def chain_call(input_value: T1,
+               f1: Callable[[T1], T2]) -> T2: ...
+@overload
+def chain_call(input_value: T1,
+               f1: Callable[[T1], T2],
+               f2: Callable[[T2], T3]) -> T3: ...
+@overload
+def chain_call(input_value: T1,
+               *f_rest: Callable[[T1], T1]) -> T1: ...
+@overload
+def chain_call(input_value: T1,
+               f1: Callable[[T1], T2],
+               f2: Callable[[T2], T3],
+               f3: Callable[[T3], Any],
+               *f_rest: Callable[[Any], Any]) -> Any: ...
+def chain_call(input_value, *f_rest):
+    for function in f_rest:
+        input_value = function(input_value)
+    return input_value
+
+
+class A: ...
+class B: ...
+class C: ...
+class D: ...
+
+def f(x: A) -> A: ...
+def f1(x: A) -> B: ...
+def f2(x: B) -> C: ...
+def f3(x: C) -> D: ...
+
+reveal_type(chain_call(A(), f1, f2))       # E: Revealed type is '__main__.C*'
+reveal_type(chain_call(A(), f1, f2, f3))   # E: Revealed type is 'Any'
+reveal_type(chain_call(A(), f, f, f, f))   # E: Revealed type is '__main__.A'
+[builtins fixtures/list.pyi]
+
+[case testOverloadVarargsSelection]
+from typing import overload, Tuple
+@overload
+def f(x: int) -> Tuple[int]: ...
+@overload
+def f(x: int, y: int) -> Tuple[int, int]: ...
+@overload
+def f(*xs: int) -> Tuple[int, ...]: ...
+def f(*args): pass
+
+i: int
+reveal_type(f(i))           # E: Revealed type is 'Tuple[builtins.int]'
+reveal_type(f(i, i))        # E: Revealed type is 'Tuple[builtins.int, builtins.int]'
+reveal_type(f(i, i, i))     # E: Revealed type is 'builtins.tuple[builtins.int]'
+
+reveal_type(f(*[]))         # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(*[i]))        # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(*[i, i]))     # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(*[i, i, i]))  # E: Revealed type is 'builtins.tuple[builtins.int]'
+[builtins fixtures/list.pyi]
+
+[case testOverloadVarargsSelectionWithTuples]
+from typing import overload, Tuple
+@overload
+def f(x: int) -> Tuple[int]: ...
+@overload
+def f(x: int, y: int) -> Tuple[int, int]: ...
+@overload
+def f(*xs: int) -> Tuple[int, ...]: ...
+def f(*args): pass
+
+i: int
+reveal_type(f(*()))         # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(*(i,)))       # E: Revealed type is 'Tuple[builtins.int]'
+reveal_type(f(*(i, i)))     # E: Revealed type is 'Tuple[builtins.int, builtins.int]'
+reveal_type(f(*(i, i, i)))  # E: Revealed type is 'builtins.tuple[builtins.int]'
+[builtins fixtures/tuple.pyi]
+
+[case testOverloadVarargsSelectionWithNamedTuples]
+from typing import overload, Tuple, NamedTuple
+@overload
+def f(x: int, y: int) -> Tuple[int, int]: ...
+@overload
+def f(*xs: int) -> Tuple[int, ...]: ...
+def f(*args): pass
+
+A = NamedTuple('A', [('x', int), ('y', int)])
+B = NamedTuple('B', [('a', int), ('b', int)])
+C = NamedTuple('C', [('a', int), ('b', int), ('c', int)])
+
+a: A
+b: B
+c: C
+reveal_type(f(*a))  # E: Revealed type is 'Tuple[builtins.int, builtins.int]'
+reveal_type(f(*b))  # E: Revealed type is 'Tuple[builtins.int, builtins.int]'
+reveal_type(f(*c))  # E: Revealed type is 'builtins.tuple[builtins.int]'
+[builtins fixtures/tuple.pyi]
+
+[case testOverloadKwargsSelectionWithDict]
+from typing import overload, Tuple, Dict
+@overload
+def f(*, x: int) -> Tuple[int]: ...
+@overload
+def f(*, x: int, y: int) -> Tuple[int, int]: ...
+@overload
+def f(**xs: int) -> Tuple[int, ...]: ...
+def f(**kwargs): pass
+
+empty: Dict[str, int]
+reveal_type(f(**empty))                      # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(**{'x': 4}))                   # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(**{'x': 4, 'y': 4}))           # E: Revealed type is 'builtins.tuple[builtins.int]'
+reveal_type(f(**{'a': 4, 'b': 4, 'c': 4}))   # E: Revealed type is 'builtins.tuple[builtins.int]'
+[builtins fixtures/dict.pyi]
+
+[case testOverloadKwargsSelectionWithTypedDict-skip]
+# TODO: Mypy doesn't seem to correctly destructure typed dicts in general.
+#       We should re-enable this once https://github.com/python/mypy/issues/5198 is resolved
+from typing import overload, Tuple
+from mypy_extensions import TypedDict
+@overload
+def f(*, x: int) -> Tuple[int]: ...
+@overload
+def f(*, x: int, y: int) -> Tuple[int, int]: ...
+@overload
+def f(**xs: int) -> Tuple[int, ...]: ...
+def f(**args): pass
+
+A = TypedDict('A', {'x': int})
+B = TypedDict('B', {'x': int, 'y': int})
+C = TypedDict('C', {'x': int, 'y': int, 'z': int})
+
+a: A
+b: B
+c: C
+
+reveal_type(f(**a))  # E: Revealed type is 'Tuple[builtins.int]'
+reveal_type(f(**b))  # E: Revealed type is 'Tuple[builtins.int, builtins.int]'
+reveal_type(f(**c))  # E: Revealed type is 'builtins.tuple[builtins.int]'
+[builtins fixtures/dict.pyi]
+
+[case testOverloadVarargsAndKwargsSelection]
+from typing import overload, Any, Tuple, Dict
+
+class A: pass
+class B(A): pass
+
+@overload
+def f(x: int, y: int) -> B: pass
+@overload
+def f(x: int, y: int, **kwargs: int) -> A: pass
+@overload
+def f(*args: int, **kwargs: int) -> Any: pass
+def f(*args, **kwargs): pass
+
+a: Tuple[int, int]
+b: Tuple[int, ...]
+c: Dict[str, int]
+
+reveal_type(f(*a, **c))  # E: Revealed type is '__main__.A'
+reveal_type(f(*b, **c))  # E: Revealed type is '__main__.A'
+reveal_type(f(*a))       # E: Revealed type is '__main__.B'
+reveal_type(f(*b))       # E: Revealed type is 'Any'
+
+# TODO: Should this be 'Any' instead?
+# The first matching overload with a kwarg is f(int, int, **int) -> A,
+# but f(*int, **int) -> Any feels like a better fit.
+reveal_type(f(**c))      # E: Revealed type is '__main__.A'
+[builtins fixtures/args.pyi]
+
 [case testOverloadWithPartiallyOverlappingUnions]
 from typing import overload, Union
 
@@ -2841,3 +3133,32 @@ class FakeAttribute(Generic[T]):
     @overload
     def dummy(self, instance: T, owner: Type[T]) -> int: ...
     def dummy(self, instance: Optional[T], owner: Type[T]) -> Union['FakeAttribute[T]', int]: ...
+
+[case testOverloadLambdaUnpackingInference]
+# flags: --py2
+from typing import Callable, TypeVar, overload
+
+T = TypeVar('T')
+S = TypeVar('S')
+
+@overload
+def foo(func, item):
+    # type: (Callable[[T], S], T) -> S
+    pass
+
+@overload
+def foo():
+    # type: () -> None
+    pass
+
+def foo(*args):
+    pass
+
+def add_proxy(x, y):
+    # type: (int, str) -> str
+    pass
+
+# The lambda definition is a syntax error in Python 3
+tup = (1, '2')
+reveal_type(foo(lambda (x, y): add_proxy(x, y), tup))  # E: Revealed type is 'builtins.str*'
+[builtins fixtures/primitives.pyi]
diff --git a/test-data/unit/check-tuples.test b/test-data/unit/check-tuples.test
index 3345626268..b019a63fa9 100644
--- a/test-data/unit/check-tuples.test
+++ b/test-data/unit/check-tuples.test
@@ -563,6 +563,29 @@ class A: pass
 [builtins fixtures/list.pyi]
 [out]
 
+[case testAssignmentToStarFromIterable]
+from typing import List, Tuple, Iterable
+
+class CustomIterable(Iterable[int]): pass
+
+a: List[int]
+b: Tuple[int, ...]
+c: Tuple[int, int, int]
+d: Iterable[int]
+e: CustomIterable
+
+a1, *a2 = a
+b1, *b2 = b
+c1, *c2 = c
+d1, *d2 = d
+e1, *e2 = e
+
+reveal_type(a2)  # E: Revealed type is 'builtins.list[builtins.int*]'
+reveal_type(b2)  # E: Revealed type is 'builtins.list[builtins.int*]'
+reveal_type(c2)  # E: Revealed type is 'builtins.list[builtins.int*]'
+reveal_type(d2)  # E: Revealed type is 'builtins.list[builtins.int]'
+reveal_type(e2)  # E: Revealed type is 'builtins.list[builtins.int]'
+[builtins fixtures/tuple.pyi]
 
 -- Nested tuple assignment
 -- ----------------------------
diff --git a/test-data/unit/check-unions.test b/test-data/unit/check-unions.test
index 9ebf6af900..799dea119f 100644
--- a/test-data/unit/check-unions.test
+++ b/test-data/unit/check-unions.test
@@ -752,7 +752,7 @@ good: Union[List[int], List[str]]
 
 x, *y, z = lst = good
 reveal_type(x) # E: Revealed type is 'Union[builtins.int*, builtins.str*]'
-reveal_type(y) # E: Revealed type is 'Union[builtins.list[builtins.int], builtins.list[builtins.str]]'
+reveal_type(y) # E: Revealed type is 'Union[builtins.list[builtins.int*], builtins.list[builtins.str*]]'
 reveal_type(z) # E: Revealed type is 'Union[builtins.int*, builtins.str*]'
 reveal_type(lst) # E: Revealed type is 'Union[builtins.list[builtins.int], builtins.list[builtins.str]]'
 [builtins fixtures/list.pyi]
diff --git a/test-data/unit/cmdline.test b/test-data/unit/cmdline.test
index fc12fa9458..3e5050636f 100644
--- a/test-data/unit/cmdline.test
+++ b/test-data/unit/cmdline.test
@@ -5,6 +5,9 @@
 --
 --   # cmd: mypy <options>
 --
+-- Note that # flags: --some-flag IS NOT SUPPORTED.
+-- Use # cmd: mypy --some-flag ...
+--
 -- '== Return code: <value>' is added to the output when the process return code
 -- is "nonobvious" -- that is, when it is something other than 0 if there are no
 -- messages and 1 if there are.
@@ -1166,7 +1169,6 @@ s1.py:2: error: Incompatible return value type (got "int", expected "str")
 
 [case testConfigWarnUnusedSection1]
 # cmd: mypy foo.py quux.py spam/eggs.py
-# flags: --follow-imports=skip
 [file mypy.ini]
 [[mypy]
 warn_unused_configs = True
@@ -1223,3 +1225,38 @@ fail
 foo/lol.py:1: error: Name 'fail' is not defined
 emarg/foo.py:1: error: Name 'fail' is not defined
 emarg/hatch/villip/mankangulisk.py:1: error: Name 'fail' is not defined
+
+[case testPackageRootEmpty]
+# cmd: mypy --package-root= a/b/c.py main.py
+[file a/b/c.py]
+[file main.py]
+import a.b.c
+
+[case testPackageRootNonEmpty]
+# cmd: mypy --package-root=a/ a/b/c.py main.py
+[file a/b/c.py]
+[file main.py]
+import b.c
+
+[case testPackageRootMultiple1]
+# cmd: mypy --package-root=. --package-root=a a/b/c.py d.py main.py
+[file a/b/c.py]
+[file d.py]
+[file main.py]
+import b.c
+import d
+
+[case testPackageRootMultiple2]
+# cmd: mypy --package-root=a/ --package-root=./ a/b/c.py d.py main.py
+[file a/b/c.py]
+[file d.py]
+[file main.py]
+import b.c
+import d
+
+[case testCacheMap]
+-- This just checks that a valid --cache-map triple is accepted.
+-- (Errors are too verbose to check.)
+# cmd: mypy a.py --cache-map a.py a.meta.json a.data.json 
+[file a.py]
+[out]
diff --git a/test-data/unit/fine-grained.test b/test-data/unit/fine-grained.test
index d2fe028145..037c71c221 100644
--- a/test-data/unit/fine-grained.test
+++ b/test-data/unit/fine-grained.test
@@ -7139,3 +7139,55 @@ def f() -> int: return 0
 def f() -> str: return '0'
 [out]
 ==
+
+[case testRefreshIgnoreErrors1]
+[file mypy.ini]
+[[mypy]
+[[mypy-b]
+ignore_errors = True
+[file a.py]
+y = '1'
+[file a.py.2]
+y = 1
+[file b.py]
+from a import y
+def fu() -> None:
+    1+'lurr'
+    y
+[out]
+==
+
+[case testRefreshIgnoreErrors2]
+[file mypy.ini]
+[[mypy]
+[[mypy-b]
+ignore_errors = True
+[file b.py]
+def fu() -> int:
+    1+'lurr'
+    return 1
+[file b.py.2]
+def fu() -> int:
+    1+'lurr'
+    return 2
+[out]
+==
+
+
+[case testRefreshOptions]
+[file mypy.ini]
+[[mypy]
+disallow_any_generics = True
+[[mypy-b]
+disallow_any_generics = False
+[file a.py]
+y = '1'
+[file a.py.2]
+y = 1
+[file b.py]
+from typing import List
+from a import y
+x = []  # type: List
+[builtins fixtures/list.pyi]
+[out]
+==
diff --git a/test-data/unit/lib-stub/dataclasses.pyi b/test-data/unit/lib-stub/dataclasses.pyi
new file mode 100644
index 0000000000..160cfcd066
--- /dev/null
+++ b/test-data/unit/lib-stub/dataclasses.pyi
@@ -0,0 +1,30 @@
+from typing import Any, Callable, Generic, Mapping, Optional, TypeVar, overload, Type
+
+_T = TypeVar('_T')
+
+class InitVar(Generic[_T]):
+    ...
+
+
+@overload
+def dataclass(_cls: Type[_T]) -> Type[_T]: ...
+
+@overload
+def dataclass(*, init: bool = ..., repr: bool = ..., eq: bool = ..., order: bool = ...,
+    unsafe_hash: bool = ..., frozen: bool = ...) -> Callable[[Type[_T]], Type[_T]]: ...
+
+
+@overload
+def field(*, default: _T,
+    init: bool = ..., repr: bool = ..., hash: Optional[bool] = ..., compare: bool = ...,
+    metadata: Optional[Mapping[str, Any]] = ...) -> _T: ...
+
+@overload
+def field(*, default_factory: Callable[[], _T],
+    init: bool = ..., repr: bool = ..., hash: Optional[bool] = ..., compare: bool = ...,
+    metadata: Optional[Mapping[str, Any]] = ...) -> _T: ...
+
+@overload
+def field(*,
+    init: bool = ..., repr: bool = ..., hash: Optional[bool] = ..., compare: bool = ...,
+    metadata: Optional[Mapping[str, Any]] = ...) -> Any: ...
diff --git a/test-data/unit/pythoneval.test b/test-data/unit/pythoneval.test
index afc1885c2f..a7b8773f63 100644
--- a/test-data/unit/pythoneval.test
+++ b/test-data/unit/pythoneval.test
@@ -1257,8 +1257,8 @@ class A:
 class B:
     __slots__ = (1, 2)
 [out]
-_testInvalidSlots.py:2: error: Incompatible types in assignment (expression has type "int", base class "object" defined the type as "Union[str, Iterable[str], None]")
-_testInvalidSlots.py:4: error: Incompatible types in assignment (expression has type "Tuple[int, int]", base class "object" defined the type as "Union[str, Iterable[str], None]")
+_testInvalidSlots.py:2: error: Incompatible types in assignment (expression has type "int", base class "object" defined the type as "Union[str, Iterable[str]]")
+_testInvalidSlots.py:4: error: Incompatible types in assignment (expression has type "Tuple[int, int]", base class "object" defined the type as "Union[str, Iterable[str]]")
 
 [case testDictWithStarStarSpecialCase]
 from typing import Dict
diff --git a/tox.ini b/tox.ini
new file mode 100644
index 0000000000..91d636daf9
--- /dev/null
+++ b/tox.ini
@@ -0,0 +1,40 @@
+[tox]
+minversion = 2.9.1
+skip_missing_interpreters = true
+envlist = py34,
+          py35,
+          py36,
+          py37,
+          lint,
+          type,
+          docs
+
+[testenv]
+description = run the test driver with {basepython}
+deps = -rtest-requirements.txt
+commands = python runtests.py -x lint -x self-check {posargs}
+
+[testenv:lint]
+description = check the code style
+basepython = python3.6
+commands = python runtests.py lint {posargs}
+
+[testenv:type]
+description = type check ourselves
+basepython = python3.6
+commands = python runtests.py self-check -p '-n0' -p '-v'
+
+[testenv:docs]
+description = invoke sphinx-build to build the HTML docs
+basepython = python3.6
+deps = -rdocs/requirements-docs.txt
+commands = sphinx-build -d "{toxworkdir}/docs_doctree" docs/source "{toxworkdir}/docs_out" --color -W -bhtml {posargs}
+
+[testenv:dev]
+description = generate a DEV environment, that has all project libraries
+usedevelop = True
+basepython = python3.6
+deps = -rtest-requirements.txt
+       -rdocs/requirements-docs.txt
+commands = python -m pip list --format=columns
+           python -c 'import sys; print(sys.executable)'
diff --git a/typeshed b/typeshed
index 2ba90a65c0..c4bf27b835 160000
--- a/typeshed
+++ b/typeshed
@@ -1 +1 @@
-Subproject commit 2ba90a65c0cf4d196a971e1c0b0362bb735e8e6d
+Subproject commit c4bf27b835646b47f6b49c7de013ed0207c84de2
