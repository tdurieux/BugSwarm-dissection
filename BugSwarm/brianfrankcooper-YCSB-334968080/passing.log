travis_fold:start:worker_info[0K[33;1mWorker information[0m
hostname: 4b4423df-7c40-46bf-ab30-925e8818dbfe@1.i-0d7f985-production-2-worker-org-ec2.travisci.net
version: v3.4.0 https://github.com/travis-ci/worker/tree/ce0440bc30c289a49a9b0c21e4e1e6f7d7825101
instance: b2024e6 travisci/ci-garnet:packer-1512502276-986baf0 (via amqp)
startup: 428.390149ms
travis_fold:end:worker_info[0Kmode of â€˜/usr/local/clang-5.0.0/binâ€™ changed from 0777 (rwxrwxrwx) to 0775 (rwxrwxr-x)
travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: 334974496
Job id: 334974498
Runtime kernel version: 4.14.12-041412-generic
travis-build version: c08e7e0bc
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
removed â€˜/etc/apt/sources.list.d/basho_riak.listâ€™
W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1)
127.0.0.1	localhost
::1	 ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
172.17.0.11	travis-job-brianfrankcoop-ycsb-334974498.travisci.net travis-job-brianfrankcoop-ycsb-334974498
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
travis_fold:start:git.checkout[0Ktravis_time:start:0008cd30[0K$ git clone --depth=50 https://github.com/brianfrankcooper/YCSB.git brianfrankcooper/YCSB
Cloning into 'brianfrankcooper/YCSB'...
remote: Counting objects: 7065, done.[K
remote: Compressing objects:   0% (1/2664)   [Kremote: Compressing objects:   1% (27/2664)   [Kremote: Compressing objects:   2% (54/2664)   [Kremote: Compressing objects:   3% (80/2664)   [Kremote: Compressing objects:   4% (107/2664)   [Kremote: Compressing objects:   5% (134/2664)   [Kremote: Compressing objects:   6% (160/2664)   [Kremote: Compressing objects:   7% (187/2664)   [Kremote: Compressing objects:   8% (214/2664)   [Kremote: Compressing objects:   9% (240/2664)   [Kremote: Compressing objects:  10% (267/2664)   [Kremote: Compressing objects:  11% (294/2664)   [Kremote: Compressing objects:  12% (320/2664)   [Kremote: Compressing objects:  13% (347/2664)   [Kremote: Compressing objects:  14% (373/2664)   [Kremote: Compressing objects:  15% (400/2664)   [Kremote: Compressing objects:  16% (427/2664)   [Kremote: Compressing objects:  17% (453/2664)   [Kremote: Compressing objects:  18% (480/2664)   [Kremote: Compressing objects:  19% (507/2664)   [Kremote: Compressing objects:  20% (533/2664)   [Kremote: Compressing objects:  21% (560/2664)   [Kremote: Compressing objects:  22% (587/2664)   [Kremote: Compressing objects:  23% (613/2664)   [Kremote: Compressing objects:  24% (640/2664)   [Kremote: Compressing objects:  25% (666/2664)   [Kremote: Compressing objects:  26% (693/2664)   [Kremote: Compressing objects:  27% (720/2664)   [Kremote: Compressing objects:  28% (746/2664)   [Kremote: Compressing objects:  29% (773/2664)   [Kremote: Compressing objects:  30% (800/2664)   [Kremote: Compressing objects:  31% (826/2664)   [Kremote: Compressing objects:  32% (853/2664)   [Kremote: Compressing objects:  33% (880/2664)   [Kremote: Compressing objects:  34% (906/2664)   [Kremote: Compressing objects:  35% (933/2664)   [Kremote: Compressing objects:  36% (960/2664)   [Kremote: Compressing objects:  37% (986/2664)   [Kremote: Compressing objects:  38% (1013/2664)   [Kremote: Compressing objects:  39% (1039/2664)   [Kremote: Compressing objects:  40% (1066/2664)   [Kremote: Compressing objects:  41% (1093/2664)   [Kremote: Compressing objects:  42% (1119/2664)   [Kremote: Compressing objects:  43% (1146/2664)   [Kremote: Compressing objects:  44% (1173/2664)   [Kremote: Compressing objects:  45% (1199/2664)   [Kremote: Compressing objects:  46% (1226/2664)   [Kremote: Compressing objects:  47% (1253/2664)   [Kremote: Compressing objects:  48% (1279/2664)   [Kremote: Compressing objects:  49% (1306/2664)   [Kremote: Compressing objects:  50% (1332/2664)   [Kremote: Compressing objects:  51% (1359/2664)   [Kremote: Compressing objects:  52% (1386/2664)   [Kremote: Compressing objects:  53% (1412/2664)   [Kremote: Compressing objects:  54% (1439/2664)   [Kremote: Compressing objects:  55% (1466/2664)   [Kremote: Compressing objects:  56% (1492/2664)   [Kremote: Compressing objects:  57% (1519/2664)   [Kremote: Compressing objects:  58% (1546/2664)   [Kremote: Compressing objects:  59% (1572/2664)   [Kremote: Compressing objects:  60% (1599/2664)   [Kremote: Compressing objects:  61% (1626/2664)   [Kremote: Compressing objects:  62% (1652/2664)   [Kremote: Compressing objects:  63% (1679/2664)   [Kremote: Compressing objects:  64% (1705/2664)   [Kremote: Compressing objects:  65% (1732/2664)   [Kremote: Compressing objects:  66% (1759/2664)   [Kremote: Compressing objects:  67% (1785/2664)   [Kremote: Compressing objects:  68% (1812/2664)   [Kremote: Compressing objects:  69% (1839/2664)   [Kremote: Compressing objects:  70% (1865/2664)   [Kremote: Compressing objects:  71% (1892/2664)   [Kremote: Compressing objects:  72% (1919/2664)   [Kremote: Compressing objects:  73% (1945/2664)   [Kremote: Compressing objects:  74% (1972/2664)   [Kremote: Compressing objects:  75% (1998/2664)   [Kremote: Compressing objects:  76% (2025/2664)   [Kremote: Compressing objects:  77% (2052/2664)   [Kremote: Compressing objects:  78% (2078/2664)   [Kremote: Compressing objects:  79% (2105/2664)   [Kremote: Compressing objects:  80% (2132/2664)   [Kremote: Compressing objects:  81% (2158/2664)   [Kremote: Compressing objects:  82% (2185/2664)   [Kremote: Compressing objects:  83% (2212/2664)   [Kremote: Compressing objects:  84% (2238/2664)   [Kremote: Compressing objects:  85% (2265/2664)   [Kremote: Compressing objects:  86% (2292/2664)   [Kremote: Compressing objects:  87% (2318/2664)   [Kremote: Compressing objects:  88% (2345/2664)   [Kremote: Compressing objects:  89% (2371/2664)   [Kremote: Compressing objects:  90% (2398/2664)   [Kremote: Compressing objects:  91% (2425/2664)   [Kremote: Compressing objects:  92% (2451/2664)   [Kremote: Compressing objects:  93% (2478/2664)   [Kremote: Compressing objects:  94% (2505/2664)   [Kremote: Compressing objects:  95% (2531/2664)   [Kremote: Compressing objects:  96% (2558/2664)   [Kremote: Compressing objects:  97% (2585/2664)   [Kremote: Compressing objects:  98% (2611/2664)   [Kremote: Compressing objects:  99% (2638/2664)   [Kremote: Compressing objects: 100% (2664/2664)   [Kremote: Compressing objects: 100% (2664/2664), done.[K
Receiving objects:   0% (1/7065)   Receiving objects:   1% (71/7065)   Receiving objects:   2% (142/7065)   Receiving objects:   3% (212/7065)   Receiving objects:   4% (283/7065)   Receiving objects:   5% (354/7065)   Receiving objects:   6% (424/7065)   Receiving objects:   7% (495/7065)   Receiving objects:   8% (566/7065)   Receiving objects:   9% (636/7065)   Receiving objects:  10% (707/7065)   Receiving objects:  11% (778/7065)   Receiving objects:  12% (848/7065)   Receiving objects:  13% (919/7065)   Receiving objects:  14% (990/7065)   Receiving objects:  15% (1060/7065)   Receiving objects:  16% (1131/7065)   Receiving objects:  17% (1202/7065)   Receiving objects:  18% (1272/7065)   Receiving objects:  19% (1343/7065)   Receiving objects:  20% (1413/7065)   Receiving objects:  21% (1484/7065)   Receiving objects:  22% (1555/7065)   Receiving objects:  23% (1625/7065)   Receiving objects:  24% (1696/7065)   Receiving objects:  25% (1767/7065)   Receiving objects:  26% (1837/7065)   Receiving objects:  27% (1908/7065)   Receiving objects:  28% (1979/7065)   Receiving objects:  29% (2049/7065)   Receiving objects:  30% (2120/7065)   Receiving objects:  31% (2191/7065)   Receiving objects:  32% (2261/7065)   Receiving objects:  33% (2332/7065)   Receiving objects:  34% (2403/7065)   Receiving objects:  35% (2473/7065)   Receiving objects:  36% (2544/7065)   Receiving objects:  37% (2615/7065)   Receiving objects:  38% (2685/7065)   Receiving objects:  39% (2756/7065)   Receiving objects:  40% (2826/7065)   Receiving objects:  41% (2897/7065)   Receiving objects:  42% (2968/7065)   Receiving objects:  43% (3038/7065)   Receiving objects:  44% (3109/7065)   Receiving objects:  45% (3180/7065)   Receiving objects:  46% (3250/7065)   Receiving objects:  47% (3321/7065)   Receiving objects:  48% (3392/7065)   Receiving objects:  49% (3462/7065)   Receiving objects:  50% (3533/7065)   Receiving objects:  51% (3604/7065)   Receiving objects:  52% (3674/7065)   Receiving objects:  53% (3745/7065)   Receiving objects:  54% (3816/7065)   Receiving objects:  55% (3886/7065)   Receiving objects:  56% (3957/7065)   Receiving objects:  57% (4028/7065)   Receiving objects:  58% (4098/7065)   Receiving objects:  59% (4169/7065)   Receiving objects:  60% (4239/7065)   Receiving objects:  61% (4310/7065)   Receiving objects:  62% (4381/7065)   Receiving objects:  63% (4451/7065)   Receiving objects:  64% (4522/7065)   Receiving objects:  65% (4593/7065)   Receiving objects:  66% (4663/7065)   Receiving objects:  67% (4734/7065)   Receiving objects:  68% (4805/7065)   Receiving objects:  69% (4875/7065)   Receiving objects:  70% (4946/7065)   Receiving objects:  71% (5017/7065)   Receiving objects:  72% (5087/7065)   Receiving objects:  73% (5158/7065)   Receiving objects:  74% (5229/7065)   Receiving objects:  75% (5299/7065)   Receiving objects:  76% (5370/7065)   Receiving objects:  77% (5441/7065)   Receiving objects:  78% (5511/7065)   Receiving objects:  79% (5582/7065)   Receiving objects:  80% (5652/7065)   Receiving objects:  81% (5723/7065)   Receiving objects:  82% (5794/7065)   Receiving objects:  83% (5864/7065)   Receiving objects:  84% (5935/7065)   Receiving objects:  85% (6006/7065)   Receiving objects:  86% (6076/7065)   Receiving objects:  87% (6147/7065)   Receiving objects:  88% (6218/7065)   Receiving objects:  89% (6288/7065)   Receiving objects:  90% (6359/7065)   Receiving objects:  91% (6430/7065)   Receiving objects:  92% (6500/7065)   Receiving objects:  93% (6571/7065)   Receiving objects:  94% (6642/7065)   Receiving objects:  95% (6712/7065)   Receiving objects:  96% (6783/7065)   Receiving objects:  97% (6854/7065)   Receiving objects:  98% (6924/7065)   Receiving objects:  99% (6995/7065)   remote: Total 7065 (delta 2238), reused 6680 (delta 1919), pack-reused 0[K
Receiving objects: 100% (7065/7065)   Receiving objects: 100% (7065/7065), 1.67 MiB | 13.18 MiB/s, done.
Resolving deltas:   0% (0/2238)   Resolving deltas:   1% (29/2238)   Resolving deltas:   2% (50/2238)   Resolving deltas:   3% (85/2238)   Resolving deltas:   4% (94/2238)   Resolving deltas:   5% (112/2238)   Resolving deltas:   6% (136/2238)   Resolving deltas:   8% (199/2238)   Resolving deltas:   9% (210/2238)   Resolving deltas:  10% (242/2238)   Resolving deltas:  12% (287/2238)   Resolving deltas:  13% (292/2238)   Resolving deltas:  15% (353/2238)   Resolving deltas:  16% (363/2238)   Resolving deltas:  17% (389/2238)   Resolving deltas:  18% (403/2238)   Resolving deltas:  19% (438/2238)   Resolving deltas:  20% (448/2238)   Resolving deltas:  21% (475/2238)   Resolving deltas:  22% (493/2238)   Resolving deltas:  23% (526/2238)   Resolving deltas:  24% (549/2238)   Resolving deltas:  25% (561/2238)   Resolving deltas:  26% (584/2238)   Resolving deltas:  27% (610/2238)   Resolving deltas:  28% (631/2238)   Resolving deltas:  29% (652/2238)   Resolving deltas:  31% (714/2238)   Resolving deltas:  32% (718/2238)   Resolving deltas:  33% (740/2238)   Resolving deltas:  34% (765/2238)   Resolving deltas:  35% (788/2238)   Resolving deltas:  36% (807/2238)   Resolving deltas:  37% (839/2238)   Resolving deltas:  38% (860/2238)   Resolving deltas:  39% (883/2238)   Resolving deltas:  41% (920/2238)   Resolving deltas:  42% (940/2238)   Resolving deltas:  43% (970/2238)   Resolving deltas:  44% (987/2238)   Resolving deltas:  45% (1013/2238)   Resolving deltas:  46% (1031/2238)   Resolving deltas:  47% (1053/2238)   Resolving deltas:  48% (1078/2238)   Resolving deltas:  49% (1097/2238)   Resolving deltas:  50% (1121/2238)   Resolving deltas:  51% (1144/2238)   Resolving deltas:  52% (1164/2238)   Resolving deltas:  53% (1187/2238)   Resolving deltas:  54% (1209/2238)   Resolving deltas:  55% (1239/2238)   Resolving deltas:  56% (1259/2238)   Resolving deltas:  57% (1279/2238)   Resolving deltas:  58% (1299/2238)   Resolving deltas:  59% (1321/2238)   Resolving deltas:  60% (1346/2238)   Resolving deltas:  61% (1366/2238)   Resolving deltas:  62% (1391/2238)   Resolving deltas:  63% (1411/2238)   Resolving deltas:  64% (1434/2238)   Resolving deltas:  65% (1460/2238)   Resolving deltas:  66% (1481/2238)   Resolving deltas:  67% (1502/2238)   Resolving deltas:  68% (1525/2238)   Resolving deltas:  69% (1562/2238)   Resolving deltas:  70% (1567/2238)   Resolving deltas:  72% (1613/2238)   Resolving deltas:  73% (1636/2238)   Resolving deltas:  74% (1658/2238)   Resolving deltas:  75% (1680/2238)   Resolving deltas:  76% (1703/2238)   Resolving deltas:  77% (1729/2238)   Resolving deltas:  78% (1746/2238)   Resolving deltas:  79% (1775/2238)   Resolving deltas:  80% (1794/2238)   Resolving deltas:  81% (1814/2238)   Resolving deltas:  82% (1850/2238)   Resolving deltas:  83% (1858/2238)   Resolving deltas:  84% (1880/2238)   Resolving deltas:  85% (1904/2238)   Resolving deltas:  86% (1930/2238)   Resolving deltas:  87% (1966/2238)   Resolving deltas:  88% (1975/2238)   Resolving deltas:  89% (1992/2238)   Resolving deltas:  90% (2022/2238)   Resolving deltas:  91% (2043/2238)   Resolving deltas:  92% (2069/2238)   Resolving deltas:  93% (2103/2238)   Resolving deltas:  94% (2110/2238)   Resolving deltas:  95% (2127/2238)   Resolving deltas:  96% (2152/2238)   Resolving deltas:  97% (2172/2238)   Resolving deltas:  98% (2195/2238)   Resolving deltas: 100% (2238/2238)   Resolving deltas: 100% (2238/2238), done.

travis_time:end:0008cd30:start=1517276143539532884,finish=1517276144432904796,duration=893371912[0K$ cd brianfrankcooper/YCSB
travis_time:start:038c0bb7[0K$ git fetch origin +refs/pull/1085/merge:
remote: Counting objects: 124, done.[K
remote: Compressing objects:   1% (1/81)   [Kremote: Compressing objects:   2% (2/81)   [Kremote: Compressing objects:   3% (3/81)   [Kremote: Compressing objects:   4% (4/81)   [Kremote: Compressing objects:   6% (5/81)   [Kremote: Compressing objects:   7% (6/81)   [Kremote: Compressing objects:   8% (7/81)   [Kremote: Compressing objects:   9% (8/81)   [Kremote: Compressing objects:  11% (9/81)   [Kremote: Compressing objects:  12% (10/81)   [Kremote: Compressing objects:  13% (11/81)   [Kremote: Compressing objects:  14% (12/81)   [Kremote: Compressing objects:  16% (13/81)   [Kremote: Compressing objects:  17% (14/81)   [Kremote: Compressing objects:  18% (15/81)   [Kremote: Compressing objects:  19% (16/81)   [Kremote: Compressing objects:  20% (17/81)   [Kremote: Compressing objects:  22% (18/81)   [Kremote: Compressing objects:  23% (19/81)   [Kremote: Compressing objects:  24% (20/81)   [Kremote: Compressing objects:  25% (21/81)   [Kremote: Compressing objects:  27% (22/81)   [Kremote: Compressing objects:  28% (23/81)   [Kremote: Compressing objects:  29% (24/81)   [Kremote: Compressing objects:  30% (25/81)   [Kremote: Compressing objects:  32% (26/81)   [Kremote: Compressing objects:  33% (27/81)   [Kremote: Compressing objects:  34% (28/81)   [Kremote: Compressing objects:  35% (29/81)   [Kremote: Compressing objects:  37% (30/81)   [Kremote: Compressing objects:  38% (31/81)   [Kremote: Compressing objects:  39% (32/81)   [Kremote: Compressing objects:  40% (33/81)   [Kremote: Compressing objects:  41% (34/81)   [Kremote: Compressing objects:  43% (35/81)   [Kremote: Compressing objects:  44% (36/81)   [Kremote: Compressing objects:  45% (37/81)   [Kremote: Compressing objects:  46% (38/81)   [Kremote: Compressing objects:  48% (39/81)   [Kremote: Compressing objects:  49% (40/81)   [Kremote: Compressing objects:  50% (41/81)   [Kremote: Compressing objects:  51% (42/81)   [Kremote: Compressing objects:  53% (43/81)   [Kremote: Compressing objects:  54% (44/81)   [Kremote: Compressing objects:  55% (45/81)   [Kremote: Compressing objects:  56% (46/81)   [Kremote: Compressing objects:  58% (47/81)   [Kremote: Compressing objects:  59% (48/81)   [Kremote: Compressing objects:  60% (49/81)   [Kremote: Compressing objects:  61% (50/81)   [Kremote: Compressing objects:  62% (51/81)   [Kremote: Compressing objects:  64% (52/81)   [Kremote: Compressing objects:  65% (53/81)   [Kremote: Compressing objects:  66% (54/81)   [Kremote: Compressing objects:  67% (55/81)   [Kremote: Compressing objects:  69% (56/81)   [Kremote: Compressing objects:  70% (57/81)   [Kremote: Compressing objects:  71% (58/81)   [Kremote: Compressing objects:  72% (59/81)   [Kremote: Compressing objects:  74% (60/81)   [Kremote: Compressing objects:  75% (61/81)   [Kremote: Compressing objects:  76% (62/81)   [Kremote: Compressing objects:  77% (63/81)   [Kremote: Compressing objects:  79% (64/81)   [Kremote: Compressing objects:  80% (65/81)   [Kremote: Compressing objects:  81% (66/81)   [Kremote: Compressing objects:  82% (67/81)   [Kremote: Compressing objects:  83% (68/81)   [Kremote: Compressing objects:  85% (69/81)   [Kremote: Compressing objects:  86% (70/81)   [Kremote: Compressing objects:  87% (71/81)   [Kremote: Compressing objects:  88% (72/81)   [Kremote: Compressing objects:  90% (73/81)   [Kremote: Compressing objects:  91% (74/81)   [Kremote: Compressing objects:  92% (75/81)   [Kremote: Compressing objects:  93% (76/81)   [Kremote: Compressing objects:  95% (77/81)   [Kremote: Compressing objects:  96% (78/81)   [Kremote: Compressing objects:  97% (79/81)   [Kremote: Compressing objects:  98% (80/81)   [Kremote: Compressing objects: 100% (81/81)   [Kremote: Compressing objects: 100% (81/81), done.[K
remote: Total 124 (delta 57), reused 96 (delta 30), pack-reused 0[K
Receiving objects:   0% (1/124)   Receiving objects:   1% (2/124)   Receiving objects:   2% (3/124)   Receiving objects:   3% (4/124)   Receiving objects:   4% (5/124)   Receiving objects:   5% (7/124)   Receiving objects:   6% (8/124)   Receiving objects:   7% (9/124)   Receiving objects:   8% (10/124)   Receiving objects:   9% (12/124)   Receiving objects:  10% (13/124)   Receiving objects:  11% (14/124)   Receiving objects:  12% (15/124)   Receiving objects:  13% (17/124)   Receiving objects:  14% (18/124)   Receiving objects:  15% (19/124)   Receiving objects:  16% (20/124)   Receiving objects:  17% (22/124)   Receiving objects:  18% (23/124)   Receiving objects:  19% (24/124)   Receiving objects:  20% (25/124)   Receiving objects:  21% (27/124)   Receiving objects:  22% (28/124)   Receiving objects:  23% (29/124)   Receiving objects:  24% (30/124)   Receiving objects:  25% (31/124)   Receiving objects:  26% (33/124)   Receiving objects:  27% (34/124)   Receiving objects:  28% (35/124)   Receiving objects:  29% (36/124)   Receiving objects:  30% (38/124)   Receiving objects:  31% (39/124)   Receiving objects:  32% (40/124)   Receiving objects:  33% (41/124)   Receiving objects:  34% (43/124)   Receiving objects:  35% (44/124)   Receiving objects:  36% (45/124)   Receiving objects:  37% (46/124)   Receiving objects:  38% (48/124)   Receiving objects:  39% (49/124)   Receiving objects:  40% (50/124)   Receiving objects:  41% (51/124)   Receiving objects:  42% (53/124)   Receiving objects:  43% (54/124)   Receiving objects:  44% (55/124)   Receiving objects:  45% (56/124)   Receiving objects:  46% (58/124)   Receiving objects:  47% (59/124)   Receiving objects:  48% (60/124)   Receiving objects:  49% (61/124)   Receiving objects:  50% (62/124)   Receiving objects:  51% (64/124)   Receiving objects:  52% (65/124)   Receiving objects:  53% (66/124)   Receiving objects:  54% (67/124)   Receiving objects:  55% (69/124)   Receiving objects:  56% (70/124)   Receiving objects:  57% (71/124)   Receiving objects:  58% (72/124)   Receiving objects:  59% (74/124)   Receiving objects:  60% (75/124)   Receiving objects:  61% (76/124)   Receiving objects:  62% (77/124)   Receiving objects:  63% (79/124)   Receiving objects:  64% (80/124)   Receiving objects:  65% (81/124)   Receiving objects:  66% (82/124)   Receiving objects:  67% (84/124)   Receiving objects:  68% (85/124)   Receiving objects:  69% (86/124)   Receiving objects:  70% (87/124)   Receiving objects:  71% (89/124)   Receiving objects:  72% (90/124)   Receiving objects:  73% (91/124)   Receiving objects:  74% (92/124)   Receiving objects:  75% (93/124)   Receiving objects:  76% (95/124)   Receiving objects:  77% (96/124)   Receiving objects:  78% (97/124)   Receiving objects:  79% (98/124)   Receiving objects:  80% (100/124)   Receiving objects:  81% (101/124)   Receiving objects:  82% (102/124)   Receiving objects:  83% (103/124)   Receiving objects:  84% (105/124)   Receiving objects:  85% (106/124)   Receiving objects:  86% (107/124)   Receiving objects:  87% (108/124)   Receiving objects:  88% (110/124)   Receiving objects:  89% (111/124)   Receiving objects:  90% (112/124)   Receiving objects:  91% (113/124)   Receiving objects:  92% (115/124)   Receiving objects:  93% (116/124)   Receiving objects:  94% (117/124)   Receiving objects:  95% (118/124)   Receiving objects:  96% (120/124)   Receiving objects:  97% (121/124)   Receiving objects:  98% (122/124)   Receiving objects:  99% (123/124)   Receiving objects: 100% (124/124)   Receiving objects: 100% (124/124), 16.58 KiB | 16.58 MiB/s, done.
Resolving deltas:   0% (0/57)   Resolving deltas:   3% (2/57)   Resolving deltas:   5% (3/57)   Resolving deltas:   7% (4/57)   Resolving deltas:  15% (9/57)   Resolving deltas:  17% (10/57)   Resolving deltas:  19% (11/57)   Resolving deltas:  24% (14/57)   Resolving deltas:  26% (15/57)   Resolving deltas:  38% (22/57)   Resolving deltas:  40% (23/57)   Resolving deltas:  42% (24/57)   Resolving deltas:  43% (25/57)   Resolving deltas:  45% (26/57)   Resolving deltas:  47% (27/57)   Resolving deltas:  49% (28/57)   Resolving deltas:  50% (29/57)   Resolving deltas:  52% (30/57)   Resolving deltas:  54% (31/57)   Resolving deltas:  56% (32/57)   Resolving deltas:  59% (34/57)   Resolving deltas:  61% (35/57)   Resolving deltas:  63% (36/57)   Resolving deltas:  64% (37/57)   Resolving deltas:  66% (38/57)   Resolving deltas:  68% (39/57)   Resolving deltas:  70% (40/57)   Resolving deltas:  71% (41/57)   Resolving deltas:  73% (42/57)   Resolving deltas:  75% (43/57)   Resolving deltas:  77% (44/57)   Resolving deltas:  78% (45/57)   Resolving deltas:  80% (46/57)   Resolving deltas:  82% (47/57)   Resolving deltas:  84% (48/57)   Resolving deltas:  85% (49/57)   Resolving deltas:  87% (50/57)   Resolving deltas:  89% (51/57)   Resolving deltas:  91% (52/57)   Resolving deltas:  94% (54/57)   Resolving deltas:  96% (55/57)   Resolving deltas:  98% (56/57)   Resolving deltas: 100% (57/57)   Resolving deltas: 100% (57/57), completed with 39 local objects.
From https://github.com/brianfrankcooper/YCSB
 * branch            refs/pull/1085/merge -> FETCH_HEAD

travis_time:end:038c0bb7:start=1517276144439307592,finish=1517276144723178066,duration=283870474[0K$ git checkout -qf FETCH_HEAD
travis_fold:end:git.checkout[0Ktravis_fold:start:services[0Ktravis_time:start:1d830520[0K$ sudo service mongod start
mongod start/running, process 2275

travis_time:end:1d830520:start=1517276144810064960,finish=1517276144834894841,duration=24829881[0Ktravis_fold:end:services[0K[33;1mDisabling Gradle daemon[0m
travis_time:start:04f60852[0K$ mkdir -p ~/.gradle && echo "org.gradle.daemon=false" >> ~/.gradle/gradle.properties

travis_time:end:04f60852:start=1517276152763794002,finish=1517276152769187128,duration=5393126[0K$ export PATH=$JAVA_HOME/bin:$PATH
$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:348cce42[0K$ mvn install -q -DskipTests=true
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[INFO] Skipping plugin execution
[INFO] Skipping plugin execution

travis_time:end:348cce42:start=1517276153975299400,finish=1517276280464173212,duration=126488873812[0Ktravis_fold:end:install[0Ktravis_time:start:094039aa[0K$ mvn test -q
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running TestSuite
Configuring TestNG with: org.apache.maven.surefire.testng.conf.TestNGMapConfigurator@255316f2
Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.32 sec

Results :

Tests run: 40, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.accumulo.AccumuloTest
Using 1 threads to write data
Using 1 threads to write data
Using 1 threads to write data
Using 1 threads to write data
Using 1 threads to write data
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 70.513 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0

2018/01/30 01:39:29 WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2018/01/30 01:39:30 WARN  org.apache.hadoop.metrics2.impl.MetricsConfig  - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2018/01/30 01:39:31 WARN  org.apache.hadoop.security.authentication.server.AuthenticationFilter  - 'signature.secret' configuration not set, using a random value as secret
2018/01/30 01:39:34 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2018/01/30 01:39:35 WARN  org.apache.hadoop.hbase.HTableDescriptor  - Use addCoprocessor* methods to add a coprocessor instead
2018/01/30 01:39:35 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2018/01/30 01:39:45 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16144b8213c0002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2018/01/30 01:39:55 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16144b8213c0006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2018/01/30 01:39:55 WARN  org.apache.hadoop.hdfs.server.datanode.DirectoryScanner  - DirectoryScanner: shutdown has been called
2018/01/30 01:39:55 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - BPOfferService for Block pool BP-1312337751-172.17.0.11-1517276370698 (Datanode Uuid da140754-dfab-47de-8339-470e84a44f4b) service to ip6-localhost/127.0.0.1:45297 interrupted
2018/01/30 01:39:55 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - Ending block pool service for: Block pool BP-1312337751-172.17.0.11-1517276370698 (Datanode Uuid da140754-dfab-47de-8339-470e84a44f4b) service to ip6-localhost/127.0.0.1:45297
2018/01/30 01:39:55 WARN  org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager  - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.yahoo.ycsb.db.CassandraCQLClientTest
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Configuration location: file:/home/travis/build/brianfrankcooper/YCSB/cassandra/target/embeddedCassandra/cu-cassandra.yaml
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 455MB
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 455MB
[main] WARN org.apache.cassandra.config.DatabaseDescriptor - Small commitlog volume detected at target/embeddedCassandra/commitlog; setting commitlog_total_space_in_mb to 4861.  You can override this in cassandra.yaml
[main] WARN org.apache.cassandra.config.DatabaseDescriptor - Only 6515 MB free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots
[main] WARN org.apache.cassandra.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[main] INFO org.apache.cassandra.db.commitlog.CommitLog - No commitlog files found; skipping replay
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Hostname: travis-job-brianfrankcoop-ycsb-334974498.travisci.net
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - JVM vendor/version: Java HotSpot(TM) 64-Bit Server VM/1.8.0_151
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Heap size: 514850816/1908932608
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Code Cache Non-heap memory: init = 2555904(2496K) used = 3593216(3509K) committed = 3604480(3520K) max = 251658240(245760K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Metaspace Non-heap memory: init = 0(0K) used = 15341928(14982K) committed = 15990784(15616K) max = -1(-1K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Compressed Class Space Non-heap memory: init = 0(0K) used = 1882640(1838K) committed = 2097152(2048K) max = 1073741824(1048576K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Eden Space Heap memory: init = 134742016(131584K) used = 83551496(81593K) committed = 134742016(131584K) max = 671612928(655872K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Survivor Space Heap memory: init = 22020096(21504K) used = 0(0K) committed = 22020096(21504K) max = 22020096(21504K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Old Gen Heap memory: init = 358088704(349696K) used = 0(0K) committed = 358088704(349696K) max = 1431830528(1398272K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Classpath: /home/travis/build/brianfrankcooper/YCSB/cassandra/target/test-classes:/home/travis/build/brianfrankcooper/YCSB/cassandra/target/classes:/home/travis/.m2/repository/com/datastax/cassandra/cassandra-driver-core/3.0.0/cassandra-driver-core-3.0.0.jar:/home/travis/.m2/repository/io/netty/netty-handler/4.0.33.Final/netty-handler-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-buffer/4.0.33.Final/netty-buffer-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-common/4.0.33.Final/netty-common-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-transport/4.0.33.Final/netty-transport-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-codec/4.0.33.Final/netty-codec-4.0.33.Final.jar:/home/travis/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/home/travis/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/home/travis/build/brianfrankcooper/YCSB/core/target/classes:/home/travis/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/travis/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.4/jackson-mapper-asl-1.9.4.jar:/home/travis/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.4/jackson-core-asl-1.9.4.jar:/home/travis/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.4/HdrHistogram-2.1.4.jar:/home/travis/.m2/repository/org/cassandraunit/cassandra-unit/3.0.0.1/cassandra-unit-3.0.0.1-shaded.jar:/home/travis/.m2/repository/org/apache/cassandra/cassandra-all/3.4/cassandra-all-3.4.jar:/home/travis/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/travis/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/home/travis/.m2/repository/com/ning/compress-lzf/0.8.4/compress-lzf-0.8.4.jar:/home/travis/.m2/repository/commons-cli/commons-cli/1.1/commons-cli-1.1.jar:/home/travis/.m2/repository/commons-codec/commons-codec/1.2/commons-codec-1.2.jar:/home/travis/.m2/repository/org/apache/commons/commons-math3/3.2/commons-math3-3.2.jar:/home/travis/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/home/travis/.m2/repository/org/antlr/antlr/3.5.2/antlr-3.5.2.jar:/home/travis/.m2/repository/org/antlr/ST4/4.0.8/ST4-4.0.8.jar:/home/travis/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/travis/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.7/jcl-over-slf4j-1.7.7.jar:/home/travis/.m2/repository/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.jar:/home/travis/.m2/repository/com/boundary/high-scale-lib/1.0.6/high-scale-lib-1.0.6.jar:/home/travis/.m2/repository/org/yaml/snakeyaml/1.11/snakeyaml-1.11.jar:/home/travis/.m2/repository/org/mindrot/jbcrypt/0.3m/jbcrypt-0.3m.jar:/home/travis/.m2/repository/com/addthis/metrics/reporter-config3/3.0.0/reporter-config3-3.0.0.jar:/home/travis/.m2/repository/com/addthis/metrics/reporter-config-base/3.0.0/reporter-config-base-3.0.0.jar:/home/travis/.m2/repository/com/thinkaurelius/thrift/thrift-server/0.3.7/thrift-server-0.3.7.jar:/home/travis/.m2/repository/com/lmax/disruptor/3.0.1/disruptor-3.0.1.jar:/home/travis/.m2/repository/com/clearspring/analytics/stream/2.5.2/stream-2.5.2.jar:/home/travis/.m2/repository/it/unimi/dsi/fastutil/6.5.7/fastutil-6.5.7.jar:/home/travis/.m2/repository/org/apache/thrift/libthrift/0.9.2/libthrift-0.9.2.jar:/home/travis/.m2/repository/org/apache/cassandra/cassandra-thrift/3.4/cassandra-thrift-3.4.jar:/home/travis/.m2/repository/com/carrotsearch/hppc/0.5.4/hppc-0.5.4.jar:/home/travis/.m2/repository/de/jflex/jflex/1.6.0/jflex-1.6.0.jar:/home/travis/.m2/repository/org/apache/ant/ant/1.7.0/ant-1.7.0.jar:/home/travis/.m2/repository/org/apache/ant/ant-launcher/1.7.0/ant-launcher-1.7.0.jar:/home/travis/.m2/repository/net/mintern/primitive/1.0/primitive-1.0.jar:/home/travis/.m2/repository/com/github/rholder/snowball-stemmer/1.3.0.581.1/snowball-stemmer-1.3.0.581.1.jar:/home/travis/.m2/repository/com/googlecode/concurrent-trees/concurrent-trees/2.4.0/concurrent-trees-2.4.0.jar:/home/travis/.m2/repository/net/java/dev/jna/jna/4.0.0/jna-4.0.0.jar:/home/travis/.m2/repository/com/github/jbellis/jamm/0.3.0/jamm-0.3.0.jar:/home/travis/.m2/repository/joda-time/joda-time/2.4/joda-time-2.4.jar:/home/travis/.m2/repository/org/fusesource/sigar/1.6.4/sigar-1.6.4.jar:/home/travis/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/travis/.m2/repository/org/caffinitas/ohc/ohc-core/0.4.2/ohc-core-0.4.2.jar:/home/travis/.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar:/home/travis/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/travis/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/home/travis/.m2/repository/org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.jar:/home/travis/.m2/repository/org/slf4j/slf4j-simple/1.7.21/slf4j-simple-1.7.21.jar:/home/travis/.m2/repository/junit/junit/4.12/junit-4.12.jar:
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - JVM Arguments: [-Djava.library.path=/home/travis/build/brianfrankcooper/YCSB/cassandra/target/cassandra-dependency/hyperic-sigar-1.6.4/sigar-bin/lib, -Xmx2048m, -Xms512m]
[pool-1-thread-1] WARN org.apache.cassandra.utils.CLibrary - Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.
[pool-1-thread-1] WARN org.apache.cassandra.service.StartupChecks - jemalloc shared library could not be preloaded to speed up memory allocations
[pool-1-thread-1] WARN org.apache.cassandra.service.StartupChecks - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
[pool-1-thread-1] ERROR org.apache.cassandra.service.StartupChecks - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
[pool-1-thread-1] INFO org.apache.cassandra.utils.SigarLibrary - Initializing SIGAR library
[pool-1-thread-1] INFO org.apache.cassandra.utils.SigarLibrary - Checked OS settings and found them configured for optimal performance.
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.IndexInfo
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.batches
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.paxos
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.local
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.peers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.peer_events
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.range_xfers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.compaction_history
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.sstable_activity
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.size_estimates
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.available_ranges
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.views_builds_in_progress
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.built_views
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.hints
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.batchlog
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_keyspaces
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_columnfamilies
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_triggers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_usertypes
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_functions
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_aggregates
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing key cache with capacity of 24 MBs.
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing row cache with capacity of 0 MBs
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing counter cache with capacity of 12 MBs
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Scheduling counter cache save to every 7200 seconds (going to save all keys).
[CompactionExecutor:2] INFO org.apache.cassandra.utils.memory.BufferPool - Global buffer pool is enabled, when pool is exahusted (max is 512 mb) it will allocate on heap
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Populating token metadata from system tables
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Token metadata: 
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.keyspaces
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.tables
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.triggers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.dropped_columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.views
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.types
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.functions
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.aggregates
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.indexes
[pool-3-thread-1] INFO org.apache.cassandra.cache.AutoSavingCache - Completed loading (9 ms; 1 keys) KeyCache cache
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Populating token metadata from system tables
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Token metadata: 
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Cassandra version: 3.4
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Thrift API version: 20.1.0
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - CQL supported versions: 3.4.0 (default: 3.4.0)
[pool-1-thread-1] INFO org.apache.cassandra.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 24 MB and a resize interval of 60 minutes
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Loading persisted ring state
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] WARN org.apache.cassandra.db.SystemKeyspace - No host ID found, created db80360c-245b-4c62-b423-305d190cddcd (Note: This should happen exactly once per node).
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Starting up server gossip
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.net.MessagingService - Starting Messaging Service on /127.0.0.1:7010 (lo)
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - This node will not auto bootstrap because it is configured to be a seed node.
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] WARN org.apache.cassandra.service.StorageService - Generated random token [7023295515975040449]. Random tokens will result in an unbalanced ring; see http://wiki.apache.org/cassandra/Operations
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@1a0c7b1e[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[ColumnDefinition{name=client, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=command, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=request, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=duration, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parameters, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@1c45a047[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[ColumnDefinition{name=activity, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=thread, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}, ColumnDefinition{name=source, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=source_elapsed, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_traces.events
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_traces.sessions
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@69989da0[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=columnfamily_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=1}],clusteringColumns=[ColumnDefinition{name=id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[ColumnDefinition{name=status, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}, ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=finished_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=participants, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.InetAddressType), kind=REGULAR, position=-1}, ColumnDefinition{name=exception_stacktrace, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=REGULAR, position=-1}, ColumnDefinition{name=range_end, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=range_begin, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=exception_message, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=columnfamily_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@1b6981fa[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names requested_ranges successful_ranges]],partitionKeyColumns=[ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[ColumnDefinition{name=requested_ranges, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=exception_message, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=successful_ranges, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=finished_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=exception_stacktrace, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=columnfamily_names, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_distributed.parent_repair_history
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_distributed.repair_history
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Node /127.0.0.1 state jump to NORMAL
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@481cd0ec[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=salted_hash, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=member_of, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=can_login, type=org.apache.cassandra.db.marshal.BooleanType, kind=REGULAR, position=-1}, ColumnDefinition{name=is_superuser, type=org.apache.cassandra.db.marshal.BooleanType, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@689e9808[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=member, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=member, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@2c6bc3a8[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}, ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=permissions, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@6f4efeb4[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.resource_role_permissons_index
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.role_members
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.role_permissions
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.roles
[pool-1-thread-1] INFO org.apache.cassandra.service.NativeTransportService - Netty using Java NIO event loop
[pool-1-thread-1] INFO org.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.33.Final.69b5aef, netty-codec=netty-codec-4.0.33.Final.69b5aef, netty-common=netty-common-4.0.33.Final.69b5aef, netty-handler=netty-handler-4.0.27.Final.054e7c5, netty-transport=netty-transport-4.0.33.Final.69b5aef]
[pool-1-thread-1] INFO org.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142 (unencrypted)...
[pool-1-thread-1] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
[Thread-1] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Listening for thrift clients...
[main] INFO com.datastax.driver.core.NettyUtil - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
[SharedPool-Worker-1] INFO org.apache.cassandra.db.monitoring.ApproximateTime - Scheduling approximate time-check task with a precision of 10 milliseconds
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
[SharedPool-Worker-3] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=ycsb, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
[SharedPool-Worker-8] INFO org.apache.cassandra.service.MigrationManager - Create new table: org.apache.cassandra.config.CFMetaData@cc48760[cfId=7f358a00-055e-11e8-8c93-ffb793236d82,ksName=ycsb,cfName=usertable,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@51780fb8, extensions={}},comparator=comparator(),partitionColumns=[[] | [field0 field1 field2 field3 field4 field5 field6 field7 field8 field9]],partitionKeyColumns=[ColumnDefinition{name=y_id, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=field7, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field4, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field2, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field0, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field3, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field6, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field8, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field5, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field9, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=y_id, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=field1, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing ycsb.usertable
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[SharedPool-Worker-1] WARN org.apache.cassandra.utils.FBUtilities - Trigger directory doesn't exist, please create it and try again.
[HANDSHAKE-/127.0.0.1] INFO org.apache.cassandra.net.OutboundTcpConnection - Handshaking version with /127.0.0.1
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[OptionalTasks:1] INFO org.apache.cassandra.auth.CassandraRoleManager - Created default superuser role 'cassandra'
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.243 sec

Results :

Tests run: 4, Failures: 0, Errors: 0, Skipped: 0

[StorageServiceShutdownHook] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Stop listening to thrift clients
[StorageServiceShutdownHook] INFO org.apache.cassandra.transport.Server - Stop listening for CQL clients
[StorageServiceShutdownHook] INFO org.apache.cassandra.gms.Gossiper - Announcing shutdown
[StorageServiceShutdownHook] INFO org.apache.cassandra.service.StorageService - Node /127.0.0.1 state jump to shutdown
[StorageServiceShutdownHook] INFO org.apache.cassandra.net.MessagingService - Waiting for messaging service to quiesce
[ACCEPT-/127.0.0.1] INFO org.apache.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
[StorageServiceShutdownHook] INFO org.apache.cassandra.hints.HintsService - Paused hints dispatch
[StorageServiceShutdownHook] INFO org.apache.cassandra.hints.HintsService - Paused hints dispatch

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.ElasticsearchClientTest
Elasticsearch starting node = es.ycsb.cluster
Elasticsearch node path.home = /tmp/junit5915339411302787316
Elasticsearch Remote Mode = false
Jan 30, 2018 1:40:29 AM org.elasticsearch.node.Node <init>
INFO: [Toxin] version[2.4.0], pid[4776], build[ce9f0c7/2016-08-29T09:14:17Z]
Jan 30, 2018 1:40:29 AM org.elasticsearch.node.Node <init>
INFO: [Toxin] initializing ...
Jan 30, 2018 1:40:29 AM org.elasticsearch.plugins.PluginsService <init>
INFO: [Toxin] modules [], plugins [], sites []
Jan 30, 2018 1:40:29 AM org.elasticsearch.env.NodeEnvironment maybeLogPathDetails
INFO: [Toxin] using [1] data paths, mounts [[/ (/dev/mapper/docker-202:16-17170442-c21f0ffc471a099d9533a69366d6bed217005b0970dbcc378a4577bb43116926)]], net usable_space [6.3gb], net total_space [18.9gb], spins? [possibly], types [xfs]
Jan 30, 2018 1:40:29 AM org.elasticsearch.env.NodeEnvironment maybeLogHeapDetails
INFO: [Toxin] heap size [1.7gb], compressed ordinary object pointers [true]
Jan 30, 2018 1:40:29 AM org.elasticsearch.env.NodeEnvironment maybeWarnFileDescriptors
WARNING: [Toxin] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
Jan 30, 2018 1:40:31 AM org.elasticsearch.node.Node <init>
INFO: [Toxin] initialized
Jan 30, 2018 1:40:31 AM org.elasticsearch.node.Node start
INFO: [Toxin] starting ...
Jan 30, 2018 1:40:31 AM org.elasticsearch.transport.TransportService doStart
INFO: [Toxin] publish_address {local[1]}, bound_addresses {local[1]}
Jan 30, 2018 1:40:31 AM org.elasticsearch.discovery.DiscoveryService doStart
INFO: [Toxin] es.ycsb.cluster/O9a_dZeASpul0en7z_RaQQ
Jan 30, 2018 1:40:31 AM org.elasticsearch.cluster.service.InternalClusterService runTasksForExecutor
INFO: [Toxin] new_master {Toxin}{O9a_dZeASpul0en7z_RaQQ}{local}{local[1]}{local=true}, reason: local-disco-initial_connect(master)
Jan 30, 2018 1:40:31 AM org.elasticsearch.gateway.GatewayService$GatewayRecoveryListener$1 clusterStateProcessed
INFO: [Toxin] recovered [0] indices into cluster_state
Jan 30, 2018 1:40:31 AM org.elasticsearch.http.HttpServer doStart
INFO: [Toxin] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}
Jan 30, 2018 1:40:31 AM org.elasticsearch.node.Node start
INFO: [Toxin] started
Jan 30, 2018 1:40:32 AM org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$1 execute
INFO: [Toxin] [es.ycsb] creating index, cause [api], templates [], shards [1]/[0], mappings []
Jan 30, 2018 1:40:32 AM org.elasticsearch.cluster.routing.allocation.AllocationService logClusterHealthStateChange
INFO: [Toxin] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[es.ycsb][0]] ...]).
Jan 30, 2018 1:40:32 AM org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor applyRequest
INFO: [Toxin] [es.ycsb] create_mapping [MOCK_TABLE]
Jan 30, 2018 1:40:32 AM org.elasticsearch.node.Node stop
INFO: [Toxin] stopping ...
Jan 30, 2018 1:40:32 AM org.elasticsearch.node.Node stop
INFO: [Toxin] stopped
Jan 30, 2018 1:40:32 AM org.elasticsearch.node.Node close
INFO: [Toxin] closing ...
Jan 30, 2018 1:40:32 AM org.elasticsearch.node.Node close
INFO: [Toxin] closed
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.518 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.HBaseClient10Test
2018/01/30 01:40:38 WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2018/01/30 01:40:39 WARN  org.apache.hadoop.metrics2.impl.MetricsConfig  - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2018/01/30 01:40:40 WARN  org.apache.hadoop.security.authentication.server.AuthenticationFilter  - 'signature.secret' configuration not set, using a random value as secret
2018/01/30 01:40:42 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2018/01/30 01:40:43 WARN  org.apache.hadoop.hbase.HTableDescriptor  - Use addCoprocessor* methods to add a coprocessor instead
2018/01/30 01:40:43 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2018/01/30 01:41:03 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16144b92bd70006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2018/01/30 01:41:03 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16144b92bd70001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2018/01/30 01:41:03 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16144b92bd70004, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2018/01/30 01:41:03 WARN  org.apache.hadoop.hdfs.server.datanode.DirectoryScanner  - DirectoryScanner: shutdown has been called
2018/01/30 01:41:03 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - BPOfferService for Block pool BP-510716615-172.17.0.11-1517276439608 (Datanode Uuid 4d8fcd91-d3a5-4ffc-9816-3b66624ca252) service to ip6-localhost/127.0.0.1:46629 interrupted
2018/01/30 01:41:03 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - Ending block pool service for: Block pool BP-510716615-172.17.0.11-1517276439608 (Datanode Uuid 4d8fcd91-d3a5-4ffc-9816-3b66624ca252) service to ip6-localhost/127.0.0.1:46629
2018/01/30 01:41:03 WARN  org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager  - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
Tests run: 5, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 25.996 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.JdbcDBClientTest
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:10, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:10, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.642 sec

Results :

Tests run: 7, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.MongoDbClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.117 sec
Running com.yahoo.ycsb.db.AsyncMongoDbClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.003 sec
Running com.yahoo.ycsb.db.OptionsSupportTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 sec

Results :

Tests run: 6, Failures: 0, Errors: 0, Skipped: 2


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.OrientDBClientTest
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 16
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 2147483647
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 4096
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 1000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2018-01-30 01:41:09 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
Jan 30, 2018 1:41:10 AM com.orientechnologies.common.log.OLogManager log
INFO: OrientDB auto-config DISKCACHE=1,820MB (heap=1,820MB direct=1,820MB os=60,366MB), assuming maximum direct memory size equals to maximum JVM heap size
Jan 30, 2018 1:41:10 AM com.orientechnologies.common.log.OLogManager log
WARNING: MaxDirectMemorySize JVM option is not set or has invalid value, that may cause out of memory errors. Please set the -XX:MaxDirectMemorySize=60366m option when you start the JVM.
2018-01-30 01:41:10 INFO  OrientDBClient:115 - OrientDB database not found, creating fresh db
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 16
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2018-01-30 01:41:13 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 16
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2018-01-30 01:41:13 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 16
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2018-01-30 01:41:13 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 16
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2018-01-30 01:41:13 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.062 sec
Jan 30, 2018 1:41:13 AM com.orientechnologies.common.log.OLogManager log
INFO: Orient Engine is shutting down...
Jan 30, 2018 1:41:13 AM com.orientechnologies.common.log.OLogManager log
INFO: - shutdown storage: test...

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.RadosClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.232 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.webservice.rest.RestClientTest
Jan 30, 2018 1:41:16 AM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["http-nio-8080"]
Jan 30, 2018 1:41:16 AM org.apache.tomcat.util.net.NioSelectorPool getSharedSelector
INFO: Using a shared selector for servlet write/read
Jan 30, 2018 1:41:16 AM org.apache.catalina.core.StandardService startInternal
INFO: Starting service Tomcat
Jan 30, 2018 1:41:16 AM org.apache.catalina.core.StandardEngine startInternal
INFO: Starting Servlet Engine: Apache Tomcat/8.0.28
Jan 30, 2018 1:41:16 AM org.apache.catalina.startup.ContextConfig getDefaultWebXmlFragment
INFO: No global web.xml found
Jan 30, 2018 1:41:16 AM org.apache.jasper.servlet.TldScanner scanJars
INFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
Jan 30, 2018 1:41:16 AM org.apache.coyote.AbstractProtocol start
INFO: Starting ProtocolHandler ["http-nio-8080"]
Jan 30, 2018 1:41:18 AM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.6 2014-02-18 21:52:53...
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.4 sec
Running com.yahoo.ycsb.webservice.rest.IntegrationTest
Jan 30, 2018 1:41:19 AM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["http-nio-8081"]
Jan 30, 2018 1:41:19 AM org.apache.tomcat.util.net.NioSelectorPool getSharedSelector
INFO: Using a shared selector for servlet write/read
Jan 30, 2018 1:41:19 AM org.apache.catalina.core.StandardService startInternal
INFO: Starting service Tomcat
Jan 30, 2018 1:41:19 AM org.apache.catalina.core.StandardEngine startInternal
INFO: Starting Servlet Engine: Apache Tomcat/8.0.28
Jan 30, 2018 1:41:19 AM org.apache.catalina.startup.ContextConfig getDefaultWebXmlFragment
INFO: No global web.xml found
Jan 30, 2018 1:41:19 AM org.apache.jasper.servlet.TldScanner scanJars
INFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
Jan 30, 2018 1:41:19 AM org.apache.coyote.AbstractProtocol start
INFO: Starting ProtocolHandler ["http-nio-8081"]
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=1.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Jan 30, 2018 1:41:20 AM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.6 2014-02-18 21:52:53...
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=1.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=1.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=1.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=1.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=1.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=1.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=1.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Jan 30, 2018 1:41:31 AM org.apache.coyote.AbstractProtocol pause
INFO: Pausing ProtocolHandler ["http-nio-8081"]
Jan 30, 2018 1:41:31 AM org.apache.catalina.core.StandardService stopInternal
INFO: Stopping service Tomcat
Jan 30, 2018 1:41:31 AM org.apache.coyote.AbstractProtocol stop
INFO: Stopping ProtocolHandler ["http-nio-8081"]
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.849 sec

Results :

Tests run: 25, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.riak.RiakKVClientTest
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.346 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.solr.SolrClientTest
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.368 sec
Running com.yahoo.ycsb.db.solr.SolrClientCloudTest
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:44773/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:44773/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:44773/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:44773/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:44773/solr
2018/01/30 01:42:31 ERROR org.apache.zookeeper.ClientCnxn  - Error while calling watcher 
java.util.concurrent.RejectedExecutionException: Task org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1@89e6661 rejected from org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor@6b4fef0e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 238]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor.execute(ExecutorUtil.java:214)
	at java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:112)
	at org.apache.solr.common.cloud.SolrZkClient$3.process(SolrZkClient.java:261)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.311 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.solr6.SolrClientCloudTest
2018/01/30 01:42:32 ERROR org.apache.solr.servlet.StartupLoggingUtils  - Missing Java Option solr.log.dir. Logging may be missing or incomplete.
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:46775/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:46775/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:46775/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:46775/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:46775/solr
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.645 sec
Running com.yahoo.ycsb.db.solr6.SolrClientTest
2018/01/30 01:43:03 ERROR org.apache.solr.servlet.StartupLoggingUtils  - Missing Java Option solr.log.dir. Logging may be missing or incomplete.
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.017 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0


travis_time:end:094039aa:start=1517276280469421019,finish=1517276610618124806,duration=330148703787[0K
[32;1mThe command "mvn test -q" exited with 0.[0m

Done. Your build exited with 0.
