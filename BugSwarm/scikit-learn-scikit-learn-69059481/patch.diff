diff --git a/sklearn/linear_model/coordinate_descent.py b/sklearn/linear_model/coordinate_descent.py
index 9f5a654b24..864483910b 100755
--- a/sklearn/linear_model/coordinate_descent.py
+++ b/sklearn/linear_model/coordinate_descent.py
@@ -24,6 +24,7 @@
 from ..utils.extmath import safe_sparse_dot
 from ..utils.validation import check_is_fitted
 from ..utils import ConvergenceWarning
+from ..utils.sparsefuncs import inplace_csr_column_scale
 
 from . import cd_fast
 
@@ -2053,14 +2054,12 @@ class AdaptiveLasso(Lasso):
     gamma : float, optional (default=1.0)
         The exponent to raise the previous iteration's estimate by. 
         Common choices are 0.5, 1 and 2.
-    alpha : float or array of floats, shape = [n_lasso_iterations], optional (default=1.0)
+    alpha : float, optional (default=1.0)
         Regularization term that multiplies the L1 term at each iteration.
         ``alpha = 0`` is equivalent to an ordinary least square, solved
         by the :class:`LinearRegression` object. For numerical
         reasons, using ``alpha = 0`` is with the Lasso object is not advised
         and you should prefer the LinearRegression object.
-        - if float: each iteration will use the same regularization.
-        - if array-like: each iteration uses the specified regularization.
     eps : float, optional
         Stability parameter to ensure that a zero valued coefficient does not 
         prohibit a nonzero estimate in the next iteration.
@@ -2114,7 +2113,7 @@ class AdaptiveLasso(Lasso):
     Lasso
     """
     
-    def __init__(self, n_lasso_iterations = 5, gamma = 1, alpha=1.0,
+    def __init__(self, n_lasso_iterations = 2, gamma = 1, alpha=1.0,
                  eps = None, fit_intercept=True, normalize=False,
                  precompute=False, copy_X=True, max_iter=1000,
                  tol=1e-4, positive=False,
@@ -2128,7 +2127,7 @@ def __init__(self, n_lasso_iterations = 5, gamma = 1, alpha=1.0,
         self.n_lasso_iterations = n_lasso_iterations
         self.gamma = gamma
         self.eps = eps
-        
+    
     def fit(self, X, y):
         """
         Fit Lasso models, each with coordinate descent.
@@ -2146,13 +2145,6 @@ def fit(self, X, y):
             
         if self.gamma <= 0:
             raise ValueError('gamma must be positive.')
-
-        alphas = column_or_1d(np.atleast_1d(self.alpha))
-        
-        if alphas.shape[0] != 1 and alphas.shape[0] != self.n_lasso_iterations:
-            raise ValueError("alpha must be a float or an array of length=%s" % repr(self.n_lasso_iterations))
-        if alphas.shape[0] != self.n_lasso_iterations:
-            alphas = column_or_1d(np.repeat(np.atleast_1d(self.alpha),  self.n_lasso_iterations))
         
         X, y = check_X_y(X, y, accept_sparse='csc', dtype=np.float64,
                  order='F', copy=self.copy_X and self.fit_intercept,
@@ -2164,10 +2156,14 @@ def fit(self, X, y):
         
         n_samples, n_features = X.shape
         weights = np.ones(n_features)
-
+        X_sparse = sparse.isspmatrix(X)
+        
         for k in range(self.n_lasso_iterations):
-            X_w = np.divide(X,weights[np.newaxis, :])
-            self.alpha = alphas[k]
+            if X_sparse:
+                X_w = X.copy()
+                inplace_csr_column_scale(X_w, weights)
+            else:
+                X_w = np.divide(X, weights[np.newaxis, :])
             super(AdaptiveLasso, self).fit(X_w, y)
             self.coef_ /= weights
             weights = np.power(np.abs(self.coef_) + eps_, -self.gamma)
