diff --git a/.mailmap b/.mailmap
index ab8db71fd8..96c3957cec 100755
--- a/.mailmap
+++ b/.mailmap
@@ -12,6 +12,7 @@ Aaron Baecker <abaecker@localhost> abaecker <abaecker@localhost>
 Abdul Muneer <abdulmuneer@gmail.com> abdulmuneer <abdulmuneer@gmail.com>
 Adam Ginsburg <adam.g.ginsburg@gmail.com> Adam Ginsburg <adam.g.ginsburg@gmail.com>
 Adam Ginsburg <adam.g.ginsburg@gmail.com> Adam Ginsburg <keflavich@gmail.com>
+Allan Haldane <allan.haldane@gmail.com> ahaldane <ealloc@gmail.com>
 Albert Jornet Puig <albert.jornet@ic3.cat> jurnix <albert.jornet@ic3.cat>
 Alex Griffing <argriffi@ncsu.edu> alex <argriffi@ncsu.edu>
 Alex Griffing <argriffi@ncsu.edu> argriffing <argriffi@ncsu.edu>
@@ -21,15 +22,20 @@ Alexander Belopolsky <abalkin@enlnt.com> Alexander Belopolsky <a@enlnt.com>
 Alok Singhal <gandalf013@gmail.com> Alok Singhal <gandalf013@gmail.com>
 Alok Singhal <gandalf013@gmail.com> Alok Singhal <alok@merfinllc.com>
 Amir Sarabadani <ladsgroup@gmail.com> amir <ladsgroup@gmail.com>
+Anatoly Techtonik <techtonik@gmail.com> anatoly techtonik <techtonik@gmail.com>
+Andrei Kucharavy <ank@andreikucharavy.com> chiffa <ank@andreikucharavy.com>
 Anne Archibald <peridot.faceted@gmail.com> aarchiba <peridot.faceted@gmail.com>
 Anne Archibald <peridot.faceted@gmail.com> Anne Archibald <archibald@astron.nl>
 Anže Starič <anze.staric@gmail.com> astaric <anze.staric@gmail.com>
 Aron Ahmadia <aron@ahmadia.net> ahmadia <aron@ahmadia.net>
 Arun Persaud <apersaud@lbl.gov> Arun Persaud <apersaud@lbl.gov>
 Arun Persaud <apersaud@lbl.gov> Arun Persaud <arun@nubati.net>
+Auke Wiggers <wiggers.auke@gmail.com> auke <wiggers.auke@gmail.com>
 Behzad Nouri <behzadnouri@gmail.com> behzad nouri <behzadnouri@gmail.com>
 Benjamin Root <ben.v.root@gmail.com> Ben Root <ben.v.root@gmail.com>
 Benjamin Root <ben.v.root@gmail.com> weathergod <?@?>
+Bertrand Lefebvre <bertrand.l3f@gmail.com> bertrand <bertrand.l3f@gmail.com>
+Bertrand Lefebvre <bertrand.l3f@gmail.com> Bertrand <bertrand.l3f@gmail.com>
 Brett R Murphy <bmurphy@enthought.com> brettrmurphy <bmurphy@enthought.com>
 Bryan Van de Ven <bryanv@continuum.io> Bryan Van de Ven <bryan@Laptop-3.local>
 Bryan Van de Ven <bryanv@continuum.io> Bryan Van de Ven <bryan@laptop.local>
@@ -65,18 +71,25 @@ Gael Varoquaux <gael.varoquaux@normalesup.org> GaelVaroquaux <gael.varoquaux@nor
 Gerrit Holl <g.holl@reading.ac.uk> Gerrit Holl <g.holl@reading.ac.uk>
 Gerrit Holl <gerrit.holl@utoronto.ca> Gerrit Holl <g.holl@reading.ac.uk>
 Giuseppe Venturini <ggventurini@users.noreply.github.com> ggventurini <ggventurini@users.noreply.github.com>
+Golnaz Irannejad <golnazirannejad@gmail.com> golnazir <golnazirannejad@gmail.com>
+Gopal Singh Meena <gopalmeena94@gmail.com> gopalmeena <gopalmeena94@gmail.com>
+Greg Knoll <gregory@bccn-berlin.de> gkBCCN <gregory@bccn-berlin.de>
 Greg Young <gfyoung17@gmail.com> gfyoung <gfyoung17@gmail.com>
 Greg Young <gfyoung17@gmail.com> gfyoung <gfyoung@mit.edu>
+Greg Yang <sorcererofdm@gmail.com> eulerreich <sorcererofdm@gmail.com>
 Jason Grout <jason-github@creativetrax.com> Jason Grout <jason-github@creativetrax.com>
 Jason Grout <jason-github@creativetrax.com> Jason Grout <jason.grout@drake.edu>
+Jason King <pizza@netspace.net.au> jason king <pizza@netspace.net.au>
 Joseph Martinot-Lagarde <contrebasse@gmail.com> Joseph Martinot-Lagarde <contrebasse@gmail.com>
 Joseph Martinot-Lagarde <contrebasse@gmail.com> Joseph Martinot-Lagarde <joseph.martinot-lagarde@onera.fr>
 Julien Lhermitte <jrmlhermitte@gmail.com> Julien Lhermitte <jrmlhermitte@gmail.com>
 Julien Lhermitte <jrmlhermitte@gmail.com> Julien Lhermitte <lhermitte@bnl.gov>
+Julien Schueller <julien.schueller@gmail.com> jschueller <julien.schueller@gmail.com>
 Han Genuit <hangenuit@gmail.com> 87 <hangenuit@gmail.com>
 Han Genuit <hangenuit@gmail.com> Han <hangenuit@gmail.com>
 Han Genuit <hangenuit@gmail.com> hangenuit@gmail.com <hangenuit@gmail.com>
 Hanno Klemm <hanno.klemm@maerskoil.com> hklemm <hanno.klemm@maerskoil.com>
+Irvin Probst <irvin.probst@ensta-bretagne.fr> I--P <irvin.probst@ensta-bretagne.fr>
 Jaime Fernandez <jaime.frio@gmail.com> Jaime <jaime.frio@gmail.com>
 Jaime Fernandez <jaime.frio@gmail.com> Jaime Fernandez <jaime.fernandez@hp.com>
 Jaime Fernandez <jaime.frio@gmail.com> jaimefrio <jaime.frio@gmail.com>
@@ -91,6 +104,7 @@ Julian Taylor <juliantaylor108@gmail.com> Julian Taylor <juliantaylor108@googlem
 Lars Buitinck <larsmans@gmail.com> Lars Buitinck <L.J.Buitinck@uva.nl>
 Lars Buitinck <larsmans@gmail.com> Lars Buitinck <l.buitinck@esciencecenter.nl>
 Luis Pedro Coelho <luis@luispedro.org> Luis Pedro Coelho <lpc@cmu.edu>
+Luke Zoltan Kelley <lkelley@cfa.harvard.edu> lzkelley <lkelley@cfa.harvard.edu>
 Mark DePristo <mdepristo@synapdx.com> markdepristo <mdepristo@synapdx.com>
 Mark Wiebe <mwwiebe@gmail.com> Mark <mwwiebe@gmail.com>
 Mark Wiebe <mwwiebe@gmail.com> Mark Wiebe <mwiebe@continuum.io>
@@ -100,6 +114,9 @@ Martin Goodson <martingoodson@gmail.com> martingoodson <martingoodson@gmail.com>
 Martin Teichmann <martin.teichmann@xfel.eu> Martin Teichmann <lkb.teichmann@gmail.com>
 Mattheus Ueckermann <empeeu@yahoo.com> empeeu <empeeu@yahoo.com>
 Michael Droettboom <mdboom@gmail.com> mdroe <mdroe@localhost>
+Michael Martin <mmartin4242@gmail.com> mmartin <mmartin4242@gmail.com>
+Michael  K. Tran  <trankmichael@gmail.com> mtran <trankmichael@gmail.com>
+Michael Behrisch <oss@behrisch.de> behrisch <behrisch@users.sourceforge.net>
 Nathaniel J. Smith <njs@pobox.com> njsmith <njs@pobox.com>
 Nicolas Scheffer <nicolas.scheffer@sri.com> Nicolas Scheffer <scheffer@speech.sri.com>
 Ondřej Čertík <ondrej.certik@gmail.com> Ondrej Certik <ondrej.certik@gmail.com>
@@ -113,6 +130,7 @@ Pierre GM <pierregmcode@gmail.com> pierregm <pierregmcode@gmail.com>
 Prabhu Ramachandran <prabhu@localhost> prabhu <prabhu@localhost>
 Ralf Gommers <ralf.gommers@gmail.com> Ralf Gommers <ralf.gommers@googlemail.com>
 Ralf Gommers <ralf.gommers@gmail.com> rgommers <ralf.gommers@googlemail.com>
+Rehas Sachdeva <aquannie@gmail.com> rehassachdeva <aquannie@gmail.com>
 Ritta Narita <narittan@gmail.com> RittaNarita <narittan@gmail.com>
 Robert Kern <rkern@enthought.com> Robert Kern <robert.kern@gmail.com>
 Robert LU <robberphex@gmail.com> RobberPhex <robberphex@gmail.com>
@@ -121,6 +139,8 @@ Ronan Lamy <ronan.lamy@gmail.com> Ronan Lamy <Ronan.Lamy@normalesup.org>
 Russell Hewett <rhewett@mit.edu> rhewett <rhewett@mit.edu>
 Ryan Blakemore <rbtnet@gmail.com> ryanblak <rbtnet@gmail.com>
 Sam Preston <j.sam.preston@gmail.com> jspreston <j.sam.preston@gmail.com>
+Sam Radhakrishnan <sk09idm@gmail.com> = <=>
+Sam Radhakrishnan <sk09idm@gmail.com> sam09 <sk09idm@gmail.com>
 Saullo Giovani <saullogiovani@gmail.com> saullogiovani <saullogiovani@gmail.com>
 Sebastian Berg <sebastian@sipsolutions.net> seberg <sebastian@sipsolutions.net>
 Stefan van der Walt <stefanv@berkeley.edu> Stefan van der Walt <sjvdwalt@gmail.com>
diff --git a/doc/release/1.12.0-notes.rst b/doc/release/1.12.0-notes.rst
index 97ec25777a..cf606c5eae 100755
--- a/doc/release/1.12.0-notes.rst
+++ b/doc/release/1.12.0-notes.rst
@@ -81,6 +81,13 @@ The following functions are changed: ``sum``, ``product``,
 The previous identity was 1, it is now -1. See entry in `Improvements`_ for
 more explanation.
 
+Scalar-Scalar power result type changed
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Raising an integer scalar to a negative integer power will always result in a
+floating point scalar type.  Previously when using mixed integer types an
+integer type would be produced, while the pure type case produced a floating
+point type.
+
 FutureWarning to changed behavior
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -127,6 +134,11 @@ Add a hook in ``numpy/__init__.py`` to import a ``numpy/_distributor_init.py``
 file that will remain empty (bar a docstring) in the standard numpy source,
 but that can be overwritten by people making binary distributions of numpy.
 
+New nanfunctions ``nancumsum`` and ``nancumprod`` added
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Nanfunctions ``nancumsum`` and ``nancumprod`` have been added to
+compute ``cumsum`` and ``cumprod`` by ignoring nans.
+
 Improvements
 ============
 
@@ -160,6 +172,11 @@ The *__complex__* method has been implemented on the ndarray object
 Calling ``complex()`` on a size 1 array will now cast to a python
 complex.
 
+Mixed type scalar-scalar operators should be faster
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Rather than defering to the ufunc, mixed type scalar-scalar operators are
+handled in the scalar operator resulting in a speedup.
+
 
 Changes
 =======
diff --git a/doc/source/reference/routines.math.rst b/doc/source/reference/routines.math.rst
index c0be4096ad..5cb1e0eec6 100755
--- a/doc/source/reference/routines.math.rst
+++ b/doc/source/reference/routines.math.rst
@@ -58,6 +58,8 @@ Sums, products, differences
    nansum
    cumprod
    cumsum
+   nancumprod
+   nancumsum
    diff
    ediff1d
    gradient
diff --git a/numpy/core/src/multiarray/conversion_utils.c b/numpy/core/src/multiarray/conversion_utils.c
index d7a6178759..c016bb8d10 100755
--- a/numpy/core/src/multiarray/conversion_utils.c
+++ b/numpy/core/src/multiarray/conversion_utils.c
@@ -535,6 +535,13 @@ PyArray_OrderConverter(PyObject *object, NPY_ORDER *val)
         PyObject *tmp;
         int ret;
         tmp = PyUnicode_AsASCIIString(object);
+        if (tmp == NULL) {
+            PyErr_SetString(PyExc_ValueError, "Invalid unicode string passed in "
+                                              "for the array ordering. "
+                                              "Please pass in 'C', 'F', 'A' "
+                                              "or 'K' instead");
+            return NPY_FAIL;
+        }
         ret = PyArray_OrderConverter(tmp, val);
         Py_DECREF(tmp);
         return ret;
diff --git a/numpy/core/src/multiarray/ctors.c b/numpy/core/src/multiarray/ctors.c
index 79c2b16b16..0017de0ad6 100755
--- a/numpy/core/src/multiarray/ctors.c
+++ b/numpy/core/src/multiarray/ctors.c
@@ -901,8 +901,7 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
 {
     PyArrayObject_fields *fa;
     int i;
-    size_t sd;
-    npy_intp size;
+    npy_intp nbytes;
 
     if (descr->subarray) {
         PyObject *ret;
@@ -929,10 +928,9 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
         return NULL;
     }
 
-    /* Check dimensions */
-    size = 1;
-    sd = (size_t) descr->elsize;
-    if (sd == 0) {
+    /* Check datatype element size */
+    nbytes = descr->elsize;
+    if (nbytes == 0) {
         if (!PyDataType_ISSTRING(descr)) {
             PyErr_SetString(PyExc_TypeError, "Empty data-type");
             Py_DECREF(descr);
@@ -943,13 +941,14 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
             return NULL;
         }
         if (descr->type_num == NPY_STRING) {
-            sd = descr->elsize = 1;
+            nbytes = descr->elsize = 1;
         }
         else {
-            sd = descr->elsize = sizeof(npy_ucs4);
+            nbytes = descr->elsize = sizeof(npy_ucs4);
         }
     }
 
+    /* Check dimensions and multiply them to nbytes */
     for (i = 0; i < nd; i++) {
         npy_intp dim = dims[i];
 
@@ -974,9 +973,10 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
          * multiplying the dimensions together to get the total size of the
          * array.
          */
-        if (npy_mul_with_overflow_intp(&size, size, dim)) {
+        if (npy_mul_with_overflow_intp(&nbytes, nbytes, dim)) {
             PyErr_SetString(PyExc_ValueError,
-                            "array is too big.");
+                "array is too big; `arr.size * arr.dtype.itemsize` "
+                "is larger than the maximum possible size.");
             Py_DECREF(descr);
             return NULL;
         }
@@ -1015,9 +1015,9 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
         }
         fa->strides = fa->dimensions + nd;
         memcpy(fa->dimensions, dims, sizeof(npy_intp)*nd);
-        if (strides == NULL) { /* fill it in */
-            sd = _array_fill_strides(fa->strides, dims, nd, sd,
-                                     flags, &(fa->flags));
+        if (strides == NULL) {  /* fill it in */
+            _array_fill_strides(fa->strides, dims, nd, descr->elsize,
+                                flags, &(fa->flags));
         }
         else {
             /*
@@ -1025,7 +1025,6 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
              * the memory, but be careful with this...
              */
             memcpy(fa->strides, strides, sizeof(npy_intp)*nd);
-            sd *= size;
         }
     }
     else {
@@ -1039,19 +1038,18 @@ PyArray_NewFromDescr_int(PyTypeObject *subtype, PyArray_Descr *descr, int nd,
          * e.g. shape=(0,) -- otherwise buffer exposure
          * (a.data) doesn't work as it should.
          */
-
-        if (sd == 0) {
-            sd = descr->elsize;
+        if (nbytes == 0) {
+            nbytes = descr->elsize;
         }
         /*
          * It is bad to have uninitialized OBJECT pointers
          * which could also be sub-fields of a VOID array
          */
         if (zeroed || PyDataType_FLAGCHK(descr, NPY_NEEDS_INIT)) {
-            data = npy_alloc_cache_zero(sd);
+            data = npy_alloc_cache_zero(nbytes);
         }
         else {
-            data = npy_alloc_cache(sd);
+            data = npy_alloc_cache(nbytes);
         }
         if (data == NULL) {
             PyErr_NoMemory();
@@ -3772,9 +3770,11 @@ PyArray_FromIter(PyObject *obj, PyArray_Descr *dtype, npy_intp count)
  * If data is not given but created here, then flags will be NPY_ARRAY_DEFAULT
  * and a non-zero flags argument can be used to indicate a FORTRAN style
  * array is desired.
+ *
+ * Dimensions and itemsize must have been checked for validity.
  */
 
-NPY_NO_EXPORT size_t
+NPY_NO_EXPORT void
 _array_fill_strides(npy_intp *strides, npy_intp *dims, int nd, size_t itemsize,
                     int inflag, int *objflags)
 {
@@ -3853,7 +3853,7 @@ _array_fill_strides(npy_intp *strides, npy_intp *dims, int nd, size_t itemsize,
             *objflags |= (NPY_ARRAY_C_CONTIGUOUS|NPY_ARRAY_F_CONTIGUOUS);
         }
     }
-    return itemsize;
+    return;
 }
 
 /*
diff --git a/numpy/core/src/multiarray/ctors.h b/numpy/core/src/multiarray/ctors.h
index 757362fb84..783818deff 100755
--- a/numpy/core/src/multiarray/ctors.h
+++ b/numpy/core/src/multiarray/ctors.h
@@ -51,7 +51,7 @@ PyArray_CopyAsFlat(PyArrayObject *dst, PyArrayObject *src,
                                 NPY_ORDER order);
 
 /* FIXME: remove those from here */
-NPY_NO_EXPORT size_t
+NPY_NO_EXPORT void
 _array_fill_strides(npy_intp *strides, npy_intp *dims, int nd, size_t itemsize,
                     int inflag, int *objflags);
 
diff --git a/numpy/core/src/multiarray/scalartypes.c.src b/numpy/core/src/multiarray/scalartypes.c.src
index 3d5e51ba92..08505c5c7e 100755
--- a/numpy/core/src/multiarray/scalartypes.c.src
+++ b/numpy/core/src/multiarray/scalartypes.c.src
@@ -264,10 +264,20 @@ gentype_@name@(PyObject *m1, PyObject *m2)
 static PyObject *
 gentype_multiply(PyObject *m1, PyObject *m2)
 {
-    PyObject *ret = NULL;
     npy_intp repeat;
 
+    /*
+     * If the other object supports sequence repeat and not number multiply
+     * we should call sequence repeat to support e.g. list repeat by numpy
+     * scalars (they may be converted to ndarray otherwise).
+     * A python defined class will always only have the nb_multiply slot and
+     * some classes may have neither defined. For the latter we want need
+     * to give the normal case a chance to convert the object to ndarray.
+     * Probably no class has both defined, but if they do, prefer number.
+     */
     if (!PyArray_IsScalar(m1, Generic) &&
+            ((Py_TYPE(m1)->tp_as_sequence != NULL) &&
+             (Py_TYPE(m1)->tp_as_sequence->sq_repeat != NULL)) &&
             ((Py_TYPE(m1)->tp_as_number == NULL) ||
              (Py_TYPE(m1)->tp_as_number->nb_multiply == NULL))) {
         /* Try to convert m2 to an int and try sequence repeat */
@@ -276,9 +286,11 @@ gentype_multiply(PyObject *m1, PyObject *m2)
             return NULL;
         }
         /* Note that npy_intp is compatible to Py_Ssize_t */
-        ret = PySequence_Repeat(m1, repeat);
+        return PySequence_Repeat(m1, repeat);
     }
-    else if (!PyArray_IsScalar(m2, Generic) &&
+    if (!PyArray_IsScalar(m2, Generic) &&
+            ((Py_TYPE(m2)->tp_as_sequence != NULL) &&
+             (Py_TYPE(m2)->tp_as_sequence->sq_repeat != NULL)) &&
             ((Py_TYPE(m2)->tp_as_number == NULL) ||
              (Py_TYPE(m2)->tp_as_number->nb_multiply == NULL))) {
         /* Try to convert m1 to an int and try sequence repeat */
@@ -286,13 +298,11 @@ gentype_multiply(PyObject *m1, PyObject *m2)
         if (repeat == -1 && PyErr_Occurred()) {
             return NULL;
         }
-        ret = PySequence_Repeat(m2, repeat);
-    }
-    if (ret == NULL) {
-        PyErr_Clear(); /* no effect if not set */
-        ret = PyArray_Type.tp_as_number->nb_multiply(m1, m2);
+        return PySequence_Repeat(m2, repeat);
     }
-    return ret;
+
+    /* All normal cases are handled by PyArray's multiply */
+    return PyArray_Type.tp_as_number->nb_multiply(m1, m2);
 }
 
 /**begin repeat
diff --git a/numpy/core/src/multiarray/shape.c b/numpy/core/src/multiarray/shape.c
index a307bed9cf..cc02d15f9c 100755
--- a/numpy/core/src/multiarray/shape.c
+++ b/numpy/core/src/multiarray/shape.c
@@ -17,8 +17,11 @@
 
 #include "shape.h"
 
+#include "templ_common.h" /* for npy_mul_with_overflow_intp */
+#include "common.h" /* for convert_shape_to_string */
+
 static int
-_fix_unknown_dimension(PyArray_Dims *newshape, npy_intp s_original);
+_fix_unknown_dimension(PyArray_Dims *newshape, PyArrayObject *arr);
 
 static int
 _attempt_nocopy_reshape(PyArrayObject *self, int newnd, npy_intp* newdims,
@@ -149,9 +152,9 @@ PyArray_Resize(PyArrayObject *self, PyArray_Dims *newshape, int refcheck,
     }
 
     /* make new_strides variable */
-    sd = (size_t) PyArray_DESCR(self)->elsize;
-    sd = (size_t) _array_fill_strides(new_strides, new_dimensions, new_nd, sd,
-            PyArray_FLAGS(self), &(((PyArrayObject_fields *)self)->flags));
+    _array_fill_strides(
+        new_strides, new_dimensions, new_nd, PyArray_DESCR(self)->elsize,
+        PyArray_FLAGS(self), &(((PyArrayObject_fields *)self)->flags));
     memmove(PyArray_DIMS(self), new_dimensions, new_nd*sizeof(npy_intp));
     memmove(PyArray_STRIDES(self), new_strides, new_nd*sizeof(npy_intp));
     Py_RETURN_NONE;
@@ -206,7 +209,7 @@ PyArray_Newshape(PyArrayObject *self, PyArray_Dims *newdims,
     /*
      * fix any -1 dimensions and check new-dimensions against old size
      */
-    if (_fix_unknown_dimension(newdims, PyArray_SIZE(self)) < 0) {
+    if (_fix_unknown_dimension(newdims, self) < 0) {
         return NULL;
     }
     /*
@@ -339,8 +342,10 @@ _putzero(char *optr, PyObject *zero, PyArray_Descr *dtype)
 /*
  * attempt to reshape an array without copying data
  *
- * This function should correctly handle all reshapes, including
- * axes of length 1. Zero strides should work but are untested.
+ * The requested newdims are not checked, but must be compatible with
+ * the size of self, which must be non-zero. Other than that this
+ * function should correctly handle all reshapes, including axes of
+ * length 1. Zero strides should work but are untested.
  *
  * If a copy is needed, returns 0
  * If no copy is needed, returns 1 and fills newstrides
@@ -361,7 +366,7 @@ _attempt_nocopy_reshape(PyArrayObject *self, int newnd, npy_intp* newdims,
     int oldnd;
     npy_intp olddims[NPY_MAXDIMS];
     npy_intp oldstrides[NPY_MAXDIMS];
-    npy_intp np, op, last_stride;
+    npy_intp last_stride;
     int oi, oj, ok, ni, nj, nk;
 
     oldnd = 0;
@@ -377,43 +382,14 @@ _attempt_nocopy_reshape(PyArrayObject *self, int newnd, npy_intp* newdims,
         }
     }
 
-    /*
-      fprintf(stderr, "_attempt_nocopy_reshape( (");
-      for (oi=0; oi<oldnd; oi++)
-      fprintf(stderr, "(%d,%d), ", olddims[oi], oldstrides[oi]);
-      fprintf(stderr, ") -> (");
-      for (ni=0; ni<newnd; ni++)
-      fprintf(stderr, "(%d,*), ", newdims[ni]);
-      fprintf(stderr, "), is_f_order=%d)\n", is_f_order);
-    */
-
-
-    np = 1;
-    for (ni = 0; ni < newnd; ni++) {
-        np *= newdims[ni];
-    }
-    op = 1;
-    for (oi = 0; oi < oldnd; oi++) {
-        op *= olddims[oi];
-    }
-    if (np != op) {
-        /* different total sizes; no hope */
-        return 0;
-    }
-
-    if (np == 0) {
-        /* the current code does not handle 0-sized arrays, so give up */
-        return 0;
-    }
-
     /* oi to oj and ni to nj give the axis ranges currently worked with */
     oi = 0;
     oj = 1;
     ni = 0;
     nj = 1;
     while (ni < newnd && oi < oldnd) {
-        np = newdims[ni];
-        op = olddims[oi];
+        npy_intp np = newdims[ni];
+        npy_intp op = olddims[oi];
 
         while (np != op) {
             if (np < op) {
@@ -475,26 +451,30 @@ _attempt_nocopy_reshape(PyArrayObject *self, int newnd, npy_intp* newdims,
         newstrides[nk] = last_stride;
     }
 
-    /*
-      fprintf(stderr, "success: _attempt_nocopy_reshape (");
-      for (oi=0; oi<oldnd; oi++)
-      fprintf(stderr, "(%d,%d), ", olddims[oi], oldstrides[oi]);
-      fprintf(stderr, ") -> (");
-      for (ni=0; ni<newnd; ni++)
-      fprintf(stderr, "(%d,%d), ", newdims[ni], newstrides[ni]);
-      fprintf(stderr, ")\n");
-    */
-
     return 1;
 }
 
+static void
+raise_reshape_size_mismatch(PyArray_Dims *newshape, PyArrayObject *arr)
+{
+    PyObject *msg = PyUString_FromFormat("cannot reshape array of size %zd "
+                                         "into shape ", PyArray_SIZE(arr));
+    PyObject *tmp = convert_shape_to_string(newshape->len, newshape->ptr, "");
+
+    PyUString_ConcatAndDel(&msg, tmp);
+    if (msg != NULL) {
+        PyErr_SetObject(PyExc_ValueError, msg);
+        Py_DECREF(msg);
+    }
+}
+
 static int
-_fix_unknown_dimension(PyArray_Dims *newshape, npy_intp s_original)
+_fix_unknown_dimension(PyArray_Dims *newshape, PyArrayObject *arr)
 {
     npy_intp *dimensions;
+    npy_intp s_original = PyArray_SIZE(arr);
     npy_intp i_unknown, s_known;
     int i, n;
-    static char msg[] = "total size of new array must be unchanged";
 
     dimensions = newshape->ptr;
     n = newshape->len;
@@ -508,26 +488,27 @@ _fix_unknown_dimension(PyArray_Dims *newshape, npy_intp s_original)
             }
             else {
                 PyErr_SetString(PyExc_ValueError,
-                                "can only specify one"  \
-                                " unknown dimension");
+                                "can only specify one unknown dimension");
                 return -1;
             }
         }
-        else {
-            s_known *= dimensions[i];
+        else if (npy_mul_with_overflow_intp(&s_known, s_known,
+                                            dimensions[i])) {
+            raise_reshape_size_mismatch(newshape, arr);
+            return -1;
         }
     }
 
     if (i_unknown >= 0) {
-        if ((s_known == 0) || (s_original % s_known != 0)) {
-            PyErr_SetString(PyExc_ValueError, msg);
+        if (s_known == 0 || s_original % s_known != 0) {
+            raise_reshape_size_mismatch(newshape, arr);
             return -1;
         }
-        dimensions[i_unknown] = s_original/s_known;
+        dimensions[i_unknown] = s_original / s_known;
     }
     else {
         if (s_original != s_known) {
-            PyErr_SetString(PyExc_ValueError, msg);
+            raise_reshape_size_mismatch(newshape, arr);
             return -1;
         }
     }
diff --git a/numpy/core/src/umath/scalarmath.c.src b/numpy/core/src/umath/scalarmath.c.src
index b4ce977be3..abae9a8b4a 100755
--- a/numpy/core/src/umath/scalarmath.c.src
+++ b/numpy/core/src/umath/scalarmath.c.src
@@ -587,112 +587,24 @@ static void
 /**begin repeat
  * #name = byte, ubyte, short, ushort, int, uint,
  *         long, ulong, longlong, ulonglong,
- *         half, float, longdouble,
+ *         half, float, double, longdouble,
  *         cfloat, cdouble, clongdouble#
  * #type = npy_byte, npy_ubyte, npy_short, npy_ushort, npy_int, npy_uint,
  *         npy_long, npy_ulong, npy_longlong, npy_ulonglong,
- *         npy_half, npy_float, npy_longdouble,
+ *         npy_half, npy_float, npy_double, npy_longdouble,
  *         npy_cfloat, npy_cdouble, npy_clongdouble#
  * #Name = Byte, UByte, Short, UShort, Int, UInt,
  *         Long, ULong, LongLong, ULongLong,
- *         Half, Float, LongDouble,
+ *         Half, Float, Double, LongDouble,
  *         CFloat, CDouble, CLongDouble#
  * #TYPE = NPY_BYTE, NPY_UBYTE, NPY_SHORT, NPY_USHORT, NPY_INT, NPY_UINT,
  *         NPY_LONG, NPY_ULONG, NPY_LONGLONG, NPY_ULONGLONG,
- *         NPY_HALF, NPY_FLOAT, NPY_LONGDOUBLE,
+ *         NPY_HALF, NPY_FLOAT, NPY_DOUBLE, NPY_LONGDOUBLE,
  *         NPY_CFLOAT, NPY_CDOUBLE, NPY_CLONGDOUBLE#
- */
-
-/*
-static int
-_@name@_convert_to_ctype(PyObject *a, @type@ *arg1)
-{
-    PyObject *temp;
-
-    if (PyArray_IsScalar(a, @Name@)) {
-        *arg1 = PyArrayScalar_VAL(a, @Name@);
-        return 0;
-    }
-    else if (PyArray_IsScalar(a, Generic)) {
-        PyArray_Descr *descr1;
-
-        if (!PyArray_IsScalar(a, Number)) {
-            return -1;
-        }
-        descr1 = PyArray_DescrFromTypeObject((PyObject *)Py_TYPE(a));
-        if (PyArray_CanCastSafely(descr1->type_num, @TYPE@)) {
-            PyArray_CastScalarDirect(a, descr1, arg1, @TYPE@);
-            Py_DECREF(descr1);
-            return 0;
-        }
-        else {
-            Py_DECREF(descr1);
-            return -1;
-        }
-    }
-    else if (PyArray_GetPriority(a, NPY_PRIORITY) > NPY_PRIORITY) {
-        return -2;
-    }
-    else if ((temp = PyArray_ScalarFromObject(a)) != NULL) {
-        int retval = _@name@_convert_to_ctype(temp, arg1);
-
-        Py_DECREF(temp);
-        return retval;
-    }
-    return -2;
-}
-*/
-
-static int
-_@name@_convert_to_ctype(PyObject *a, @type@ *arg1)
-{
-    PyObject *temp;
-
-    if (PyArray_IsScalar(a, @Name@)) {
-        *arg1 = PyArrayScalar_VAL(a, @Name@);
-        return 0;
-    }
-    else if (PyArray_IsScalar(a, Generic)) {
-        PyArray_Descr *descr1;
-
-        if (!PyArray_IsScalar(a, Number)) {
-            return -1;
-        }
-        descr1 = PyArray_DescrFromTypeObject((PyObject *)Py_TYPE(a));
-        if (PyArray_CanCastSafely(descr1->type_num, @TYPE@)) {
-            PyArray_CastScalarDirect(a, descr1, arg1, @TYPE@);
-            Py_DECREF(descr1);
-            return 0;
-        }
-        else {
-            int retval = descr1->type_num;
-            Py_DECREF(descr1);
-            return retval;
-        }
-    }
-    else if (PyArray_GetPriority(a, NPY_PRIORITY) > NPY_PRIORITY) {
-        return -2;
-    }
-    else if ((temp = PyArray_ScalarFromObject(a)) != NULL) {
-        int retval = _@name@_convert_to_ctype(temp, arg1);
-
-        Py_DECREF(temp);
-        return retval;
-    }
-    return -2;
-}
-/**end repeat**/
-
-
-/* Same as above but added exact checks against known python types for speed */
-
-/**begin repeat
- * #name = double#
- * #type = npy_double#
- * #Name = Double#
- * #TYPE = NPY_DOUBLE#
- * #PYCHECKEXACT = PyFloat_CheckExact#
- * #PYEXTRACTCTYPE = PyFloat_AS_DOUBLE#
+ * #HasExact = 0*12, 1, 0*4#
+ * #PYCHECKEXACT = 0*12, PyFloat_CheckExact, 0*4#
+ * #PYEXTRACTCTYPE = 0*12, PyFloat_AS_DOUBLE, 0*4#
+ *
  */
 
 static int
@@ -700,10 +612,12 @@ _@name@_convert_to_ctype(PyObject *a, @type@ *arg1)
 {
     PyObject *temp;
 
+#if @HasExact@
     if (@PYCHECKEXACT@(a)){
         *arg1 = @PYEXTRACTCTYPE@(a);
         return 0;
     }
+#endif
 
     if (PyArray_IsScalar(a, @Name@)) {
         *arg1 = PyArrayScalar_VAL(a, @Name@);
@@ -722,8 +636,9 @@ _@name@_convert_to_ctype(PyObject *a, @type@ *arg1)
             return 0;
         }
         else {
+            int retval = descr1->type_num;
             Py_DECREF(descr1);
-            return -1;
+            return retval;
         }
     }
     else if (PyArray_GetPriority(a, NPY_PRIORITY) > NPY_PRIORITY) {
@@ -737,17 +652,16 @@ _@name@_convert_to_ctype(PyObject *a, @type@ *arg1)
     }
     return -2;
 }
-
 /**end repeat**/
 
-
 /**begin repeat
  * #name = byte, ubyte, short, ushort, int, uint,
  *         long, ulong, longlong, ulonglong,
- *         half, float, double, cfloat, cdouble#
+ *         half, float, double, longdouble, cfloat, cdouble, clongdouble#
  * #type = npy_byte, npy_ubyte, npy_short, npy_ushort, npy_int, npy_uint,
  *         npy_long, npy_ulong, npy_longlong, npy_ulonglong,
- *         npy_half, npy_float, npy_double, npy_cfloat, npy_cdouble#
+ *         npy_half, npy_float, npy_double, npy_longdouble, npy_cfloat, npy_cdouble, npy_clongdouble#
+ * #islongdouble = 0*13, 1, 0*2, 1#
  */
 static int
 _@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
@@ -755,34 +669,58 @@ _@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
 {
     int ret_a;
     ret_a = _@name@_convert_to_ctype(a, arg1);
+#if @islongdouble@
+    if (ret_a == -2) {
+        ret_a = -3;
+    }
+#endif
     if (ret_a < 0) {
         return ret_a;
     }
     else if (ret_a == 0) {
         int ret_b;
         ret_b = _@name@_convert_to_ctype(b, arg2);
+#if @islongdouble@
+        if (ret_b == -2) {
+            ret_b = -3;
+        }
+#endif
         if (ret_b <= 0) {
             return ret_b;
         }
         else {
-         /* couldn't cast b to @name@.  Since converting a returned 0, it is
-          * convertable to @name@. See if instead we can convert it to b.
-          * then defer the operator call to that type.
-          */
-          PyArray_Descr *descr_a;
-          int ret = -1;
-          descr_a = PyArray_DescrFromTypeObject((PyObject *)Py_TYPE(a));
-          if (PyArray_CanCastSafely(descr_a->type_num, ret_b)) {
-            ret = ret_b;
-          }
-          Py_DECREF(descr_a);
-          return ret;
+            /* couldn't cast b to @name@ but it is a numeric scalar.  Since
+             * converting a returned 0, it is convertable to @name@. See if
+             * instead we can convert it to b then defer the operator call to
+             * that type.
+             */
+            PyArray_Descr *descr_a;
+            int ret = -1;
+            descr_a = PyArray_DescrFromTypeObject((PyObject *)Py_TYPE(a));
+            if (PyArray_CanCastSafely(descr_a->type_num, ret_b)) {
+                ret = ret_b;
+            }
+            else {
+                /* neither of a and b can be safely converted to the type of the
+                 * other.  Since they are both numeric scalars, use the type
+                 * promotion table to find the correct type to use.
+                 */
+                PyArray_Descr *descr_b, *descr_result;
+                descr_b = PyArray_DescrFromType(ret_b);
+                descr_result = PyArray_PromoteTypes(descr_a, descr_b);
+                ret = descr_result->type_num;
+                Py_DECREF(descr_b);
+                Py_DECREF(descr_result);
+            }
+            Py_DECREF(descr_a);
+            return ret;
         }
     }
     else {
-        /* couldn't cast a to @name@. If b is a also a scalar number, check if
-         * we could instead cast a to the type of b. If so, return b's type_num
-         * and defer the operator call to that type's.
+        /* couldn't cast a to @name@ but it is a numeric scalar and ret_a
+         * contains its typenum. If b is a also a numeric scalar, check if
+         * we could instead cast a to the type of b. If so, return b's
+         * type_num and defer the operator call to that type's.
          */
         int ret = -1;
         if (PyArray_IsScalar(b, Number)) {
@@ -791,6 +729,18 @@ _@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
             if (PyArray_CanCastSafely(ret_a, descr_b->type_num)) {
                 ret = descr_b->type_num;
             }
+            else {
+                /* neither of a and b can be safely converted to the type of the
+                 * other.  Since they are both numeric scalars, use the type
+                 * promotion table to find the correct type to use.
+                 */
+                PyArray_Descr *descr_a, *descr_result;
+                descr_a = PyArray_DescrFromType(ret_a);
+                descr_result = PyArray_PromoteTypes(descr_a, descr_b);
+                ret = descr_result->type_num;
+                Py_DECREF(descr_a);
+                Py_DECREF(descr_result);
+            }
             Py_DECREF(descr_b);
         }
         return ret;
@@ -798,52 +748,8 @@ _@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
     return -2;
 }
 
-/*
-static int
-_@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
-                           PyObject *b, @type@ *arg2)
-{
-    int ret;
-    ret = _@name@_convert_to_ctype(a, arg1);
-    if (ret < 0) {
-        return ret;
-    }
-    ret = _@name@_convert_to_ctype(b, arg2);
-    if (ret < 0) {
-        return ret;
-    }
-    return 0;
-}
-*/
-/**end repeat**/
-
-/**begin repeat
- * #name = longdouble, clongdouble#
- * #type = npy_longdouble, npy_clongdouble#
- */
-
-static int
-_@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
-                           PyObject *b, @type@ *arg2)
-{
-    int ret;
-    ret = _@name@_convert_to_ctype(a, arg1);
-    if (ret < 0) {
-        return ret;
-    }
-    ret = _@name@_convert_to_ctype(b, arg2);
-    if (ret == -2) {
-        ret = -3;
-    }
-    if (ret < 0) {
-        return ret;
-    }
-    return 0;
-}
-
 /**end repeat**/
 
-
 #if defined(NPY_PY3K)
 #define CODEGEN_SKIP_divide_FLAG
 #endif
@@ -908,9 +814,7 @@ _@name@_convert2_to_ctypes(PyObject *a, @type@ *arg1,
  *          (Half, Float, Double, LongDouble,
  *              CFloat, CDouble, CLongDouble)*6,
  *          (Half, Float, Double, LongDouble)*2#
- *
  * #float_oper = 1*70, 0*50, 1*60#
- *
  * #complex_oper = 1*40, 0*20, 1*10, 0*50, 1*52, 0*8#
  */
 
@@ -939,7 +843,6 @@ static PyObject *
     int retstatus;
     int first;
 #endif
-
     switch(_@name@_convert2_to_ctypes(a, &arg1, b, &arg2)) {
         case 0:
             break;
@@ -1084,6 +987,18 @@ static PyObject *
 
 #undef CODEGEN_SKIP_divide_FLAG
 
+/**begin repeat
+ *
+ * #name = byte, ubyte, short, ushort, int, uint,
+ *         long, ulong, longlong, ulonglong,
+ *         half, float, double, longdouble,
+ *         cfloat, cdouble, clongdouble#
+ */
+
+static PyObject* @name@_power(PyObject *a, PyObject* b, PyObject *c);
+
+/**end repeat**/
+
 #define _IS_ZERO(x) (x == 0)
 
 /**begin repeat
@@ -1120,23 +1035,6 @@ static PyObject *
  * #zero = 0*10, NPY_HALF_ZERO, 0*6#
  * #one = 1*10, NPY_HALF_ONE, 1*6#
  */
-static PyObject* byte_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* ubyte_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* short_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* ushort_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* int_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* uint_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* long_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* ulong_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* longlong_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* ulonglong_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* half_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* float_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* double_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* longdouble_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* cfloat_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* cdouble_power(PyObject *a, PyObject* b, PyObject *c);
-static PyObject* clongdouble_power(PyObject *a, PyObject* b, PyObject *c);
 
 #if @cmplx@
 static PyObject *
@@ -1167,39 +1065,10 @@ static PyObject *
              */
             Py_INCREF(Py_NotImplemented);
             return Py_NotImplemented;
-        /* probably don't need all of these here since complex types
+
+        /* All cases don't need to be listed here since complex types
          * can only be safely cast upward to other complex types.
          */
-        case NPY_BYTE:
-            return byte_power(a, b, c);
-        case NPY_UBYTE:
-            return ubyte_power(a, b, c);
-        case NPY_SHORT:
-            return short_power(a, b, c);
-        case NPY_USHORT:
-            return ushort_power(a, b, c);
-        case NPY_INT:
-            return int_power(a, b, c);
-        case NPY_UINT:
-            return uint_power(a, b, c);
-        case NPY_LONG:
-            return long_power(a, b, c);
-        case NPY_ULONG:
-            return ulong_power(a, b, c);
-        case NPY_LONGLONG:
-            return longlong_power(a, b, c);
-        case NPY_ULONGLONG:
-            return ulonglong_power(a, b, c);
-        case NPY_HALF:
-            return half_power(a, b, c);
-        case NPY_FLOAT:
-            return float_power(a, b, c);
-        case NPY_DOUBLE:
-            return double_power(a, b, c);
-        case NPY_LONGDOUBLE:
-            return longdouble_power(a, b, c);
-        case NPY_CFLOAT:
-            return cfloat_power(a, b, c);
         case NPY_CDOUBLE:
             return cdouble_power(a, b, c);
         case NPY_CLONGDOUBLE:
@@ -1278,40 +1147,21 @@ static PyObject *
              */
             Py_INCREF(Py_NotImplemented);
             return Py_NotImplemented;
-        case NPY_BYTE:
-            return byte_power(a, b, c);
-        case NPY_UBYTE:
-            return ubyte_power(a, b, c);
-        case NPY_SHORT:
-            return short_power(a, b, c);
-        case NPY_USHORT:
-            return ushort_power(a, b, c);
-        case NPY_INT:
-            return int_power(a, b, c);
-        case NPY_UINT:
-            return uint_power(a, b, c);
-        case NPY_LONG:
-            return long_power(a, b, c);
-        case NPY_ULONG:
-            return ulong_power(a, b, c);
-        case NPY_LONGLONG:
-            return longlong_power(a, b, c);
-        case NPY_ULONGLONG:
-            return ulonglong_power(a, b, c);
-        case NPY_HALF:
-            return half_power(a, b, c);
-        case NPY_FLOAT:
-            return float_power(a, b, c);
-        case NPY_DOUBLE:
-            return double_power(a, b, c);
-        case NPY_LONGDOUBLE:
-            return longdouble_power(a, b, c);
-        case NPY_CFLOAT:
-            return cfloat_power(a, b, c);
-        case NPY_CDOUBLE:
-            return cdouble_power(a, b, c);
-        case NPY_CLONGDOUBLE:
-            return clongdouble_power(a, b, c);
+
+/**begin repeat1
+ *
+ * #name1 = byte, ubyte, short, ushort, int, uint,
+ *         long, ulong, longlong, ulonglong,
+ *         half, float, double, longdouble,
+ *         cfloat, cdouble, clongdouble#
+ * #type1 = NPY_BYTE, NPY_UBYTE, NPY_SHORT, NPY_USHORT, NPY_INT, NPY_UINT,
+ *          NPY_LONG, NPY_ULONG, NPY_LONGLONG, NPY_ULONGLONG,
+ *          NPY_HALF, NPY_FLOAT, NPY_DOUBLE, NPY_LONGDOUBLE,
+ *          NPY_CFLOAT, NPY_CDOUBLE, NPY_CLONGDOUBLE#
+ */
+        case @type1@:
+            return @name1@_power(a, b, c);
+/**end repeat1**/
     }
 
     PyUFunc_clearfperr();
@@ -1396,40 +1246,21 @@ static PyObject *
              */
             Py_INCREF(Py_NotImplemented);
             return Py_NotImplemented;
-        case NPY_BYTE:
-            return byte_power(a, b, c);
-        case NPY_UBYTE:
-            return ubyte_power(a, b, c);
-        case NPY_SHORT:
-            return short_power(a, b, c);
-        case NPY_USHORT:
-            return ushort_power(a, b, c);
-        case NPY_INT:
-            return int_power(a, b, c);
-        case NPY_UINT:
-            return uint_power(a, b, c);
-        case NPY_LONG:
-            return long_power(a, b, c);
-        case NPY_ULONG:
-            return ulong_power(a, b, c);
-        case NPY_LONGLONG:
-            return longlong_power(a, b, c);
-        case NPY_ULONGLONG:
-            return ulonglong_power(a, b, c);
-        case NPY_HALF:
-            return half_power(a, b, c);
-        case NPY_FLOAT:
-            return float_power(a, b, c);
-        case NPY_DOUBLE:
-            return double_power(a, b, c);
-        case NPY_LONGDOUBLE:
-            return longdouble_power(a, b, c);
-        case NPY_CFLOAT:
-            return cfloat_power(a, b, c);
-        case NPY_CDOUBLE:
-            return cdouble_power(a, b, c);
-        case NPY_CLONGDOUBLE:
-            return clongdouble_power(a, b, c);
+
+/**begin repeat1
+ *
+ * #name1 = byte, ubyte, short, ushort, int, uint,
+ *         long, ulong, longlong, ulonglong,
+ *         half, float, double, longdouble,
+ *         cfloat, cdouble, clongdouble#
+ * #type1 = NPY_BYTE, NPY_UBYTE, NPY_SHORT, NPY_USHORT, NPY_INT, NPY_UINT,
+ *          NPY_LONG, NPY_ULONG, NPY_LONGLONG, NPY_ULONGLONG,
+ *          NPY_HALF, NPY_FLOAT, NPY_DOUBLE, NPY_LONGDOUBLE,
+ *          NPY_CFLOAT, NPY_CDOUBLE, NPY_CLONGDOUBLE#
+ */
+        case @type1@:
+            return @name1@_power(a, b, c);
+/**end repeat1**/
      }
 
     PyUFunc_clearfperr();
diff --git a/numpy/core/src/umath/ufunc_object.c b/numpy/core/src/umath/ufunc_object.c
index 6eb0aae551..28c59f8901 100755
--- a/numpy/core/src/umath/ufunc_object.c
+++ b/numpy/core/src/umath/ufunc_object.c
@@ -3293,13 +3293,16 @@ PyUFunc_Accumulate(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *out,
             dataptr_copy[1] = dataptr[1];
             dataptr_copy[2] = dataptr[0];
 
-            /* Copy the first element to start the reduction */
+            /*
+             * Copy the first element to start the reduction.
+             *
+             * Output (dataptr[0]) and input (dataptr[1]) may point to
+             * the same memory, e.g. np.add.accumulate(a, out=a).
+             */
             if (otype == NPY_OBJECT) {
                 /*
-                 * Input (dataptr[0]) and output (dataptr[1]) may point
-                 * to the same memory (i.e. np.add.accumulate(a, out=a)).
-                 * In that case need to incref before decref to avoid the
-                 * possibility of the reference count being zero temporarily.
+                 * Incref before decref to avoid the possibility of the
+                 * reference count being zero temporarily.
                  */
                 Py_XINCREF(*(PyObject **)dataptr_copy[1]);
                 Py_XDECREF(*(PyObject **)dataptr_copy[0]);
@@ -3307,7 +3310,7 @@ PyUFunc_Accumulate(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *out,
                                     *(PyObject **)dataptr_copy[1];
             }
             else {
-                memcpy(dataptr_copy[0], dataptr_copy[1], itemsize);
+                memmove(dataptr_copy[0], dataptr_copy[1], itemsize);
             }
 
             if (count_m1 > 0) {
@@ -3355,13 +3358,16 @@ PyUFunc_Accumulate(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *out,
         dataptr_copy[1] = PyArray_BYTES(op[1]);
         dataptr_copy[2] = PyArray_BYTES(op[0]);
 
-        /* Copy the first element to start the reduction */
+        /*
+         * Copy the first element to start the reduction.
+         *
+         * Output (dataptr[0]) and input (dataptr[1]) may point to the
+         * same memory, e.g. np.add.accumulate(a, out=a).
+         */
         if (otype == NPY_OBJECT) {
             /*
-             * Input (dataptr[0]) and output (dataptr[1]) may point
-             * to the same memory (i.e. np.add.accumulate(a, out=a, axis=0)).
-             * In that case need to incref before decref to avoid the
-             * possibility of the reference count being zero temporarily.
+             * Incref before decref to avoid the possibility of the
+             * reference count being zero temporarily.
              */
             Py_XINCREF(*(PyObject **)dataptr_copy[1]);
             Py_XDECREF(*(PyObject **)dataptr_copy[0]);
@@ -3369,7 +3375,7 @@ PyUFunc_Accumulate(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *out,
                                 *(PyObject **)dataptr_copy[1];
         }
         else {
-            memcpy(dataptr_copy[0], dataptr_copy[1], itemsize);
+            memmove(dataptr_copy[0], dataptr_copy[1], itemsize);
         }
 
         if (count > 1) {
@@ -3698,15 +3704,25 @@ PyUFunc_Reduceat(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *ind,
                 dataptr_copy[1] = dataptr[1] + stride1*start;
                 dataptr_copy[2] = dataptr[0] + stride0_ind*i;
 
-                /* Copy the first element to start the reduction */
+                /*
+                 * Copy the first element to start the reduction.
+                 *
+                 * Output (dataptr[0]) and input (dataptr[1]) may point
+                 * to the same memory, e.g.
+                 * np.add.reduceat(a, np.arange(len(a)), out=a).
+                 */
                 if (otype == NPY_OBJECT) {
+                    /*
+                     * Incref before decref to avoid the possibility of
+                     * the reference count being zero temporarily.
+                     */
+                    Py_XINCREF(*(PyObject **)dataptr_copy[1]);
                     Py_XDECREF(*(PyObject **)dataptr_copy[0]);
                     *(PyObject **)dataptr_copy[0] =
                                         *(PyObject **)dataptr_copy[1];
-                    Py_XINCREF(*(PyObject **)dataptr_copy[0]);
                 }
                 else {
-                    memcpy(dataptr_copy[0], dataptr_copy[1], itemsize);
+                    memmove(dataptr_copy[0], dataptr_copy[1], itemsize);
                 }
 
                 if (count > 1) {
@@ -3756,15 +3772,25 @@ PyUFunc_Reduceat(PyUFuncObject *ufunc, PyArrayObject *arr, PyArrayObject *ind,
             dataptr_copy[1] = PyArray_BYTES(op[1]) + stride1*start;
             dataptr_copy[2] = PyArray_BYTES(op[0]) + stride0_ind*i;
 
-            /* Copy the first element to start the reduction */
+            /*
+             * Copy the first element to start the reduction.
+             *
+             * Output (dataptr[0]) and input (dataptr[1]) may point to
+             * the same memory, e.g.
+             * np.add.reduceat(a, np.arange(len(a)), out=a).
+             */
             if (otype == NPY_OBJECT) {
+                /*
+                 * Incref before decref to avoid the possibility of the
+                 * reference count being zero temporarily.
+                 */
+                Py_XINCREF(*(PyObject **)dataptr_copy[1]);
                 Py_XDECREF(*(PyObject **)dataptr_copy[0]);
                 *(PyObject **)dataptr_copy[0] =
                                     *(PyObject **)dataptr_copy[1];
-                Py_XINCREF(*(PyObject **)dataptr_copy[0]);
             }
             else {
-                memcpy(dataptr_copy[0], dataptr_copy[1], itemsize);
+                memmove(dataptr_copy[0], dataptr_copy[1], itemsize);
             }
 
             if (count > 1) {
diff --git a/numpy/core/tests/test_multiarray.py b/numpy/core/tests/test_multiarray.py
index ffdc50d2ca..deb1f66ebf 100755
--- a/numpy/core/tests/test_multiarray.py
+++ b/numpy/core/tests/test_multiarray.py
@@ -730,6 +730,21 @@ def __len__(self):
         d = A([1,2,3])
         assert_equal(len(np.array(d)), 3)
 
+    def test_array_too_big(self):
+        # Test that array creation succeeds for arrays addressable by intp
+        # on the byte level and fails for too large arrays.
+        buf = np.zeros(100)
+
+        max_bytes = np.iinfo(np.intp).max
+        for dtype in ["intp", "S20", "b"]:
+            dtype = np.dtype(dtype)
+            itemsize = dtype.itemsize
+
+            np.ndarray(buffer=buf, strides=(0,),
+                       shape=(max_bytes//itemsize,), dtype=dtype)
+            assert_raises(ValueError, np.ndarray, buffer=buf, strides=(0,),
+                          shape=(max_bytes//itemsize + 1,), dtype=dtype)
+
 
 class TestStructured(TestCase):
     def test_subarray_field_access(self):
@@ -6422,6 +6437,10 @@ def test_null_inside_ustring_array_is_truthy(self):
         a[0] = ' \0 \0'
         self.assertTrue(a)
 
+def test_orderconverter_with_nonASCII_unicode_ordering():
+    # gh-7475
+    a = np.arange(5)
+    assert_raises(ValueError, a.flatten, order=u'\xe2')
 
 if __name__ == "__main__":
     run_module_suite()
diff --git a/numpy/core/tests/test_regression.py b/numpy/core/tests/test_regression.py
index a61e64d8de..ace2c18149 100755
--- a/numpy/core/tests/test_regression.py
+++ b/numpy/core/tests/test_regression.py
@@ -2182,6 +2182,21 @@ def test_void_compare_segfault(self):
         a = np.ones(3, dtype=[('object', 'O'), ('int', '<i2')])
         a.sort()
 
+    def test_reshape_size_overflow(self):
+        # gh-7455
+        a = np.ones(20)[::2]
+        if np.dtype(np.intp).itemsize == 8:
+            # 64 bit. The following are the prime factors of 2**63 + 5,
+            # plus a leading 2, so when multiplied together as int64,
+            # the result overflows to a total size of 10.
+            new_shape = (2, 13, 419, 691, 823, 2977518503)
+        else:
+            # 32 bit. The following are the prime factors of 2**31 + 5,
+            # plus a leading 2, so when multiplied together as int32,
+            # the result overflows to a total size of 10.
+            new_shape = (2, 7, 7, 43826197)
+        assert_raises(ValueError, a.reshape, new_shape)
+
 
 if __name__ == "__main__":
     run_module_suite()
diff --git a/numpy/core/tests/test_scalarmath.py b/numpy/core/tests/test_scalarmath.py
index 75e91d2473..668b903b9f 100755
--- a/numpy/core/tests/test_scalarmath.py
+++ b/numpy/core/tests/test_scalarmath.py
@@ -9,7 +9,7 @@
 from numpy.testing.utils import _gen_alignment_data
 from numpy.testing import (
     TestCase, run_module_suite, assert_, assert_equal, assert_raises,
-    assert_almost_equal, assert_allclose
+    assert_almost_equal, assert_allclose, assert_array_equal
 )
 
 types = [np.bool_, np.byte, np.ubyte, np.short, np.ushort, np.intc, np.uintc,
@@ -156,6 +156,19 @@ def test_mixed_types(self):
                 else:
                     assert_almost_equal(result, 9, err_msg=msg)
 
+    def test_mixed_integer_types_negative_power(self):
+        # should always result in a floating type
+        signed_int_types = [np.int8, np.int16, np.int32, np.int64, int]
+        all_int_types = signed_int_types + [np.uint8, np.uint16, np.uint32, np.uint64]
+        for base_type in all_int_types:
+            for exponent_type in signed_int_types:
+                result = base_type(4) ** exponent_type(-4)
+                msg = "4 ** -4 == {} using {} ** {} -> {}".format(result,
+                        base_type.__name__, exponent_type.__name__,
+                        result.__class__.__name__)
+                assert_(isinstance(result, (np.floating, float)), msg)
+                assert_almost_equal(result, 0.00390625)
+
 
 class TestModulus(TestCase):
 
@@ -466,6 +479,44 @@ def test_error(self):
         assert_raises(TypeError, d.__sizeof__, "a")
 
 
+class TestMultiply(TestCase):
+    def test_seq_repeat(self):
+        # Test that basic sequences get repeated when multiplied with
+        # numpy integers. And errors are raised when multiplied with others.
+        # Some of this behaviour may be controversial and could be open for
+        # change.
+        for seq_type in (list, tuple):
+            seq = seq_type([1, 2, 3])
+            for numpy_type in np.typecodes["AllInteger"]:
+                i = np.dtype(numpy_type).type(2)
+                assert_equal(seq * i, seq * int(i))
+                assert_equal(i * seq, int(i) * seq)
+
+            for numpy_type in np.typecodes["All"].replace("V", ""):
+                if numpy_type in np.typecodes["AllInteger"]:
+                    continue
+                i = np.dtype(numpy_type).type()
+                assert_raises(TypeError, operator.mul, seq, i)
+                assert_raises(TypeError, operator.mul, i, seq)
+
+    def test_no_seq_repeat_basic_array_like(self):
+        # Test that an array-like which does not know how to be multiplied
+        # does not attempt sequence repeat (raise TypeError).
+        # See also gh-7428.
+        class ArrayLike(object):
+            def __init__(self, arr):
+                self.arr = arr
+            def __array__(self):
+                return self.arr
+
+        # Test for simple ArrayLike above and memoryviews (original report)
+        for arr_like in (ArrayLike(np.ones(3)), memoryview(np.ones(3))):
+            assert_array_equal(arr_like * np.float32(3.), np.full(3, 3.))
+            assert_array_equal(np.float32(3.) * arr_like, np.full(3, 3.))
+            assert_array_equal(arr_like * np.int_(3), np.full(3, 3))
+            assert_array_equal(np.int_(3) * arr_like, np.full(3, 3))
+
+
 class TestAbs(TestCase):
 
     def _test_abs_func(self, absfunc):
@@ -486,6 +537,14 @@ def test_builtin_abs(self):
     def test_numpy_abs(self):
         self._test_abs_func(np.abs)
 
+def test_longdouble_inf_loop():
+    mul = lambda x, y: x * y
+    assert_raises(TypeError, mul, np.longdouble(3), None)
+    assert_raises(TypeError, mul, None, np.longdouble(3))
+
+    assert_raises(TypeError, mul, np.clongdouble(3), None)
+    assert_raises(TypeError, mul, None, np.clongdouble(3))
+
 
 if __name__ == "__main__":
     run_module_suite()
diff --git a/numpy/core/tests/test_ufunc.py b/numpy/core/tests/test_ufunc.py
index ab8cecff0f..62fe3c04b4 100755
--- a/numpy/core/tests/test_ufunc.py
+++ b/numpy/core/tests/test_ufunc.py
@@ -665,6 +665,25 @@ def test_object_array_accumulate_inplace(self):
         np.add.accumulate(arr, out=arr, axis=-1)
         assert_array_equal(arr[0, :], np.array([[2]*i for i in [1, 3, 6, 10]]))
 
+    def test_object_array_reduceat_inplace(self):
+        # Checks that in-place reduceats work, see also gh-7465
+        arr = np.empty(4, dtype=object)
+        arr[:] = [[1] for i in range(4)]
+        out = np.empty(4, dtype=object)
+        out[:] = [[1] for i in range(4)]
+        np.add.reduceat(arr, np.arange(4), out=arr)
+        np.add.reduceat(arr, np.arange(4), out=arr)
+        assert_array_equal(arr, out)
+
+        # And the same if the axis argument is used
+        arr = np.ones((2, 4), dtype=object)
+        arr[0, :] = [[2] for i in range(4)]
+        out = np.ones((2, 4), dtype=object)
+        out[0, :] = [[2] for i in range(4)]
+        np.add.reduceat(arr, np.arange(4), out=arr, axis=-1)
+        np.add.reduceat(arr, np.arange(4), out=arr, axis=-1)
+        assert_array_equal(arr, out)
+
     def test_object_scalar_multiply(self):
         # Tickets #2469 and #4482
         arr = np.matrix([1, 2], dtype=object)
diff --git a/numpy/lib/nanfunctions.py b/numpy/lib/nanfunctions.py
index b963abb213..9d36406478 100755
--- a/numpy/lib/nanfunctions.py
+++ b/numpy/lib/nanfunctions.py
@@ -10,6 +10,8 @@
 - `nanargmax` -- index of maximum non-NaN value
 - `nansum` -- sum of non-NaN values
 - `nanprod` -- product of non-NaN values
+- `nancumsum` -- cumulative sum of non-NaN values
+- `nancumprod` -- cumulative product of non-NaN values
 - `nanmean` -- mean of non-NaN values
 - `nanvar` -- variance of non-NaN values
 - `nanstd` -- standard deviation of non-NaN values
@@ -27,6 +29,7 @@
 __all__ = [
     'nansum', 'nanmax', 'nanmin', 'nanargmax', 'nanargmin', 'nanmean',
     'nanmedian', 'nanpercentile', 'nanvar', 'nanstd', 'nanprod',
+    'nancumsum', 'nancumprod'
     ]
 
 
@@ -493,7 +496,11 @@ def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
 
     Returns
     -------
-    y : ndarray or numpy scalar
+    nansum : ndarray.
+        A new array holding the result is returned unless `out` is
+        specified, in which it is returned. The result has the same
+        size as `a`, and the same shape as `a` if `axis` is not None
+        or `a` is a 1-d array.
 
     See Also
     --------
@@ -506,11 +513,6 @@ def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
     If both positive and negative infinity are present, the sum will be Not
     A Number (NaN).
 
-    Numpy integer arithmetic is modular. If the size of a sum exceeds the
-    size of an integer accumulator, its value will wrap around and the
-    result will be incorrect. Specifying ``dtype=double`` can alleviate
-    that problem.
-
     Examples
     --------
     >>> np.nansum(1)
@@ -539,7 +541,7 @@ def nansum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
 def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
     """
     Return the product of array elements over a given axis treating Not a
-    Numbers (NaNs) as zero.
+    Numbers (NaNs) as ones.
 
     One is returned for slices that are all-NaN or empty.
 
@@ -573,20 +575,15 @@ def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
 
     Returns
     -------
-    y : ndarray or numpy scalar
+    nanprod : ndarray
+        A new array holding the result is returned unless `out` is
+        specified, in which case it is returned.
 
     See Also
     --------
     numpy.prod : Product across array propagating NaNs.
     isnan : Show which elements are NaN.
 
-    Notes
-    -----
-    Numpy integer arithmetic is modular. If the size of a product exceeds
-    the size of an integer accumulator, its value will wrap around and the
-    result will be incorrect. Specifying ``dtype=double`` can alleviate
-    that problem.
-
     Examples
     --------
     >>> np.nanprod(1)
@@ -606,6 +603,133 @@ def nanprod(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
     return np.prod(a, axis=axis, dtype=dtype, out=out, keepdims=keepdims)
 
 
+def nancumsum(a, axis=None, dtype=None, out=None):
+    """
+    Return the cumulative sum of array elements over a given axis treating Not a
+    Numbers (NaNs) as zero.  The cumulative sum does not change when NaNs are
+    encountered and leading NaNs are replaced by zeros.
+
+    Zeros are returned for slices that are all-NaN or empty.
+
+    .. versionadded:: 1.12.0
+
+    Parameters
+    ----------
+    a : array_like
+        Input array.
+    axis : int, optional
+        Axis along which the cumulative sum is computed. The default
+        (None) is to compute the cumsum over the flattened array.
+    dtype : dtype, optional
+        Type of the returned array and of the accumulator in which the
+        elements are summed.  If `dtype` is not specified, it defaults
+        to the dtype of `a`, unless `a` has an integer dtype with a
+        precision less than that of the default platform integer.  In
+        that case, the default platform integer is used.
+    out : ndarray, optional
+        Alternative output array in which to place the result. It must
+        have the same shape and buffer length as the expected output
+        but the type will be cast if necessary. See `doc.ufuncs`
+        (Section "Output arguments") for more details.
+
+    Returns
+    -------
+    nancumsum : ndarray.
+        A new array holding the result is returned unless `out` is
+        specified, in which it is returned. The result has the same
+        size as `a`, and the same shape as `a` if `axis` is not None
+        or `a` is a 1-d array.
+
+    See Also
+    --------
+    numpy.cumsum : Cumulative sum across array propagating NaNs.
+    isnan : Show which elements are NaN.
+
+    Examples
+    --------
+    >>> np.nancumsum(1)
+    array([1])
+    >>> np.nancumsum([1])
+    array([1])
+    >>> np.nancumsum([1, np.nan])
+    array([ 1.,  1.])
+    >>> a = np.array([[1, 2], [3, np.nan]])
+    >>> np.nancumsum(a)
+    array([ 1.,  3.,  6.,  6.])
+    >>> np.nancumsum(a, axis=0)
+    array([[ 1.,  2.],
+           [ 4.,  2.]])
+    >>> np.nancumsum(a, axis=1)
+    array([[ 1.,  3.],
+           [ 3.,  3.]])
+
+    """
+    a, mask = _replace_nan(a, 0)
+    return np.cumsum(a, axis=axis, dtype=dtype, out=out)
+
+
+def nancumprod(a, axis=None, dtype=None, out=None):
+    """
+    Return the cumulative product of array elements over a given axis treating Not a
+    Numbers (NaNs) as one.  The cumulative product does not change when NaNs are
+    encountered and leading NaNs are replaced by ones.
+
+    Ones are returned for slices that are all-NaN or empty.
+
+    .. versionadded:: 1.12.0
+
+    Parameters
+    ----------
+    a : array_like
+        Input array.
+    axis : int, optional
+        Axis along which the cumulative product is computed.  By default
+        the input is flattened.
+    dtype : dtype, optional
+        Type of the returned array, as well as of the accumulator in which
+        the elements are multiplied.  If *dtype* is not specified, it
+        defaults to the dtype of `a`, unless `a` has an integer dtype with
+        a precision less than that of the default platform integer.  In
+        that case, the default platform integer is used instead.
+    out : ndarray, optional
+        Alternative output array in which to place the result. It must
+        have the same shape and buffer length as the expected output
+        but the type of the resulting values will be cast if necessary.
+
+    Returns
+    -------
+    nancumprod : ndarray
+        A new array holding the result is returned unless `out` is
+        specified, in which case it is returned.
+
+    See Also
+    --------
+    numpy.cumprod : Cumulative product across array propagating NaNs.
+    isnan : Show which elements are NaN.
+
+    Examples
+    --------
+    >>> np.nancumprod(1)
+    array([1])
+    >>> np.nancumprod([1])
+    array([1])
+    >>> np.nancumprod([1, np.nan])
+    array([ 1.,  1.])
+    >>> a = np.array([[1, 2], [3, np.nan]])
+    >>> np.nancumprod(a)
+    array([ 1.,  2.,  6.,  6.])
+    >>> np.nancumprod(a, axis=0)
+    array([[ 1.,  2.],
+           [ 3.,  2.]])
+    >>> np.nancumprod(a, axis=1)
+    array([[ 1.,  2.],
+           [ 3.,  3.]])
+
+    """
+    a, mask = _replace_nan(a, 1)
+    return np.cumprod(a, axis=axis, dtype=dtype, out=out)
+
+
 def nanmean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue):
     """
     Compute the arithmetic mean along the specified axis, ignoring NaNs.
diff --git a/numpy/lib/tests/test_nanfunctions.py b/numpy/lib/tests/test_nanfunctions.py
index 989c563d99..03f9beff6f 100755
--- a/numpy/lib/tests/test_nanfunctions.py
+++ b/numpy/lib/tests/test_nanfunctions.py
@@ -5,7 +5,7 @@
 import numpy as np
 from numpy.testing import (
     run_module_suite, TestCase, assert_, assert_equal, assert_almost_equal,
-    assert_raises, assert_array_equal
+    assert_warns, assert_no_warnings, assert_raises, assert_array_equal
     )
 
 
@@ -22,6 +22,18 @@
          np.array([0.1042, -0.5954]),
          np.array([0.1610, 0.1859, 0.3146])]
 
+# Rows of _ndat with nans converted to ones
+_ndat_ones = np.array([[0.6244, 1.0, 0.2692, 0.0116, 1.0, 0.1170],
+                       [0.5351, -0.9403, 1.0, 0.2100, 0.4759, 0.2833],
+                       [1.0, 1.0, 1.0, 0.1042, 1.0, -0.5954],
+                       [0.1610, 1.0, 1.0, 0.1859, 0.3146, 1.0]])
+
+# Rows of _ndat with nans converted to zeros
+_ndat_zeros = np.array([[0.6244, 0.0, 0.2692, 0.0116, 0.0, 0.1170],
+                        [0.5351, -0.9403, 0.0, 0.2100, 0.4759, 0.2833],
+                        [0.0, 0.0, 0.0, 0.1042, 0.0, -0.5954],
+                        [0.1610, 0.0, 0.0, 0.1859, 0.3146, 0.0]])
+
 
 class TestNanFunctions_MinMax(TestCase):
 
@@ -241,6 +253,16 @@ def test_nanprod(self):
         for mat in self.integer_arrays():
             assert_equal(np.nanprod(mat), tgt)
 
+    def test_nancumsum(self):
+        tgt = np.cumsum(self.mat)
+        for mat in self.integer_arrays():
+            assert_equal(np.nancumsum(mat), tgt)
+
+    def test_nancumprod(self):
+        tgt = np.cumprod(self.mat)
+        for mat in self.integer_arrays():
+            assert_equal(np.nancumprod(mat), tgt)
+
     def test_nanmean(self):
         tgt = np.mean(self.mat)
         for mat in self.integer_arrays():
@@ -388,6 +410,89 @@ def test_empty(self):
             assert_equal(res, tgt)
 
 
+class TestNanFunctions_CumSumProd(TestCase, SharedNanFunctionsTestsMixin):
+
+    nanfuncs = [np.nancumsum, np.nancumprod]
+    stdfuncs = [np.cumsum, np.cumprod]
+
+    def test_allnans(self):
+        for f, tgt_value in zip(self.nanfuncs, [0, 1]):
+            # Unlike other nan-functions, sum/prod/cumsum/cumprod don't warn on all nan input
+            with assert_no_warnings():
+                res = f([np.nan]*3, axis=None)
+                tgt = tgt_value*np.ones((3))
+                assert_(np.array_equal(res, tgt), 'result is not %s * np.ones((3))' % (tgt_value))
+                # Check scalar
+                res = f(np.nan)
+                tgt = tgt_value*np.ones((1))
+                assert_(np.array_equal(res, tgt), 'result is not %s * np.ones((1))' % (tgt_value))
+                # Check there is no warning for not all-nan
+                f([0]*3, axis=None)
+
+    def test_empty(self):
+        for f, tgt_value in zip(self.nanfuncs, [0, 1]):
+            mat = np.zeros((0, 3))
+            tgt = tgt_value*np.ones((0, 3))
+            res = f(mat, axis=0)
+            assert_equal(res, tgt)
+            tgt = mat
+            res = f(mat, axis=1)
+            assert_equal(res, tgt)
+            tgt = np.zeros((0))
+            res = f(mat, axis=None)
+            assert_equal(res, tgt)
+
+    def test_keepdims(self):
+        for f, g in zip(self.nanfuncs, self.stdfuncs):
+            mat = np.eye(3)
+            for axis in [None, 0, 1]:
+                tgt = f(mat, axis=axis, out=None)
+                res = g(mat, axis=axis, out=None)
+                assert_(res.ndim == tgt.ndim)
+
+        for f in self.nanfuncs:
+            d = np.ones((3, 5, 7, 11))
+            # Randomly set some elements to NaN:
+            rs = np.random.RandomState(0)
+            d[rs.rand(*d.shape) < 0.5] = np.nan
+            res = f(d, axis=None)
+            assert_equal(res.shape, (1155,))
+            for axis in np.arange(4):
+                res = f(d, axis=axis)
+                assert_equal(res.shape, (3, 5, 7, 11))
+
+    def test_matrices(self):
+        # Check that it works and that type and
+        # shape are preserved
+        mat = np.matrix(np.eye(3))
+        for f in self.nanfuncs:
+            for axis in np.arange(2):
+                res = f(mat, axis=axis)
+                assert_(isinstance(res, np.matrix))
+                assert_(res.shape == (3, 3))
+            res = f(mat)
+            assert_(res.shape == (1, 3*3))
+
+    def test_result_values(self):
+        for axis in (-2, -1, 0, 1, None):
+            tgt = np.cumprod(_ndat_ones, axis=axis)
+            res = np.nancumprod(_ndat, axis=axis)
+            assert_almost_equal(res, tgt)
+            tgt = np.cumsum(_ndat_zeros,axis=axis)
+            res = np.nancumsum(_ndat, axis=axis)
+            assert_almost_equal(res, tgt)
+
+    def test_out(self):
+        mat = np.eye(3)
+        for nf, rf in zip(self.nanfuncs, self.stdfuncs):
+            resout = np.eye(3)
+            for axis in (-2, -1, 0, 1):
+                tgt = rf(mat, axis=axis)
+                res = nf(mat, axis=axis, out=resout)
+                assert_almost_equal(res, resout)
+                assert_almost_equal(res, tgt)
+
+
 class TestNanFunctions_MeanVarStd(TestCase, SharedNanFunctionsTestsMixin):
 
     nanfuncs = [np.nanmean, np.nanvar, np.nanstd]
diff --git a/numpy/lib/type_check.py b/numpy/lib/type_check.py
index 1313adff71..d6e0704ad4 100755
--- a/numpy/lib/type_check.py
+++ b/numpy/lib/type_check.py
@@ -424,7 +424,7 @@ def real_if_close(a,tol=100):
         from numpy.core import getlimits
         f = getlimits.finfo(a.dtype.type)
         tol = f.eps * tol
-    if _nx.allclose(a.imag, 0, atol=tol):
+    if _nx.all(_nx.absolute(a.imag) < tol):
         a = a.real
     return a
 
