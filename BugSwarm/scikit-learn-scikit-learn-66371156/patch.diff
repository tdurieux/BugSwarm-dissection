diff --git a/doc/developers/index.rst b/doc/developers/index.rst
index eb64e07165..c45c9061b0 100755
--- a/doc/developers/index.rst
+++ b/doc/developers/index.rst
@@ -527,6 +527,7 @@ to ``zero_one`` and call ``zero_one_loss`` from that function::
 
     def zero_one_loss(y_true, y_pred, normalize=True):
         # actual implementation
+        pass
 
     @deprecated("Function 'zero_one' has been renamed to "
                 "'zero_one_loss' and will be removed in release 0.15."
diff --git a/doc/whats_new.rst b/doc/whats_new.rst
index 0a3a6dd054..1c0a38efb7 100755
--- a/doc/whats_new.rst
+++ b/doc/whats_new.rst
@@ -74,6 +74,9 @@ Enhancements
    - Add ``sample_weight`` support to :class:`linear_model.RidgeClassifier`.
      By `Trevor Stephens`_.
 
+   - Provide an option for sparse output from
+     :func:`sklearn.metrics.pairwise.cosine_similarity`. By `Jaidev Deshpande`_.
+
 Bug fixes
 .........
 
diff --git a/sklearn/ensemble/bagging.py b/sklearn/ensemble/bagging.py
index c965c181ff..05adb20400 100755
--- a/sklearn/ensemble/bagging.py
+++ b/sklearn/ensemble/bagging.py
@@ -20,7 +20,9 @@
 from ..tree import DecisionTreeClassifier, DecisionTreeRegressor
 from ..utils import check_random_state, check_X_y, check_array
 from ..utils.random import sample_without_replacement
-from ..utils.validation import has_fit_parameter, check_is_fitted
+from ..utils.validation import check_is_fitted
+from ..utils.validation import DataConversionWarning
+from ..utils.validation import has_fit_parameter
 from ..utils.fixes import bincount
 from ..utils.metaestimators import if_delegate_has_method
 
@@ -289,6 +291,13 @@ def fit(self, X, y, sample_weight=None):
 
         # Remap output
         n_samples, self.n_features_ = X.shape
+
+        y = np.atleast_1d(y)
+        if y.ndim == 2 and y.shape[1] == 1:
+            warn("A column-vector y was passed when a 1d array was"
+                 " expected. Please change the shape of y to "
+                 "(n_samples,), for example using ravel().",
+                 DataConversionWarning, stacklevel=2)
         self.n_outputs_ = 1 if y.ndim == 1 else y.shape[1]
         y = self._validate_y(y)
 
@@ -384,7 +393,8 @@ def _validate_y(self, y):
         return y
 
     def _validate_X_predict(self, X):
-        check_is_fitted(self, "estimators_")
+        check_is_fitted(self, ["estimators_", "n_features_", "n_outputs_"])
+
         # Check data
         X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])
 
@@ -725,6 +735,8 @@ def predict_log_proba(self, X):
             The class probabilities of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
         """
+        check_is_fitted(self, "base_estimator_")
+
         if hasattr(self.base_estimator_, "predict_log_proba"):
             # Check data
             X = self._validate_X_predict(X)
diff --git a/sklearn/metrics/pairwise.py b/sklearn/metrics/pairwise.py
index aee203daaf..a5120f2cd0 100755
--- a/sklearn/metrics/pairwise.py
+++ b/sklearn/metrics/pairwise.py
@@ -791,7 +791,7 @@ def rbf_kernel(X, Y=None, gamma=None):
     return K
 
 
-def cosine_similarity(X, Y=None):
+def cosine_similarity(X, Y=None, dense_output=True):
     """Compute cosine similarity between samples in X and Y.
 
     Cosine similarity, or the cosine kernel, computes similarity as the
@@ -805,11 +805,16 @@ def cosine_similarity(X, Y=None):
 
     Parameters
     ----------
-    X : array_like, sparse matrix
-        with shape (n_samples_X, n_features).
+    X : ndarray or sparse array, shape: (n_samples_X, n_features)
+        Input data.
 
-    Y : array_like, sparse matrix (optional)
-        with shape (n_samples_Y, n_features).
+    Y : ndarray or sparse array, shape: (n_samples_Y, n_features)
+        Input data. If ``None``, the output will be the pairwise
+        similarities between all samples in ``X``.
+
+    dense_output : boolean (optional), default True
+        Whether to return dense output even when the input is sparse. If
+        ``False``, the output is sparse if both input arrays are sparse.
 
     Returns
     -------
@@ -826,7 +831,7 @@ def cosine_similarity(X, Y=None):
     else:
         Y_normalized = normalize(Y, copy=True)
 
-    K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=True)
+    K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=dense_output)
 
     return K
 
diff --git a/sklearn/metrics/tests/test_pairwise.py b/sklearn/metrics/tests/test_pairwise.py
index 43a8eaddb8..e293886d72 100755
--- a/sklearn/metrics/tests/test_pairwise.py
+++ b/sklearn/metrics/tests/test_pairwise.py
@@ -445,6 +445,22 @@ def test_rbf_kernel():
     assert_array_almost_equal(K.flat[::6], np.ones(5))
 
 
+def test_cosine_similarity_sparse_output():
+    # Test if cosine_similarity correctly produces sparse output.
+
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((5, 4))
+    Y = rng.random_sample((3, 4))
+    Xcsr = csr_matrix(X)
+    Ycsr = csr_matrix(Y)
+
+    K1 = cosine_similarity(Xcsr, Ycsr, dense_output=False)
+    assert_true(issparse(K1))
+
+    K2 = pairwise_kernels(Xcsr, Y=Ycsr, metric="cosine")
+    assert_array_almost_equal(K1.todense(), K2)
+
+
 def test_cosine_similarity():
     # Test the cosine_similarity.
 
