diff --git a/doc/whats_new.rst b/doc/whats_new.rst
index ad99711e50e3..005284bf59f4 100644
--- a/doc/whats_new.rst
+++ b/doc/whats_new.rst
@@ -266,6 +266,10 @@ Enhancements
 
    - Added :func:`metrics.pairwise.laplacian_kernel`.  By `Clyde Fare <https://github.com/Clyde-fare>`_.
 
+   - Added optional parameter ``verbose`` in :class:`pipeline.Pipeline` for showing
+     progress and timing of each step. By Sam Zhang.
+     (`#5298 <https://github.com/scikit-learn/scikit-learn/issues/5298>`_)
+
 Bug fixes
 .........
     - Fixed non-determinism in :class:`dummy.DummyClassifier` with sparse
diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py
index 3576ae3bdeb6..5f3cbc10f57e 100644
--- a/sklearn/linear_model/ridge.py
+++ b/sklearn/linear_model/ridge.py
@@ -529,7 +529,7 @@ class Ridge(_BaseRidge, RegressorMixin):
           (possibility to set `tol` and `max_iter`).
 
         - 'lsqr' uses the dedicated regularized least-squares routine
-          scipy.sparse.linalg.lsqr. It is the fatest but may not be available
+          scipy.sparse.linalg.lsqr. It is the fastest but may not be available
           in old scipy versions. It also uses an iterative procedure.
 
         - 'sag' uses a Stochastic Average Gradient descent. It also uses an
diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py
index aad082361304..0a27d829183d 100644
--- a/sklearn/pipeline.py
+++ b/sklearn/pipeline.py
@@ -143,7 +143,7 @@ def _pre_transform(self, X, y=None, **fit_params):
             step, param = pname.split('__', 1)
             fit_params_steps[step][param] = pval
         Xt = X
-        for name, transform in self.steps[:-1]:
+        for i, (name, transform) in enumerate(self.steps[:-1]):
             start_time = time.time()
             if hasattr(transform, "fit_transform"):
                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])
@@ -153,7 +153,8 @@ def _pre_transform(self, X, y=None, **fit_params):
             if self.verbose:
                 elapsed = time.time() - start_time
                 time_str = logger.short_format_time(elapsed)
-                print('[Pipeline] %s ... %s' % (name, time_str))
+                print('[Pipeline] (step %d of %d) %s ... %s' % (i,
+                    len(self.steps[:-1]), name, time_str))
 
         return Xt, fit_params_steps[self.steps[-1][0]]
 
@@ -176,7 +177,9 @@ def fit(self, X, y=None, **fit_params):
         if self.verbose:
             elapsed = time.time() - start_time
             time_str = logger.short_format_time(elapsed)
-            print('[Pipeline] %s ... %s' % (self.steps[-1][0], time_str))
+            print('[Pipeline] (step %d of %d) %s ... %s' %
+                    (len(self.steps[:-1]), len(self.steps[:-1]),
+                        self.steps[-1][0], time_str))
 
         return self
 
@@ -205,7 +208,9 @@ def fit_transform(self, X, y=None, **fit_params):
         if self.verbose:
             elapsed = time.time() - start_time
             time_str = logger.short_format_time(elapsed)
-            print('[Pipeline] %s ... %s' % (self.steps[-1][0], time_str))
+            print('[Pipeline] (step %d of %d) %s ... %s' %
+                    (len(self.steps[:-1]), len(self.steps[:-1]),
+                        self.steps[-1][0], time_str))
         return ret
 
     @if_delegate_has_method(delegate='_final_estimator')
diff --git a/sklearn/tests/test_pipeline.py b/sklearn/tests/test_pipeline.py
index d8cd737777fa..ee0313784d41 100644
--- a/sklearn/tests/test_pipeline.py
+++ b/sklearn/tests/test_pipeline.py
@@ -492,7 +492,7 @@ def test_verbosity():
             ('kbest', SelectKBest(k=1)), ('lr', LinearRegression())
         ], verbose=True)
         verbose_reg.fit(X, y)
-        assert_true("[Pipeline] kbest ..." in out.getvalue())
-        assert_true("[Pipeline] lr ..." in out.getvalue())
+        assert_true("[Pipeline] (step 0 of 1) kbest ..." in out.getvalue())
+        assert_true("[Pipeline] (step 1 of 1) lr ..." in out.getvalue())
     finally:
         sys.stdout = old_stdout
