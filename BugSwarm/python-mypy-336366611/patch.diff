diff --git a/.travis.yml b/.travis.yml
index 1039577891..7cce180a51 100755
--- a/.travis.yml
+++ b/.travis.yml
@@ -1,7 +1,7 @@
 cache: pip
 dist: trusty
 group: stable
-install: [pip install -U pip==9.0.1 setuptools==38.4.0 wheel==0.30.0, pip install
+install: [pip install -U pip==9.0.1 setuptools==38.5.1 wheel==0.30.0, pip install
     -r test-requirements.txt, python2 -m pip install --user typing==3.6.4, pip install
     .]
 language: python
diff --git a/mypy/build.py b/mypy/build.py
index 8aa95b6079..82ae17b941 100755
--- a/mypy/build.py
+++ b/mypy/build.py
@@ -393,6 +393,7 @@ def default_lib_path(data_dir: str,
                         ('child_modules', List[str]),  # all submodules of the given module
                         ('options', Optional[Dict[str, object]]),  # build options
                         ('dep_prios', List[int]),
+                        ('dep_lines', List[int]),
                         ('interface_hash', str),  # hash representing the public interface
                         ('version_id', str),  # mypy version for cache invalidation
                         ('ignore_all', bool),  # if errors were ignored
@@ -418,6 +419,7 @@ def cache_meta_from_dict(meta: Dict[str, Any], data_json: str) -> CacheMeta:
         meta.get('child_modules', []),
         meta.get('options'),
         meta.get('dep_prios', []),
+        meta.get('dep_lines', []),
         meta.get('interface_hash', ''),
         meta.get('version_id', sentinel),
         meta.get('ignore_all', True),
@@ -1040,7 +1042,8 @@ def find_cache_meta(id: str, path: str, manager: BuildManager) -> Optional[Cache
     # Ignore cache if generated by an older mypy version.
     if ((m.version_id != manager.version_id and not manager.options.skip_version_check)
             or m.options is None
-            or len(m.dependencies) != len(m.dep_prios)):
+            or len(m.dependencies) != len(m.dep_prios)
+            or len(m.dependencies) != len(m.dep_lines)):
         manager.log('Metadata abandoned for {}: new attributes are missing'.format(id))
         return None
 
@@ -1128,6 +1131,17 @@ def validate_meta(meta: Optional[CacheMeta], id: str, path: Optional[str],
     if not stat.S_ISREG(st.st_mode):
         manager.log('Metadata abandoned for {}: file {} does not exist'.format(id, path))
         return None
+
+    # When we are using a fine-grained cache, we want our initial
+    # build() to load all of the cache information and then do a
+    # fine-grained incremental update to catch anything that has
+    # changed since the cache was generated. We *don't* want to do a
+    # coarse-grained incremental rebuild, so we accept the cache
+    # metadata even if it doesn't match the source file.
+    if manager.options.use_fine_grained_cache:
+        manager.log('Using potentially stale metadata for {}'.format(id))
+        return meta
+
     size = st.st_size
     if size != meta.size:
         manager.log('Metadata abandoned for {}: file {} has different size'.format(id, path))
@@ -1157,6 +1171,7 @@ def validate_meta(meta: Optional[CacheMeta], id: str, path: Optional[str],
                 'options': (manager.options.clone_for_module(id)
                             .select_options_affecting_cache()),
                 'dep_prios': meta.dep_prios,
+                'dep_lines': meta.dep_lines,
                 'interface_hash': meta.interface_hash,
                 'version_id': manager.version_id,
                 'ignore_all': meta.ignore_all,
@@ -1186,7 +1201,7 @@ def compute_hash(text: str) -> str:
 def write_cache(id: str, path: str, tree: MypyFile,
                 serialized_fine_grained_deps: Dict[str, List[str]],
                 dependencies: List[str], suppressed: List[str],
-                child_modules: List[str], dep_prios: List[int],
+                child_modules: List[str], dep_prios: List[int], dep_lines: List[int],
                 old_interface_hash: str, source_hash: str,
                 ignore_all: bool, manager: BuildManager) -> Tuple[str, Optional[CacheMeta]]:
     """Write cache files for a module.
@@ -1203,6 +1218,7 @@ def write_cache(id: str, path: str, tree: MypyFile,
       suppressed: module IDs which were suppressed as dependencies
       child_modules: module IDs which are this package's direct submodules
       dep_prios: priorities (parallel array to dependencies)
+      dep_lines: import line locations (parallel array to dependencies)
       old_interface_hash: the hash from the previous version of the data cache file
       source_hash: the hash of the source code
       ignore_all: the ignore_all flag for this module
@@ -1286,6 +1302,7 @@ def write_cache(id: str, path: str, tree: MypyFile,
             'child_modules': child_modules,
             'options': options.select_options_affecting_cache(),
             'dep_prios': dep_prios,
+            'dep_lines': dep_lines,
             'interface_hash': interface_hash,
             'version_id': manager.version_id,
             'ignore_all': ignore_all,
@@ -1633,8 +1650,10 @@ def __init__(self,
             assert len(self.meta.dependencies) == len(self.meta.dep_prios)
             self.priorities = {id: pri
                                for id, pri in zip(self.meta.dependencies, self.meta.dep_prios)}
+            assert len(self.meta.dependencies) == len(self.meta.dep_lines)
+            self.dep_line_map = {id: line
+                                 for id, line in zip(self.meta.dependencies, self.meta.dep_lines)}
             self.child_modules = set(self.meta.child_modules)
-            self.dep_line_map = {}
         else:
             # Parse the file (and then some) to get the dependencies.
             self.parse_file()
@@ -2023,11 +2042,12 @@ def write_cache(self) -> None:
             self.mark_interface_stale(on_errors=True)
             return
         dep_prios = self.dependency_priorities()
+        dep_lines = self.dependency_lines()
         new_interface_hash, self.meta = write_cache(
             self.id, self.path, self.tree,
             {k: list(v) for k, v in self.fine_grained_deps.items()},
             list(self.dependencies), list(self.suppressed), list(self.child_modules),
-            dep_prios, self.interface_hash, self.source_hash, self.ignore_all,
+            dep_prios, dep_lines, self.interface_hash, self.source_hash, self.ignore_all,
             self.manager)
         if new_interface_hash == self.interface_hash:
             self.manager.log("Cached module {} has same interface".format(self.id))
@@ -2039,6 +2059,9 @@ def write_cache(self) -> None:
     def dependency_priorities(self) -> List[int]:
         return [self.priorities.get(dep, PRI_HIGH) for dep in self.dependencies]
 
+    def dependency_lines(self) -> List[int]:
+        return [self.dep_line_map.get(dep, 1) for dep in self.dependencies]
+
     def generate_unused_ignore_notes(self) -> None:
         if self.options.warn_unused_ignores:
             self.manager.errors.generate_unused_ignore_notes(self.xpath)
@@ -2371,6 +2394,14 @@ def process_graph(graph: Graph, manager: BuildManager) -> None:
                 manager.log("Processing SCC of size %d (%s) as %s" % (size, scc_str, fresh_msg))
             process_stale_scc(graph, scc, manager)
 
+    # If we are running in fine-grained incremental mode with caching,
+    # we always process fresh SCCs so that we have all of the symbol
+    # tables and fine-grained dependencies available.
+    if manager.options.use_fine_grained_cache:
+        for prev_scc in fresh_scc_queue:
+            process_fresh_scc(graph, prev_scc, manager)
+        fresh_scc_queue = []
+
     sccs_left = len(fresh_scc_queue)
     nodes_left = sum(len(scc) for scc in fresh_scc_queue)
     manager.add_stats(sccs_left=sccs_left, nodes_left=nodes_left)
@@ -2557,7 +2588,7 @@ def process_stale_scc(graph: Graph, scc: List[str], manager: BuildManager) -> No
             graph[id].transitive_error = True
     for id in stale:
         graph[id].finish_passes()
-        if manager.options.cache_fine_grained:
+        if manager.options.cache_fine_grained or manager.options.fine_grained_incremental:
             graph[id].compute_fine_grained_deps()
         graph[id].generate_unused_ignore_notes()
         manager.flush_errors(manager.errors.file_messages(graph[id].xpath), False)
diff --git a/mypy/checker.py b/mypy/checker.py
index 8e4af18c17..109fc24043 100755
--- a/mypy/checker.py
+++ b/mypy/checker.py
@@ -59,6 +59,7 @@
 from mypy.meet import is_overlapping_types
 from mypy.options import Options
 from mypy.plugin import Plugin, CheckerPluginInterface
+from mypy.sharedparse import BINARY_MAGIC_METHODS
 
 from mypy import experiments
 
@@ -2179,8 +2180,11 @@ def check_return_stmt(self, s: ReturnStmt) -> None:
                 if isinstance(typ, AnyType):
                     # (Unless you asked to be warned in that case, and the
                     # function is not declared to return Any)
-                    if (self.options.warn_return_any and not self.current_node_deferred and
-                            not is_proper_subtype(AnyType(TypeOfAny.special_form), return_type)):
+                    if (self.options.warn_return_any
+                        and not self.current_node_deferred
+                        and not is_proper_subtype(AnyType(TypeOfAny.special_form), return_type)
+                        and not (defn.name() in BINARY_MAGIC_METHODS and
+                                 is_literal_not_implemented(s.expr))):
                         self.msg.incorrectly_returning_any(return_type, s)
                     return
 
@@ -3232,6 +3236,10 @@ def remove_optional(typ: Type) -> Type:
         return typ
 
 
+def is_literal_not_implemented(n: Expression) -> bool:
+    return isinstance(n, NameExpr) and n.fullname == 'builtins.NotImplemented'
+
+
 def builtin_item_type(tp: Type) -> Optional[Type]:
     """Get the item type of a builtin container.
 
diff --git a/mypy/dmypy_server.py b/mypy/dmypy_server.py
index c05d43eced..5428ad7969 100755
--- a/mypy/dmypy_server.py
+++ b/mypy/dmypy_server.py
@@ -24,7 +24,7 @@
 from mypy.dmypy_util import STATUS_FILE, receive
 from mypy.gclogger import GcLogger
 from mypy.fscache import FileSystemCache
-from mypy.fswatcher import FileSystemWatcher
+from mypy.fswatcher import FileSystemWatcher, FileData
 
 
 def daemonize(func: Callable[[], None], log_file: Optional[str] = None) -> int:
@@ -99,13 +99,18 @@ def __init__(self, flags: List[str]) -> None:
             sys.exit("dmypy: start/restart should not disable incremental mode")
         if options.quick_and_dirty:
             sys.exit("dmypy: start/restart should not specify quick_and_dirty mode")
+        if options.use_fine_grained_cache and not options.fine_grained_incremental:
+            sys.exit("dmypy: fine-grained cache can only be used in experimental mode")
         self.options = options
         if os.path.isfile(STATUS_FILE):
             os.unlink(STATUS_FILE)
         if self.fine_grained:
             options.incremental = True
             options.show_traceback = True
-            options.cache_dir = os.devnull
+            if options.use_fine_grained_cache:
+                options.cache_fine_grained = True  # set this so that cache options match
+            else:
+                options.cache_dir = os.devnull
 
     def serve(self) -> None:
         """Serve requests, synchronously (no thread or fork)."""
@@ -263,11 +268,29 @@ def initialize_fine_grained(self, sources: List[mypy.build.BuildSource]) -> Dict
         manager = result.manager
         graph = result.graph
         self.fine_grained_manager = mypy.server.update.FineGrainedBuildManager(manager, graph)
-        status = 1 if messages else 0
-        self.previous_messages = messages[:]
         self.fine_grained_initialized = True
         self.previous_sources = sources
         self.fscache.flush()
+
+        # If we are using the fine-grained cache, build hasn't actually done
+        # the typechecking on the updated files yet.
+        # Run a fine-grained update starting from the cached data
+        if self.options.use_fine_grained_cache:
+            # Pull times and hashes out of the saved_cache and stick them into
+            # the fswatcher, so we pick up the changes.
+            for meta, mypyfile, type_map in manager.saved_cache.values():
+                if meta.mtime is None: continue
+                self.fswatcher.set_file_data(
+                    meta.path,
+                    FileData(st_mtime=float(meta.mtime), st_size=meta.size, md5=meta.hash))
+
+            # Run an update
+            changed = self.find_changed(sources)
+            if changed:
+                messages = self.fine_grained_manager.update(changed)
+
+        status = 1 if messages else 0
+        self.previous_messages = messages[:]
         return {'out': ''.join(s + '\n' for s in messages), 'err': '', 'status': status}
 
     def fine_grained_increment(self, sources: List[mypy.build.BuildSource]) -> Dict[str, Any]:
diff --git a/mypy/fswatcher.py b/mypy/fswatcher.py
index c6eeae2ddb..d4efc10d61 100755
--- a/mypy/fswatcher.py
+++ b/mypy/fswatcher.py
@@ -36,6 +36,9 @@ def __init__(self, fs: FileSystemCache) -> None:
     def paths(self) -> AbstractSet[str]:
         return self._paths
 
+    def set_file_data(self, path: str, data: FileData) -> None:
+        self._file_data[path] = data
+
     def add_watched_paths(self, paths: Iterable[str]) -> None:
         for path in paths:
             if path not in self._paths:
diff --git a/mypy/main.py b/mypy/main.py
index 10d8d1251b..cbcab24d2b 100755
--- a/mypy/main.py
+++ b/mypy/main.py
@@ -395,6 +395,8 @@ def add_invertible_flag(flag: str,
     if server_options:
         parser.add_argument('--experimental', action='store_true', dest='fine_grained_incremental',
                             help="enable fine-grained incremental mode")
+        parser.add_argument('--use-fine-grained-cache', action='store_true',
+                            help="use the cache in fine-grained incremental mode")
 
     report_group = parser.add_argument_group(
         title='report generation',
diff --git a/mypy/myunit/__init__.py b/mypy/myunit/__init__.py
deleted file mode 100755
index 8361f44b35..0000000000
--- a/mypy/myunit/__init__.py
+++ /dev/null
@@ -1,394 +0,0 @@
-import importlib
-import os
-import sys
-import tempfile
-import time
-import traceback
-
-from typing import List, Tuple, Any, Callable, Union, cast, Optional, Iterable
-from types import TracebackType, MethodType
-
-
-# TODO remove global state
-is_verbose = False
-is_quiet = False
-patterns = []  # type: List[str]
-times = []  # type: List[Tuple[float, str]]
-
-
-class AssertionFailure(Exception):
-    """Exception used to signal failed test cases."""
-    def __init__(self, s: Optional[str] = None) -> None:
-        if s:
-            super().__init__(s)
-        else:
-            super().__init__()
-
-
-class SkipTestCaseException(Exception):
-    """Exception used to signal skipped test cases."""
-    pass
-
-
-def assert_true(b: bool, msg: Optional[str] = None) -> None:
-    if not b:
-        raise AssertionFailure(msg)
-
-
-def assert_false(b: bool, msg: Optional[str] = None) -> None:
-    if b:
-        raise AssertionFailure(msg)
-
-
-def good_repr(obj: object) -> str:
-    if isinstance(obj, str):
-        if obj.count('\n') > 1:
-            bits = ["'''\\"]
-            for line in obj.split('\n'):
-                # force repr to use ' not ", then cut it off
-                bits.append(repr('"' + line)[2:-1])
-            bits[-1] += "'''"
-            return '\n'.join(bits)
-    return repr(obj)
-
-
-def assert_equal(a: object, b: object, fmt: str = '{} != {}') -> None:
-    if a != b:
-        raise AssertionFailure(fmt.format(good_repr(a), good_repr(b)))
-
-
-def assert_not_equal(a: object, b: object, fmt: str = '{} == {}') -> None:
-    if a == b:
-        raise AssertionFailure(fmt.format(good_repr(a), good_repr(b)))
-
-
-def assert_raises(typ: type, *rest: Any) -> None:
-    """Usage: assert_raises(exception class[, message], function[, args])
-
-    Call function with the given arguments and expect an exception of the given
-    type.
-
-    TODO use overloads for better type checking
-    """
-    # Parse arguments.
-    msg = None  # type: Optional[str]
-    if isinstance(rest[0], str) or rest[0] is None:
-        msg = rest[0]
-        rest = rest[1:]
-    f = rest[0]
-    args = []  # type: List[Any]
-    if len(rest) > 1:
-        args = rest[1]
-        assert len(rest) <= 2
-
-    # Perform call and verify the exception.
-    try:
-        f(*args)
-    except BaseException as e:
-        if isinstance(e, KeyboardInterrupt):
-            raise
-        assert_type(typ, e)
-        if msg:
-            assert_equal(e.args[0], msg, 'Invalid message {}, expected {}')
-    else:
-        raise AssertionFailure('No exception raised')
-
-
-def assert_type(typ: type, value: object) -> None:
-    if type(value) != typ:
-        raise AssertionFailure('Invalid type {}, expected {}'.format(
-            typename(type(value)), typename(typ)))
-
-
-def fail() -> None:
-    raise AssertionFailure()
-
-
-class BaseTestCase:
-    """Common base class for _MyUnitTestCase and DataDrivenTestCase.
-
-    Handles temporary folder creation and deletion.
-    """
-    def __init__(self, name: str) -> None:
-        self.name = name
-        self.old_cwd = None  # type: Optional[str]
-        self.tmpdir = None  # type: Optional[tempfile.TemporaryDirectory[str]]
-
-    def setup(self) -> None:
-        self.old_cwd = os.getcwd()
-        self.tmpdir = tempfile.TemporaryDirectory(prefix='mypy-test-')
-        os.chdir(self.tmpdir.name)
-        os.mkdir('tmp')
-
-    def teardown(self) -> None:
-        assert self.old_cwd is not None and self.tmpdir is not None, \
-            "test was not properly set up"
-        os.chdir(self.old_cwd)
-        try:
-            self.tmpdir.cleanup()
-        except OSError:
-            pass
-        self.old_cwd = None
-        self.tmpdir = None
-
-
-class _MyUnitTestCase(BaseTestCase):
-    """A concrete, myunit-specific test case, a wrapper around a method to run."""
-
-    def __init__(self, name: str, suite: 'Suite', run: Callable[[], None]) -> None:
-        super().__init__(name)
-        self.run = run
-        self.suite = suite
-
-    def setup(self) -> None:
-        super().setup()
-        self.suite.setup()
-
-    def teardown(self) -> None:
-        self.suite.teardown()  # No-op
-        super().teardown()
-
-
-class Suite:
-    """Abstract class for myunit test suites - node in the tree whose leaves are _MyUnitTestCases.
-
-    The children `cases` are looked up during __init__, looking for attributes named test_*
-    they are either no-arg methods or of a pair (name, Suite).
-    """
-
-    cases = None  # type: Iterable[Union[_MyUnitTestCase, Tuple[str, Suite]]]
-
-    def __init__(self) -> None:
-        self.prefix = typename(type(self)) + '.'
-        self.cases = []
-        for m in dir(self):
-            if m.startswith('test_'):
-                t = getattr(self, m)
-                if isinstance(t, Suite):
-                    self.cases.append((m + '.', t))
-                else:
-                    assert isinstance(t, MethodType)
-                    self.cases.append(_MyUnitTestCase(m, self, t))
-
-    def setup(self) -> None:
-        """Set up fixtures"""
-        pass
-
-    def teardown(self) -> None:
-        # This method is not overridden in practice
-        pass
-
-    def skip(self) -> None:
-        raise SkipTestCaseException()
-
-
-def add_suites_from_module(suites: List[Suite], mod_name: str) -> None:
-    mod = importlib.import_module(mod_name)
-    got_suite = False
-    for suite in mod.__dict__.values():
-        if isinstance(suite, type) and issubclass(suite, Suite) and suite is not Suite:
-            got_suite = True
-            suites.append(cast(Callable[[], Suite], suite)())
-    if not got_suite:
-        # Sanity check in case e.g. it uses unittest instead of a myunit.
-        # The codecs tests do since they need to be python2-compatible.
-        sys.exit('Test module %s had no test!' % mod_name)
-
-
-class ListSuite(Suite):
-    def __init__(self, suites: List[Suite]) -> None:
-        for suite in suites:
-            mod_name = type(suite).__module__.replace('.', '_')
-            mod_name = mod_name.replace('mypy_', '')
-            mod_name = mod_name.replace('test_', '')
-            mod_name = mod_name.strip('_').replace('__', '_')
-            type_name = type(suite).__name__
-            name = 'test_%s_%s' % (mod_name, type_name)
-            setattr(self, name, suite)
-        super().__init__()
-
-
-def main(args: Optional[List[str]] = None) -> None:
-    global patterns, is_verbose, is_quiet
-    if not args:
-        args = sys.argv[1:]
-    is_verbose = False
-    is_quiet = False
-    suites = []  # type: List[Suite]
-    patterns = []
-    i = 0
-    while i < len(args):
-        a = args[i]
-        if a == '-v':
-            is_verbose = True
-        elif a == '-q':
-            is_quiet = True
-        elif a == '-m':
-            i += 1
-            if i == len(args):
-                sys.exit('-m requires an argument')
-            add_suites_from_module(suites, args[i])
-        elif not a.startswith('-'):
-            patterns.append(a)
-        else:
-            sys.exit('Usage: python -m mypy.myunit [-v] [-q]'
-                    + ' -m mypy.test.module [-m mypy.test.module ...] [filter ...]')
-        i += 1
-    if len(patterns) == 0:
-        patterns.append('*')
-    if not suites:
-        sys.exit('At least one -m argument is required')
-
-    t = ListSuite(suites)
-    num_total, num_fail, num_skip = run_test_recursive(t, 0, 0, 0, '', 0)
-
-    skip_msg = ''
-    if num_skip > 0:
-        skip_msg = ', {} skipped'.format(num_skip)
-
-    if num_fail == 0:
-        if not is_quiet:
-            print('%d test cases run%s, all passed.' % (num_total, skip_msg))
-            print('*** OK ***')
-    else:
-        sys.stderr.write('%d/%d test cases failed%s.\n' % (num_fail,
-                                                           num_total,
-                                                           skip_msg))
-        sys.stderr.write('*** FAILURE ***\n')
-        sys.exit(1)
-
-
-def run_test_recursive(test: Union[_MyUnitTestCase, Tuple[str, Suite], ListSuite],
-                       num_total: int, num_fail: int, num_skip: int,
-                       prefix: str, depth: int) -> Tuple[int, int, int]:
-    """The first argument may be _MyUnitTestCase, Suite or (str, Suite)."""
-    if isinstance(test, _MyUnitTestCase):
-        name = prefix + test.name
-        for pattern in patterns:
-            if match_pattern(name, pattern):
-                match = True
-                break
-        else:
-            match = False
-        if match:
-            is_fail, is_skip = run_single_test(name, test)
-            if is_fail: num_fail += 1
-            if is_skip: num_skip += 1
-            num_total += 1
-    else:
-        suite_prefix = ''
-        if isinstance(test, list) or isinstance(test, tuple):
-            suite = test[1]  # type: Suite
-            suite_prefix = test[0]
-        else:
-            suite = test
-            suite_prefix = test.prefix
-
-        for stest in suite.cases:
-            new_prefix = prefix
-            if depth > 0:
-                new_prefix = prefix + suite_prefix
-            num_total, num_fail, num_skip = run_test_recursive(
-                stest, num_total, num_fail, num_skip, new_prefix, depth + 1)
-    return num_total, num_fail, num_skip
-
-
-def run_single_test(name: str, test: _MyUnitTestCase) -> Tuple[bool, bool]:
-    if is_verbose:
-        sys.stderr.write(name)
-        sys.stderr.flush()
-
-    time0 = time.time()
-    test.setup()  # FIX: check exceptions
-    exc_traceback = None  # type: Optional[TracebackType]
-    try:
-        test.run()
-    except BaseException as e:
-        if isinstance(e, KeyboardInterrupt):
-            raise
-        exc_type, exc_value, exc_traceback = sys.exc_info()
-    finally:
-        test.teardown()
-    times.append((time.time() - time0, name))
-
-    if exc_traceback:
-        if isinstance(exc_value, SkipTestCaseException):
-            if is_verbose:
-                sys.stderr.write(' (skipped)\n')
-            return False, True
-        else:
-            assert exc_type is not None and exc_value is not None
-            handle_failure(name, exc_type, exc_value, exc_traceback)
-            return True, False
-    elif is_verbose:
-        sys.stderr.write('\n')
-
-    return False, False
-
-
-def handle_failure(name: str,
-                   exc_type: type,
-                   exc_value: BaseException,
-                   exc_traceback: TracebackType,
-                   ) -> None:
-    # Report failed test case.
-    if is_verbose:
-        sys.stderr.write('\n\n')
-    msg = ''
-    if exc_value.args and exc_value.args[0]:
-        msg = ': ' + str(exc_value)
-    else:
-        msg = ''
-    if not isinstance(exc_value, SystemExit):
-        # We assume that before doing exit() (which raises SystemExit) we've printed
-        # enough context about what happened so that a stack trace is not useful.
-        # In particular, uncaught exceptions during semantic analysis or type checking
-        # call exit() and they already print out a stack trace.
-        sys.stderr.write('Traceback (most recent call last):\n')
-        tb = traceback.format_tb(exc_traceback)
-        tb = clean_traceback(tb)
-        for s in tb:
-            sys.stderr.write(s)
-    else:
-        sys.stderr.write('\n')
-    exception = typename(exc_type)
-    sys.stderr.write('{}{}\n\n'.format(exception, msg))
-    sys.stderr.write('{} failed\n\n'.format(name))
-
-
-def typename(t: type) -> str:
-    if '.' in str(t):
-        return str(t).split('.')[-1].rstrip("'>")
-    else:
-        return str(t)[8:-2]
-
-
-def match_pattern(s: str, p: str) -> bool:
-    if len(p) == 0:
-        return len(s) == 0
-    elif p[0] == '*':
-        if len(p) == 1:
-            return True
-        else:
-            for i in range(len(s) + 1):
-                if match_pattern(s[i:], p[1:]):
-                    return True
-            return False
-    elif len(s) == 0:
-        return False
-    else:
-        return s[0] == p[0] and match_pattern(s[1:], p[1:])
-
-
-def clean_traceback(tb: List[str]) -> List[str]:
-    # Remove clutter from the traceback.
-    start = 0
-    for i, s in enumerate(tb):
-        if '\n    test.run()\n' in s or '\n    self.func()\n' in s:
-            start = i + 1
-    tb = tb[start:]
-    for f in ['assert_equal', 'assert_not_equal', 'assert_type',
-              'assert_raises', 'assert_true']:
-        if tb != [] and ', in {}\n'.format(f) in tb[-1]:
-            tb = tb[:-1]
-    return tb
diff --git a/mypy/myunit/__main__.py b/mypy/myunit/__main__.py
deleted file mode 100755
index 34098d4064..0000000000
--- a/mypy/myunit/__main__.py
+++ /dev/null
@@ -1,9 +0,0 @@
-# This is a separate module from mypy.myunit so it doesn't exist twice.
-"""Myunit test runner command line tool.
-
-Usually used as a slave by runtests.py, but can be used directly.
-"""
-
-from mypy.myunit import main
-
-main()
diff --git a/mypy/nodes.py b/mypy/nodes.py
index 227a34dda0..f5adcbc349 100755
--- a/mypy/nodes.py
+++ b/mypy/nodes.py
@@ -209,6 +209,8 @@ class MypyFile(SymbolNode):
     ignored_lines = None  # type: Set[int]
     # Is this file represented by a stub file (.pyi)?
     is_stub = False
+    # Is this loaded from the cache and thus missing the actual body of the file?
+    is_cache_skeleton = False
 
     def __init__(self,
                  defs: List[Statement],
@@ -256,6 +258,7 @@ def deserialize(cls, data: JsonDict) -> 'MypyFile':
         tree.names = SymbolTable.deserialize(data['names'])
         tree.is_stub = data['is_stub']
         tree.path = data['path']
+        tree.is_cache_skeleton = True
         return tree
 
 
diff --git a/mypy/options.py b/mypy/options.py
index c62520075d..cb7871778f 100755
--- a/mypy/options.py
+++ b/mypy/options.py
@@ -144,6 +144,7 @@ def __init__(self) -> None:
         self.skip_version_check = False
         self.fine_grained_incremental = False
         self.cache_fine_grained = False
+        self.use_fine_grained_cache = False
 
         # Paths of user plugins
         self.plugins = []  # type: List[str]
diff --git a/mypy/server/update.py b/mypy/server/update.py
index 211b1b1f84..47caffca25 100755
--- a/mypy/server/update.py
+++ b/mypy/server/update.py
@@ -143,10 +143,6 @@
 from mypy.server.trigger import make_trigger
 
 
-# If True, print out debug logging output.
-DEBUG = False
-
-
 MAX_ITER = 1000
 
 
@@ -170,6 +166,10 @@ def __init__(self,
         self.blocking_error = None  # type: Optional[Tuple[str, str]]
         # Module that we haven't processed yet but that are known to be stale.
         self.stale = []  # type: List[Tuple[str, str]]
+        # Disable the cache so that load_graph doesn't try going back to disk
+        # for the cache. This is kind of a hack and it might be better to have
+        # this directly reflected in load_graph's interface.
+        self.options.cache_dir = os.devnull
         mark_all_meta_as_memory_only(graph, manager)
         manager.saved_cache = preserve_full_cache(graph, manager)
         self.type_maps = extract_type_maps(graph)
@@ -201,25 +201,23 @@ def update(self, changed_modules: List[Tuple[str, str]]) -> List[str]:
         self.triggered = []
         changed_modules = dedupe_modules(changed_modules + self.stale)
         initial_set = {id for id, _ in changed_modules}
-        if DEBUG:
-            print('==== update %s ====' % ', '.join(repr(id)
-                                                    for id, _ in changed_modules))
-            if self.previous_targets_with_errors:
-                print('previous targets with errors: %s' %
-                      sorted(self.previous_targets_with_errors))
+        self.manager.log('fine-grained: ==== update %s ====' % ', '.join(
+            repr(id) for id, _ in changed_modules))
+        if self.previous_targets_with_errors and self.options.verbosity >= 1:
+            self.manager.log('fine-grained: previous targets with errors: %s' %
+                             sorted(self.previous_targets_with_errors))
 
         if self.blocking_error:
             # Handle blocking errors first. We'll exit as soon as we find a
             # module that still has blocking errors.
-            if DEBUG:
-                print('existing blocker: %s' % self.blocking_error[0])
+            self.manager.log('fine-grained: existing blocker: %s' % self.blocking_error[0])
             changed_modules = dedupe_modules([self.blocking_error] + changed_modules)
             self.blocking_error = None
 
         while changed_modules:
             next_id, next_path = changed_modules.pop(0)
             if next_id not in self.previous_modules and next_id not in initial_set:
-                print('skip %r (module not in import graph)' % next_id)
+                self.manager.log('fine-grained: skip %r (module not in import graph)' % next_id)
                 continue
             result = self.update_single(next_id, next_path)
             messages, remaining, (next_id, next_path), blocker = result
@@ -250,8 +248,7 @@ def update_single(self, module: str, path: str) -> Tuple[List[str],
             - Module which was actually processed as (id, path) tuple
             - Whether there was a blocking error in the module
         """
-        if DEBUG:
-            print('--- update single %r ---' % module)
+        self.manager.log('fine-grained: --- update single %r ---' % module)
 
         # TODO: If new module brings in other modules, we parse some files multiple times.
         manager = self.manager
@@ -275,15 +272,16 @@ def update_single(self, module: str, path: str) -> Tuple[List[str],
 
         # TODO: What to do with stale dependencies?
         triggered = calculate_active_triggers(manager, old_snapshots, {module: tree})
-        if DEBUG:
+        if self.options.verbosity >= 1:
             filtered = [trigger for trigger in triggered
                         if not trigger.endswith('__>')]
-            print('triggered:', sorted(filtered))
+            self.manager.log('fine-grained: triggered: %r' % sorted(filtered))
         self.triggered.extend(triggered | self.previous_targets_with_errors)
         collect_dependencies({module: tree}, self.deps, graph)
-        propagate_changes_using_dependencies(manager, graph, self.deps, triggered,
-                                             {module},
-                                             self.previous_targets_with_errors)
+        remaining += propagate_changes_using_dependencies(
+            manager, graph, self.deps, triggered,
+            {module},
+            self.previous_targets_with_errors)
 
         # Preserve state needed for the next update.
         self.previous_targets_with_errors = manager.errors.targets()
@@ -318,6 +316,7 @@ def mark_all_meta_as_memory_only(graph: Dict[str, State],
 def get_all_dependencies(manager: BuildManager, graph: Dict[str, State],
                          options: Options) -> Dict[str, Set[str]]:
     """Return the fine-grained dependency map for an entire build."""
+    # Deps for each module were computed during build() or loaded from the cache.
     deps = {}  # type: Dict[str, Set[str]]
     collect_dependencies(manager.modules, deps, graph)
     return deps
@@ -367,14 +366,14 @@ def update_single_isolated(module: str,
     """
     if module in manager.modules:
         assert_equivalent_paths(path, manager.modules[module].path)
-    elif DEBUG:
-        print('new module %r' % module)
+    else:
+        manager.log('fine-grained: new module %r' % module)
 
     old_modules = dict(manager.modules)
     sources = get_sources(previous_modules, [(module, path)])
     invalidate_stale_cache_entries(manager.saved_cache, [(module, path)])
 
-    manager.missing_modules = set()
+    manager.missing_modules.clear()
     try:
         graph = load_graph(sources, manager)
     except CompileError as err:
@@ -412,8 +411,7 @@ def update_single_isolated(module: str,
             else:
                 del manager.modules[id]
             del graph[id]
-        if DEBUG:
-            print('--> %r (newly imported)' % module)
+        manager.log('fine-grained: --> %r (newly imported)' % module)
     else:
         remaining_modules = []
 
@@ -441,6 +439,7 @@ def update_single_isolated(module: str,
     # Perform type checking.
     state.type_check_first_pass()
     state.type_check_second_pass()
+    state.compute_fine_grained_deps()
     state.finish_passes()
     # TODO: state.write_cache()?
     # TODO: state.mark_as_rechecked()?
@@ -486,13 +485,13 @@ def assert_equivalent_paths(path1: str, path2: str) -> None:
 def delete_module(module_id: str,
                   graph: Dict[str, State],
                   manager: BuildManager) -> Dict[str, State]:
-    if DEBUG:
-        print('delete module %r' % module_id)
+    manager.log('fine-grained: delete module %r' % module_id)
     # TODO: Deletion of a package
     # TODO: Remove deps for the module (this only affects memory use, not correctness)
     assert module_id not in graph
     new_graph = graph.copy()
-    del manager.modules[module_id]
+    if module_id in manager.modules:
+        del manager.modules[module_id]
     if module_id in manager.saved_cache:
         del manager.saved_cache[module_id]
     components = module_id.split('.')
@@ -562,6 +561,7 @@ def preserve_full_cache(graph: Graph, manager: BuildManager) -> SavedCache:
                 # There is no corresponding JSON so create partial "memory-only" metadata.
                 assert state.path
                 dep_prios = state.dependency_priorities()
+                dep_lines = state.dependency_lines()
                 meta = memory_only_cache_meta(
                     id,
                     state.path,
@@ -569,6 +569,7 @@ def preserve_full_cache(graph: Graph, manager: BuildManager) -> SavedCache:
                     state.suppressed,
                     list(state.child_modules),
                     dep_prios,
+                    dep_lines,
                     state.source_hash,
                     state.ignore_all,
                     manager)
@@ -584,6 +585,7 @@ def memory_only_cache_meta(id: str,
                            suppressed: List[str],
                            child_modules: List[str],
                            dep_prios: List[int],
+                           dep_lines: List[int],
                            source_hash: str,
                            ignore_all: bool,
                            manager: BuildManager) -> CacheMeta:
@@ -603,6 +605,7 @@ def memory_only_cache_meta(id: str,
             'child_modules': child_modules,
             'options': options.select_options_affecting_cache(),
             'dep_prios': dep_prios,
+            'dep_lines': dep_lines,
             'interface_hash': '',
             'version_id': manager.version_id,
             'ignore_all': ignore_all,
@@ -650,7 +653,6 @@ def collect_dependencies(new_modules: Mapping[str, Optional[MypyFile]],
     for id, node in new_modules.items():
         if node is None:
             continue
-        graph[id].compute_fine_grained_deps()
         for trigger, targets in graph[id].fine_grained_deps.items():
             deps.setdefault(trigger, set()).update(targets)
 
@@ -707,9 +709,15 @@ def propagate_changes_using_dependencies(
         deps: Dict[str, Set[str]],
         triggered: Set[str],
         up_to_date_modules: Set[str],
-        targets_with_errors: Set[str]) -> None:
+        targets_with_errors: Set[str]) -> List[Tuple[str, str]]:
+    """Transitively rechecks targets based on triggers and the dependency map.
+
+    Returns a list (module id, path) tuples representing modules that contain
+    a target that needs to be reprocessed but that has not been parsed yet."""
+
     # TODO: Multiple type checking passes
     num_iter = 0
+    remaining_modules = []
 
     # Propagate changes until nothing visible has changed during the last
     # iteration.
@@ -718,7 +726,8 @@ def propagate_changes_using_dependencies(
         if num_iter > MAX_ITER:
             raise RuntimeError('Max number of iterations (%d) reached (endless loop?)' % MAX_ITER)
 
-        todo = find_targets_recursive(triggered, deps, manager.modules, up_to_date_modules)
+        todo = find_targets_recursive(manager, triggered, deps,
+                                      manager.modules, up_to_date_modules)
         # Also process targets that used to have errors, as otherwise some
         # errors might be lost.
         for target in targets_with_errors:
@@ -726,24 +735,32 @@ def propagate_changes_using_dependencies(
             if id is not None and id not in up_to_date_modules:
                 if id not in todo:
                     todo[id] = set()
-                if DEBUG:
-                    print('process', target)
+                manager.log('fine-grained: process: %s' % target)
                 todo[id].update(lookup_target(manager.modules, target))
         triggered = set()
         # TODO: Preserve order (set is not optimal)
         for id, nodes in sorted(todo.items(), key=lambda x: x[0]):
             assert id not in up_to_date_modules
-            triggered |= reprocess_nodes(manager, graph, id, nodes, deps)
+            if manager.modules[id].is_cache_skeleton:
+                # We have only loaded the cache for this file, not the actual file,
+                # so we can't access the nodes to reprocess.
+                # Add it to the queue of files that need to be processed fully.
+                remaining_modules.append((id, manager.modules[id].path))
+            else:
+                triggered |= reprocess_nodes(manager, graph, id, nodes, deps)
         # Changes elsewhere may require us to reprocess modules that were
         # previously considered up to date. For example, there may be a
         # dependency loop that loops back to an originally processed module.
         up_to_date_modules = set()
         targets_with_errors = set()
-        if DEBUG:
-            print('triggered:', list(triggered))
+        if manager.options.verbosity >= 1:
+            manager.log('fine-grained: triggered: %r' % list(triggered))
+
+    return remaining_modules
 
 
 def find_targets_recursive(
+        manager: BuildManager,
         triggers: Set[str],
         deps: Dict[str, Set[str]],
         modules: Dict[str, MypyFile],
@@ -776,8 +793,7 @@ def find_targets_recursive(
                     continue
                 if module_id not in result:
                     result[module_id] = set()
-                if DEBUG:
-                    print('process', target)
+                manager.log('fine-grained: process %s' % target)
                 deferred = lookup_target(modules, target)
                 result[module_id].update(deferred)
 
@@ -794,8 +810,8 @@ def reprocess_nodes(manager: BuildManager,
     Return fired triggers.
     """
     if module_id not in manager.saved_cache or module_id not in graph:
-        if DEBUG:
-            print('%s not in saved cache or graph (blocking errors or deleted?)' % module_id)
+        manager.log('fine-grained: %s not in saved cache or graph (blocking errors or deleted?)' %
+                    module_id)
         return set()
 
     file_node = manager.modules[module_id]
@@ -992,4 +1008,6 @@ def lookup_target(modules: Dict[str, MypyFile], target: str) -> List[DeferredNod
 
 
 def extract_type_maps(graph: Graph) -> Dict[str, Dict[Expression, Type]]:
-    return {id: state.type_map() for id, state in graph.items()}
+    # This is used to export information used only by the testmerge harness.
+    return {id: state.type_map() for id, state in graph.items()
+            if state.tree}
diff --git a/mypy/sharedparse.py b/mypy/sharedparse.py
index 1b3e5a3a94..91015b6d69 100755
--- a/mypy/sharedparse.py
+++ b/mypy/sharedparse.py
@@ -16,7 +16,6 @@
     "__delitem__",
     "__divmod__",
     "__div__",
-    "__divmod__",
     "__enter__",
     "__exit__",
     "__eq__",
@@ -92,6 +91,52 @@
 
 MAGIC_METHODS_POS_ARGS_ONLY = MAGIC_METHODS - MAGIC_METHODS_ALLOWING_KWARGS
 
+BINARY_MAGIC_METHODS = {
+    "__add__",
+    "__and__",
+    "__cmp__",
+    "__divmod__",
+    "__div__",
+    "__eq__",
+    "__floordiv__",
+    "__ge__",
+    "__gt__",
+    "__iadd__",
+    "__iand__",
+    "__idiv__",
+    "__ifloordiv__",
+    "__ilshift__",
+    "__imod__",
+    "__imul__",
+    "__ior__",
+    "__ipow__",
+    "__irshift__",
+    "__isub__",
+    "__ixor__",
+    "__le__",
+    "__lshift__",
+    "__lt__",
+    "__mod__",
+    "__mul__",
+    "__or__",
+    "__pow__",
+    "__radd__",
+    "__rand__",
+    "__rdiv__",
+    "__rfloordiv__",
+    "__rlshift__",
+    "__rmod__",
+    "__rmul__",
+    "__ror__",
+    "__rpow__",
+    "__rrshift__",
+    "__rshift__",
+    "__rsub__",
+    "__rxor__",
+    "__sub__",
+    "__xor__",
+}
+
 
 def special_function_elide_names(name: str) -> bool:
     return name in MAGIC_METHODS_POS_ARGS_ONLY
diff --git a/mypy/test/data.py b/mypy/test/data.py
index 0be3be2e3f..e948aaaecc 100755
--- a/mypy/test/data.py
+++ b/mypy/test/data.py
@@ -2,6 +2,7 @@
 
 import os.path
 import os
+import tempfile
 import posixpath
 import re
 from os import remove, rmdir
@@ -11,7 +12,6 @@
 import pytest  # type: ignore  # no pytest in typeshed
 from typing import List, Tuple, Set, Optional, Iterator, Any, Dict, NamedTuple, Union
 
-from mypy.myunit import BaseTestCase
 from mypy.test.config import test_data_prefix, test_temp_dir
 
 root_dir = os.path.normpath(os.path.join(os.path.dirname(__file__), '..', '..'))
@@ -192,7 +192,7 @@ def parse_test_cases(
     return out
 
 
-class DataDrivenTestCase(BaseTestCase):
+class DataDrivenTestCase:
     """Holds parsed data and handles directory setup and teardown for MypyDataCase."""
 
     # TODO: rename to ParsedTestCase or merge with MypyDataCase (yet avoid multiple inheritance)
@@ -229,7 +229,9 @@ def __init__(self,
                  native_sep: bool = False,
                  triggered: Optional[List[str]] = None,
                  ) -> None:
-        super().__init__(name)
+        self.name = name
+        self.old_cwd = None  # type: Optional[str]
+        self.tmpdir = None  # type: Optional[tempfile.TemporaryDirectory[str]]
         self.input = input
         self.output = output
         self.output2 = output2
@@ -245,7 +247,10 @@ def __init__(self,
         self.triggered = triggered or []
 
     def setup(self) -> None:
-        super().setup()
+        self.old_cwd = os.getcwd()
+        self.tmpdir = tempfile.TemporaryDirectory(prefix='mypy-test-')
+        os.chdir(self.tmpdir.name)
+        os.mkdir('tmp')
         encountered_files = set()
         self.clean_up = []
         for paths in self.deleted_paths.values():
@@ -321,7 +326,15 @@ def teardown(self) -> None:
                     if path.startswith(test_temp_dir + '/') and os.path.isdir(path):
                         shutil.rmtree(path)
                     raise
-        super().teardown()
+        assert self.old_cwd is not None and self.tmpdir is not None, \
+            "test was not properly set up"
+        os.chdir(self.old_cwd)
+        try:
+            self.tmpdir.cleanup()
+        except OSError:
+            pass
+        self.old_cwd = None
+        self.tmpdir = None
 
     def find_steps(self) -> List[List[FileOperation]]:
         """Return a list of descriptions of file operations for each incremental step.
@@ -614,8 +627,10 @@ def __init__(self, name: str, parent: MypyDataSuite, case: DataDrivenTestCase) -
     def runtest(self) -> None:
         if self.skip:
             pytest.skip()
-        update_data = self.config.getoption('--update-data', False)
-        self.parent.obj(update_data=update_data).run_case(self.case)
+        suite = self.parent.obj()
+        suite.update_data = self.config.getoption('--update-data', False)
+        suite.setup()
+        suite.run_case(self.case)
 
     def setup(self) -> None:
         self.case.setup()
@@ -643,12 +658,16 @@ def repr_failure(self, excinfo: Any) -> str:
 class DataSuite:
     # option fields - class variables
     files = None  # type: List[str]
-    base_path = '.'  # type: str
-    optional_out = False  # type: bool
-    native_sep = False  # type: bool
+    base_path = '.'
+    optional_out = False
+    native_sep = False
 
-    def __init__(self, *, update_data: bool) -> None:
-        self.update_data = update_data
+    # Assigned from MypyDataCase.runtest
+    update_data = False
+
+    def setup(self) -> None:
+        """Setup fixtures (ad-hoc)"""
+        pass
 
     @abstractmethod
     def run_case(self, testcase: DataDrivenTestCase) -> None:
diff --git a/mypy/test/helpers.py b/mypy/test/helpers.py
index 169a02e76c..daffa8344d 100755
--- a/mypy/test/helpers.py
+++ b/mypy/test/helpers.py
@@ -3,14 +3,21 @@
 import sys
 import time
 
-from typing import List, Dict, Tuple, Callable, Any
+from typing import List, Dict, Tuple, Callable, Any, Optional
 
 from mypy import defaults
-from mypy.myunit import AssertionFailure
+
+import pytest  # type: ignore  # no pytest in typeshed
+
+# Exporting Suite as alias to TestCase for backwards compatibility
+# TODO: avoid aliasing - import and subclass TestCase directly
+from unittest import TestCase as Suite
+
 from mypy.main import process_options
 from mypy.options import Options
 from mypy.test.data import DataDrivenTestCase
 
+skip = pytest.mark.skip
 
 # AssertStringArraysEqual displays special line alignment helper messages if
 # the first different line has at least this many characters,
@@ -85,7 +92,7 @@ def assert_string_arrays_equal(expected: List[str], actual: List[str],
             # long lines.
             show_align_message(expected[first_diff], actual[first_diff])
 
-        raise AssertionFailure(msg)
+        raise AssertionError(msg)
 
 
 def update_testcase_output(testcase: DataDrivenTestCase, output: List[str]) -> None:
@@ -171,21 +178,6 @@ def show_align_message(s1: str, s2: str) -> None:
     sys.stderr.write('\n')
 
 
-def assert_string_arrays_equal_wildcards(expected: List[str],
-                                         actual: List[str],
-                                         msg: str) -> None:
-    # Like above, but let a line with only '...' in expected match any number
-    # of lines in actual.
-    actual = clean_up(actual)
-
-    while actual != [] and actual[-1] == '':
-        actual = actual[:-1]
-
-    # Expand "..." wildcards away.
-    expected = match_array(expected, actual)
-    assert_string_arrays_equal(expected, actual, msg)
-
-
 def clean_up(a: List[str]) -> List[str]:
     """Remove common directory prefix from all strings in a.
 
@@ -205,52 +197,6 @@ def clean_up(a: List[str]) -> List[str]:
     return res
 
 
-def match_array(pattern: List[str], target: List[str]) -> List[str]:
-    """Expand '...' wildcards in pattern by matching against target."""
-
-    res = []  # type: List[str]
-    i = 0
-    j = 0
-
-    while i < len(pattern):
-        if pattern[i] == '...':
-            # Wildcard in pattern.
-            if i + 1 == len(pattern):
-                # Wildcard at end of pattern; match the rest of target.
-                res.extend(target[j:])
-                # Finished.
-                break
-            else:
-                # Must find the instance of the next pattern line in target.
-                jj = j
-                while jj < len(target):
-                    if target[jj] == pattern[i + 1]:
-                        break
-                    jj += 1
-                if jj == len(target):
-                    # No match. Get out.
-                    res.extend(pattern[i:])
-                    break
-                res.extend(target[j:jj])
-                i += 1
-                j = jj
-        elif (j < len(target) and (pattern[i] == target[j]
-                                   or (i + 1 < len(pattern)
-                                       and j + 1 < len(target)
-                                       and pattern[i + 1] == target[j + 1]))):
-            # In sync; advance one line. The above condition keeps sync also if
-            # only a single line is different, but loses it if two consecutive
-            # lines fail to match.
-            res.append(pattern[i])
-            i += 1
-            j += 1
-        else:
-            # Out of sync. Get out.
-            res.extend(pattern[i:])
-            break
-    return res
-
-
 def num_skipped_prefix_lines(a1: List[str], a2: List[str]) -> int:
     num_eq = 0
     while num_eq < min(len(a1), len(a2)) and a1[num_eq] == a2[num_eq]:
@@ -311,6 +257,48 @@ def retry_on_error(func: Callable[[], Any], max_wait: float = 1.0) -> None:
                 raise
             time.sleep(wait_time)
 
+# TODO: assert_true and assert_false are redundant - use plain assert
+
+
+def assert_true(b: bool, msg: Optional[str] = None) -> None:
+    if not b:
+        raise AssertionError(msg)
+
+
+def assert_false(b: bool, msg: Optional[str] = None) -> None:
+    if b:
+        raise AssertionError(msg)
+
+
+def good_repr(obj: object) -> str:
+    if isinstance(obj, str):
+        if obj.count('\n') > 1:
+            bits = ["'''\\"]
+            for line in obj.split('\n'):
+                # force repr to use ' not ", then cut it off
+                bits.append(repr('"' + line)[2:-1])
+            bits[-1] += "'''"
+            return '\n'.join(bits)
+    return repr(obj)
+
+
+def assert_equal(a: object, b: object, fmt: str = '{} != {}') -> None:
+    if a != b:
+        raise AssertionError(fmt.format(good_repr(a), good_repr(b)))
+
+
+def typename(t: type) -> str:
+    if '.' in str(t):
+        return str(t).split('.')[-1].rstrip("'>")
+    else:
+        return str(t)[8:-2]
+
+
+def assert_type(typ: type, value: object) -> None:
+    if type(value) != typ:
+        raise AssertionError('Invalid type {}, expected {}'.format(
+            typename(type(value)), typename(typ)))
+
 
 def parse_options(program_text: str, testcase: DataDrivenTestCase,
                   incremental_step: int) -> Options:
diff --git a/mypy/test/testargs.py b/mypy/test/testargs.py
index edee17b90f..20db610cda 100755
--- a/mypy/test/testargs.py
+++ b/mypy/test/testargs.py
@@ -5,8 +5,8 @@
 object it creates.
 """
 
-from mypy.myunit import Suite, assert_equal
-from mypy.options import Options, BuildType
+from mypy.test.helpers import Suite, assert_equal
+from mypy.options import Options
 from mypy.main import process_options
 
 
@@ -14,4 +14,6 @@ class ArgSuite(Suite):
     def test_coherence(self) -> None:
         options = Options()
         _, parsed_options = process_options([], require_targets=False)
+        # FIX: test this too. Requires changing working dir to avoid finding 'setup.cfg'
+        options.config_file = parsed_options.config_file
         assert_equal(options, parsed_options)
diff --git a/mypy/test/testcheck.py b/mypy/test/testcheck.py
index 0bdf645e25..ddcf9de533 100755
--- a/mypy/test/testcheck.py
+++ b/mypy/test/testcheck.py
@@ -8,7 +8,6 @@
 
 from mypy import build, defaults
 from mypy.build import BuildSource, find_module_clear_caches
-from mypy.myunit import AssertionFailure
 from mypy.test.config import test_temp_dir
 from mypy.test.data import DataDrivenTestCase, DataSuite
 from mypy.test.helpers import (
@@ -246,8 +245,8 @@ def verify_cache(self, module_data: List[Tuple[str, str, str]], a: List[str],
         modules.update({module_name: path for module_name, path, text in module_data})
         missing_paths = self.find_missing_cache_files(modules, manager)
         if not missing_paths.issubset(error_paths):
-            raise AssertionFailure("cache data discrepancy %s != %s" %
-                                   (missing_paths, error_paths))
+            raise AssertionError("cache data discrepancy %s != %s" %
+                                 (missing_paths, error_paths))
 
     def find_error_paths(self, a: List[str]) -> Set[str]:
         hits = set()
diff --git a/mypy/test/testcmdline.py b/mypy/test/testcmdline.py
index 05ea436569..57910c1a1d 100755
--- a/mypy/test/testcmdline.py
+++ b/mypy/test/testcmdline.py
@@ -11,7 +11,6 @@
 
 from typing import List
 
-from mypy.myunit import AssertionFailure
 from mypy.test.config import test_temp_dir
 from mypy.test.data import fix_cobertura_filename
 from mypy.test.data import DataDrivenTestCase, DataSuite
@@ -65,7 +64,7 @@ def test_python_cmdline(testcase: DataDrivenTestCase) -> None:
     if testcase.output_files:
         for path, expected_content in testcase.output_files:
             if not os.path.exists(path):
-                raise AssertionFailure(
+                raise AssertionError(
                     'Expected file {} was not produced by test case'.format(path))
             with open(path, 'r') as output_file:
                 actual_output_content = output_file.read().splitlines()
diff --git a/mypy/test/testdmypy.py b/mypy/test/testdmypy.py
index ef2f87e64d..7d9f96a4c7 100755
--- a/mypy/test/testdmypy.py
+++ b/mypy/test/testdmypy.py
@@ -10,7 +10,6 @@
 from mypy import build
 from mypy import defaults
 from mypy.main import process_options
-from mypy.myunit import AssertionFailure
 from mypy.test.config import test_temp_dir
 from mypy.test.data import DataDrivenTestCase, DataSuite, has_stable_flags, is_incremental
 from mypy.test.helpers import (
@@ -44,7 +43,7 @@
 STUB_SUFFIX = '_stub'
 
 
-class TypeCheckSuite(DataSuite):
+class DmypySuite(DataSuite):
     files = dmypy_files
     base_path = test_temp_dir
     optional_out = True
@@ -120,6 +119,7 @@ def run_case_once(self, testcase: DataDrivenTestCase, incremental_step: int) ->
             server_options = []  # type: List[str]
             if 'fine-grained' in testcase.file:
                 server_options.append('--experimental')
+                options.fine_grained_incremental = True
             self.server = dmypy_server.Server(server_options)  # TODO: Fix ugly API
             self.server.options = options
 
@@ -195,8 +195,8 @@ def verify_cache(self, module_data: List[Tuple[str, str, Optional[str]]], a: Lis
         modules.update({module_name: path for module_name, path, text in module_data})
         missing_paths = self.find_missing_cache_files(modules, manager)
         if not missing_paths.issubset(error_paths):
-            raise AssertionFailure("cache data discrepancy %s != %s" %
-                                   (missing_paths, error_paths))
+            raise AssertionError("cache data discrepancy %s != %s" %
+                                 (missing_paths, error_paths))
 
     def find_error_paths(self, a: List[str]) -> Set[str]:
         hits = set()
diff --git a/mypy/test/testerrorstream.py b/mypy/test/testerrorstream.py
index 55e4e3d922..b67451db78 100755
--- a/mypy/test/testerrorstream.py
+++ b/mypy/test/testerrorstream.py
@@ -5,7 +5,6 @@
 
 from mypy import defaults, build
 from mypy.test.config import test_temp_dir
-from mypy.myunit import AssertionFailure
 from mypy.test.helpers import assert_string_arrays_equal
 from mypy.test.data import DataDrivenTestCase, DataSuite
 from mypy.build import BuildSource
diff --git a/mypy/test/testfinegrained.py b/mypy/test/testfinegrained.py
index a442f1052e..5cd5c04320 100755
--- a/mypy/test/testfinegrained.py
+++ b/mypy/test/testfinegrained.py
@@ -30,6 +30,7 @@
 from mypy.test.testtypegen import ignore_node
 from mypy.types import TypeStrVisitor, Type
 from mypy.util import short_type
+import pytest  # type: ignore  # no pytest in typeshed
 
 
 class FineGrainedSuite(DataSuite):
@@ -41,17 +42,44 @@ class FineGrainedSuite(DataSuite):
     ]
     base_path = test_temp_dir
     optional_out = True
+    # Whether to use the fine-grained cache in the testing. This is overridden
+    # by a trivial subclass to produce a suite that uses the cache.
+    use_cache = False
+
+    # Decide whether to skip the test. This could have been structured
+    # as a filter() classmethod also, but we want the tests reported
+    # as skipped, not just elided.
+    def should_skip(self, testcase: DataDrivenTestCase) -> bool:
+        if self.use_cache:
+            if testcase.name.endswith("-skip-cache"):
+                return True
+            # TODO: In caching mode we currently don't well support
+            # starting from cached states with errors in them.
+            if testcase.output and testcase.output[0] != '==':
+                return True
+        else:
+            if testcase.name.endswith("-skip-nocache"):
+                return True
+
+        return False
 
     def run_case(self, testcase: DataDrivenTestCase) -> None:
+        if self.should_skip(testcase):
+            pytest.skip()
+            return
+
         main_src = '\n'.join(testcase.input)
         sources_override = self.parse_sources(main_src)
-        messages, manager, graph = self.build(main_src, testcase, sources_override)
-
+        messages, manager, graph = self.build(main_src, testcase, sources_override,
+                                              build_cache=self.use_cache,
+                                              enable_cache=self.use_cache)
         a = []
         if messages:
             a.extend(normalize_messages(messages))
 
-        fine_grained_manager = FineGrainedBuildManager(manager, graph)
+        fine_grained_manager = None
+        if not self.use_cache:
+            fine_grained_manager = FineGrainedBuildManager(manager, graph)
 
         steps = testcase.find_steps()
         all_triggered = []
@@ -70,6 +98,14 @@ def run_case(self, testcase: DataDrivenTestCase) -> None:
                 modules = [(module, path)
                            for module, path in sources_override
                            if any(m == module for m, _ in modules)]
+
+            # If this is the second iteration and we are using a
+            # cache, now we need to set it up
+            if fine_grained_manager is None:
+                messages, manager, graph = self.build(main_src, testcase, sources_override,
+                                                      build_cache=False, enable_cache=True)
+                fine_grained_manager = FineGrainedBuildManager(manager, graph)
+
             new_messages = fine_grained_manager.update(modules)
             all_triggered.append(fine_grained_manager.triggered)
             new_messages = normalize_messages(new_messages)
@@ -82,8 +118,8 @@ def run_case(self, testcase: DataDrivenTestCase) -> None:
 
         assert_string_arrays_equal(
             testcase.output, a,
-            'Invalid output ({}, line {})'.format(testcase.file,
-                                                  testcase.line))
+            'Invalid output ({}, line {})'.format(
+                testcase.file, testcase.line))
 
         if testcase.triggered:
             assert_string_arrays_equal(
@@ -95,14 +131,18 @@ def run_case(self, testcase: DataDrivenTestCase) -> None:
     def build(self,
               source: str,
               testcase: DataDrivenTestCase,
-              sources_override: Optional[List[Tuple[str, str]]]) -> Tuple[List[str],
-                                                                          BuildManager,
-                                                                          Graph]:
+              sources_override: Optional[List[Tuple[str, str]]],
+              build_cache: bool,
+              enable_cache: bool) -> Tuple[List[str], BuildManager, Graph]:
         # This handles things like '# flags: --foo'.
         options = parse_options(source, testcase, incremental_step=1)
         options.incremental = True
         options.use_builtins_fixtures = True
         options.show_traceback = True
+        options.fine_grained_incremental = not build_cache
+        options.use_fine_grained_cache = enable_cache and not build_cache
+        options.cache_fine_grained = enable_cache
+
         main_path = os.path.join(test_temp_dir, 'main')
         with open(main_path, 'w') as f:
             f.write(source)
diff --git a/mypy/test/testfinegrainedcache.py b/mypy/test/testfinegrainedcache.py
new file mode 100755
index 0000000000..78701016ef
--- /dev/null
+++ b/mypy/test/testfinegrainedcache.py
@@ -0,0 +1,12 @@
+"""Tests for fine-grained incremental checking using the cache.
+
+All of the real code for this lives in testfinegrained.py.
+"""
+
+# We can't "import FineGrainedSuite from ..." because that will cause pytest
+# to collect the non-caching tests when running this file.
+import mypy.test.testfinegrained
+
+
+class FineGrainedCacheSuite(mypy.test.testfinegrained.FineGrainedSuite):
+    use_cache = True
diff --git a/mypy/test/testgraph.py b/mypy/test/testgraph.py
index e47234925b..33d10c0ae1 100755
--- a/mypy/test/testgraph.py
+++ b/mypy/test/testgraph.py
@@ -2,14 +2,13 @@
 
 from typing import AbstractSet, Dict, Set, List
 
-from mypy.myunit import Suite, assert_equal
+from mypy.test.helpers import assert_equal, Suite
 from mypy.build import BuildManager, State, BuildSourceSet
 from mypy.build import topsort, strongly_connected_components, sorted_components, order_ascc
 from mypy.version import __version__
 from mypy.options import Options
 from mypy.report import Reports
 from mypy.plugin import Plugin
-from mypy import defaults
 from mypy.errors import Errors
 
 
diff --git a/mypy/test/testinfer.py b/mypy/test/testinfer.py
index 39ab474667..8fc6bf2cfe 100755
--- a/mypy/test/testinfer.py
+++ b/mypy/test/testinfer.py
@@ -2,7 +2,7 @@
 
 from typing import List, Optional, Tuple, Union
 
-from mypy.myunit import Suite, assert_equal, assert_true
+from mypy.test.helpers import Suite, assert_equal
 from mypy.checkexpr import map_actuals_to_formals
 from mypy.nodes import ARG_POS, ARG_OPT, ARG_STAR, ARG_STAR2, ARG_NAMED
 from mypy.types import AnyType, TupleType, Type, TypeOfAny
diff --git a/mypy/test/testmerge.py b/mypy/test/testmerge.py
index 7cbf8041b7..cc79958d5c 100755
--- a/mypy/test/testmerge.py
+++ b/mypy/test/testmerge.py
@@ -45,8 +45,8 @@ class ASTMergeSuite(DataSuite):
     base_path = test_temp_dir
     optional_out = True
 
-    def __init__(self, *, update_data: bool) -> None:
-        super().__init__(update_data=update_data)
+    def setup(self) -> None:
+        super().setup()
         self.str_conv = StrConv(show_ids=True)
         assert self.str_conv.id_mapper is not None
         self.id_mapper = self.str_conv.id_mapper  # type: IdMapper
@@ -99,6 +99,7 @@ def run_case(self, testcase: DataDrivenTestCase) -> None:
     def build(self, source: str) -> Tuple[List[str], Optional[BuildManager], Dict[str, State]]:
         options = Options()
         options.incremental = True
+        options.fine_grained_incremental = True
         options.use_builtins_fixtures = True
         options.show_traceback = True
         main_path = os.path.join(test_temp_dir, 'main')
diff --git a/mypy/test/testmoduleinfo.py b/mypy/test/testmoduleinfo.py
index 581847914c..329eccc285 100755
--- a/mypy/test/testmoduleinfo.py
+++ b/mypy/test/testmoduleinfo.py
@@ -1,7 +1,5 @@
 from mypy import moduleinfo
-from mypy.myunit import (
-    Suite, assert_equal, assert_true, assert_false
-)
+from mypy.test.helpers import assert_true, assert_false, Suite
 
 
 class ModuleInfoSuite(Suite):
diff --git a/mypy/test/testparse.py b/mypy/test/testparse.py
index 17546d87e6..2c0350f92c 100755
--- a/mypy/test/testparse.py
+++ b/mypy/test/testparse.py
@@ -1,8 +1,6 @@
 """Tests for the mypy parser."""
-from typing import List
 
 from mypy import defaults
-from mypy.myunit import AssertionFailure
 from mypy.test.helpers import assert_string_arrays_equal
 from mypy.test.data import DataDrivenTestCase, DataSuite
 from mypy.parse import parse
@@ -61,7 +59,7 @@ def test_parse_error(testcase: DataDrivenTestCase) -> None:
         # Compile temporary file. The test file contains non-ASCII characters.
         parse(bytes('\n'.join(testcase.input), 'utf-8'), INPUT_FILE_NAME, '__main__', None,
               Options())
-        raise AssertionFailure('No errors reported')
+        raise AssertionError('No errors reported')
     except CompileError as e:
         assert e.module_with_blocker == '__main__'
         # Verify that there was a compile error and that the error messages
diff --git a/mypy/test/testreports.py b/mypy/test/testreports.py
index 285e833065..84ac3e005b 100755
--- a/mypy/test/testreports.py
+++ b/mypy/test/testreports.py
@@ -1,7 +1,7 @@
 """Test cases for reports generated by mypy."""
 import textwrap
 
-from mypy.myunit import Suite, assert_equal
+from mypy.test.helpers import Suite, assert_equal
 from mypy.report import CoberturaPackage, get_line_rate
 
 import lxml.etree as etree  # type: ignore
diff --git a/mypy/test/testsolve.py b/mypy/test/testsolve.py
index 5d68f6cb61..172e4e4743 100755
--- a/mypy/test/testsolve.py
+++ b/mypy/test/testsolve.py
@@ -2,7 +2,7 @@
 
 from typing import List, Union, Tuple, Optional
 
-from mypy.myunit import Suite, assert_equal
+from mypy.test.helpers import Suite, assert_equal
 from mypy.constraints import SUPERTYPE_OF, SUBTYPE_OF, Constraint
 from mypy.solve import solve_constraints
 from mypy.test.typefixture import TypeFixture
@@ -10,8 +10,7 @@
 
 
 class SolveSuite(Suite):
-    def __init__(self) -> None:
-        super().__init__()
+    def setUp(self) -> None:
         self.fx = TypeFixture()
 
     def test_empty_input(self) -> None:
diff --git a/mypy/test/teststubgen.py b/mypy/test/teststubgen.py
index e292fdd169..7150e44078 100755
--- a/mypy/test/teststubgen.py
+++ b/mypy/test/teststubgen.py
@@ -9,8 +9,7 @@
 
 from typing import List, Tuple
 
-from mypy.myunit import Suite, assert_equal
-from mypy.test.helpers import assert_string_arrays_equal
+from mypy.test.helpers import Suite, assert_equal, assert_string_arrays_equal
 from mypy.test.data import DataSuite, DataDrivenTestCase
 from mypy.errors import CompileError
 from mypy.stubgen import generate_stub, generate_stub_for_module, parse_options, Options
diff --git a/mypy/test/testsubtypes.py b/mypy/test/testsubtypes.py
index 2e5d960809..876f3eaf3c 100755
--- a/mypy/test/testsubtypes.py
+++ b/mypy/test/testsubtypes.py
@@ -1,4 +1,4 @@
-from mypy.myunit import Suite, assert_true
+from mypy.test.helpers import Suite, assert_true, skip
 from mypy.nodes import CONTRAVARIANT, INVARIANT, COVARIANT
 from mypy.subtypes import is_subtype
 from mypy.test.typefixture import TypeFixture, InterfaceTypeFixture
@@ -6,7 +6,7 @@
 
 
 class SubtypingSuite(Suite):
-    def setup(self) -> None:
+    def setUp(self) -> None:
         self.fx = TypeFixture(INVARIANT)
         self.fx_contra = TypeFixture(CONTRAVARIANT)
         self.fx_co = TypeFixture(COVARIANT)
@@ -67,10 +67,9 @@ def test_interface_subtyping(self) -> None:
         self.assert_equivalent(self.fx.f, self.fx.f)
         self.assert_not_subtype(self.fx.a, self.fx.f)
 
+    @skip
     def test_generic_interface_subtyping(self) -> None:
         # TODO make this work
-        self.skip()
-
         fx2 = InterfaceTypeFixture()
 
         self.assert_subtype(fx2.m1, fx2.gfa)
diff --git a/mypy/test/testtransform.py b/mypy/test/testtransform.py
index 5f693b5d23..e5f0c2ceb0 100755
--- a/mypy/test/testtransform.py
+++ b/mypy/test/testtransform.py
@@ -63,7 +63,7 @@ def test_transform(testcase: DataDrivenTestCase) -> None:
                     and not os.path.basename(f.path).startswith('_')
                     and not os.path.splitext(
                         os.path.basename(f.path))[0].endswith('_')):
-                t = TestTransformVisitor()
+                t = TypeAssertTransformVisitor()
                 f = t.mypyfile(f)
                 a += str(f).split('\n')
     except CompileError as e:
@@ -75,7 +75,7 @@ def test_transform(testcase: DataDrivenTestCase) -> None:
                                                                 testcase.line))
 
 
-class TestTransformVisitor(TransformVisitor):
+class TypeAssertTransformVisitor(TransformVisitor):
     def type(self, type: Type) -> Type:
         assert type is not None
         return type
diff --git a/mypy/test/testtypes.py b/mypy/test/testtypes.py
index c8d258fc11..2e8d2c153d 100755
--- a/mypy/test/testtypes.py
+++ b/mypy/test/testtypes.py
@@ -2,9 +2,7 @@
 
 from typing import List, Tuple
 
-from mypy.myunit import (
-    Suite, assert_equal, assert_true, assert_false, assert_type
-)
+from mypy.test.helpers import Suite, assert_equal, assert_true, assert_false, assert_type, skip
 from mypy.erasetype import erase_type
 from mypy.expandtype import expand_type
 from mypy.join import join_types, join_simple
@@ -19,8 +17,7 @@
 
 
 class TypesSuite(Suite):
-    def __init__(self) -> None:
-        super().__init__()
+    def setUp(self) -> None:
         self.x = UnboundType('X')  # Helpers
         self.y = UnboundType('Y')
         self.fx = TypeFixture()
@@ -93,7 +90,7 @@ def test_generic_function_type(self) -> None:
 
 
 class TypeOpsSuite(Suite):
-    def setup(self) -> None:
+    def setUp(self) -> None:
         self.fx = TypeFixture(INVARIANT)
         self.fx_co = TypeFixture(COVARIANT)
         self.fx_contra = TypeFixture(CONTRAVARIANT)
@@ -358,7 +355,7 @@ def callable(self, vars: List[str], *a: Type) -> CallableType:
 
 
 class JoinSuite(Suite):
-    def setup(self) -> None:
+    def setUp(self) -> None:
         self.fx = TypeFixture()
 
     def test_trivial_cases(self) -> None:
@@ -529,31 +526,29 @@ def ov(*items: CallableType) -> Overloaded:
         self.assert_join(ov(c(fx.a, fx.a), c(fx.b, fx.b)), c(any, fx.b), c(any, fx.b))
         self.assert_join(ov(c(fx.a, fx.a), c(any, fx.b)), c(fx.b, fx.b), c(any, fx.b))
 
+    @skip
     def test_join_interface_types(self) -> None:
-        self.skip()  # FIX
         self.assert_join(self.fx.f, self.fx.f, self.fx.f)
         self.assert_join(self.fx.f, self.fx.f2, self.fx.o)
         self.assert_join(self.fx.f, self.fx.f3, self.fx.f)
 
+    @skip
     def test_join_interface_and_class_types(self) -> None:
-        self.skip()  # FIX
-
         self.assert_join(self.fx.o, self.fx.f, self.fx.o)
         self.assert_join(self.fx.a, self.fx.f, self.fx.o)
 
         self.assert_join(self.fx.e, self.fx.f, self.fx.f)
 
+    @skip
     def test_join_class_types_with_interface_result(self) -> None:
-        self.skip()  # FIX
         # Unique result
         self.assert_join(self.fx.e, self.fx.e2, self.fx.f)
 
         # Ambiguous result
         self.assert_join(self.fx.e2, self.fx.e3, self.fx.anyt)
 
+    @skip
     def test_generic_interfaces(self) -> None:
-        self.skip()  # FIX
-
         fx = InterfaceTypeFixture()
 
         self.assert_join(fx.gfa, fx.gfa, fx.gfa)
@@ -628,7 +623,7 @@ def type_callable(self, *a: Type) -> CallableType:
 
 
 class MeetSuite(Suite):
-    def setup(self) -> None:
+    def setUp(self) -> None:
         self.fx = TypeFixture()
 
     def test_trivial_cases(self) -> None:
@@ -761,10 +756,8 @@ def test_meet_class_types_with_shared_interfaces(self) -> None:
         self.assert_meet(self.fx.e, self.fx.e2, self.fx.nonet)
         self.assert_meet(self.fx.e2, self.fx.e3, self.fx.nonet)
 
+    @skip
     def test_meet_with_generic_interfaces(self) -> None:
-        # TODO fix
-        self.skip()
-
         fx = InterfaceTypeFixture()
         self.assert_meet(fx.gfa, fx.m1, fx.m1)
         self.assert_meet(fx.gfa, fx.gfa, fx.gfa)
diff --git a/pytest.ini b/pytest.ini
index cfbac25380..808f581b63 100755
--- a/pytest.ini
+++ b/pytest.ini
@@ -12,8 +12,10 @@ python_files = test*.py
 # and invokes it at the relevant moment.  See
 # http://doc.pytest.org/en/latest/writing_plugins.html#collection-hooks
 
-# Because we provide our own collection logic, disable the default
-# python collector by giving it empty patterns to search for.
+# Both our plugin and unittest provide their own collection logic,
+# So we can disable the default python collector by giving it empty
+# patterns to search for.
+# Note that unittest requires that no "Test*" classes exist.
 python_classes =
 python_functions =
 
diff --git a/runtests.py b/runtests.py
index e9d9a000c6..c2f3361ead 100755
--- a/runtests.py
+++ b/runtests.py
@@ -164,7 +164,6 @@ def add_basic(driver: Driver) -> None:
         driver.add_mypy('file setup.py', 'setup.py')
     driver.add_mypy('file runtests.py', 'runtests.py')
     driver.add_mypy('legacy entry script', 'scripts/mypy')
-    driver.add_mypy('legacy myunit script', 'scripts/myunit')
     # needs typed_ast installed:
     driver.add_mypy('fast-parse', '--fast-parse', 'test-data/samples/hello.py')
 
@@ -209,34 +208,33 @@ def test_path(*names: str):
     'testdeps',
     'testdiff',
     'testfinegrained',
+    'testfinegrainedcache',
     'testmerge',
     'testtransform',
     'testtypegen',
     'testparse',
     'testsemanal',
     'testerrorstream',
-)
-
-SLOW_FILES = test_path(
-    'testpythoneval',
-    'testcmdline',
-    'teststubgen',
-)
-
-MYUNIT_FILES = test_path(
-    'teststubgen',
-    'testargs',
+    # non-data-driven:
     'testgraph',
     'testinfer',
     'testmoduleinfo',
+    'teststubgen',
+    'testargs',
     'testreports',
     'testsolve',
     'testsubtypes',
     'testtypes',
 )
 
+SLOW_FILES = test_path(
+    'testpythoneval',
+    'testcmdline',
+    'teststubgen',
+)
+
 for f in find_files('mypy', prefix='test', suffix='.py'):
-    assert f in PYTEST_FILES + SLOW_FILES + MYUNIT_FILES, f
+    assert f in PYTEST_FILES + SLOW_FILES, f
 
 
 def add_pytest(driver: Driver) -> None:
@@ -244,13 +242,6 @@ def add_pytest(driver: Driver) -> None:
                       [('integration', name) for name in SLOW_FILES])
 
 
-def add_myunit(driver: Driver) -> None:
-    for f in MYUNIT_FILES:
-        mod = file_to_module(f)
-        driver.add_python_mod('myunit unit-test %s' % mod, 'mypy.myunit', '-m', mod,
-                              *driver.arglist, coverage=True)
-
-
 def add_stubs(driver: Driver) -> None:
     # We only test each module in the one version mypy prefers to find.
     # TODO: test stubs for other versions, especially Python 2 stubs.
@@ -311,7 +302,6 @@ def usage(status: int) -> None:
     print('  --ff                   run all tests but run the last failures first')
     print('  -q, --quiet            decrease driver verbosity')
     print('  -jN                    run N tasks at once (default: one per CPU)')
-    print('  -a, --argument ARG     pass an argument to myunit tasks')
     print('  -p, --pytest_arg ARG   pass an argument to pytest tasks')
     print('                         (-v: verbose; glob pattern: filter by test name)')
     print('  -l, --list             list included tasks (after filtering) and exit')
@@ -428,7 +418,6 @@ def main() -> None:
     add_pytest(driver)
     add_basic(driver)
     add_selftypecheck(driver)
-    add_myunit(driver)
     add_imports(driver)
     add_stubs(driver)
     add_stdlibsamples(driver)
diff --git a/setup.py b/setup.py
index 746fb84e6a..0fff83c85b 100755
--- a/setup.py
+++ b/setup.py
@@ -100,7 +100,7 @@ def run(self):
       license='MIT License',
       platforms=['POSIX'],
       py_modules=[],
-      packages=['mypy', 'mypy.test', 'mypy.myunit', 'mypy.server'],
+      packages=['mypy', 'mypy.test', 'mypy.server'],
       entry_points={'console_scripts': ['mypy=mypy.__main__:console_entry',
                                         'stubgen=mypy.stubgen:main',
                                         'dmypy=mypy.dmypy:main',
diff --git a/test-data/unit/check-incremental.test b/test-data/unit/check-incremental.test
index 653db57256..ebd17c2b34 100755
--- a/test-data/unit/check-incremental.test
+++ b/test-data/unit/check-incremental.test
@@ -3466,3 +3466,14 @@ tmp/main.py:2: error: Expression has type "Any"
 
 [out2]
 tmp/main.py:2: error: Expression has type "Any"
+
+[case testDeletedDepLineNumber]
+# The import is not on line 1 and that data should be preserved
+import a
+[file a.py]
+[delete a.py.2]
+[out1]
+
+[out2]
+main:2: error: Cannot find module named 'a'
+main:2: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
diff --git a/test-data/unit/check-warnings.test b/test-data/unit/check-warnings.test
index 4acbfe69df..d812ed83ef 100755
--- a/test-data/unit/check-warnings.test
+++ b/test-data/unit/check-warnings.test
@@ -143,6 +143,21 @@ def f() -> int: return g()
 [out]
 main:4: warning: Returning Any from function declared to return "int"
 
+[case testReturnAnyForNotImplementedInBinaryMagicMethods]
+# flags: --warn-return-any
+class A:
+    def __eq__(self, other: object) -> bool: return NotImplemented
+[builtins fixtures/notimplemented.pyi]
+[out]
+
+[case testReturnAnyForNotImplementedInNormalMethods]
+# flags: --warn-return-any
+class A:
+    def some(self) -> bool: return NotImplemented
+[builtins fixtures/notimplemented.pyi]
+[out]
+main:3: warning: Returning Any from function declared to return "bool"
+
 [case testReturnAnyFromTypedFunctionWithSpecificFormatting]
 # flags: --warn-return-any
 from typing import Any, Tuple
diff --git a/test-data/unit/deps-types.test b/test-data/unit/deps-types.test
index 6704b6f583..f12dd8eb3d 100755
--- a/test-data/unit/deps-types.test
+++ b/test-data/unit/deps-types.test
@@ -243,7 +243,7 @@ class S: pass
 <mod.I> -> <m.A>, <m.f>, m, m.f
 <mod.S> -> <m.A>, <m.f>, m, m.f
 
-[case testAliasDepsGenericClass]
+[case testAliasDepsGenericClass-skip]
 from mod import I, D, S, T
 A = D[S, T]
 class C:
@@ -404,3 +404,71 @@ class S: pass
 <mod.D> -> <m.A>, <m.B>, <m.C.x>, m
 <mod.I> -> <m.A>, <m.B>, <m.C.x>, m
 <mod.S> -> <m.A>, <m.B>, <m.C.x>, m
+
+[case testAliasDepsCast]
+from typing import cast
+from mod import I
+A = I
+def fun() -> None:
+    x = cast(A, 42)
+[file mod.py]
+from typing import TypeVar, Generic
+T = TypeVar('T')
+U = TypeVar('U')
+class D(Generic[T, U]): pass
+class I: pass
+class S: pass
+[out]
+<m.A> -> m, m.fun
+<mod.I.__init__> -> m
+<mod.I> -> <m.A>, m, m.fun
+
+[case testAliasDepsRuntime]
+from mod import I, S, D
+A = I
+x = D[S, A]()
+[file mod.py]
+from typing import TypeVar, Generic
+T = TypeVar('T')
+U = TypeVar('U')
+class D(Generic[T, U]): pass
+class I: pass
+class S: pass
+[out]
+<m.A> -> m
+<m.x> -> m
+<mod.D.__init__> -> m
+<mod.D> -> <m.x>, m
+<mod.I.__init__> -> m
+<mod.I> -> <m.A>, <m.x>, m
+<mod.S> -> <m.x>, m
+
+[case testAliasDepsNamedTuple]
+from typing import NamedTuple
+from mod import I
+A = I
+class P(NamedTuple):
+    x: A
+[file mod.py]
+class I: pass
+[out]
+<m.A> -> m
+<m.P> -> m.P
+<mod.I.__init__> -> m
+<mod.I> -> <m.A>, <m.P.x>, <m.P>, m, m.P
+
+[case testAliasDepsTypedDict]
+from mypy_extensions import TypedDict
+from mod import I
+A = I
+class P(TypedDict):
+    x: A
+[file mod.py]
+class I: pass
+[builtins fixtures/dict.pyi]
+[out]
+<m.A> -> m
+<m.P> -> m.P
+<mod.I.__init__> -> m
+<mod.I> -> <m.A>, <m.P>, m, m.P
+<mypy_extensions.TypedDict> -> m
diff --git a/test-data/unit/fine-grained-blockers.test b/test-data/unit/fine-grained-blockers.test
index 9eaf25eeea..3a746e1ea3 100755
--- a/test-data/unit/fine-grained-blockers.test
+++ b/test-data/unit/fine-grained-blockers.test
@@ -237,7 +237,9 @@ a.py:1: error: invalid syntax
 b.py:3: error: Too many arguments for "f"
 a.py:3: error: Too many arguments for "g"
 
-[case testDeleteFileWithBlockingError]
+[case testDeleteFileWithBlockingError-skip-cache]
+-- Different cache/no-cache tests because:
+-- Error message ordering differs
 import a
 import b
 [file a.py]
@@ -256,6 +258,27 @@ main:1: error: Cannot find module named 'a'
 main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 b.py:1: error: Cannot find module named 'a'
 
+[case testDeleteFileWithBlockingError-skip-nocache]
+-- Different cache/no-cache tests because:
+-- Error message ordering differs
+import a
+import b
+[file a.py]
+def f() -> None: pass
+[file b.py]
+import a
+a.f()
+[file a.py.2]
+x x
+[delete a.py.3]
+[out]
+==
+a.py:1: error: invalid syntax
+==
+b.py:1: error: Cannot find module named 'a'
+b.py:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
+main:1: error: Cannot find module named 'a'
+
 [case testModifyFileWhileBlockingErrorElsewhere]
 import a
 import b
@@ -308,7 +331,10 @@ import blocker2
 ==
 a.py:1: error: "int" not callable
 
-[case testFixingBlockingErrorTriggersDeletion1]
+[case testFixingBlockingErrorTriggersDeletion1-skip-cache]
+-- Disabled in cache mdode:
+-- Cache mode fails to produce the error in the final step, but this is
+-- a manifestation of a bug that can occur in no-cache mode also.
 import a
 
 def g(x: a.A) -> None:
diff --git a/test-data/unit/fine-grained-cycles.test b/test-data/unit/fine-grained-cycles.test
index eeac0b427b..737d0ed0d4 100755
--- a/test-data/unit/fine-grained-cycles.test
+++ b/test-data/unit/fine-grained-cycles.test
@@ -174,7 +174,44 @@ def h() -> None:
 ==
 a.py:1: error: Module 'b' has no attribute 'C'
 
-[case testReferenceToTypeThroughCycleAndReplaceWithFunction]
+[case testReferenceToTypeThroughCycleAndReplaceWithFunction-skip-cache]
+-- Different cache/no-cache tests because:
+-- Cache mode has a "need type annotation" message (like coarse incremental does)
+
+import a
+
+[file a.py]
+from b import C
+
+def f() -> C: pass
+
+[file b.py]
+import a
+
+class C:
+    def g(self) -> None: pass
+
+def h() -> None:
+    c = a.f()
+    c.g()
+
+[file b.py.2]
+import a
+
+def C() -> int: pass
+
+def h() -> None:
+    c = a.f()
+    c.g()
+
+[out]
+==
+a.py:3: error: Invalid type "b.C"
+
+[case testReferenceToTypeThroughCycleAndReplaceWithFunction-skip-nocache]
+-- Different cache/no-cache tests because:
+-- Cache mode has a "need type annotation" message (like coarse incremental does)
+
 import a
 
 [file a.py]
@@ -204,6 +241,7 @@ def h() -> None:
 [out]
 ==
 a.py:3: error: Invalid type "b.C"
+b.py:6: error: Need type annotation for 'c'
 
 -- TODO: More import cycle:
 --
diff --git a/test-data/unit/fine-grained-modules.test b/test-data/unit/fine-grained-modules.test
index 91c7589e63..43f13657a6 100755
--- a/test-data/unit/fine-grained-modules.test
+++ b/test-data/unit/fine-grained-modules.test
@@ -234,7 +234,10 @@ main:1: error: Cannot find module named 'a'
 main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 ==
 
-[case testDeletionOfSubmoduleTriggersImportFrom1]
+[case testDeletionOfSubmoduleTriggersImportFrom1-skip-cache]
+-- Different cache/no-cache tests because:
+-- Cache mode matches the message from regular mode and no-cache mode
+-- matches the message from coarse incremental mode...
 from p import q
 [file p/__init__.py]
 [file p/q.py]
@@ -245,9 +248,23 @@ from p import q
 main:1: error: Cannot find module named 'p.q'
 -- TODO: The following messages are different compared to non-incremental mode
 main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
+==
+
+[case testDeletionOfSubmoduleTriggersImportFrom1-skip-nocache]
+-- Different cache/no-cache tests because:
+-- Cache mode matches the message from regular mode and no-cache mode
+-- matches the message from coarse incremental mode...
+from p import q
+[file p/__init__.py]
+[file p/q.py]
+[delete p/q.py.2]
+[file p/q.py.3]
+[out]
+==
 main:1: error: Module 'p' has no attribute 'q'
 ==
 
+
 [case testDeletionOfSubmoduleTriggersImportFrom2]
 from p.q import f
 f()
@@ -485,8 +502,6 @@ def g() -> None: pass
 ==
 main:1: error: Cannot find module named 'a'
 main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
--- TODO: Remove redundant error message
-main:1: error: Cannot find module named 'b'
 main:2: error: Cannot find module named 'b'
 
 [case testDeleteTwoFilesNoErrors]
@@ -528,8 +543,6 @@ a.py:3: error: Too many arguments for "g"
 ==
 main:1: error: Cannot find module named 'a'
 main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
--- TODO: Remove redundant error message
-main:1: error: Cannot find module named 'b'
 main:2: error: Cannot find module named 'b'
 
 [case testAddFileWhichImportsLibModule]
@@ -735,7 +748,9 @@ a/b.py:3: error: Revealed type is 'Any'
 ==
 a/b.py:3: error: Unsupported operand types for + ("int" and "str")
 
-[case testDeleteModuleWithinPackageInitIgnored]
+[case testDeleteModuleWithinPackageInitIgnored-skip-cache]
+-- Disabled in cache mode because incorrect behavior:
+-- Having deleted files specified on command line seems dodgy, though.
 # cmd: mypy x.py a/b.py
 # flags: --follow-imports=skip --ignore-missing-imports
 [file x.py]
diff --git a/test-data/unit/fine-grained.test b/test-data/unit/fine-grained.test
index cd49ea2da1..7a2055d385 100755
--- a/test-data/unit/fine-grained.test
+++ b/test-data/unit/fine-grained.test
@@ -286,7 +286,9 @@ main:5: error: Module has no attribute "B"
 ==
 main:5: error: Module has no attribute "B"
 
-[case testContinueToReportErrorAtTopLevel]
+[case testContinueToReportErrorAtTopLevel-skip-cache]
+-- Different cache/no-cache tests because:
+-- Error message ordering differs
 import n
 import m
 m.A().f()
@@ -309,6 +311,31 @@ n.py:2: error: "A" has no attribute "g"
 ==
 n.py:2: error: "A" has no attribute "g"
 
+[case testContinueToReportErrorAtTopLevel-skip-nocache]
+-- Different cache/no-cache tests because:
+-- Error message ordering differs
+import n
+import m
+m.A().f()
+[file n.py]
+import m
+m.A().g()
+[file m.py]
+class A:
+    def f(self) -> None: pass
+    def g(self) -> None: pass
+[file m.py.2]
+class A: pass
+[file m.py.3]
+class A:
+    def f(self) -> None: pass
+[out]
+==
+n.py:2: error: "A" has no attribute "g"
+main:3: error: "A" has no attribute "f"
+==
+n.py:2: error: "A" has no attribute "g"
+
 [case testContinueToReportErrorInMethod]
 import m
 class C:
@@ -1081,9 +1108,8 @@ def f() -> Iterator[None]:
 [out]
 main:2: error: Revealed type is 'contextlib.GeneratorContextManager[builtins.None]'
 ==
-a.py:1: error: Cannot find module named 'b'
-a.py:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 a.py:3: error: Cannot find module named 'b'
+a.py:3: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 main:2: error: Revealed type is 'contextlib.GeneratorContextManager[builtins.None]'
 ==
 main:2: error: Revealed type is 'contextlib.GeneratorContextManager[builtins.None]'
@@ -1129,9 +1155,8 @@ def g() -> None:
 [out]
 a.py:11: error: Too many arguments for "h"
 ==
-a.py:1: error: Cannot find module named 'b'
-a.py:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 a.py:10: error: Cannot find module named 'b'
+a.py:10: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 ==
 a.py:11: error: Too many arguments for "h"
 ==
@@ -1164,9 +1189,8 @@ def f(x: List[int]) -> Iterator[None]:
 [builtins fixtures/list.pyi]
 [out]
 ==
-a.py:1: error: Cannot find module named 'b'
-a.py:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 a.py:3: error: Cannot find module named 'b'
+a.py:3: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 ==
 ==
 
@@ -1223,10 +1247,8 @@ def g() -> None: pass
 [delete n.py.2]
 [out]
 ==
-main:1: error: Cannot find module named 'm'
-main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
-main:1: error: Cannot find module named 'n'
 main:2: error: Cannot find module named 'm'
+main:2: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 main:9: error: Cannot find module named 'n'
 
 [case testOverloadSpecialCase]
@@ -1253,10 +1275,8 @@ def g() -> None: pass
 [builtins fixtures/ops.pyi]
 [out]
 ==
-main:1: error: Cannot find module named 'm'
-main:1: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
-main:1: error: Cannot find module named 'n'
 main:2: error: Cannot find module named 'm'
+main:2: note: (Perhaps setting MYPYPATH or using the "--ignore-missing-imports" flag would help)
 main:14: error: Cannot find module named 'n'
 
 [case testRefreshGenericClass]
@@ -1894,7 +1914,7 @@ x: a.A = {str(): int()}
 ==
 b.py:2: error: Dict entry 0 has incompatible type "str": "int"; expected "str": "str"
 
-[case testAliasFineGenericFunc]
+[case testAliasFineGenericFunc-skip]
 import b
 [file a.py]
 from typing import Dict
@@ -1906,12 +1926,11 @@ A = Dict[str, str]
 import a
 def f(x: a.A):
     pass
-reveal_type(f)
+f({str(): int()})
 [builtins fixtures/dict.pyi]
 [out]
-b.py:4: error: Revealed type is 'def (x: builtins.dict[builtins.str, builtins.int]) -> Any'
 ==
-b.py:4: error: Revealed type is 'def (x: builtins.dict[builtins.str, builtins.str]) -> Any'
+b.py:4: error: Dict entry 0 has incompatible type "str": "int"; expected "str": "str"
 
 [case testAliasFineForwardMod]
 import b
@@ -2015,3 +2034,94 @@ def f(x: aa.B):
 [out]
 ==
 b.py:3: error: Dict entry 0 has incompatible type "str": "int"; expected "str": "str"
+
+[case testAliasFineNonGenericToGeneric]
+import b
+[file a.py]
+from typing import Dict, TypeVar
+T = TypeVar('T')
+A = Dict[T, int]
+[file a.py.2]
+A = str
+[file b.py]
+import a
+def f(x: a.A[str]):
+    pass
+[builtins fixtures/dict.pyi]
+[out]
+==
+b.py:2: error: "str" expects no type arguments, but 1 given
+
+[case testAliasFineGenericToNonGeneric]
+import b
+[file a.py]
+A = str
+[file a.py.2]
+from typing import Dict, TypeVar
+T = TypeVar('T')
+A = Dict[T, int]
+[file b.py]
+import a
+def f(x: a.A):
+    pass
+reveal_type(f)
+[builtins fixtures/dict.pyi]
+[out]
+b.py:4: error: Revealed type is 'def (x: builtins.str) -> Any'
+==
+b.py:4: error: Revealed type is 'def (x: builtins.dict[Any, builtins.int]) -> Any'
+
+[case testAliasFineChangedNumberOfTypeVars]
+import b
+[file a.py]
+from typing import Dict, TypeVar
+T = TypeVar('T')
+A = Dict[T, int]
+[file a.py.2]
+from typing import Dict, TypeVar
+T = TypeVar('T')
+S = TypeVar('S')
+A = Dict[T, S]
+[file b.py]
+import a
+def f(x: a.A[str]):
+    pass
+[builtins fixtures/dict.pyi]
+[out]
+==
+b.py:2: error: Bad number of arguments for type alias, expected: 2, given: 1
+
+[case testAliasFineComponentDeleted-skip]
+import b
+[file a.py]
+class B: pass
+[file a.py.2]
+x = 1
+[file b.py]
+import a
+from typing import Dict, TypeVar
+T = TypeVar('T')
+A = Dict[T, a.B]
+def f(x: A[int]):
+    pass
+[builtins fixtures/dict.pyi]
+[out]
+==
+b.py:4: error: Name 'a.B' is not defined
+
+[case testAliasFineTargetDeleted]
+import c
+[file a.py]
+A = int
+[file b.py]
+import a
+B = a.A
+[file b.py.2]
+x = 1
+[file c.py]
+import b
+def f(x: b.B):
+    pass
+[out]
+==
+c.py:2: error: Name 'b.B' is not defined
\ No newline at end of file
diff --git a/test-data/unit/fixtures/notimplemented.pyi b/test-data/unit/fixtures/notimplemented.pyi
new file mode 100755
index 0000000000..e619a6c5ad
--- /dev/null
+++ b/test-data/unit/fixtures/notimplemented.pyi
@@ -0,0 +1,13 @@
+# builtins stub used in NotImplemented related cases.
+from typing import Any, cast
+
+
+class object:
+    def __init__(self) -> None: pass
+
+class type: pass
+class function: pass
+class bool: pass
+class int: pass
+class str: pass
+NotImplemented = cast(Any, None)
diff --git a/test-requirements.txt b/test-requirements.txt
index 5fcaffc402..fb3fa40b5d 100755
--- a/test-requirements.txt
+++ b/test-requirements.txt
@@ -1,5 +1,5 @@
 flake8==3.5.0
-flake8-bugbear==17.12.0; python_version >= '3.5'
+flake8-bugbear==18.2.0; python_version >= '3.5'
 flake8-pyi==17.3.0; python_version >= '3.6'
 lxml==4.1.1
 psutil==5.4.0
