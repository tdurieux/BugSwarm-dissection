diff --git a/doc/data_transforms.rst b/doc/data_transforms.rst
index e861762891ec..4730d32d2b65 100644
--- a/doc/data_transforms.rst
+++ b/doc/data_transforms.rst
@@ -28,6 +28,7 @@ scikit-learn.
     modules/pipeline
     modules/feature_extraction
     modules/preprocessing
+    modules/impute
     modules/unsupervised_reduction
     modules/random_projection
     modules/kernel_approximation
diff --git a/doc/modules/impute.rst b/doc/modules/impute.rst
index e42257abd19b..98ab4cf36b72 100644
--- a/doc/modules/impute.rst
+++ b/doc/modules/impute.rst
@@ -1,9 +1,11 @@
-
 .. _impute:
 
+============================
 Imputation of missing values
 ============================
 
+.. currentmodule:: sklearn.impute
+
 For various reasons, many real world datasets contain missing values, often
 encoded as blanks, NaNs or other placeholders. Such datasets however are
 incompatible with scikit-learn estimators which assume that all values in an
diff --git a/doc/modules/preprocessing.rst b/doc/modules/preprocessing.rst
index 9aac20dca966..7c779161c4b9 100644
--- a/doc/modules/preprocessing.rst
+++ b/doc/modules/preprocessing.rst
@@ -594,54 +594,7 @@ as a dict, not as scalars.
 Imputation of missing values
 ============================
 
-For various reasons, many real world datasets contain missing values, often
-encoded as blanks, NaNs or other placeholders. Such datasets however are
-incompatible with scikit-learn estimators which assume that all values in an
-array are numerical, and that all have and hold meaning. A basic strategy to use
-incomplete datasets is to discard entire rows and/or columns containing missing
-values. However, this comes at the price of losing data which may be valuable
-(even though incomplete). A better strategy is to impute the missing values,
-i.e., to infer them from the known part of the data.
-
-The :class:`Imputer` class provides basic strategies for imputing missing
-values, either using the mean, the median or the most frequent value of
-the row or column in which the missing values are located. This class
-also allows for different missing values encodings.
-
-The following snippet demonstrates how to replace missing values,
-encoded as ``np.nan``, using the mean value of the columns (axis 0)
-that contain the missing values::
-
-    >>> import numpy as np
-    >>> from sklearn.preprocessing import Imputer
-    >>> imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
-    >>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])
-    Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)
-    >>> X = [[np.nan, 2], [6, np.nan], [7, 6]]
-    >>> print(imp.transform(X))                           # doctest: +ELLIPSIS
-    [[ 4.          2.        ]
-     [ 6.          3.666...]
-     [ 7.          6.        ]]
-
-The :class:`Imputer` class also supports sparse matrices::
-
-    >>> import scipy.sparse as sp
-    >>> X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])
-    >>> imp = Imputer(missing_values=0, strategy='mean', axis=0)
-    >>> imp.fit(X)
-    Imputer(axis=0, copy=True, missing_values=0, strategy='mean', verbose=0)
-    >>> X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])
-    >>> print(imp.transform(X_test))                      # doctest: +ELLIPSIS
-    [[ 4.          2.        ]
-     [ 6.          3.666...]
-     [ 7.          6.        ]]
-
-Note that, here, missing values are encoded by 0 and are thus implicitly stored
-in the matrix. This format is thus suitable when there are many more missing
-values than observed values.
-
-:class:`Imputer` can be used in a Pipeline as a way to build a composite
-estimator that supports imputation. See :ref:`sphx_glr_auto_examples_plot_missing_values.py`.
+Tools for imputing missing values are discussed at :ref:`impute`.
 
 .. _polynomial_features:
 
diff --git a/doc/related_projects.rst b/doc/related_projects.rst
index 37dde0d17923..dd8ff1dd0baa 100644
--- a/doc/related_projects.rst
+++ b/doc/related_projects.rst
@@ -45,10 +45,10 @@ enhance the functionality of scikit-learn's estimators.
   scikit-learn estimator.
 
 - `scikit-optimize <https://scikit-optimize.github.io/>`_
-   A library to minimize (very) expensive and noisy black-box functions. It
-   implements several methods for sequential model-based optimization, and
-   includes a replacement for ``GridSearchCV`` or ``RandomizedSearchCV`` to do
-   cross-validated parameter search using any of these strategies.
+  A library to minimize (very) expensive and noisy black-box functions. It
+  implements several methods for sequential model-based optimization, and
+  includes a replacement for ``GridSearchCV`` or ``RandomizedSearchCV`` to do
+  cross-validated parameter search using any of these strategies.
 
 **Experimentation frameworks**
 
diff --git a/sklearn/.vscode/settings.json b/sklearn/.vscode/settings.json
new file mode 100644
index 000000000000..56c2d2dc815a
--- /dev/null
+++ b/sklearn/.vscode/settings.json
@@ -0,0 +1,6 @@
+{
+    "python.unitTest.pyTestArgs": [
+        "tests"
+    ],
+    "python.unitTest.pyTestEnabled": true
+}
\ No newline at end of file
diff --git a/sklearn/metrics/cluster/tests/test_supervised.py b/sklearn/metrics/cluster/tests/test_supervised.py
index cdaea44e8656..933e3ceff363 100644
--- a/sklearn/metrics/cluster/tests/test_supervised.py
+++ b/sklearn/metrics/cluster/tests/test_supervised.py
@@ -45,16 +45,10 @@ def test_error_messages_on_wrong_input():
         assert_raise_message(ValueError, expected, score_func,
                              [0, 1, 0], [[1, 1], [0, 0]])
 
-    score_funcs = [
-        mutual_info_score,
-        adjusted_mutual_info_score,
-        normalized_mutual_info_score
-    ]
-    for score_func in score_funcs:
-        expected = ("Unsupported value for 'log_base': f; allowed"
-                    " values are 2 or 'e'")
-        assert_raise_message(ValueError, expected, score_func,
-                             [0, 0], [0, 0], log_base='f')
+    expected = ("Unsupported value for 'log_base': f; allowed"
+                " values are 2 or 'e'")
+    assert_raise_message(ValueError, expected, entropy, [0, 0],
+                         log_base='f')
 
 
 def test_perfect_matches():
