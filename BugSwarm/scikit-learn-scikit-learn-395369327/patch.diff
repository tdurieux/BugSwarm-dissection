diff --git a/README.rst b/README.rst
index cf011277f539..4df228acd4c4 100644
--- a/README.rst
+++ b/README.rst
@@ -78,6 +78,12 @@ or ``conda``::
 The documentation includes more detailed `installation instructions <http://scikit-learn.org/stable/install.html>`_.
 
 
+Changelog
+---------
+
+See the `changelog <http://scikit-learn.org/dev/whats_new.html>`__
+for a history of notable changes to scikit-learn.
+
 Development
 -----------
 
diff --git a/build_tools/circle/list_versions.py b/build_tools/circle/list_versions.py
index 9bf993c20653..f6696177e06d 100755
--- a/build_tools/circle/list_versions.py
+++ b/build_tools/circle/list_versions.py
@@ -47,6 +47,8 @@ def get_pdf_size(version):
             return human_readable_data_quantity(path_details['size'], 1000)
 
 
+print(':orphan:')
+print()
 heading = 'Available documentation for Scikit-learn'
 print(heading)
 print('=' * len(heading))
diff --git a/doc/conf.py b/doc/conf.py
index a420659af53b..fac3b9fc043f 100644
--- a/doc/conf.py
+++ b/doc/conf.py
@@ -70,9 +70,6 @@
 # The encoding of source files.
 #source_encoding = 'utf-8'
 
-# Generate the plots for the gallery
-plot_gallery = True
-
 # The master toctree document.
 master_doc = 'index'
 
@@ -102,7 +99,7 @@
 
 # List of patterns, relative to source directory, that match files and
 # directories to ignore when looking for source files.
-exclude_patterns = ['_build', 'templates', 'includes']
+exclude_patterns = ['_build', 'templates', 'includes', 'themes']
 
 # The reST default role (used for this markup: `text`) to use for all
 # documents.
diff --git a/doc/conftest.py b/doc/conftest.py
index 158fff5830ac..463df3f38221 100644
--- a/doc/conftest.py
+++ b/doc/conftest.py
@@ -6,6 +6,8 @@
 from sklearn.utils.testing import SkipTest
 from sklearn.utils.testing import check_skip_network
 from sklearn.datasets import get_data_home
+from sklearn.datasets.base import _pkl_filepath
+from sklearn.datasets.twenty_newsgroups import CACHE_NAME
 from sklearn.utils.testing import install_mldata_mock
 from sklearn.utils.testing import uninstall_mldata_mock
 
@@ -47,12 +49,16 @@ def setup_rcv1():
 
 def setup_twenty_newsgroups():
     data_home = get_data_home()
-    if not exists(join(data_home, '20news_home')):
+    cache_path = _pkl_filepath(get_data_home(), CACHE_NAME)
+    if not exists(cache_path):
         raise SkipTest("Skipping dataset loading doctests")
 
 
 def setup_working_with_text_data():
     check_skip_network()
+    cache_path = _pkl_filepath(get_data_home(), CACHE_NAME)
+    if not exists(cache_path):
+        raise SkipTest("Skipping dataset loading doctests")
 
 
 def setup_compose():
@@ -62,20 +68,31 @@ def setup_compose():
         raise SkipTest("Skipping compose.rst, pandas not installed")
 
 
+def setup_impute():
+    try:
+        import pandas  # noqa
+    except ImportError:
+        raise SkipTest("Skipping impute.rst, pandas not installed")
+
+
 def pytest_runtest_setup(item):
     fname = item.fspath.strpath
-    if fname.endswith('datasets/labeled_faces.rst'):
+    is_index = fname.endswith('datasets/index.rst')
+    if fname.endswith('datasets/labeled_faces.rst') or is_index:
         setup_labeled_faces()
-    elif fname.endswith('datasets/mldata.rst'):
+    elif fname.endswith('datasets/mldata.rst') or is_index:
         setup_mldata()
-    elif fname.endswith('datasets/rcv1.rst'):
+    elif fname.endswith('datasets/rcv1.rst') or is_index:
         setup_rcv1()
-    elif fname.endswith('datasets/twenty_newsgroups.rst'):
+    elif fname.endswith('datasets/twenty_newsgroups.rst') or is_index:
         setup_twenty_newsgroups()
-    elif fname.endswith('tutorial/text_analytics/working_with_text_data.rst'):
+    elif fname.endswith('tutorial/text_analytics/working_with_text_data.rst')\
+            or is_index:
         setup_working_with_text_data()
-    elif fname.endswith('modules/compose.rst'):
+    elif fname.endswith('modules/compose.rst') or is_index:
         setup_compose()
+    elif fname.endswith('modules/impute.rst'):
+        setup_impute()
 
 
 def pytest_runtest_teardown(item):
diff --git a/doc/datasets/covtype.rst b/doc/datasets/covtype.rst
index c0ed4ea08af3..4b31eff69cf0 100644
--- a/doc/datasets/covtype.rst
+++ b/doc/datasets/covtype.rst
@@ -1,15 +1,14 @@
-
 .. _covtype:
 
 Forest covertypes
-=================
+-----------------
 
 The samples in this dataset correspond to 30Ã—30m patches of forest in the US,
 collected for the task of predicting each patch's cover type,
 i.e. the dominant species of tree.
 There are seven covertypes, making this a multiclass classification problem.
 Each sample has 54 features, described on the
-`dataset's homepage <http://archive.ics.uci.edu/ml/datasets/Covertype>`_.
+`dataset's homepage <http://archive.ics.uci.edu/ml/datasets/Covertype>`__.
 Some of the features are boolean indicators,
 while others are discrete or continuous measurements.
 
diff --git a/doc/datasets/index.rst b/doc/datasets/index.rst
index 1d27bdfd7f62..73ab66feceaa 100644
--- a/doc/datasets/index.rst
+++ b/doc/datasets/index.rst
@@ -43,12 +43,15 @@ The datasets also contain a description in ``DESCR`` and some contain
 ``feature_names`` and ``target_names``.
 See the dataset descriptions below for details.
 
+.. _toy_datasets:
 
 Toy datasets
 ============
 
 scikit-learn comes with a few small standard datasets that do not
-require to download any file from some external website.
+require to download any file from some external website. 
+
+*desc*
 
 .. autosummary::
 
@@ -67,46 +70,81 @@ These datasets are useful to quickly illustrate the behavior of the
 various algorithms implemented in scikit-learn. They are however often too
 small to be representative of real world machine learning tasks.
 
-.. _sample_images:
+.. toctree::
+    :maxdepth: 2
+    :hidden:
 
-Sample images
-=============
+    boston_house_prices
+    iris
+    diabetes
+    digits
+    linnerud
+    wine_data
+    breast_cancer
 
-Scikit-learn also embed a couple of sample JPEG images published under Creative
-Commons license by their authors. Those image can be useful to test algorithms
-and pipeline on 2D data.
+.. include:: ../../sklearn/datasets/descr/boston_house_prices.rst
+
+.. include:: ../../sklearn/datasets/descr/iris.rst
+
+.. include:: ../../sklearn/datasets/descr/diabetes.rst
+
+.. include:: ../../sklearn/datasets/descr/digits.rst
+
+.. include:: ../../sklearn/datasets/descr/linnerud.rst
+
+.. include:: ../../sklearn/datasets/descr/wine_data.rst
+
+.. include:: ../../sklearn/datasets/descr/breast_cancer.rst
+
+.. _real_world_datasets:
+
+Real world datasets
+===================
+
+*Add desc*
 
 .. autosummary::
 
    :toctree: ../modules/generated/
    :template: function.rst
 
-   load_sample_images
-   load_sample_image
+   fetch_olivetti_faces
+   fetch_20newsgroups
+   fetch_20newsgroups_vectorized
+   fetch_lfw_people
+   fetch_lfw_pairs
+   fetch_covtype
+   fetch_rcv1
+   fetch_kddcup99
 
-.. image:: ../auto_examples/cluster/images/sphx_glr_plot_color_quantization_001.png
-   :target: ../auto_examples/cluster/plot_color_quantization.html
-   :scale: 30
-   :align: right
 
+.. toctree::
+    :maxdepth: 2
+    :hidden:
 
-.. warning::
+    olivetti_faces
+    twenty_newsgroups
+    labeled_faces
+    covtype
+    rcv1
+    kddcup99
 
-  The default coding of images is based on the ``uint8`` dtype to
-  spare memory.  Often machine learning algorithms work best if the
-  input is converted to a floating point representation first.  Also,
-  if you plan to use ``matplotlib.pyplpt.imshow`` don't forget to scale to the range
-  0 - 1 as done in the following example.
+.. include:: ./olivetti_faces.rst
 
-.. topic:: Examples:
+.. include:: ./twenty_newsgroups.rst
 
-    * :ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`
+.. include:: ./labeled_faces.rst
+
+.. include:: ./covtype.rst
+
+.. include:: ./rcv1.rst
 
+.. include:: ./kddcup99.rst
 
-.. _sample_generators:
+.. _generated_datasets:
 
-Sample generators
-=================
+Generated datasets
+==================
 
 In addition, scikit-learn includes various random sample generators that
 can be used to build artificial datasets of controlled size and complexity.
@@ -219,10 +257,50 @@ Generators for decomposition
    make_sparse_spd_matrix
 
 
+.. _loading_other_datasets:
+
+Loading other datasets
+======================
+
+.. _sample_images:
+
+Sample images
+-------------
+
+Scikit-learn also embed a couple of sample JPEG images published under Creative
+Commons license by their authors. Those image can be useful to test algorithms
+and pipeline on 2D data.
+
+.. autosummary::
+
+   :toctree: ../modules/generated/
+   :template: function.rst
+
+   load_sample_images
+   load_sample_image
+
+.. image:: ../auto_examples/cluster/images/sphx_glr_plot_color_quantization_001.png
+   :target: ../auto_examples/cluster/plot_color_quantization.html
+   :scale: 30
+   :align: right
+
+
+.. warning::
+
+  The default coding of images is based on the ``uint8`` dtype to
+  spare memory.  Often machine learning algorithms work best if the
+  input is converted to a floating point representation first.  Also,
+  if you plan to use ``matplotlib.pyplpt.imshow`` don't forget to scale to the range
+  0 - 1 as done in the following example.
+
+.. topic:: Examples:
+
+    * :ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`
+
 .. _libsvm_loader:
 
 Datasets in svmlight / libsvm format
-====================================
+------------------------------------
 
 scikit-learn includes utility functions for loading
 datasets in the svmlight / libsvm format. In this format, each line
@@ -256,10 +334,93 @@ features::
 
  _`Faster API-compatible implementation`: https://github.com/mblondel/svmlight-loader
 
+..
+    For doctests:
+
+    >>> import numpy as np
+    >>> import os
+    >>> import tempfile
+    >>> # Create a temporary folder for the data fetcher
+    >>> custom_data_home = tempfile.mkdtemp()
+    >>> os.makedirs(os.path.join(custom_data_home, 'mldata'))
+
+
+.. _mldata:
+
+Downloading datasets from the mldata.org repository
+---------------------------------------------------
+
+`mldata.org <http://mldata.org>`_ is a public repository for machine learning
+data, supported by the `PASCAL network <http://www.pascal-network.org>`_ .
+
+The ``sklearn.datasets`` package is able to directly download data
+sets from the repository using the function
+:func:`sklearn.datasets.fetch_mldata`.
+
+For example, to download the MNIST digit recognition database::
+
+  >>> from sklearn.datasets import fetch_mldata
+  >>> mnist = fetch_mldata('MNIST original', data_home=custom_data_home)
+
+The MNIST database contains a total of 70000 examples of handwritten digits
+of size 28x28 pixels, labeled from 0 to 9::
+
+  >>> mnist.data.shape
+  (70000, 784)
+  >>> mnist.target.shape
+  (70000,)
+  >>> np.unique(mnist.target)
+  array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
+
+After the first download, the dataset is cached locally in the path
+specified by the ``data_home`` keyword argument, which defaults to
+``~/scikit_learn_data/``::
+
+  >>> os.listdir(os.path.join(custom_data_home, 'mldata'))
+  ['mnist-original.mat']
+
+Data sets in `mldata.org <http://mldata.org>`_ do not adhere to a strict
+naming or formatting convention. :func:`sklearn.datasets.fetch_mldata` is
+able to make sense of the most common cases, but allows to tailor the
+defaults to individual datasets:
+
+* The data arrays in `mldata.org <http://mldata.org>`_ are most often
+  shaped as ``(n_features, n_samples)``. This is the opposite of the
+  ``scikit-learn`` convention, so :func:`sklearn.datasets.fetch_mldata`
+  transposes the matrix by default. The ``transpose_data`` keyword controls
+  this behavior::
+
+    >>> iris = fetch_mldata('iris', data_home=custom_data_home)
+    >>> iris.data.shape
+    (150, 4)
+    >>> iris = fetch_mldata('iris', transpose_data=False,
+    ...                     data_home=custom_data_home)
+    >>> iris.data.shape
+    (4, 150)
+
+* For datasets with multiple columns, :func:`sklearn.datasets.fetch_mldata`
+  tries to identify the target and data columns and rename them to ``target``
+  and ``data``. This is done by looking for arrays named ``label`` and
+  ``data`` in the dataset, and failing that by choosing the first array to be
+  ``target`` and the second to be ``data``. This behavior can be changed with
+  the ``target_name`` and ``data_name`` keywords, setting them to a specific
+  name or index number (the name and order of the columns in the datasets
+  can be found at its `mldata.org <http://mldata.org>`_ under the tab "Data"::
+
+    >>> iris2 = fetch_mldata('datasets-UCI iris', target_name=1, data_name=0,
+    ...                      data_home=custom_data_home)
+    >>> iris3 = fetch_mldata('datasets-UCI iris', target_name='class',
+    ...                      data_name='double0', data_home=custom_data_home)
+
+
+..
+    >>> import shutil
+    >>> shutil.rmtree(custom_data_home)
+
 .. _external_datasets:
 
 Loading from external datasets
-==============================
+------------------------------
 
 scikit-learn works on any numeric data stored as numpy arrays or scipy sparse
 matrices. Other types that are convertible to numeric arrays such as pandas
@@ -295,65 +456,11 @@ refer to:
   for reading WAV files into a numpy array
 
 Categorical (or nominal) features stored as strings (common in pandas DataFrames) 
-will need converting to integers, and integer categorical variables may be best 
-exploited when encoded as one-hot variables 
-(:class:`sklearn.preprocessing.OneHotEncoder`) or similar. 
+will need converting to numerical features using :class:`sklearn.preprocessing.OneHotEncoder`
+or :class:`sklearn.preprocessing.OrdinalEncoder` or similar.
 See :ref:`preprocessing`.
 
 Note: if you manage your own numerical data it is recommended to use an 
 optimized file format such as HDF5 to reduce data load times. Various libraries
 such as H5Py, PyTables and pandas provides a Python interface for reading and 
 writing data in that format.
-
-.. make sure everything is in a toc tree
-
-.. toctree::
-    :maxdepth: 2
-    :hidden:
-
-    olivetti_faces
-    twenty_newsgroups
-    mldata
-    labeled_faces
-    covtype
-    rcv1
-    kddcup99
-
-
-.. include:: olivetti_faces.rst
-
-.. include:: twenty_newsgroups.rst
-
-.. include:: mldata.rst
-
-.. include:: labeled_faces.rst
-
-.. include:: covtype.rst
-
-.. include:: rcv1.rst
-
-.. include:: kddcup99.rst
-
-.. _boston_house_prices:
-
-.. include:: ../../sklearn/datasets/descr/boston_house_prices.rst
-
-.. _breast_cancer:
-
-.. include:: ../../sklearn/datasets/descr/breast_cancer.rst
-
-.. _diabetes:
-
-.. include:: ../../sklearn/datasets/descr/diabetes.rst
-
-.. _digits:
-
-.. include:: ../../sklearn/datasets/descr/digits.rst
-
-.. _iris:
-
-.. include:: ../../sklearn/datasets/descr/iris.rst
-
-.. _linnerud:
-
-.. include:: ../../sklearn/datasets/descr/linnerud.rst
diff --git a/doc/datasets/kddcup99.rst b/doc/datasets/kddcup99.rst
index 407b2d8e2c0b..e770a9a2d60e 100644
--- a/doc/datasets/kddcup99.rst
+++ b/doc/datasets/kddcup99.rst
@@ -1,13 +1,12 @@
-
 .. _kddcup99:
 
 Kddcup 99 dataset
-=================
+-----------------
 
 The KDD Cup '99 dataset was created by processing the tcpdump portions
 of the 1998 DARPA Intrusion Detection System (IDS) Evaluation dataset,
 created by MIT Lincoln Lab. The artificial data (described on the `dataset's
-homepage <http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html>`_) was
+homepage <http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html>`__) was
 generated using a closed network and hand-injected attacks to produce a
 large number of different types of attack with normal activity in the
 background. As the initial goal was to produce a large training set for
diff --git a/doc/datasets/labeled_faces.rst b/doc/datasets/labeled_faces.rst
index 0e70aca8aa70..a7b592ae1a94 100644
--- a/doc/datasets/labeled_faces.rst
+++ b/doc/datasets/labeled_faces.rst
@@ -1,7 +1,7 @@
 .. _labeled_faces_in_the_wild:
 
 The Labeled Faces in the Wild face recognition dataset
-======================================================
+------------------------------------------------------
 
 This dataset is a collection of JPEG pictures of famous people collected
 over the internet, all details are available on the official website:
@@ -25,7 +25,7 @@ face detector from various online websites.
 
 
 Usage
------
+~~~~~
 
 ``scikit-learn`` provides two loaders that will automatically download,
 cache, parse the metadata files, decode the jpeg and convert the
@@ -113,6 +113,6 @@ an evaluation ``10_folds`` set meant to compute performance metrics using a
 
 
 Examples
---------
+~~~~~~~~
 
 :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`
diff --git a/doc/datasets/mldata.rst b/doc/datasets/mldata.rst
deleted file mode 100644
index b098abbdcef9..000000000000
--- a/doc/datasets/mldata.rst
+++ /dev/null
@@ -1,82 +0,0 @@
-..
-    For doctests:
-
-    >>> import numpy as np
-    >>> import os
-    >>> import tempfile
-    >>> # Create a temporary folder for the data fetcher
-    >>> custom_data_home = tempfile.mkdtemp()
-    >>> os.makedirs(os.path.join(custom_data_home, 'mldata'))
-
-
-.. _mldata:
-
-Downloading datasets from the mldata.org repository
-===================================================
-
-`mldata.org <http://mldata.org>`_ is a public repository for machine learning
-data, supported by the `PASCAL network <http://www.pascal-network.org>`_ .
-
-The ``sklearn.datasets`` package is able to directly download data
-sets from the repository using the function
-:func:`sklearn.datasets.fetch_mldata`.
-
-For example, to download the MNIST digit recognition database::
-
-  >>> from sklearn.datasets import fetch_mldata
-  >>> mnist = fetch_mldata('MNIST original', data_home=custom_data_home)
-
-The MNIST database contains a total of 70000 examples of handwritten digits
-of size 28x28 pixels, labeled from 0 to 9::
-
-  >>> mnist.data.shape
-  (70000, 784)
-  >>> mnist.target.shape
-  (70000,)
-  >>> np.unique(mnist.target)
-  array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
-
-After the first download, the dataset is cached locally in the path
-specified by the ``data_home`` keyword argument, which defaults to
-``~/scikit_learn_data/``::
-
-  >>> os.listdir(os.path.join(custom_data_home, 'mldata'))
-  ['mnist-original.mat']
-
-Data sets in `mldata.org <http://mldata.org>`_ do not adhere to a strict
-naming or formatting convention. :func:`sklearn.datasets.fetch_mldata` is
-able to make sense of the most common cases, but allows to tailor the
-defaults to individual datasets:
-
-* The data arrays in `mldata.org <http://mldata.org>`_ are most often
-  shaped as ``(n_features, n_samples)``. This is the opposite of the
-  ``scikit-learn`` convention, so :func:`sklearn.datasets.fetch_mldata`
-  transposes the matrix by default. The ``transpose_data`` keyword controls
-  this behavior::
-
-    >>> iris = fetch_mldata('iris', data_home=custom_data_home)
-    >>> iris.data.shape
-    (150, 4)
-    >>> iris = fetch_mldata('iris', transpose_data=False,
-    ...                     data_home=custom_data_home)
-    >>> iris.data.shape
-    (4, 150)
-
-* For datasets with multiple columns, :func:`sklearn.datasets.fetch_mldata`
-  tries to identify the target and data columns and rename them to ``target``
-  and ``data``. This is done by looking for arrays named ``label`` and
-  ``data`` in the dataset, and failing that by choosing the first array to be
-  ``target`` and the second to be ``data``. This behavior can be changed with
-  the ``target_name`` and ``data_name`` keywords, setting them to a specific
-  name or index number (the name and order of the columns in the datasets
-  can be found at its `mldata.org <http://mldata.org>`_ under the tab "Data"::
-
-    >>> iris2 = fetch_mldata('datasets-UCI iris', target_name=1, data_name=0,
-    ...                      data_home=custom_data_home)
-    >>> iris3 = fetch_mldata('datasets-UCI iris', target_name='class',
-    ...                      data_name='double0', data_home=custom_data_home)
-
-
-..
-    >>> import shutil
-    >>> shutil.rmtree(custom_data_home)
diff --git a/doc/datasets/olivetti_faces.rst b/doc/datasets/olivetti_faces.rst
index 19c5601f7cac..71be4f66a2fc 100644
--- a/doc/datasets/olivetti_faces.rst
+++ b/doc/datasets/olivetti_faces.rst
@@ -2,7 +2,7 @@
 .. _olivetti_faces:
 
 The Olivetti faces dataset
-==========================
+--------------------------
 
 
 `This dataset contains a set of face images`_ taken between April 1992 and April
diff --git a/doc/datasets/rcv1.rst b/doc/datasets/rcv1.rst
index bcc0c95ef8f3..afbe797cc0c0 100644
--- a/doc/datasets/rcv1.rst
+++ b/doc/datasets/rcv1.rst
@@ -2,7 +2,7 @@
 .. _rcv1:
 
 RCV1 dataset
-============
+------------
 
 Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories made available by Reuters, Ltd. for research purposes. The dataset is extensively described in [1]_.
 
diff --git a/doc/datasets/twenty_newsgroups.rst b/doc/datasets/twenty_newsgroups.rst
index a068b18efb8a..5aaca66c5d67 100644
--- a/doc/datasets/twenty_newsgroups.rst
+++ b/doc/datasets/twenty_newsgroups.rst
@@ -1,7 +1,7 @@
 .. _20newsgroups:
 
 The 20 newsgroups text dataset
-==============================
+------------------------------
 
 The 20 newsgroups dataset comprises around 18000 newsgroups posts on
 20 topics split in two subsets: one for training (or development)
@@ -19,7 +19,7 @@ returns ready-to-use features, i.e., it is not necessary to use a feature
 extractor.
 
 Usage
------
+~~~~~
 
 The :func:`sklearn.datasets.fetch_20newsgroups` function is a data
 fetching / caching functions that downloads the data archive from
@@ -62,7 +62,7 @@ attribute is the integer index of the category::
   >>> newsgroups_train.target.shape
   (11314,)
   >>> newsgroups_train.target[:10]
-  array([12,  6,  9,  8,  6,  7,  9,  2, 13, 19])
+  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])
 
 It is possible to load only a sub-selection of the categories by passing the
 list of the categories to load to the
@@ -78,10 +78,10 @@ list of the categories to load to the
   >>> newsgroups_train.target.shape
   (1073,)
   >>> newsgroups_train.target[:10]
-  array([1, 1, 1, 0, 1, 0, 0, 1, 1, 1])
+  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])
 
 Converting text to vectors
---------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 In order to feed predictive or clustering models with the text data,
 one first need to turn the text into vectors of numerical values suitable
@@ -105,7 +105,7 @@ components by sample in a more than 30000-dimensional space
 (less than .5% non-zero features)::
 
   >>> vectors.nnz / float(vectors.shape[0])
-  159.01327433628319
+  159.01327...
 
 :func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which returns
 ready-to-use tfidf features instead of file names.
@@ -115,7 +115,8 @@ ready-to-use tfidf features instead of file names.
 
 
 Filtering text for more realistic training
-------------------------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
 It is easy for a classifier to overfit on particular things that appear in the
 20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very
 high F-scores, but their results would not generalize to other documents that
@@ -131,11 +132,13 @@ which is fast to train and achieves a decent F-score::
   >>> vectors_test = vectorizer.transform(newsgroups_test.data)
   >>> clf = MultinomialNB(alpha=.01)
   >>> clf.fit(vectors, newsgroups_train.target)
+  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
+
   >>> pred = clf.predict(vectors_test)
   >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')
-  0.88213592402729568
+  0.88213...
 
-(The example :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py` shuffles
+(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles
 the training and test data, instead of segmenting by time, and in that case
 multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious
 yet of what's going on inside this classifier?)
@@ -150,10 +153,10 @@ Let's take a look at what the most informative features are:
   ...         print("%s: %s" % (category, " ".join(feature_names[top10])))
   ...
   >>> show_top10(clf, vectorizer, newsgroups_train.target_names)
-  alt.atheism: sgi livesey atheists writes people caltech com god keith edu
-  comp.graphics: organization thanks files subject com image lines university edu graphics
-  sci.space: toronto moon gov com alaska access henry nasa edu space
-  talk.religion.misc: article writes kent people christian jesus sandvik edu com god
+  alt.atheism: edu it and in you that is of to the
+  comp.graphics: edu in graphics it is for and of to the
+  sci.space: edu it that is in and space to of the
+  talk.religion.misc: not it you in is that and to of the
 
 You can now see many things that these features have overfit to:
 
@@ -183,7 +186,7 @@ blocks, and quotation blocks respectively.
   >>> vectors_test = vectorizer.transform(newsgroups_test.data)
   >>> pred = clf.predict(vectors_test)
   >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')
-  0.77310350681274775
+  0.77310...
 
 This classifier lost over a lot of its F-score, just because we removed
 metadata that has little to do with topic classification.
@@ -195,10 +198,12 @@ It loses even more if we also strip this metadata from the training data:
   >>> vectors = vectorizer.fit_transform(newsgroups_train.data)
   >>> clf = MultinomialNB(alpha=.01)
   >>> clf.fit(vectors, newsgroups_train.target)
+  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)
+
   >>> vectors_test = vectorizer.transform(newsgroups_test.data)
   >>> pred = clf.predict(vectors_test)
   >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')
-  0.76995175184521725
+  0.76995...
 
 Some other classifiers cope better with this harder version of the task. Try
 running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without
@@ -215,4 +220,4 @@ the ``--filter`` option to compare the results.
 
    * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`
 
-   * :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
diff --git a/doc/developers/advanced_installation.rst b/doc/developers/advanced_installation.rst
index 4129ac1cc7c8..2ae1065893f9 100644
--- a/doc/developers/advanced_installation.rst
+++ b/doc/developers/advanced_installation.rst
@@ -140,7 +140,7 @@ From source package
 ~~~~~~~~~~~~~~~~~~~
 
 download the source package from
-`pypi <https://pypi.python.org/pypi/scikit-learn>`_, unpack the sources and
+`pypi <https://pypi.python.org/pypi/scikit-learn>`__, unpack the sources and
 cd into the source directory.
 
 This packages uses distutils, which is the default way of installing
diff --git a/doc/developers/contributing.rst b/doc/developers/contributing.rst
index 0d6174f3b2d4..3293fd0282f4 100644
--- a/doc/developers/contributing.rst
+++ b/doc/developers/contributing.rst
@@ -53,11 +53,36 @@ project maintainers.
 Another way to contribute is to report issues you're facing, and give a "thumbs
 up" on issues that others reported and that are relevant to you.  It also helps
 us if you spread the word: reference the project from your blog and articles,
-link to it from your website, or simply say "I use it":
+link to it from your website, or simply star to say "I use it":
 
 .. raw:: html
 
-   <script type="text/javascript" src="http://www.ohloh.net/p/480792/widgets/project_users.js?style=rainbow"></script>
+   <a class="github-button" href="https://github.com/scikit-learn/scikit-learn"
+   data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star
+   scikit-learn/scikit-learn on GitHub">Star</a>
+   <script async defer src="https://buttons.github.io/buttons.js"></script>
+
+.. topic:: Contributing to related projects
+
+   Scikit-learn thrives in an ecosystem of several related projects, which also
+   may have relevant issues to work on, including smaller projects such as:
+
+   * `scikit-learn-contrib <https://github.com/search?q=org%3Ascikit-learn-contrib+is%3Aissue+is%3Aopen+sort%3Aupdated-desc&type=Issues>`__
+   * `joblib <https://github.com/joblib/joblib/issues>`__
+   * `sphinx-gallery <https://github.com/sphinx-gallery/sphinx-gallery/issues>`__
+   * `numpydoc <https://github.com/numpy/numpydoc/issues>`__
+
+   and larger projects:
+
+   * `numpy <https://github.com/numpy/numpy/issues>`__
+   * `scipy <https://github.com/scipy/scipy/issues>`__
+   * `matplotlib <https://github.com/matplotlib/matplotlib/issues>`__
+   * and so on.
+
+   Look for issues marked "help wanted" or similar.
+   Helping these projects may help Scikit-learn too.
+   See also :ref:`related_projects`.
+
 
 Submitting a bug report or a feature request
 ============================================
@@ -88,7 +113,7 @@ How to make a good bug report
 -----------------------------
 
 When you submit an issue to `Github
-<https://github.com/scikit-learn/scikit-learn/issues>`_, please do your best to
+<https://github.com/scikit-learn/scikit-learn/issues>`__, please do your best to
 follow these guidelines! This will make it a lot easier to provide you with good
 feedback:
 
@@ -416,7 +441,7 @@ underestimate how easy an issue is to solve!
     we use the help wanted tag to mark Pull Requests which have been abandoned
     by their original contributor and are available for someone to pick up where the original
     contributor left off. The list of issues with the help wanted tag can be found
-    `here <https://github.com/scikit-learn/scikit-learn/labels/help%20wanted>`_ .
+    `here <https://github.com/scikit-learn/scikit-learn/labels/help%20wanted>`__ .
 
     Note that not all issues which need contributors will have this tag.
 
@@ -434,10 +459,9 @@ HTML output by building the documentation website.
 Building the documentation
 ^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-Building the documentation requires the ``sphinx``, ``sphinx-gallery``,
-``numpydoc``, ``matplotlib``, and ``Pillow`` packages::
+Building the documentation requires installing some additional packages::
 
-    pip install sphinx sphinx-gallery numpydoc matplotlib Pillow
+    pip install sphinx sphinx-gallery numpydoc matplotlib Pillow pandas scikit-image
 
 To build the documentation, you need to be in the ``doc`` folder::
 
@@ -454,11 +478,12 @@ To generate the full web site, including the example gallery::
 
 Generating the example gallery will run all our examples which takes a
 while. To save some time, you can use:
-    - ``make html-noplot``: this will generate the documentation without the
-      example gallery. This is useful when changing a docstring for example.
-    - ``EXAMPLES_PATTERN=your_regex_goes_here make html``: only the examples
-      matching ``your_regex_goes_here`` will be run. This is particularly
-      useful if you are modifying a few examples.
+
+- ``make html-noplot``: this will generate the documentation without the
+  example gallery. This is useful when changing a docstring for example.
+- ``EXAMPLES_PATTERN=your_regex_goes_here make html``: only the examples
+  matching ``your_regex_goes_here`` will be run. This is particularly
+  useful if you are modifying a few examples.
 
 That should create all the documentation in the ``_build/html/stable``
 directory.  Set the environment variable `NO_MATHJAX=1` if you intend to view
@@ -879,7 +904,7 @@ from high-level questions to a more detailed check-list.
   the tests validate that the code is correct, i.e. doing what the
   documentation says it does? If the change is a bug-fix, is a
   non-regression test included? Look at `this
-  <https://jeffknupp.com/blog/2013/12/09/improve-your-python-understanding-unit-testing>`_
+  <https://jeffknupp.com/blog/2013/12/09/improve-your-python-understanding-unit-testing>`__
   to get started with testing in Python.
 
 - Do the tests pass in the continuous integration build? If
@@ -1153,7 +1178,7 @@ the correct interface more easily.
     and optionally the mixin classes in ``sklearn.base``.
     For example, below is a custom classifier, with more examples included
     in the scikit-learn-contrib
-    `project template <https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/template.py>`_.
+    `project template <https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/template.py>`__.
 
       >>> import numpy as np
       >>> from sklearn.base import BaseEstimator, ClassifierMixin
diff --git a/doc/developers/performance.rst b/doc/developers/performance.rst
index d3d6204ec328..89ee4af1325f 100644
--- a/doc/developers/performance.rst
+++ b/doc/developers/performance.rst
@@ -388,8 +388,7 @@ Checkout the official joblib documentation:
 
 .. _warm-restarts:
 
-A sample algorithmic trick: warm restarts for cross validation
+A sample algorithmic trick: warm restarts
 ==============================================================
 
-TODO: demonstrate the warm restart tricks for cross validation of linear
-regression with Coordinate Descent.
+See the glossary entry for `warm_start <http://scikit-learn.org/dev/glossary.html#term-warm-start>`_
diff --git a/doc/developers/tips.rst b/doc/developers/tips.rst
index 7e97bcfb2a2c..2334bd769730 100644
--- a/doc/developers/tips.rst
+++ b/doc/developers/tips.rst
@@ -27,7 +27,7 @@ We use CircleCI to build the HTML documentation for every pull request. To
 access that documentation, instructions are provided in the :ref:`documentation
 section of the contributor guide <contribute_documentation>`. To save you a few
 clicks, we provide a `userscript
-<https://raw.githubusercontent.com/lesteve/userscripts/master/add-button-for-pr-circleci-doc.user.js>`_
+<https://raw.githubusercontent.com/lesteve/userscripts/master/add-button-for-pr-circleci-doc.user.js>`__
 that adds a button to every PR. After installing the userscript, navigate to
 any GitHub PR; a new button labeled "See CircleCI doc for this PR" should
 appear in the top-right area.
@@ -37,7 +37,7 @@ Folding and unfolding outdated diffs on pull requests
 
 GitHub hides discussions on PRs when the corresponding lines of code have been
 changed in the mean while. This `userscript
-<https://raw.githubusercontent.com/lesteve/userscripts/master/github-expand-all.user.js>`_
+<https://raw.githubusercontent.com/lesteve/userscripts/master/github-expand-all.user.js>`__
 provides a shortcut (Control-Alt-P at the time of writing but look at the code
 to be sure) to unfold all such hidden discussions at once, so you can catch up.
 
diff --git a/doc/documentation.rst b/doc/documentation.rst
index d8b70104271f..8ec2e41989a7 100644
--- a/doc/documentation.rst
+++ b/doc/documentation.rst
@@ -1,3 +1,5 @@
+:orphan:
+
 .. raw:: html
 
   <div class="container-index">
diff --git a/doc/faq.rst b/doc/faq.rst
index ed58a8719dbc..8d5a6f4f4dde 100644
--- a/doc/faq.rst
+++ b/doc/faq.rst
@@ -355,15 +355,15 @@ instances everywhere and ensure that both estimators and cross-validation
 splitters have their ``random_state`` parameter set.
 
 Why do categorical variables need preprocessing in scikit-learn, compared to other tools?
---------------------------------------------------------------------------------
+-----------------------------------------------------------------------------------------
 
 Most of scikit-learn assumes data is in NumPy arrays or SciPy sparse matrices
 of a single numeric dtype. These do not explicitly represent categorical
 variables at present. Thus, unlike R's data.frames or pandas.DataFrame, we
 require explicit conversion of categorical features to numeric values, as
 discussed in :ref:`preprocessing_categorical_features`.
-See also :ref:`sphx_glr_auto_examples_hetero_feature_union.py` for an example of
-working with heterogeneous (e.g. categorical and numeric) data.
+See also :ref:`sphx_glr_auto_examples_compose_column_transformer_mixed_types.py` for an
+example of working with heterogeneous (e.g. categorical and numeric) data.
 
 Why does Scikit-learn not directly work with, for example, pandas.DataFrame?
 
diff --git a/doc/glossary.rst b/doc/glossary.rst
index a8f31c1b3fdf..f2f17671339c 100644
--- a/doc/glossary.rst
+++ b/doc/glossary.rst
@@ -165,8 +165,10 @@ General Concepts
         tree-based models such as random forests and gradient boosting
         models that often work better and faster with integer-coded
         categorical variables.
-        :class:`~sklearn.preprocessing.CategoricalEncoder` helps
-        encoding string-valued categorical features.
+        :class:`~sklearn.preprocessing.OrdinalEncoder` helps encoding
+        string-valued categorical features as ordinal integers, and
+        :class:`~sklearn.preprocessing.OneHotEncoder` can be used to
+        one-hot encode categorical features.
         See also :ref:`preprocessing_categorical_features` and the
         `http://contrib.scikit-learn.org/categorical-encoding
         <category_encoders>`_ package for tools related to encoding
@@ -433,6 +435,13 @@ General Concepts
     hyper-parameter
         See :term:`parameter`.
 
+    impute
+    imputation
+        Most machine learning algorithms require that their inputs have no
+        :term:`missing values`, and will not work if this requirement is
+        violated. Algorithms that attempt to fill in (or impute) missing values
+        are referred to as imputation algorithms.
+
     indexable
         An :term:`array-like`, :term:`sparse matrix`, pandas DataFrame or
         sequence (usually a list).
@@ -452,6 +461,7 @@ General Concepts
 
     label indicator matrix
     multilabel indicator matrix
+    multilabel indicator matrices
         The format used to represent multilabel data, where each row of a 2d
         array or sparse matrix corresponds to a sample, each column
         corresponds to a class, and each element is 1 if the sample is labeled
@@ -483,7 +493,7 @@ General Concepts
         do (e.g. in :class:`impute.SimpleImputer`), NaN is the preferred
         representation of missing values in float arrays.  If the array has
         integer dtype, NaN cannot be represented. For this reason, we support
-        specifying another ``missing_values`` value when imputation or
+        specifying another ``missing_values`` value when :term:`imputation` or
         learning can be performed in integer space.  :term:`Unlabeled data`
         is a special case of missing values in the :term:`target`.
 
@@ -939,8 +949,9 @@ such as:
 
     scorer
         A non-estimator callable object which evaluates an estimator on given
-        test data, returning a number. See :ref:`scoring_parameter`; see also
-        :term:`evaluation metric`.
+        test data, returning a number. Unlike :term:`evaluation metrics`,
+        a greater returned number must correspond with a *better* score.
+        See :ref:`scoring_parameter`.
 
 Further examples:
 
@@ -1067,6 +1078,13 @@ Target Types
         :func:`~utils.multiclass.type_of_target` will return
         'multilabel-indicator' for multilabel input, whether sparse or dense.
 
+    multioutput
+    multi-output
+        A target where each sample has multiple classification/regression
+        labels. See :term:`multiclass multioutput` and :term:`continuous
+        multioutput`. We do not currently support modelling mixed
+        classification and regression targets.
+
 .. _glossary_methods:
 
 Methods
diff --git a/doc/modules/classes.rst b/doc/modules/classes.rst
index 99ccec601ece..b6342b7906fd 100644
--- a/doc/modules/classes.rst
+++ b/doc/modules/classes.rst
@@ -653,7 +653,7 @@ Kernels:
    :template: class.rst
 
    impute.SimpleImputer
-   impute.MICEImputer
+   impute.ChainedImputer
 
 .. _kernel_approximation_ref:
 
@@ -1249,7 +1249,7 @@ Model validation
    preprocessing.MinMaxScaler
    preprocessing.Normalizer
    preprocessing.OneHotEncoder
-   preprocessing.CategoricalEncoder
+   preprocessing.OrdinalEncoder
    preprocessing.PolynomialFeatures
    preprocessing.PowerTransformer
    preprocessing.QuantileTransformer
diff --git a/doc/modules/clustering.rst b/doc/modules/clustering.rst
index ce335cef2dd5..21c342d3ff1a 100644
--- a/doc/modules/clustering.rst
+++ b/doc/modules/clustering.rst
@@ -271,7 +271,7 @@ small, as shown in the example and cited reference.
  * :ref:`sphx_glr_auto_examples_cluster_plot_mini_batch_kmeans.py`: Comparison of KMeans and
    MiniBatchKMeans
 
- * :ref:`sphx_glr_auto_examples_text_document_clustering.py`: Document clustering using sparse
+ * :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`: Document clustering using sparse
    MiniBatchKMeans
 
  * :ref:`sphx_glr_auto_examples_cluster_plot_dict_face_patches.py`
diff --git a/doc/modules/compose.rst b/doc/modules/compose.rst
index 1f050cc12588..629cbf2663ba 100644
--- a/doc/modules/compose.rst
+++ b/doc/modules/compose.rst
@@ -119,10 +119,10 @@ ignored by setting them to ``None``::
 
  * :ref:`sphx_glr_auto_examples_feature_selection_plot_feature_selection_pipeline.py`
  * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`
- * :ref:`sphx_glr_auto_examples_plot_digits_pipe.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`
  * :ref:`sphx_glr_auto_examples_plot_kernel_approximation.py`
  * :ref:`sphx_glr_auto_examples_svm_plot_svm_anova.py`
- * :ref:`sphx_glr_auto_examples_plot_compare_reduction.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`
 
 .. topic:: See also:
 
@@ -218,7 +218,7 @@ object::
 
 .. topic:: Examples:
 
- * :ref:`sphx_glr_auto_examples_plot_compare_reduction.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`
 
 .. _transformed_target_regressor:
 
@@ -293,6 +293,10 @@ each other. However, it is possible to bypass this checking by setting
    pair of functions ``func`` and ``inverse_func``. However, setting both
    options will raise an error.
 
+.. topic:: Examples:
+
+ * :ref:`sphx_glr_auto_examples_compose_plot_transformed_target.py`
+
 
 .. _feature_union:
 
@@ -360,7 +364,7 @@ and ignored by setting to ``None``::
 
 .. topic:: Examples:
 
- * :ref:`sphx_glr_auto_examples_plot_feature_stacker.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_feature_union.py`
 
 
 .. _column_transformer:
@@ -459,4 +463,5 @@ above example would be::
 
 .. topic:: Examples:
 
- * :ref:`sphx_glr_auto_examples_column_transformer.py`
+ * :ref:`sphx_glr_auto_examples_compose_column_transformer.py`
+ * :ref:`sphx_glr_auto_examples_compose_column_transformer_mixed_types.py`
diff --git a/doc/modules/decomposition.rst b/doc/modules/decomposition.rst
index 6411fc9472f5..75c5439d3e4e 100644
--- a/doc/modules/decomposition.rst
+++ b/doc/modules/decomposition.rst
@@ -347,7 +347,7 @@ compensating for LSA's erroneous assumptions about textual data.
 
 .. topic:: Examples:
 
-   * :ref:`sphx_glr_auto_examples_text_document_clustering.py`
+   * :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`
 
 .. topic:: References:
 
@@ -451,6 +451,32 @@ After using such a procedure to fit the dictionary, the transform is simply a
 sparse coding step that shares the same implementation with all dictionary
 learning objects (see :ref:`SparseCoder`).
 
+It is also possible to constrain the dictionary and/or code to be positive to
+match constraints that may be present in the data. Below are the faces with
+different positivity constraints applied. Red indicates negative values, blue
+indicates positive values, and white represents zeros.
+
+
+.. |dict_img_pos1| image:: ../auto_examples/decomposition/images/sphx_glr_plot_faces_decomposition_011.png
+    :target: ../auto_examples/decomposition/plot_image_denoising.html
+    :scale: 60%
+
+.. |dict_img_pos2| image:: ../auto_examples/decomposition/images/sphx_glr_plot_faces_decomposition_012.png
+    :target: ../auto_examples/decomposition/plot_image_denoising.html
+    :scale: 60%
+
+.. |dict_img_pos3| image:: ../auto_examples/decomposition/images/sphx_glr_plot_faces_decomposition_013.png
+    :target: ../auto_examples/decomposition/plot_image_denoising.html
+    :scale: 60%
+
+.. |dict_img_pos4| image:: ../auto_examples/decomposition/images/sphx_glr_plot_faces_decomposition_014.png
+    :target: ../auto_examples/decomposition/plot_image_denoising.html
+    :scale: 60%
+
+.. centered:: |dict_img_pos1| |dict_img_pos2|
+.. centered:: |dict_img_pos3| |dict_img_pos4|
+
+
 The following image shows how a dictionary learned from 4x4 pixel image patches
 extracted from part of the image of a raccoon face looks like.
 
diff --git a/doc/modules/ensemble.rst b/doc/modules/ensemble.rst
index 655d5638472a..83da35eb46ca 100644
--- a/doc/modules/ensemble.rst
+++ b/doc/modules/ensemble.rst
@@ -782,7 +782,7 @@ accessed via the ``feature_importances_`` property::
     >>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,
     ...     max_depth=1, random_state=0).fit(X, y)
     >>> clf.feature_importances_  # doctest: +ELLIPSIS
-    array([0.11, 0.1 , 0.11, ...
+    array([0.10..., 0.10..., 0.11..., ...
 
 .. topic:: Examples:
 
diff --git a/doc/modules/feature_extraction.rst b/doc/modules/feature_extraction.rst
index 6756ae88b9be..611c7ecb60ee 100644
--- a/doc/modules/feature_extraction.rst
+++ b/doc/modules/feature_extraction.rst
@@ -657,12 +657,12 @@ In particular in a **supervised setting** it can be successfully combined
 with fast and scalable linear models to train **document classifiers**,
 for instance:
 
- * :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+ * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
 
 In an **unsupervised setting** it can be used to group similar documents
 together by applying clustering algorithms such as :ref:`k_means`:
 
-  * :ref:`sphx_glr_auto_examples_text_document_clustering.py`
+  * :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`
 
 Finally it is possible to discover the main topics of a corpus by
 relaxing the hard assignment constraint of clustering, for instance by
diff --git a/doc/modules/feature_selection.rst b/doc/modules/feature_selection.rst
index fea33ab180b7..ae630af183cd 100644
--- a/doc/modules/feature_selection.rst
+++ b/doc/modules/feature_selection.rst
@@ -198,7 +198,7 @@ alpha parameter, the fewer features selected.
 
 .. topic:: Examples:
 
-    * :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`: Comparison
+    * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`: Comparison
       of different algorithms for document classification including L1-based
       feature selection.
 
diff --git a/doc/modules/impute.rst b/doc/modules/impute.rst
index f16182510597..0f9089c98178 100644
--- a/doc/modules/impute.rst
+++ b/doc/modules/impute.rst
@@ -13,16 +13,30 @@ array are numerical, and that all have and hold meaning. A basic strategy to use
 incomplete datasets is to discard entire rows and/or columns containing missing
 values. However, this comes at the price of losing data which may be valuable
 (even though incomplete). A better strategy is to impute the missing values,
-i.e., to infer them from the known part of the data.
+i.e., to infer them from the known part of the data. See the :ref:`glossary`
+entry on imputation.
 
 
+Univariate vs. Multivariate Imputation
+======================================
+
+One type of imputation algorithm is univariate, which imputes values in the i-th
+feature dimension using only non-missing values in that feature dimension
+(e.g. :class:`impute.SimpleImputer`). By contrast, multivariate imputation
+algorithms use the entire set of available feature dimensions to estimate the
+missing values (e.g. :class:`impute.ChainedImputer`).
+
+
+.. _single_imputer:
+
 Univariate feature imputation
 =============================
 
 The :class:`SimpleImputer` class provides basic strategies for imputing missing
-values, either using the mean, the median or the most frequent value of
-the row or column in which the missing values are located. This class
-also allows for different missing values encodings.
+values. Missing values can be imputed with a provided constant value, or using
+the statistics (mean, median or most frequent) of each column in which the
+missing values are located. This class also allows for different missing values
+encodings.
 
 The following snippet demonstrates how to replace missing values,
 encoded as ``np.nan``, using the mean value of the columns (axis 0)
@@ -30,9 +44,9 @@ that contain the missing values::
 
     >>> import numpy as np
     >>> from sklearn.impute import SimpleImputer
-    >>> imp = SimpleImputer(missing_values='NaN', strategy='mean')
+    >>> imp = SimpleImputer(missing_values=np.nan, strategy='mean')
     >>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])       # doctest: +NORMALIZE_WHITESPACE
-    SimpleImputer(copy=True, missing_values='NaN', strategy='mean', verbose=0)
+    SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean', verbose=0)
     >>> X = [[np.nan, 2], [6, np.nan], [7, 6]]
     >>> print(imp.transform(X))           # doctest: +NORMALIZE_WHITESPACE  +ELLIPSIS
     [[4.          2.        ]
@@ -45,7 +59,7 @@ The :class:`SimpleImputer` class also supports sparse matrices::
     >>> X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])
     >>> imp = SimpleImputer(missing_values=0, strategy='mean')
     >>> imp.fit(X)                  # doctest: +NORMALIZE_WHITESPACE
-    SimpleImputer(copy=True, missing_values=0, strategy='mean', verbose=0)
+    SimpleImputer(copy=True, fill_value=None, missing_values=0, strategy='mean', verbose=0)
     >>> X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])
     >>> print(imp.transform(X_test))      # doctest: +NORMALIZE_WHITESPACE  +ELLIPSIS
     [[4.          2.        ]
@@ -56,35 +70,75 @@ Note that, here, missing values are encoded by 0 and are thus implicitly stored
 in the matrix. This format is thus suitable when there are many more missing
 values than observed values.
 
-.. _mice:
+The :class:`SimpleImputer` class also supports categorical data represented as
+string values or pandas categoricals when using the ``'most_frequent'`` or
+``'constant'`` strategy::
+
+    >>> import pandas as pd
+    >>> df = pd.DataFrame([["a", "x"],
+    ...                    [np.nan, "y"],
+    ...                    ["a", np.nan],
+    ...                    ["b", "y"]], dtype="category")
+    ...
+    >>> imp = SimpleImputer(strategy="most_frequent")
+    >>> print(imp.fit_transform(df))      # doctest: +NORMALIZE_WHITESPACE
+    [['a' 'x']
+     ['a' 'y']
+     ['a' 'y']
+     ['b' 'y']]
+
+.. _chained_imputer:
+
 
 Multivariate feature imputation
 ===============================
 
-A more sophisticated approach is to use the :class:`MICEImputer` class, which
-implements the Multivariate Imputation by Chained Equations technique. MICE
-models each feature with missing values as a function of other features, and
-uses that estimate for imputation. It does so in a round-robin fashion: at
-each step, a feature column is designated as output `y` and the other feature
-columns are treated as inputs `X`. A regressor is fit on `(X, y)` for known `y`.
-Then, the regressor is used to predict the unknown values of `y`. This is
-repeated for each feature, and then is done for a number of imputation rounds.
-Here is an example snippet::
+A more sophisticated approach is to use the :class:`ChainedImputer` class, which
+implements the imputation technique from MICE (Multivariate Imputation by
+Chained Equations). MICE models each feature with missing values as a function of
+other features, and uses that estimate for imputation. It does so in a round-robin
+fashion: at each step, a feature column is designated as output `y` and the other
+feature columns are treated as inputs `X`. A regressor is fit on `(X, y)` for known `y`.
+Then, the regressor is used to predict the unknown values of `y`. This is repeated
+for each feature in a chained fashion, and then is done for a number of imputation
+rounds. Here is an example snippet::
 
     >>> import numpy as np
-    >>> from sklearn.impute import MICEImputer
-    >>> imp = MICEImputer(n_imputations=10, random_state=0)
+    >>> from sklearn.impute import ChainedImputer
+    >>> imp = ChainedImputer(n_imputations=10, random_state=0)
     >>> imp.fit([[1, 2], [np.nan, 3], [7, np.nan]])
-    MICEImputer(imputation_order='ascending', initial_strategy='mean',
-          max_value=None, min_value=None, missing_values='NaN', n_burn_in=10,
-          n_imputations=10, n_nearest_features=None, predictor=None,
-          random_state=0, verbose=False)
+    ChainedImputer(imputation_order='ascending', initial_strategy='mean',
+            max_value=None, min_value=None, missing_values=nan, n_burn_in=10,
+            n_imputations=10, n_nearest_features=None, predictor=None,
+            random_state=0, verbose=False)
     >>> X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]
     >>> print(np.round(imp.transform(X_test)))
     [[ 1.  2.]
      [ 6.  4.]
      [13.  6.]]
 
-Both :class:`SimpleImputer` and :class:`MICEImputer` can be used in a Pipeline
+Both :class:`SimpleImputer` and :class:`ChainedImputer` can be used in a Pipeline
 as a way to build a composite estimator that supports imputation.
 See :ref:`sphx_glr_auto_examples_plot_missing_values.py`.
+
+
+.. _multiple_imputation:
+
+Multiple vs. Single Imputation
+==============================
+
+In the statistics community, it is common practice to perform multiple imputations,
+generating, for example, 10 separate imputations for a single feature matrix.
+Each of these 10 imputations is then put through the subsequent analysis pipeline
+(e.g. feature engineering, clustering, regression, classification). The 10 final
+analysis results (e.g. held-out validation error) allow the data scientist to
+obtain understanding of the uncertainty inherent in the missing values. The above
+practice is called multiple imputation. As implemented, the :class:`ChainedImputer`
+class generates a single (averaged) imputation for each missing value because this
+is the most common use case for machine learning applications. However, it can also be used
+for multiple imputations by applying it repeatedly to the same dataset with different
+random seeds with the ``n_imputations`` parameter set to 1.
+
+Note that a call to the ``transform`` method of :class:`ChainedImputer` is not
+allowed to change the number of samples. Therefore multiple imputations cannot be
+achieved by a single call to ``transform``.
diff --git a/doc/modules/linear_model.rst b/doc/modules/linear_model.rst
index 83554c4363a8..e2cc0ba2601a 100644
--- a/doc/modules/linear_model.rst
+++ b/doc/modules/linear_model.rst
@@ -114,7 +114,7 @@ its ``coef_`` member::
 .. topic:: Examples:
 
    * :ref:`sphx_glr_auto_examples_linear_model_plot_ridge_path.py`
-   * :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
 
 
 Ridge Complexity
@@ -205,6 +205,20 @@ computes the coefficients along the full path of possible values.
       thus be used to perform feature selection, as detailed in
       :ref:`l1_feature_selection`.
 
+The following two references explain the iterations
+used in the coordinate descent solver of scikit-learn, as well as
+the duality gap computation used for convergence control.
+
+.. topic:: References
+
+    * "Regularization Path For Generalized linear Models by Coordinate Descent",
+      Friedman, Hastie & Tibshirani, J Stat Softw, 2010 (`Paper
+      <https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf>`_).
+    * "An Interior-Point Method for Large-Scale L1-Regularized Least Squares,"
+      S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky,
+      in IEEE Journal of Selected Topics in Signal Processing, 2007
+      (`Paper <https://web.stanford.edu/~boyd/papers/pdf/l1_ls.pdf>`_)
+
 
 Setting regularization parameter
 --------------------------------
@@ -358,7 +372,19 @@ The class :class:`ElasticNetCV` can be used to set the parameters
   * :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_and_elasticnet.py`
   * :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py`
 
+The following two references explain the iterations
+used in the coordinate descent solver of scikit-learn, as well as
+the duality gap computation used for convergence control.
+
+.. topic:: References
 
+    * "Regularization Path For Generalized linear Models by Coordinate Descent",
+      Friedman, Hastie & Tibshirani, J Stat Softw, 2010 (`Paper
+      <https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf>`_).
+    * "An Interior-Point Method for Large-Scale L1-Regularized Least Squares,"
+      S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky,
+      in IEEE Journal of Selected Topics in Signal Processing, 2007
+      (`Paper <https://web.stanford.edu/~boyd/papers/pdf/l1_ls.pdf>`_)
 
 .. _multi_task_elastic_net:
 
diff --git a/doc/modules/model_evaluation.rst b/doc/modules/model_evaluation.rst
index 400009b9b9ec..8c4874edf84c 100644
--- a/doc/modules/model_evaluation.rst
+++ b/doc/modules/model_evaluation.rst
@@ -565,7 +565,7 @@ false negatives and true positives as follows::
     for an example of using a confusion matrix to classify
     hand-written digits.
 
-  * See :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+  * See :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
     for an example of using a confusion matrix to classify text
     documents.
 
@@ -598,7 +598,7 @@ and inferred labels::
     for an example of classification report usage for
     hand-written digits.
 
-  * See :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+  * See :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
     for an example of classification report usage for text
     documents.
 
@@ -749,7 +749,7 @@ binary classification and multilabel indicator format.
 
 .. topic:: Examples:
 
-  * See :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+  * See :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
     for an example of :func:`f1_score` usage to classify  text
     documents.
 
diff --git a/doc/modules/model_persistence.rst b/doc/modules/model_persistence.rst
index 15ecf3c2d88f..f5173e5d9f3f 100644
--- a/doc/modules/model_persistence.rst
+++ b/doc/modules/model_persistence.rst
@@ -42,12 +42,12 @@ is often the case for fitted scikit-learn estimators, but can only pickle to the
 disk and not to a string::
 
   >>> from sklearn.externals import joblib
-  >>> joblib.dump(clf, 'filename.pkl') # doctest: +SKIP
+  >>> joblib.dump(clf, 'filename.joblib') # doctest: +SKIP
 
 Later you can load back the pickled model (possibly in another Python process)
 with::
 
-  >>> clf = joblib.load('filename.pkl') # doctest:+SKIP
+  >>> clf = joblib.load('filename.joblib') # doctest:+SKIP
 
 .. note::
 
diff --git a/doc/modules/naive_bayes.rst b/doc/modules/naive_bayes.rst
index b61637c12d87..f3abe5720540 100644
--- a/doc/modules/naive_bayes.rst
+++ b/doc/modules/naive_bayes.rst
@@ -8,17 +8,18 @@ Naive Bayes
 
 
 Naive Bayes methods are a set of supervised learning algorithms
-based on applying Bayes' theorem with the "naive" assumption of independence
-between every pair of features. Given a class variable :math:`y` and a
-dependent feature vector :math:`x_1` through :math:`x_n`,
-Bayes' theorem states the following relationship:
+based on applying Bayes' theorem with the "naive" assumption of
+conditional independence between every pair of features given the
+value of the class variable. Bayes' theorem states the following
+relationship, given class variable :math:`y` and dependent feature
+vector :math:`x_1` through :math:`x_n`, :
 
 .. math::
 
    P(y \mid x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots x_n \mid y)}
                                     {P(x_1, \dots, x_n)}
 
-Using the naive independence assumption that
+Using the naive conditional independence assumption that
 
 .. math::
 
diff --git a/doc/modules/pipeline.rst b/doc/modules/pipeline.rst
index 3ffbc38b6b6c..9f07a9e34cb2 100644
--- a/doc/modules/pipeline.rst
+++ b/doc/modules/pipeline.rst
@@ -1,3 +1,5 @@
+:orphan:
+
 .. raw:: html
 
     <meta http-equiv="refresh" content="1; url=./compose.html" />
diff --git a/doc/modules/preprocessing.rst b/doc/modules/preprocessing.rst
index 19bdfc0d432a..2561a5abebbe 100644
--- a/doc/modules/preprocessing.rst
+++ b/doc/modules/preprocessing.rst
@@ -508,15 +508,13 @@ Such features can be efficiently coded as integers, for instance
 ``[1, 2, 1]``.
 
 To convert categorical features to such integer codes, we can use the
-:class:`CategoricalEncoder`. When specifying that we want to perform an
-ordinal encoding, the estimator transforms each categorical feature to one
+:class:`OrdinalEncoder`. This estimator transforms each categorical feature to one
 new feature of integers (0 to n_categories - 1)::
 
-    >>> enc = preprocessing.CategoricalEncoder(encoding='ordinal')
+    >>> enc = preprocessing.OrdinalEncoder()
     >>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]
     >>> enc.fit(X)  # doctest: +ELLIPSIS
-    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,
-              encoding='ordinal', handle_unknown='error')
+    OrdinalEncoder(categories='auto', dtype=<... 'numpy.float64'>)
     >>> enc.transform([['female', 'from US', 'uses Safari']])
     array([[0., 1., 1.]])
 
@@ -528,18 +526,19 @@ browsers was ordered arbitrarily).
 Another possibility to convert categorical features to features that can be used
 with scikit-learn estimators is to use a one-of-K, also known as one-hot or
 dummy encoding.
-This type of encoding is the default behaviour of the :class:`CategoricalEncoder`.
-The :class:`CategoricalEncoder` then transforms each categorical feature with
+This type of encoding can be obtained with the :class:`OneHotEncoder`,
+which transforms each categorical feature with
 ``n_categories`` possible values into ``n_categories`` binary features, with
 one of them 1, and all others 0.
 
 Continuing the example above::
 
-  >>> enc = preprocessing.CategoricalEncoder()
+  >>> enc = preprocessing.OneHotEncoder()
   >>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]
   >>> enc.fit(X)  # doctest: +ELLIPSIS
-  CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,
-            encoding='onehot', handle_unknown='error')
+  OneHotEncoder(categorical_features=None, categories=None,
+         dtype=<... 'numpy.float64'>, handle_unknown='error',
+         n_values=None, sparse=True)
   >>> enc.transform([['female', 'from US', 'uses Safari'],
   ...                ['male', 'from Europe', 'uses Safari']]).toarray()
   array([[1., 0., 0., 1., 0., 1.],
@@ -558,14 +557,15 @@ dataset::
     >>> genders = ['female', 'male']
     >>> locations = ['from Africa', 'from Asia', 'from Europe', 'from US']
     >>> browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']
-    >>> enc = preprocessing.CategoricalEncoder(categories=[genders, locations, browsers])
+    >>> enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])
     >>> # Note that for there are missing categorical values for the 2nd and 3rd
     >>> # feature
     >>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]
     >>> enc.fit(X) # doctest: +ELLIPSIS
-    CategoricalEncoder(categories=[...],
-              dtype=<... 'numpy.float64'>, encoding='onehot',
-              handle_unknown='error')
+    OneHotEncoder(categorical_features=None,
+           categories=[...],
+           dtype=<... 'numpy.float64'>, handle_unknown='error',
+           n_values=None, sparse=True)
     >>> enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()
     array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])
 
@@ -577,11 +577,12 @@ during transform, no error will be raised but the resulting one-hot encoded
 columns for this feature will be all zeros
 (``handle_unknown='ignore'`` is only supported for one-hot encoding)::
 
-    >>> enc = preprocessing.CategoricalEncoder(handle_unknown='ignore')
+    >>> enc = preprocessing.OneHotEncoder(handle_unknown='ignore')
     >>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]
     >>> enc.fit(X) # doctest: +ELLIPSIS
-    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,
-              encoding='onehot', handle_unknown='ignore')
+    OneHotEncoder(categorical_features=None, categories=None,
+           dtype=<... 'numpy.float64'>, handle_unknown='ignore',
+           n_values=None, sparse=True)
     >>> enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()
     array([[1., 0., 0., 0., 0., 0.]])
 
diff --git a/doc/modules/sgd.rst b/doc/modules/sgd.rst
index 6b384e12ce31..64eea91a9fa9 100644
--- a/doc/modules/sgd.rst
+++ b/doc/modules/sgd.rst
@@ -218,7 +218,7 @@ matrix format as defined in `scipy.sparse.csr_matrix
 
 .. topic:: Examples:
 
- - :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+ - :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
 
 Complexity
 ==========
diff --git a/doc/support.rst b/doc/support.rst
index cf71145c0e00..70efd7a109b0 100644
--- a/doc/support.rst
+++ b/doc/support.rst
@@ -92,7 +92,7 @@ Documentation resources
 
 This documentation is relative to |release|. Documentation for
 other versions can be found `here
-<http://scikit-learn.org/dev/versions.html>`_.
+<http://scikit-learn.org/dev/versions.html>`__.
 
 Printable pdf documentation for old versions can be found `here
 <https://sourceforge.net/projects/scikit-learn/files/documentation/>`_.
diff --git a/doc/testimonials/testimonials.rst b/doc/testimonials/testimonials.rst
index 0ac325002294..f30e14f12a97 100644
--- a/doc/testimonials/testimonials.rst
+++ b/doc/testimonials/testimonials.rst
@@ -120,7 +120,7 @@ Gilad Lotan, Chief Data Scientist
 
 
 `Hugging Face <https://huggingface.co>`_
-------------------------------------
+----------------------------------------
 
 .. raw:: html
 
diff --git a/doc/tutorial/basic/tutorial.rst b/doc/tutorial/basic/tutorial.rst
index ece691f7de97..781495df9931 100644
--- a/doc/tutorial/basic/tutorial.rst
+++ b/doc/tutorial/basic/tutorial.rst
@@ -239,12 +239,12 @@ which is more efficient on big data but it can only pickle to the disk
 and not to a string::
 
   >>> from sklearn.externals import joblib
-  >>> joblib.dump(clf, 'filename.pkl') # doctest: +SKIP
+  >>> joblib.dump(clf, 'filename.joblib') # doctest: +SKIP
 
 Later, you can reload the pickled model (possibly in another Python process)
 with::
 
-  >>> clf = joblib.load('filename.pkl') # doctest:+SKIP
+  >>> clf = joblib.load('filename.joblib') # doctest:+SKIP
 
 .. note::
 
diff --git a/doc/tutorial/statistical_inference/putting_together.rst b/doc/tutorial/statistical_inference/putting_together.rst
index 556b6b8df089..5106958d77e9 100644
--- a/doc/tutorial/statistical_inference/putting_together.rst
+++ b/doc/tutorial/statistical_inference/putting_together.rst
@@ -11,12 +11,12 @@ Pipelining
 We have seen that some estimators can transform data and that some estimators
 can predict variables. We can also create combined estimators:
 
-.. image:: /auto_examples/images/sphx_glr_plot_digits_pipe_001.png
-   :target: ../../auto_examples/plot_digits_pipe.html
+.. image:: ../../auto_examples/compose/images/sphx_glr_plot_digits_pipe_001.png
+   :target: ../../auto_examples/compose/plot_digits_pipe.html
    :scale: 65
    :align: right
 
-.. literalinclude:: ../../auto_examples/plot_digits_pipe.py
+.. literalinclude:: ../../auto_examples/compose/plot_digits_pipe.py
     :lines: 23-63
 
 
diff --git a/doc/tutorial/text_analytics/working_with_text_data.rst b/doc/tutorial/text_analytics/working_with_text_data.rst
index 9be0b0af3fc5..24b0b5b3e371 100644
--- a/doc/tutorial/text_analytics/working_with_text_data.rst
+++ b/doc/tutorial/text_analytics/working_with_text_data.rst
@@ -554,7 +554,7 @@ upon the completion of this tutorial:
   :class:`CountVectorizer`.
 
 * If you don't have labels, try using
-  :ref:`Clustering <sphx_glr_auto_examples_text_document_clustering.py>`
+  :ref:`Clustering <sphx_glr_auto_examples_text_plot_document_clustering.py>`
   on your problem.
 
 * If you have multiple labels per document, e.g categories, have a look
diff --git a/doc/whats_new.rst b/doc/whats_new.rst
index 63b1b309b844..0e7345836f48 100644
--- a/doc/whats_new.rst
+++ b/doc/whats_new.rst
@@ -8,6 +8,9 @@ Release History
 Release notes for current and recent releases are detailed on this page, with
 :ref:`previous releases <previous_releases_whats_new>` linked below.
 
+**Tip:** `Subscribe to scikit-learn releases <https://libraries.io/pypi/scikit-learn>`__
+on libraries.io to be notified when new versions are released.
+
 .. include:: whats_new/v0.20.rst
 .. include:: whats_new/v0.19.rst
 
diff --git a/doc/whats_new/older_versions.rst b/doc/whats_new/older_versions.rst
index eeb672914f03..ad4567ec4db5 100644
--- a/doc/whats_new/older_versions.rst
+++ b/doc/whats_new/older_versions.rst
@@ -1273,7 +1273,7 @@ Examples
 
 - new examples using some of the mlcomp datasets:
   ``sphx_glr_auto_examples_mlcomp_sparse_document_classification.py`` (since removed) and
-  :ref:`sphx_glr_auto_examples_text_document_classification_20newsgroups.py`
+  :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`
 
 - Many more examples. `See here
   <http://scikit-learn.org/stable/auto_examples/index.html>`_
diff --git a/doc/whats_new/v0.18.rst b/doc/whats_new/v0.18.rst
index ad240d578279..ea3548c0b9a0 100644
--- a/doc/whats_new/v0.18.rst
+++ b/doc/whats_new/v0.18.rst
@@ -463,7 +463,7 @@ Model evaluation and meta-estimators
 - Added support for substituting or disabling :class:`pipeline.Pipeline`
   and :class:`pipeline.FeatureUnion` components using the ``set_params``
   interface that powers :mod:`sklearn.grid_search`.
-  See :ref:`sphx_glr_auto_examples_plot_compare_reduction.py`
+  See :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`
   By `Joel Nothman`_ and :user:`Robert McGibbon <rmcgibbo>`.
 
 - The new ``cv_results_`` attribute of :class:`model_selection.GridSearchCV`
diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst
index 0e206878862a..23304b267372 100644
--- a/doc/whats_new/v0.20.rst
+++ b/doc/whats_new/v0.20.rst
@@ -7,10 +7,37 @@
 Version 0.20 (under development)
 ================================
 
-As well as a plethora of new features and enhancements, this release is the
-first to be accompanied by a :ref:`glossary` developed by `Joel Nothman`_. The
-glossary is a reference resource to help users and contributors become familiar
-with the terminology and conventions used in Scikit-learn.
+This release packs in a mountain of bug fixes, features and enhancements for
+the Scikit-learn library, and improvements to the documentation and examples.
+Thanks to our many contributors!
+
+Highlights
+----------
+
+We have tried to improve our support for common data-science use-cases
+including missing values, categorical variables, heterogeneous data, and
+features/targets with unusual distributions.
+
+Missing values in features, represented by NaNs, are now accepted in
+column-wise preprocessing such as scalers.  Each feature is fitted disregarding
+NaNs, and data containing NaNs can be transformed. The new :mod:`impute`
+module provides estimators for learning despite missing data.
+
+:class:`~compose.ColumnTransformer` handles the case where different features
+or columns of a pandas.DataFrame need different preprocessing.
+String or pandas Categorical columns can now be encoded with
+:class:`~preprocessing.OneHotEncoder` or
+:class:`~preprocessing.OrdinalEncoder`.
+
+:class:`~compose.TransformedTargetRegressor` helps when the regression target
+needs to be transformed to be modeled. :class:`~preprocessing.PowerTransformer`
+joins :class:`~preprocessing.QuantileTransformer` as a non-linear
+transformation.
+
+This release is also the first to be accompanied by a :ref:`glossary` developed
+by `Joel Nothman`_. The glossary is a reference resource to help users and
+contributors become familiar with the terminology and conventions used in
+Scikit-learn.
 
 Changed models
 --------------
@@ -29,6 +56,7 @@ random sampling procedures.
 - :class:`neural_network.MLPRegressor` (bug fix)
 - :class:`neural_network.MLPClassifier` (bug fix)
 - :class:`neural_network.BaseMultilayerPerceptron` (bug fix)
+- :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)
 - The v0.19.0 release notes failed to mention a backwards incompatibility with
   :class:`model_selection.StratifiedKFold` when ``shuffle=True`` due to
   :issue:`7823`.
@@ -70,14 +98,14 @@ Classifiers and regressors
 
 Preprocessing
 
-- Added :class:`preprocessing.CategoricalEncoder`, which allows to encode
-  categorical features as a numeric array, either using a one-hot (or dummy)
-  encoding scheme or by converting to ordinal integers.  Compared to the
-  existing :class:`~preprocessing.OneHotEncoder`, this new class handles
+- Expanded :class:`preprocessing.OneHotEncoder` to allow to encode
+  categorical string features as a numeric array using a one-hot (or dummy)
+  encoding scheme, and added :class:`preprocessing.OrdinalEncoder` to
+  convert to ordinal integers.  Those two classes now handle
   encoding of all feature types (also handles string-valued features) and
   derives the categories based on the unique values in the features instead of
-  the maximum value in the features. :issue:`9151` by :user:`Vighnesh Birodkar
-  <vighneshbirodkar>` and `Joris Van den Bossche`_.
+  the maximum value in the features. :issue:`9151` and :issue:`10521` by
+  :user:`Vighnesh Birodkar <vighneshbirodkar>` and `Joris Van den Bossche`_.
 
 - Added :class:`compose.ColumnTransformer`, which allows to apply
   different transformers to different columns of arrays or pandas
@@ -95,7 +123,7 @@ Preprocessing
   back to the original space via an inverse transform. :issue:`9041` by
   `Andreas MÃ¼ller`_ and :user:`Guillaume Lemaitre <glemaitre>`.
 
-- Added :class:`impute.MICEImputer`, which is a strategy for imputing missing
+- Added :class:`impute.ChainedImputer`, which is a strategy for imputing missing
   values by modeling each feature with missing values as a function of
   other features in a round-robin fashion. :issue:`8478` by
   :user:`Sergey Feldman <sergeyf>`.
@@ -119,6 +147,10 @@ Decomposition, manifold learning and clustering
   sample weights via new parameter ``sample_weight`` in ``fit`` function.
   :issue:`10933` by :user:`Johannes Hansen <jnhansen>`.
 
+- :mod:`dict_learning` functions and models now support positivity constraints.
+  This applies to the dictionary and sparse code.
+  :issue:`6374` by :user:`John Kirkham <jakirkham>`.
+
 Metrics
 
 - Partial AUC is available via ``max_fpr`` parameter in
@@ -186,6 +218,10 @@ Classifiers and regressors
 - :func:`manifold.t_sne.trustworthiness` accepts metrics other than
   Euclidean. :issue:`9775` by :user:`William de Vazelhes <wdevazelhes>`.
 
+- :mod:`Nearest neighbors <neighbors>` query methods are now more memory
+  efficient when ``algorithm='brute'``. :issue:`11136` by `Joel Nothman`_
+  and :user:`Aman Dalmia <dalmia>`.
+
 Cluster
 
 - :class:`cluster.KMeans`, :class:`cluster.MiniBatchKMeans` and
@@ -221,8 +257,18 @@ Preprocessing
 - :class:`preprocessing.QuantileTransformer` handles and ignores NaN values.
   :issue:`10404` by :user:`Guillaume Lemaitre <glemaitre>`.
 
-- Updated :class:`preprocessing.MinMaxScaler` to pass through NaN values.
-  :issue:`10404` by :user:`Lucija Gregov <LucijaGregov>`.
+- Updated :class:`preprocessing.MinMaxScaler` and
+  :func:`preprocessing.minmax_scale` to pass through NaN values.
+  :issue:`10404` and :issue:`11243` by :user:`Lucija Gregov <LucijaGregov>` and
+  :user:`Guillaume Lemaitre <glemaitre>`.
+
+- :class:`preprocessing.StandardScaler` and :func:`preprocessing.scale`
+  ignore and pass-through NaN values.
+  :issue:`11206` by :user:`Guillaume Lemaitre <glemaitre>`.
+
+- :class:`preprocessing.PowerTransformer` and
+  :func:`preprocessing.power_transform` ignore and pass-through NaN values.
+  :issue:`11306` by :user:`Guillaume Lemaitre <glemaitre>`.
 
 Model evaluation and meta-estimators
 
@@ -244,8 +290,15 @@ Model evaluation and meta-estimators
   :issue:`9304` by :user:`Breno Freitas <brenolf>`.
 
 - Add `return_estimator` parameter in :func:`model_selection.cross_validate` to
-  return estimators fitted on each split. :issue:`9686` by :user:`AurÃ©lien Bellet
-  <bellet>`.
+  return estimators fitted on each split.
+  :issue:`9686` by :user:`AurÃ©lien Bellet <bellet>`.
+
+- New ``refit_time_`` attribute will be stored in
+  :class:`model_selection.GridSearchCV` and
+  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.
+  This will allow measuring the complete time it takes to perform
+  hyperparameter optimization and refitting the best model on the whole
+  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.
 
 Decomposition and manifold learning
 
@@ -256,13 +309,15 @@ Decomposition and manifold learning
 Metrics
 
 - :func:`metrics.roc_auc_score` now supports binary ``y_true`` other than
-  ``{0, 1}`` or ``{-1, 1}``. :issue:`9828` by :user:`Hanmin Qin <qinhanmin2014>`.
+  ``{0, 1}`` or ``{-1, 1}``.
+  :issue:`9828` by :user:`Hanmin Qin <qinhanmin2014>`.
 
-- :func:`metrics.label_ranking_average_precision_score` now supports vector ``sample_weight``.
+- :func:`metrics.label_ranking_average_precision_score` now supports vector
+  ``sample_weight``.
   :issue:`10845` by :user:`Jose Perez-Parras Toledano <jopepato>`.
 
-- Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`. When
-  False and both inputs are sparse, will return a sparse matrix.
+- Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`.
+  When False and both inputs are sparse, will return a sparse matrix.
   :issue:`10999` by :user:`Taylor G Smith <tgsmith61591>`.
 
 - :func:`metrics.cluster.silhouette_score` and
@@ -326,6 +381,11 @@ Classifiers and regressors
   returning incorrect probabilities in the case of binary outcomes.
   :issue:`9939` by :user:`Roger Westover <rwolst>`.
 
+- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the
+  ``score`` method always computes accuracy, not the metric given by
+  the ``scoring`` parameter.
+  :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.
+
 - Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was
   broken when setting ``normalize=False``.
   :issue:`10071` by `Alexandre Gramfort`_.
@@ -380,6 +440,13 @@ Classifiers and regressors
   and :class:`linear_model.ElasticNet` when working with sparse matrices.
   :issue:`10992` by `Alexandre Gramfort`_.
 
+- Fixed a bug in :class:`ensemble.gradient_boosting.GradientBoostingRegressor`
+  and :class:`ensemble.gradient_boosting.GradientBoostingClassifier` to have
+  feature importances summed and then normalized, rather than normalizing on a
+  per-tree basis. The previous behavior over-weighted the Gini importance of
+  features that appear in later stages. This issue only affected feature
+  importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.
+
 Decomposition, manifold learning and clustering
 
 - Fix for uninformative error in :class:`decomposition.IncrementalPCA`:
@@ -480,6 +547,13 @@ Feature Extraction
   (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`
   and `Roman Yurchak`_.
 
+- Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which 
+  was ignoring the parameter ``dtype``. In addition,
+  :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``
+  for floating and raise a warning if ``dtype`` requested is integer.
+  :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and
+  :user:`Guillaume Lemaitre <glemaitre>`.
+  
 Utils
 
 - :func:`utils.check_array` yield a ``FutureWarning`` indicating
@@ -496,6 +570,18 @@ Preprocessing
   ``inverse_transform`` on unseen labels. :issue:`9816` by :user:`Charlie Newey
   <newey01c>`.
 
+- Fix bug in :class:`preprocessing.OneHotEncoder` which discarded the ``dtype``
+  when returning a sparse matrix output. :issue:`11042` by :user:`Daniel
+  Morales <DanielMorales9>`.
+
+- Fix ``fit`` and ``partial_fit`` in :class:`preprocessing.StandardScaler` in
+  the rare case when `with_mean=False` and `with_std=False` which was crashing
+  by calling ``fit`` more than once and giving inconsistent results for
+  ``mean_`` whether the input was a sparse or a dense matrix. ``mean_`` will be
+  set to ``None`` with both sparse and dense inputs. ``n_samples_seen_`` will
+  be also reported for both input types.
+  :issue:`11235` by :user:`Guillaume Lemaitre <glemaitre>`.
+
 Feature selection
 
 - Fixed computation of ``n_features_to_compute`` for edge case with tied CV
@@ -547,6 +633,17 @@ Linear, kernelized and related models
   :class:`linear_model.LogisticRegression` when ``verbose`` is set to 0.
   :issue:`10881` by :user:`Alexandre Sevin <AlexandreSev>`.
 
+Preprocessing
+
+- Deprecate ``n_values`` and ``categorical_features`` parameters and
+  ``active_features_``, ``feature_indices_`` and ``n_values_`` attributes
+  of :class:`preprocessing.OneHotEncoder`. The ``n_values`` parameter can be
+  replaced with the new ``categories`` parameter, and the attributes with the
+  new ``categories_`` attribute. Selecting the categorical features with
+  the ``categorical_features`` parameter is now better supported using the
+  :class:`compose.ColumnTransformer`.
+  :issue:`10521` by `Joris Van den Bossche`_.
+
 Decomposition, manifold learning and clustering
 
 - Deprecate ``precomputed`` parameter in function
@@ -581,12 +678,23 @@ Imputer
   :class:`impute.SimpleImputer`. :issue:`9726` by :user:`Kumar Ashutosh
   <thechargedneutron>`.
 
-- The ``axis`` parameter in :class:`impute.SimpleImputer` was removed. The
-  behavior is equivalent to ``axis=0`` (impute along columns). Row-wise
-  imputation can be performed with FunctionTransformer (e.g.,
-  ``FunctionTransformer(lambda X: Imputer().fit_transform(X.T).T)``).
-  :issue:`10829` by :user:`Guillaume Lemaitre <glemaitre>` and :user:`Gilberto
-  Olimpio <gilbertoolimpio>`.
+- The ``axis`` parameter that was in :class:`preprocessing.Imputer` is no
+  longer present in :class:`impute.SimpleImputer`. The behavior is equivalent
+  to ``axis=0`` (impute along columns). Row-wise imputation can be performed
+  with FunctionTransformer (e.g., ``FunctionTransformer(lambda X:
+  SimpleImputer().fit_transform(X.T).T)``). :issue:`10829` by :user:`Guillaume
+  Lemaitre <glemaitre>` and :user:`Gilberto Olimpio <gilbertoolimpio>`.
+
+- The :class:`impute.SimpleImputer` has a new strategy, ``'constant'``, to
+  complete missing values with a fixed one, given by the ``fill_value``
+  parameter. This strategy supports numeric and non-numeric data, and so does
+  the ``'most_frequent'`` strategy now. :issue:`11211` by :user:`Jeremie du
+  Boisberranger <jeremiedbb>`.
+
+- The NaN marker for the missing values has been changed between the
+  :class:`preprocessing.Imputer` and the :class:`impute.SimpleImputer`.
+  ``missing_values='NaN'``Â should now be ``missing_values=np.nan``.
+  :issue:`11211` by :user:`Jeremie du Boisberranger <jeremiedbb>`.
 
 Outlier Detection models
 
diff --git a/examples/README.txt b/examples/README.txt
index 33cfd2e6101b..4ee6efc46d1d 100644
--- a/examples/README.txt
+++ b/examples/README.txt
@@ -4,6 +4,6 @@ Examples
 ========
 
 Miscellaneous examples
-----------------
+----------------------
 
 Miscellaneous and introductory examples for scikit-learn.
diff --git a/examples/calibration/plot_compare_calibration.py b/examples/calibration/plot_compare_calibration.py
index bc1f73a06eb1..2d9d0af0dcbc 100644
--- a/examples/calibration/plot_compare_calibration.py
+++ b/examples/calibration/plot_compare_calibration.py
@@ -21,8 +21,8 @@
 * RandomForestClassifier shows the opposite behavior: the histograms show
   peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 or 1
   are very rare. An explanation for this is given by Niculescu-Mizil and Caruana
-  [1]: "Methods such as bagging and random forests that average predictions from
-  a base set of models can have difficulty making predictions near 0 and 1
+  [1]_: "Methods such as bagging and random forests that average predictions
+  from a base set of models can have difficulty making predictions near 0 and 1
   because variance in the underlying base models will bias predictions that
   should be near zero or one away from these values. Because predictions are
   restricted to the interval [0,1], errors caused by variance tend to be one-
@@ -39,7 +39,7 @@
 
 * Support Vector Classification (SVC) shows an even more sigmoid curve as
   the  RandomForestClassifier, which is typical for maximum-margin methods
-  (compare Niculescu-Mizil and Caruana [1]), which focus on hard samples
+  (compare Niculescu-Mizil and Caruana [1]_), which focus on hard samples
   that are close to the decision boundary (the support vectors).
 
 .. topic:: References:
diff --git a/examples/compose/README.txt b/examples/compose/README.txt
new file mode 100644
index 000000000000..9330b5a71419
--- /dev/null
+++ b/examples/compose/README.txt
@@ -0,0 +1,6 @@
+.. _compose_examples:
+
+Pipelines and composite estimators
+----------------------------------
+
+Examples of how to compose transformers and pipelines from other estimators. See the :ref:`User Guide <combining_estimators>`.
diff --git a/examples/column_transformer.py b/examples/compose/plot_column_transformer.py
similarity index 100%
rename from examples/column_transformer.py
rename to examples/compose/plot_column_transformer.py
diff --git a/examples/compose/plot_column_transformer_mixed_types.py b/examples/compose/plot_column_transformer_mixed_types.py
new file mode 100644
index 000000000000..64f1a3c88d3d
--- /dev/null
+++ b/examples/compose/plot_column_transformer_mixed_types.py
@@ -0,0 +1,107 @@
+"""
+===================================
+Column Transformer with Mixed Types
+===================================
+
+This example illustrates how to apply different preprocessing and
+feature extraction pipelines to different subsets of features,
+using :class:`sklearn.compose.ColumnTransformer`.
+This is particularly handy for the case of datasets that contain
+heterogeneous data types, since we may want to scale the
+numeric features and one-hot encode the categorical ones.
+
+In this example, the numeric data is standard-scaled after
+mean-imputation, while the categorical data is one-hot
+encoded after imputing missing values with a new category
+(``'missing'``).
+
+Finally, the preprocessing pipeline is integrated in a
+full prediction pipeline using :class:`sklearn.pipeline.Pipeline`,
+together with a simple classification model.
+"""
+
+# Author: Pedro Morales <part.morales@gmail.com>
+#
+# License: BSD 3 clause
+
+from __future__ import print_function
+
+import pandas as pd
+import numpy as np
+
+from sklearn.compose import ColumnTransformer
+from sklearn.pipeline import Pipeline
+from sklearn.impute import SimpleImputer
+from sklearn.preprocessing import StandardScaler, OneHotEncoder
+from sklearn.linear_model import LogisticRegression
+from sklearn.model_selection import train_test_split, GridSearchCV
+
+np.random.seed(0)
+
+# Read data from Titanic dataset.
+titanic_url = ('https://raw.githubusercontent.com/amueller/'
+               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')
+data = pd.read_csv(titanic_url)
+
+# We will train our classifier with the following features:
+# Numeric Features:
+# - age: float.
+# - fare: float.
+# Categorical Features:
+# - embarked: categories encoded as strings {'C', 'S', 'Q'}.
+# - sex: categories encoded as strings {'female', 'male'}.
+# - pclass: ordinal integers {1, 2, 3}.
+
+# We create the preprocessing pipelines for both numeric and categorical data.
+numeric_features = ['age', 'fare']
+numeric_transformer = Pipeline(steps=[
+    ('imputer', SimpleImputer(strategy='median')),
+    ('scaler', StandardScaler())])
+
+categorical_features = ['embarked', 'sex', 'pclass']
+categorical_transformer = Pipeline(steps=[
+    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
+    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))])
+
+preprocessor = ColumnTransformer(
+    transformers=[
+        ('num', numeric_transformer, numeric_features),
+        ('cat', categorical_transformer, categorical_features)],
+    remainder='drop')
+
+# Append classifier to preprocessing pipeline.
+# Now we have a full prediction pipeline.
+clf = Pipeline(steps=[('preprocessor', preprocessor),
+                      ('classifier', LogisticRegression())])
+
+X = data.drop('survived', axis=1)
+y = data['survived']
+
+X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
+                                                    shuffle=True)
+
+clf.fit(X_train, y_train)
+print("model score: %.3f" % clf.score(X_test, y_test))
+
+
+###############################################################################
+# Using the prediction pipeline in a grid search
+###############################################################################
+# Grid search can also be performed on the different preprocessing steps
+# defined in the ``ColumnTransformer`` object, together with the classifier's
+# hyperparameters as part of the ``Pipeline``.
+# We will search for both the imputer strategy of the numeric preprocessing
+# and the regularization parameter of the logistic regression using
+# :class:`sklearn.model_selection.GridSearchCV`.
+
+
+param_grid = {
+    'preprocessor__num__imputer__strategy': ['mean', 'median'],
+    'classifier__C': [0.1, 1.0, 10, 100],
+}
+
+grid_search = GridSearchCV(clf, param_grid, cv=10, iid=False)
+grid_search.fit(X_train, y_train)
+
+print(("best logistic regression from grid search: %.3f"
+       % grid_search.score(X_test, y_test)))
diff --git a/examples/plot_compare_reduction.py b/examples/compose/plot_compare_reduction.py
similarity index 100%
rename from examples/plot_compare_reduction.py
rename to examples/compose/plot_compare_reduction.py
diff --git a/examples/plot_digits_pipe.py b/examples/compose/plot_digits_pipe.py
similarity index 100%
rename from examples/plot_digits_pipe.py
rename to examples/compose/plot_digits_pipe.py
diff --git a/examples/plot_feature_stacker.py b/examples/compose/plot_feature_union.py
similarity index 100%
rename from examples/plot_feature_stacker.py
rename to examples/compose/plot_feature_union.py
diff --git a/examples/preprocessing/plot_transformed_target.py b/examples/compose/plot_transformed_target.py
similarity index 100%
rename from examples/preprocessing/plot_transformed_target.py
rename to examples/compose/plot_transformed_target.py
diff --git a/examples/decomposition/plot_faces_decomposition.py b/examples/decomposition/plot_faces_decomposition.py
index d29af6ad408f..9c2144a77942 100644
--- a/examples/decomposition/plot_faces_decomposition.py
+++ b/examples/decomposition/plot_faces_decomposition.py
@@ -48,13 +48,13 @@
 print("Dataset consists of %d faces" % n_samples)
 
 
-def plot_gallery(title, images, n_col=n_col, n_row=n_row):
+def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray):
     plt.figure(figsize=(2. * n_col, 2.26 * n_row))
     plt.suptitle(title, size=16)
     for i, comp in enumerate(images):
         plt.subplot(n_row, n_col, i + 1)
         vmax = max(comp.max(), -comp.min())
-        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,
+        plt.imshow(comp.reshape(image_shape), cmap=cmap,
                    interpolation='nearest',
                    vmin=-vmax, vmax=vmax)
         plt.xticks(())
@@ -137,3 +137,56 @@ def plot_gallery(title, images, n_col=n_col, n_row=n_row):
                  components_[:n_components])
 
 plt.show()
+
+# #############################################################################
+# Various positivity constraints applied to dictionary learning.
+estimators = [
+    ('Dictionary learning',
+        decomposition.MiniBatchDictionaryLearning(n_components=15, alpha=0.1,
+                                                  n_iter=50, batch_size=3,
+                                                  random_state=rng),
+     True),
+    ('Dictionary learning - positive dictionary',
+        decomposition.MiniBatchDictionaryLearning(n_components=15, alpha=0.1,
+                                                  n_iter=50, batch_size=3,
+                                                  random_state=rng,
+                                                  positive_dict=True),
+     True),
+    ('Dictionary learning - positive code',
+        decomposition.MiniBatchDictionaryLearning(n_components=15, alpha=0.1,
+                                                  n_iter=50, batch_size=3,
+                                                  random_state=rng,
+                                                  positive_code=True),
+     True),
+    ('Dictionary learning - positive dictionary & code',
+        decomposition.MiniBatchDictionaryLearning(n_components=15, alpha=0.1,
+                                                  n_iter=50, batch_size=3,
+                                                  random_state=rng,
+                                                  positive_dict=True,
+                                                  positive_code=True),
+     True),
+]
+
+
+# #############################################################################
+# Plot a sample of the input data
+
+plot_gallery("First centered Olivetti faces", faces_centered[:n_components],
+             cmap=plt.cm.RdBu)
+
+# #############################################################################
+# Do the estimation and plot it
+
+for name, estimator, center in estimators:
+    print("Extracting the top %d %s..." % (n_components, name))
+    t0 = time()
+    data = faces
+    if center:
+        data = faces_centered
+    estimator.fit(data)
+    train_time = (time() - t0)
+    print("done in %0.3fs" % train_time)
+    components_ = estimator.components_
+    plot_gallery(name, components_[:n_components], cmap=plt.cm.RdBu)
+
+plt.show()
diff --git a/examples/ensemble/plot_feature_transformation.py b/examples/ensemble/plot_feature_transformation.py
index e4a6a8b313d8..bb1fd7ec6684 100644
--- a/examples/ensemble/plot_feature_transformation.py
+++ b/examples/ensemble/plot_feature_transformation.py
@@ -34,7 +34,7 @@
 from sklearn.linear_model import LogisticRegression
 from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,
                               GradientBoostingClassifier)
-from sklearn.preprocessing import CategoricalEncoder
+from sklearn.preprocessing import OneHotEncoder
 from sklearn.model_selection import train_test_split
 from sklearn.metrics import roc_curve
 from sklearn.pipeline import make_pipeline
@@ -62,7 +62,7 @@
 
 # Supervised transformation based on random forests
 rf = RandomForestClassifier(max_depth=3, n_estimators=n_estimator)
-rf_enc = CategoricalEncoder()
+rf_enc = OneHotEncoder()
 rf_lm = LogisticRegression()
 rf.fit(X_train, y_train)
 rf_enc.fit(rf.apply(X_train))
@@ -72,7 +72,7 @@
 fpr_rf_lm, tpr_rf_lm, _ = roc_curve(y_test, y_pred_rf_lm)
 
 grd = GradientBoostingClassifier(n_estimators=n_estimator)
-grd_enc = CategoricalEncoder()
+grd_enc = OneHotEncoder()
 grd_lm = LogisticRegression()
 grd.fit(X_train, y_train)
 grd_enc.fit(grd.apply(X_train)[:, :, 0])
diff --git a/examples/ensemble/plot_gradient_boosting_early_stopping.py b/examples/ensemble/plot_gradient_boosting_early_stopping.py
index 366d9e0b148d..0ffa36cd0b15 100644
--- a/examples/ensemble/plot_gradient_boosting_early_stopping.py
+++ b/examples/ensemble/plot_gradient_boosting_early_stopping.py
@@ -131,7 +131,7 @@ def autolabel(rects, n_estimators):
 
 #######################################################################
 # Compare fit times with and without early stopping
-# ----------------------------------------------
+# -------------------------------------------------
 
 plt.figure(figsize=(9, 5))
 
diff --git a/examples/ensemble/plot_isolation_forest.py b/examples/ensemble/plot_isolation_forest.py
index 6dc8aacd462a..e6c8ce3bf8ef 100644
--- a/examples/ensemble/plot_isolation_forest.py
+++ b/examples/ensemble/plot_isolation_forest.py
@@ -3,7 +3,8 @@
 IsolationForest example
 ==========================================
 
-An example using IsolationForest for anomaly detection.
+An example using :class:`sklearn.ensemble.IsolationForest` for anomaly
+detection.
 
 The IsolationForest 'isolates' observations by randomly selecting a feature
 and then randomly selecting a split value between the maximum and minimum
@@ -20,9 +21,6 @@
 Hence, when a forest of random trees collectively produce shorter path lengths
 for particular samples, they are highly likely to be anomalies.
 
-.. [1] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. "Isolation forest."
-    Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on.
-
 """
 print(__doc__)
 
diff --git a/examples/manifold/plot_compare_methods.py b/examples/manifold/plot_compare_methods.py
index 34e161dfb046..3af18269aeaa 100644
--- a/examples/manifold/plot_compare_methods.py
+++ b/examples/manifold/plot_compare_methods.py
@@ -1,6 +1,6 @@
 """
 =========================================
- Comparison of Manifold Learning methods
+Comparison of Manifold Learning methods
 =========================================
 
 An illustration of dimensionality reduction on the S-curve dataset
diff --git a/examples/manifold/plot_t_sne_perplexity.py b/examples/manifold/plot_t_sne_perplexity.py
index c1cbe0001d0e..0fbade5746af 100644
--- a/examples/manifold/plot_t_sne_perplexity.py
+++ b/examples/manifold/plot_t_sne_perplexity.py
@@ -1,6 +1,6 @@
 """
 =============================================================================
- t-SNE: The effect of various perplexity values on the shape
+t-SNE: The effect of various perplexity values on the shape
 =============================================================================
 
 An illustration of t-SNE on the two concentric circles and the S-curve
diff --git a/examples/plot_missing_values.py b/examples/plot_missing_values.py
index e32c19fae084..d238a16592ed 100644
--- a/examples/plot_missing_values.py
+++ b/examples/plot_missing_values.py
@@ -8,10 +8,11 @@
 The median is a more robust estimator for data with high magnitude variables
 which could dominate results (otherwise known as a 'long tail').
 
-Another option is the MICE imputer. This uses round-robin linear regression,
-treating every variable as an output in turn. The version implemented assumes
-Gaussian (output) variables. If your features are obviously non-Normal,
-consider transforming them to look more Normal so as to improve performance.
+Another option is the ``ChainedImputer``. This uses round-robin linear
+regression, treating every variable as an output in turn. The version
+implemented assumes Gaussian (output) variables. If your features are obviously
+non-Normal, consider transforming them to look more Normal so as to improve
+performance.
 """
 
 import numpy as np
@@ -21,7 +22,7 @@
 from sklearn.datasets import load_boston
 from sklearn.ensemble import RandomForestRegressor
 from sklearn.pipeline import Pipeline
-from sklearn.impute import SimpleImputer, MICEImputer
+from sklearn.impute import SimpleImputer, ChainedImputer
 from sklearn.model_selection import cross_val_score
 
 rng = np.random.RandomState(0)
@@ -66,18 +67,18 @@ def get_results(dataset):
     mean_impute_scores = cross_val_score(estimator, X_missing, y_missing,
                                          scoring='neg_mean_squared_error')
 
-    # Estimate the score after imputation (MICE strategy) of the missing values
-    estimator = Pipeline([("imputer", MICEImputer(missing_values=0,
-                                                  random_state=0)),
+    # Estimate the score after chained imputation of the missing values
+    estimator = Pipeline([("imputer", ChainedImputer(missing_values=0,
+                                                     random_state=0)),
                           ("forest", RandomForestRegressor(random_state=0,
                                                            n_estimators=100))])
-    mice_impute_scores = cross_val_score(estimator, X_missing, y_missing,
-                                         scoring='neg_mean_squared_error')
+    chained_impute_scores = cross_val_score(estimator, X_missing, y_missing,
+                                            scoring='neg_mean_squared_error')
 
     return ((full_scores.mean(), full_scores.std()),
             (zero_impute_scores.mean(), zero_impute_scores.std()),
             (mean_impute_scores.mean(), mean_impute_scores.std()),
-            (mice_impute_scores.mean(), mice_impute_scores.std()))
+            (chained_impute_scores.mean(), chained_impute_scores.std()))
 
 
 results_diabetes = np.array(get_results(load_diabetes()))
@@ -94,7 +95,7 @@ def get_results(dataset):
 x_labels = ['Full data',
             'Zero imputation',
             'Mean Imputation',
-            'MICE Imputation']
+            'Chained Imputation']
 colors = ['r', 'g', 'b', 'orange']
 
 # plot diabetes results
@@ -104,7 +105,7 @@ def get_results(dataset):
     ax1.barh(j, mses_diabetes[j], xerr=stds_diabetes[j],
              color=colors[j], alpha=0.6, align='center')
 
-ax1.set_title('Feature Selection Techniques with Diabetes Data')
+ax1.set_title('Imputation Techniques with Diabetes Data')
 ax1.set_xlim(left=np.min(mses_diabetes) * 0.9,
              right=np.max(mses_diabetes) * 1.1)
 ax1.set_yticks(xval)
@@ -118,7 +119,7 @@ def get_results(dataset):
     ax2.barh(j, mses_boston[j], xerr=stds_boston[j],
              color=colors[j], alpha=0.6, align='center')
 
-ax2.set_title('Feature Selection Techniques with Boston Data')
+ax2.set_title('Imputation Techniques with Boston Data')
 ax2.set_yticks(xval)
 ax2.set_xlabel('MSE')
 ax2.invert_yaxis()
diff --git a/examples/svm/plot_separating_hyperplane.py b/examples/svm/plot_separating_hyperplane.py
index 9fdbcc785ed2..cbd61abad53e 100644
--- a/examples/svm/plot_separating_hyperplane.py
+++ b/examples/svm/plot_separating_hyperplane.py
@@ -41,5 +41,5 @@
            linestyles=['--', '-', '--'])
 # plot support vectors
 ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,
-           linewidth=1, facecolors='none')
+           linewidth=1, facecolors='none', edgecolors='k')
 plt.show()
diff --git a/examples/svm/plot_separating_hyperplane_unbalanced.py b/examples/svm/plot_separating_hyperplane_unbalanced.py
index 05c768c4a22f..2a0540fead31 100644
--- a/examples/svm/plot_separating_hyperplane_unbalanced.py
+++ b/examples/svm/plot_separating_hyperplane_unbalanced.py
@@ -49,9 +49,8 @@
 wclf = svm.SVC(kernel='linear', class_weight={1: 10})
 wclf.fit(X, y)
 
-# plot separating hyperplanes and samples
+# plot the samples
 plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')
-plt.legend()
 
 # plot the decision functions for both classifiers
 ax = plt.gca()
diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py
index be1057f7d7bd..6ea4ccdd6b05 100644
--- a/sklearn/compose/_column_transformer.py
+++ b/sklearn/compose/_column_transformer.py
@@ -290,22 +290,25 @@ def get_feature_names(self):
         return feature_names
 
     def _update_fitted_transformers(self, transformers):
+        # transformers are fitted; excludes 'drop' cases
         transformers = iter(transformers)
         transformers_ = []
 
         for name, old, column in self.transformers:
             if old == 'drop':
-                trans = old
+                trans = 'drop'
             elif old == 'passthrough':
                 # FunctionTransformer is present in list of transformers,
                 # so get next transformer, but save original string
                 next(transformers)
-                trans = old
+                trans = 'passthrough'
             else:
                 trans = next(transformers)
 
             transformers_.append((name, trans, column))
 
+        # sanity check that transformers is exhausted
+        assert not list(transformers)
         self.transformers_ = transformers_
 
     def _validate_output(self, result):
@@ -454,7 +457,17 @@ def transform(self, X):
 
 def _check_key_type(key, superclass):
     """
-    Check that scalar, list or slice is of certain type.
+    Check that scalar, list or slice is of a certain type.
+
+    This is only used in _get_column and _get_column_indices to check
+    if the `key` (column specification) is fully integer or fully string-like.
+
+    Parameters
+    ----------
+    key : scalar, list, slice, array-like
+        The column specification to check
+    superclass : int or six.string_types
+        The type for which to check the `key`
 
     """
     if isinstance(key, superclass):
@@ -465,7 +478,11 @@ def _check_key_type(key, superclass):
     if isinstance(key, list):
         return all(isinstance(x, superclass) for x in key)
     if hasattr(key, 'dtype'):
-        return key.dtype.kind == 'i'
+        if superclass is int:
+            return key.dtype.kind == 'i'
+        else:
+            # superclass = six.string_types
+            return key.dtype.kind in ('O', 'U', 'S')
     return False
 
 
@@ -494,7 +511,7 @@ def _get_column(X, key):
         column_names = False
     elif _check_key_type(key, six.string_types):
         column_names = True
-    elif hasattr(key, 'dtype') and np.issubdtype(key.dtype, np.bool):
+    elif hasattr(key, 'dtype') and np.issubdtype(key.dtype, np.bool_):
         # boolean mask
         column_names = False
         if hasattr(X, 'loc'):
@@ -561,7 +578,7 @@ def _get_column_indices(X, key):
 
         return [all_columns.index(col) for col in columns]
 
-    elif hasattr(key, 'dtype') and np.issubdtype(key.dtype, np.bool):
+    elif hasattr(key, 'dtype') and np.issubdtype(key.dtype, np.bool_):
         # boolean mask
         return list(np.arange(n_columns)[key])
     else:
@@ -595,6 +612,15 @@ def make_column_transformer(*transformers, **kwargs):
     ----------
     *transformers : tuples of column selections and transformers
 
+    remainder : {'passthrough', 'drop'}, default 'passthrough'
+        By default, all remaining columns that were not specified in
+        `transformers` will be automatically passed through (default of
+        ``'passthrough'``). This subset of columns is concatenated with the
+        output of the transformers.
+        By using ``remainder='drop'``, only the specified columns in
+        `transformers` are transformed and combined in the output, and the
+        non-specified columns are dropped.
+
     n_jobs : int, optional
         Number of jobs to run in parallel (default 1).
 
@@ -610,25 +636,27 @@ def make_column_transformer(*transformers, **kwargs):
 
     Examples
     --------
-    >>> from sklearn.preprocessing import StandardScaler, CategoricalEncoder
+    >>> from sklearn.preprocessing import StandardScaler, OneHotEncoder
     >>> from sklearn.compose import make_column_transformer
     >>> make_column_transformer(
     ...     (['numerical_column'], StandardScaler()),
-    ...     (['categorical_column'], CategoricalEncoder()))
+    ...     (['categorical_column'], OneHotEncoder()))
     ...     # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
     ColumnTransformer(n_jobs=1, remainder='passthrough',
              transformer_weights=None,
              transformers=[('standardscaler',
                             StandardScaler(...),
                             ['numerical_column']),
-                           ('categoricalencoder',
-                            CategoricalEncoder(...),
+                           ('onehotencoder',
+                            OneHotEncoder(...),
                             ['categorical_column'])])
 
     """
     n_jobs = kwargs.pop('n_jobs', 1)
+    remainder = kwargs.pop('remainder', 'passthrough')
     if kwargs:
         raise TypeError('Unknown keyword arguments: "{}"'
                         .format(list(kwargs.keys())[0]))
     transformer_list = _get_transformer_list(transformers)
-    return ColumnTransformer(transformer_list, n_jobs=n_jobs)
+    return ColumnTransformer(transformer_list, n_jobs=n_jobs,
+                             remainder=remainder)
diff --git a/sklearn/compose/_target.py b/sklearn/compose/_target.py
index cb3e1cedd0eb..757cec54ee22 100644
--- a/sklearn/compose/_target.py
+++ b/sklearn/compose/_target.py
@@ -25,12 +25,15 @@ class TransformedTargetRegressor(BaseEstimator, RegressorMixin):
     The computation during ``fit`` is::
 
         regressor.fit(X, func(y))
+
     or::
 
         regressor.fit(X, transformer.transform(y))
+
     The computation during ``predict`` is::
 
         inverse_func(regressor.predict(X))
+
     or::
 
         transformer.inverse_transform(regressor.predict(X))
@@ -97,8 +100,8 @@ class TransformedTargetRegressor(BaseEstimator, RegressorMixin):
     to be used by scikit-learn transformers. At the time of prediction, the
     output will be reshaped to a have the same number of dimensions as ``y``.
 
-    See :ref:`examples/preprocessing/plot_transformed_target.py
-    <sphx_glr_auto_examples_preprocessing_plot_transformed_target.py>`.
+    See :ref:`examples/compose/plot_transformed_target.py
+    <sphx_glr_auto_examples_compose_plot_transformed_target.py>`.
 
     """
     def __init__(self, regressor=None, transformer=None,
diff --git a/sklearn/compose/tests/test_column_transformer.py b/sklearn/compose/tests/test_column_transformer.py
index 420481ff0ad4..2d77f3af85fb 100644
--- a/sklearn/compose/tests/test_column_transformer.py
+++ b/sklearn/compose/tests/test_column_transformer.py
@@ -16,6 +16,7 @@
 from sklearn.utils.testing import assert_allclose_dense_sparse
 
 from sklearn.base import BaseEstimator
+from sklearn.externals import six
 from sklearn.compose import ColumnTransformer, make_column_transformer
 from sklearn.exceptions import NotFittedError
 from sklearn.preprocessing import StandardScaler, Normalizer
@@ -301,7 +302,7 @@ def test_column_transformer_invalid_columns(remainder):
     X_array = np.array([[0, 1, 2], [2, 4, 6]]).T
 
     # general invalid
-    for col in [1.5, ['string', 1], slice(1, 's')]:
+    for col in [1.5, ['string', 1], slice(1, 's'), np.array([1.])]:
         ct = ColumnTransformer([('trans', Trans(), col)], remainder=remainder)
         assert_raise_message(ValueError, "No valid specification",
                              ct.fit, X_array)
@@ -342,12 +343,13 @@ def test_make_column_transformer_kwargs():
     scaler = StandardScaler()
     norm = Normalizer()
     ct = make_column_transformer(('first', scaler), (['second'], norm),
-                                 n_jobs=3)
+                                 n_jobs=3, remainder='drop')
     assert_equal(
         ct.transformers,
         make_column_transformer(('first', scaler),
                                 (['second'], norm)).transformers)
     assert_equal(ct.n_jobs, 3)
+    assert_equal(ct.remainder, 'drop')
     # invalid keyword parameters should raise an error message
     assert_raise_message(
         TypeError,
@@ -551,12 +553,15 @@ def test_column_transformer_remainder_numpy(key):
     assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)
 
 
-@pytest.mark.parametrize("key", [[0], slice(0, 1), np.array([True, False]),
-                                 ['first'], slice(None, 'first'),
-                                 slice('first', 'first')])
+@pytest.mark.parametrize(
+    "key", [[0], slice(0, 1), np.array([True, False]), ['first'], 'pd-index',
+            np.array(['first']), np.array(['first'], dtype=object),
+            slice(None, 'first'), slice('first', 'first')])
 def test_column_transformer_remainder_pandas(key):
     # test different ways that columns are specified with passthrough
     pd = pytest.importorskip('pandas')
+    if isinstance(key, six.string_types) and key == 'pd-index':
+        key = pd.Index(['first'])
 
     X_array = np.array([[0, 1, 2], [2, 4, 6]]).T
     X_df = pd.DataFrame(X_array, columns=['first', 'second'])
diff --git a/sklearn/covariance/elliptic_envelope.py b/sklearn/covariance/elliptic_envelope.py
index 874155bdd28d..0f9075abfb2e 100644
--- a/sklearn/covariance/elliptic_envelope.py
+++ b/sklearn/covariance/elliptic_envelope.py
@@ -64,7 +64,7 @@ class EllipticEnvelope(MinCovDet, OutlierMixin):
 
     offset_ : float
         Offset used to define the decision function from the raw scores.
-        We have the relation: decision_function = score_samples - offset_.
+        We have the relation: ``decision_function = score_samples - offset_``.
         The offset depends on the contamination parameter and is defined in
         such a way we obtain the expected number of outliers (samples with
         decision function < 0) in training.
@@ -81,8 +81,9 @@ class EllipticEnvelope(MinCovDet, OutlierMixin):
 
     References
     ----------
-    ..  [1] Rousseeuw, P.J., Van Driessen, K. "A fast algorithm for the minimum
-        covariance determinant estimator" Technometrics 41(3), 212 (1999)
+    .. [1] Rousseeuw, P.J., Van Driessen, K. "A fast algorithm for the
+       minimum covariance determinant estimator" Technometrics 41(3), 212
+       (1999)
 
     """
     def __init__(self, store_precision=True, assume_centered=False,
diff --git a/sklearn/datasets/california_housing.py b/sklearn/datasets/california_housing.py
index ce3d5dcf4da2..8973ba59ad21 100644
--- a/sklearn/datasets/california_housing.py
+++ b/sklearn/datasets/california_housing.py
@@ -67,8 +67,9 @@ def fetch_california_housing(data_home=None, download_if_missing=True,
         instead of trying to download the data from the source site.
 
 
-    return_X_y : boolean, default=False. If True, returns ``(data.data,
-    data.target)`` instead of a Bunch object.
+    return_X_y : boolean, default=False.
+        If True, returns ``(data.data, data.target)`` instead of a Bunch
+        object.
 
         .. versionadded:: 0.20
 
diff --git a/sklearn/datasets/covtype.py b/sklearn/datasets/covtype.py
index 7630e92056f0..c7b880b116ea 100644
--- a/sklearn/datasets/covtype.py
+++ b/sklearn/datasets/covtype.py
@@ -65,8 +65,9 @@ def fetch_covtype(data_home=None, download_if_missing=True,
     shuffle : bool, default=False
         Whether to shuffle dataset.
 
-    return_X_y : boolean, default=False. If True, returns ``(data.data,
-    data.target)`` instead of a Bunch object.
+    return_X_y : boolean, default=False.
+        If True, returns ``(data.data, data.target)`` instead of a Bunch
+        object.
 
         .. versionadded:: 0.20
 
diff --git a/sklearn/datasets/descr/boston_house_prices.rst b/sklearn/datasets/descr/boston_house_prices.rst
index 31227b087dff..dec9b999cd59 100644
--- a/sklearn/datasets/descr/boston_house_prices.rst
+++ b/sklearn/datasets/descr/boston_house_prices.rst
@@ -1,15 +1,13 @@
-Boston House Prices dataset
-===========================
+.. _boston_dataset:
 
-Notes
-------
-Data Set Characteristics:  
+Boston house prices dataset
+---------------------------
+
+**Data Set Characteristics:**  
 
     :Number of Instances: 506 
 
-    :Number of Attributes: 13 numeric/categorical predictive
-    
-    :Median Value (attribute 14) is usually the target
+    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.
 
     :Attribute Information (in order):
         - CRIM     per capita crime rate by town
@@ -46,7 +44,7 @@ pages 244-261 of the latter.
 The Boston house-price data has been used in many machine learning papers that address regression
 problems.   
      
-**References**
+.. topic:: References
 
    - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.
    - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.
diff --git a/sklearn/datasets/descr/breast_cancer.rst b/sklearn/datasets/descr/breast_cancer.rst
index 547b41021ef2..fea6b6f017c1 100644
--- a/sklearn/datasets/descr/breast_cancer.rst
+++ b/sklearn/datasets/descr/breast_cancer.rst
@@ -1,9 +1,10 @@
-Breast Cancer Wisconsin (Diagnostic) Database
-=============================================
+.. _breast_cancer_dataset:
+
+Breast cancer wisconsin (diagnostic) dataset
+--------------------------------------------
+
+**Data Set Characteristics:**
 
-Notes
------
-Data Set Characteristics:
     :Number of Instances: 569
 
     :Number of Attributes: 30 numeric, predictive attributes and the class
@@ -103,8 +104,8 @@ This database is also available through the UW CS ftp server:
 ftp ftp.cs.wisc.edu
 cd math-prog/cpo-dataset/machine-learn/WDBC/
 
-References
-----------
+.. topic:: References
+
    - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction 
      for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on 
      Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
@@ -114,4 +115,4 @@ References
      July-August 1995.
    - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
      to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 
-     163-171.
+     163-171.
\ No newline at end of file
diff --git a/sklearn/datasets/descr/diabetes.rst b/sklearn/datasets/descr/diabetes.rst
index df102a1bec1f..f75beafd37b9 100644
--- a/sklearn/datasets/descr/diabetes.rst
+++ b/sklearn/datasets/descr/diabetes.rst
@@ -1,15 +1,14 @@
-Diabetes dataset
-================
+.. _diabetes_dataset:
 
-Notes
------
+Diabetes dataset
+----------------
 
 Ten baseline variables, age, sex, body mass index, average blood
 pressure, and six blood serum measurements were obtained for each of n =
 442 diabetes patients, as well as the response of interest, a
 quantitative measure of disease progression one year after baseline.
 
-Data Set Characteristics:
+**Data Set Characteristics:**
 
   :Number of Instances: 442
 
@@ -17,17 +16,17 @@ Data Set Characteristics:
 
   :Target: Column 11 is a quantitative measure of disease progression one year after baseline
 
-  :Attributes:
-    :Age:
-    :Sex:
-    :Body mass index:
-    :Average blood pressure:
-    :S1:
-    :S2:
-    :S3:
-    :S4:
-    :S5:
-    :S6:
+  :Attribute Information:
+      - Age
+      - Sex
+      - Body mass index
+      - Average blood pressure
+      - S1
+      - S2
+      - S3
+      - S4
+      - S5
+      - S6
 
 Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).
 
@@ -36,4 +35,4 @@ http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html
 
 For more information see:
 Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) "Least Angle Regression," Annals of Statistics (with discussion), 407-499.
-(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
+(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
\ No newline at end of file
diff --git a/sklearn/datasets/descr/digits.rst b/sklearn/datasets/descr/digits.rst
index a30514474f52..b4ecb714a01b 100644
--- a/sklearn/datasets/descr/digits.rst
+++ b/sklearn/datasets/descr/digits.rst
@@ -1,9 +1,10 @@
-Optical Recognition of Handwritten Digits Data Set
-===================================================
+.. _digits_dataset:
+
+Optical recognition of handwritten digits dataset
+--------------------------------------------------
+
+**Data Set Characteristics:**
 
-Notes
------
-Data Set Characteristics:
     :Number of Instances: 5620
     :Number of Attributes: 64
     :Attribute Information: 8x8 image of integer pixels in the range 0..16.
@@ -31,8 +32,8 @@ T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.
 L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,
 1994.
 
-References
-----------
+.. topic:: References
+
   - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their
     Applications to Handwritten Digit Recognition, MSc Thesis, Institute of
     Graduate Studies in Science and Engineering, Bogazici University.
@@ -42,4 +43,4 @@ References
     Electrical and Electronic Engineering Nanyang Technological University.
     2005.
   - Claudio Gentile. A New Approximate Maximal Margin Classification
-    Algorithm. NIPS. 2000.
+    Algorithm. NIPS. 2000.
\ No newline at end of file
diff --git a/sklearn/datasets/descr/iris.rst b/sklearn/datasets/descr/iris.rst
index 25cada25f54f..a35edc728c7d 100644
--- a/sklearn/datasets/descr/iris.rst
+++ b/sklearn/datasets/descr/iris.rst
@@ -1,9 +1,10 @@
-Iris Plants Database
-====================
+.. _iris_dataset:
+
+Iris plants dataset
+--------------------
+
+**Data Set Characteristics:**
 
-Notes
------
-Data Set Characteristics:
     :Number of Instances: 150 (50 in each of three classes)
     :Number of Attributes: 4 numeric, predictive attributes and the class
     :Attribute Information:
@@ -15,6 +16,7 @@ Data Set Characteristics:
                 - Iris-Setosa
                 - Iris-Versicolour
                 - Iris-Virginica
+                
     :Summary Statistics:
 
     ============== ==== ==== ======= ===== ====================
@@ -43,8 +45,8 @@ data set contains 3 classes of 50 instances each, where each class refers to a
 type of iris plant.  One class is linearly separable from the other 2; the
 latter are NOT linearly separable from each other.
 
-References
-----------
+.. topic:: References
+
    - Fisher, R.A. "The use of multiple measurements in taxonomic problems"
      Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to
      Mathematical Statistics" (John Wiley, NY, 1950).
@@ -58,4 +60,4 @@ References
      on Information Theory, May 1972, 431-433.
    - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II
      conceptual clustering system finds 3 classes in the data.
-   - Many, many more ...
+   - Many, many more ...
\ No newline at end of file
diff --git a/sklearn/datasets/descr/linnerud.rst b/sklearn/datasets/descr/linnerud.rst
index d790d3c0c908..848ee193e1ad 100644
--- a/sklearn/datasets/descr/linnerud.rst
+++ b/sklearn/datasets/descr/linnerud.rst
@@ -1,9 +1,10 @@
+.. _linnerrud_dataset:
+
 Linnerrud dataset
-=================
+-----------------
+
+**Data Set Characteristics:**
 
-Notes
------
-Data Set Characteristics:
     :Number of Instances: 20
     :Number of Attributes: 3
     :Missing Attribute Values: None
@@ -16,6 +17,6 @@ The Linnerud dataset constains two small dataset:
 - *physiological*: Data frame with 20 observations on 3 physiological variables:
    Chins, Situps and Jumps.
 
-References
-----------
-  * Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.
+.. topic:: References
+
+  * Tenenhaus, M. (1998). La regression PLS: theorie et pratique. Paris: Editions Technic.
\ No newline at end of file
diff --git a/sklearn/datasets/descr/wine_data.rst b/sklearn/datasets/descr/wine_data.rst
index 3d3341874a58..f43e6524130b 100644
--- a/sklearn/datasets/descr/wine_data.rst
+++ b/sklearn/datasets/descr/wine_data.rst
@@ -1,29 +1,30 @@
-Wine Data Database
-====================
+.. _wine_dataset:
+
+Wine recognition dataset
+------------------------
+
+**Data Set Characteristics:**
 
-Notes
------
-Data Set Characteristics:
     :Number of Instances: 178 (50 in each of three classes)
     :Number of Attributes: 13 numeric, predictive attributes and the class
     :Attribute Information:
- 		- 1) Alcohol
- 		- 2) Malic acid
- 		- 3) Ash
-		- 4) Alcalinity of ash  
- 		- 5) Magnesium
-		- 6) Total phenols
- 		- 7) Flavanoids
- 		- 8) Nonflavanoid phenols
- 		- 9) Proanthocyanins
-		- 10)Color intensity
- 		- 11)Hue
- 		- 12)OD280/OD315 of diluted wines
- 		- 13)Proline
-        	- class:
-                - class_0
-                - class_1
-                - class_2
+ 		- Alcohol
+ 		- Malic acid
+ 		- Ash
+		- Alcalinity of ash  
+ 		- Magnesium
+		- Total phenols
+ 		- Flavanoids
+ 		- Nonflavanoid phenols
+ 		- Proanthocyanins
+		- Color intensity
+ 		- Hue
+ 		- OD280/OD315 of diluted wines
+ 		- Proline
+    - class:
+            - class_0
+            - class_1
+            - class_2
 		
     :Summary Statistics:
     
@@ -72,24 +73,22 @@ Lichman, M. (2013). UCI Machine Learning Repository
 [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,
 School of Information and Computer Science. 
 
-References
-----------
-(1) 
-S. Aeberhard, D. Coomans and O. de Vel, 
-Comparison of Classifiers in High Dimensional Settings, 
-Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of 
-Mathematics and Statistics, James Cook University of North Queensland. 
-(Also submitted to Technometrics). 
+.. topic:: References
+
+  (1) S. Aeberhard, D. Coomans and O. de Vel, 
+  Comparison of Classifiers in High Dimensional Settings, 
+  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  
+  Mathematics and Statistics, James Cook University of North Queensland. 
+  (Also submitted to Technometrics). 
 
-The data was used with many others for comparing various 
-classifiers. The classes are separable, though only RDA 
-has achieved 100% correct classification. 
-(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) 
-(All results using the leave-one-out technique) 
+  The data was used with many others for comparing various 
+  classifiers. The classes are separable, though only RDA 
+  has achieved 100% correct classification. 
+  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) 
+  (All results using the leave-one-out technique) 
 
-(2) 
-S. Aeberhard, D. Coomans and O. de Vel, 
-"THE CLASSIFICATION PERFORMANCE OF RDA" 
-Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of 
-Mathematics and Statistics, James Cook University of North Queensland. 
-(Also submitted to Journal of Chemometrics). 
+  (2) S. Aeberhard, D. Coomans and O. de Vel, 
+  "THE CLASSIFICATION PERFORMANCE OF RDA" 
+  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of 
+  Mathematics and Statistics, James Cook University of North Queensland. 
+  (Also submitted to Journal of Chemometrics).
\ No newline at end of file
diff --git a/sklearn/datasets/lfw.py b/sklearn/datasets/lfw.py
index 8c2573b8c4dd..16fb2c2ef744 100644
--- a/sklearn/datasets/lfw.py
+++ b/sklearn/datasets/lfw.py
@@ -287,9 +287,10 @@ def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,
         If False, raise a IOError if the data is not locally available
         instead of trying to download the data from the source site.
 
-    return_X_y : boolean, default=False. If True, returns ``(dataset.data,
-    dataset.target)`` instead of a Bunch object. See below for more
-    information about the `dataset.data` and `dataset.target` object.
+    return_X_y : boolean, default=False.
+        If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch
+        object. See below for more information about the `dataset.data` and
+        `dataset.target` object.
 
         .. versionadded:: 0.20
 
@@ -472,8 +473,7 @@ def fetch_lfw_pairs(subset='train', data_home=None, funneled=True, resize=0.5,
         pixels. Changing the ``slice_``, ``resize`` or ``subset`` parameters
         will change the shape of the output.
 
-    pairs : numpy array of shape (2200, 2, 62, 47). Shape depends on
-            ``subset``.
+    pairs : numpy array of shape (2200, 2, 62, 47). Shape depends on ``subset``
         Each row has 2 face images corresponding to same or different person
         from the dataset containing 5749 people. Changing the ``slice_``,
         ``resize`` or ``subset`` parameters will change the shape of the
diff --git a/sklearn/datasets/mlcomp.py b/sklearn/datasets/mlcomp.py
index 1b0b6daf284f..169df6e55151 100644
--- a/sklearn/datasets/mlcomp.py
+++ b/sklearn/datasets/mlcomp.py
@@ -26,6 +26,8 @@ def _load_document_classification(dataset_path, metadata, set_=None, **kwargs):
 def load_mlcomp(name_or_id, set_="raw", mlcomp_root=None, **kwargs):
     """Load a datasets as downloaded from http://mlcomp.org
 
+    Read more in the :ref:`User Guide <datasets>`.
+
     Parameters
     ----------
 
@@ -33,7 +35,7 @@ def load_mlcomp(name_or_id, set_="raw", mlcomp_root=None, **kwargs):
         The integer id or the string name metadata of the MLComp
         dataset to load
 
-    set_ : str, default='raw'
+    set\_ : str, default='raw'
         Select the portion to load: 'train', 'test' or 'raw'
 
     mlcomp_root : str, optional
@@ -43,8 +45,6 @@ def load_mlcomp(name_or_id, set_="raw", mlcomp_root=None, **kwargs):
 
     **kwargs : domain specific kwargs to be passed to the dataset loader.
 
-    Read more in the :ref:`User Guide <datasets>`.
-
     Returns
     -------
 
diff --git a/sklearn/datasets/rcv1.py b/sklearn/datasets/rcv1.py
index f66823471277..b0ef91972a72 100644
--- a/sklearn/datasets/rcv1.py
+++ b/sklearn/datasets/rcv1.py
@@ -113,9 +113,10 @@ def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,
     shuffle : bool, default=False
         Whether to shuffle dataset.
 
-    return_X_y : boolean, default=False. If True, returns ``(dataset.data,
-    dataset.target)`` instead of a Bunch object. See below for more
-    information about the `dataset.data` and `dataset.target` object.
+    return_X_y : boolean, default=False.
+        If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch
+        object. See below for more information about the `dataset.data` and
+        `dataset.target` object.
 
         .. versionadded:: 0.20
 
diff --git a/sklearn/datasets/twenty_newsgroups.py b/sklearn/datasets/twenty_newsgroups.py
index a51812dd601d..6eed41f0de88 100644
--- a/sklearn/datasets/twenty_newsgroups.py
+++ b/sklearn/datasets/twenty_newsgroups.py
@@ -311,8 +311,9 @@ def fetch_20newsgroups_vectorized(subset="train", remove=(), data_home=None,
         If False, raise an IOError if the data is not locally available
         instead of trying to download the data from the source site.
 
-    return_X_y : boolean, default=False. If True, returns ``(data.data,
-    data.target)`` instead of a Bunch object.
+    return_X_y : boolean, default=False.
+        If True, returns ``(data.data, data.target)`` instead of a Bunch
+        object.
 
         .. versionadded:: 0.20
 
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index e4b36d120773..85c53959126b 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -26,7 +26,8 @@
 
 def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
                    regularization=None, copy_cov=True,
-                   init=None, max_iter=1000, check_input=True, verbose=0):
+                   init=None, max_iter=1000, check_input=True, verbose=0,
+                   positive=False):
     """Generic sparse coding
 
     Each column of the result is the solution to a Lasso problem.
@@ -79,6 +80,11 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
     verbose : int
         Controls the verbosity; the higher, the more messages. Defaults to 0.
 
+    positive: boolean
+        Whether to enforce a positivity constraint on the sparse code.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     code : array of shape (n_components, n_features)
@@ -113,7 +119,8 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
             # corrects the verbosity level.
             lasso_lars = LassoLars(alpha=alpha, fit_intercept=False,
                                    verbose=verbose, normalize=False,
-                                   precompute=gram, fit_path=False)
+                                   precompute=gram, fit_path=False,
+                                   positive=positive)
             lasso_lars.fit(dictionary.T, X.T, Xy=cov)
             new_code = lasso_lars.coef_
         finally:
@@ -126,7 +133,8 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
         # sklearn.linear_model.coordinate_descent.enet_path has a verbosity
         # argument that we could pass in from Lasso.
         clf = Lasso(alpha=alpha, fit_intercept=False, normalize=False,
-                    precompute=gram, max_iter=max_iter, warm_start=True)
+                    precompute=gram, max_iter=max_iter, warm_start=True,
+                    positive=positive)
 
         if init is not None:
             clf.coef_ = init
@@ -142,7 +150,7 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
             # corrects the verbosity level.
             lars = Lars(fit_intercept=False, verbose=verbose, normalize=False,
                         precompute=gram, n_nonzero_coefs=int(regularization),
-                        fit_path=False)
+                        fit_path=False, positive=positive)
             lars.fit(dictionary.T, X.T, Xy=cov)
             new_code = lars.coef_
         finally:
@@ -151,9 +159,15 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
     elif algorithm == 'threshold':
         new_code = ((np.sign(cov) *
                     np.maximum(np.abs(cov) - regularization, 0)).T)
+        if positive:
+            new_code[new_code < 0] = 0
 
     elif algorithm == 'omp':
         # TODO: Should verbose argument be passed to this?
+        if positive:
+            raise ValueError(
+                "Positive constraint not supported for \"omp\" coding method."
+            )
         new_code = orthogonal_mp_gram(
             Gram=gram, Xy=cov, n_nonzero_coefs=int(regularization),
             tol=None, norms_squared=row_norms(X, squared=True),
@@ -170,7 +184,8 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
 # XXX : could be moved to the linear_model module
 def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
                   n_nonzero_coefs=None, alpha=None, copy_cov=True, init=None,
-                  max_iter=1000, n_jobs=1, check_input=True, verbose=0):
+                  max_iter=1000, n_jobs=1, check_input=True, verbose=0,
+                  positive=False):
     """Sparse coding
 
     Each row of the result is the solution to a sparse coding problem.
@@ -240,6 +255,11 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
     verbose : int, optional
         Controls the verbosity; the higher, the more messages. Defaults to 0.
 
+    positive : boolean, optional
+        Whether to enforce positivity when finding the encoding.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     code : array of shape (n_samples, n_components)
@@ -287,7 +307,8 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
                               init=init,
                               max_iter=max_iter,
                               check_input=False,
-                              verbose=verbose)
+                              verbose=verbose,
+                              positive=positive)
         return code
 
     # Enter parallel code block
@@ -302,7 +323,8 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
             regularization=regularization, copy_cov=copy_cov,
             init=init[this_slice] if init is not None else None,
             max_iter=max_iter,
-            check_input=False)
+            check_input=False,
+            positive=positive)
         for this_slice in slices)
     for this_slice, this_view in zip(slices, code_views):
         code[this_slice] = this_view
@@ -310,7 +332,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
 
 
 def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
-                 random_state=None):
+                 random_state=None, positive=False):
     """Update the dense dictionary factor in place.
 
     Parameters
@@ -337,6 +359,11 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
         If None, the random number generator is the RandomState instance used
         by `np.random`.
 
+    positive : boolean, optional
+        Whether to enforce positivity when finding the dictionary.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     dictionary : array of shape (n_features, n_components)
@@ -344,7 +371,7 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
 
     """
     n_components = len(code)
-    n_samples = Y.shape[0]
+    n_features = Y.shape[0]
     random_state = check_random_state(random_state)
     # Residuals, computed 'in-place' for efficiency
     R = -np.dot(dictionary, code)
@@ -355,6 +382,8 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
         # R <- 1.0 * U_k * V_k^T + R
         R = ger(1.0, dictionary[:, k], code[k, :], a=R, overwrite_a=True)
         dictionary[:, k] = np.dot(R, code[k, :].T)
+        if positive:
+            dictionary[:, k][dictionary[:, k] < 0] = 0.0
         # Scale k'th atom
         atom_norm_square = np.dot(dictionary[:, k], dictionary[:, k])
         if atom_norm_square < 1e-20:
@@ -363,7 +392,9 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
                 sys.stdout.flush()
             elif verbose:
                 print("Adding new random atom")
-            dictionary[:, k] = random_state.randn(n_samples)
+            dictionary[:, k] = random_state.randn(n_features)
+            if positive:
+                dictionary[:, k][dictionary[:, k] < 0] = 0.0
             # Setting corresponding coefs to 0
             code[k, :] = 0.0
             dictionary[:, k] /= sqrt(np.dot(dictionary[:, k],
@@ -387,7 +418,8 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
 def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
                   method='lars', n_jobs=1, dict_init=None, code_init=None,
                   callback=None, verbose=False, random_state=None,
-                  return_n_iter=False):
+                  return_n_iter=False, positive_dict=False,
+                  positive_code=False):
     """Solves a dictionary learning matrix factorization problem.
 
     Finds the best dictionary and the corresponding sparse code for
@@ -449,6 +481,16 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
     return_n_iter : bool
         Whether or not to return the number of iterations.
 
+    positive_dict : bool
+        Whether to enforce positivity when finding the dictionary.
+
+        .. versionadded:: 0.20
+
+    positive_code : bool
+        Whether to enforce positivity when finding the code.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     code : array of shape (n_samples, n_components)
@@ -528,11 +570,12 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
 
         # Update code
         code = sparse_encode(X, dictionary, algorithm=method, alpha=alpha,
-                             init=code, n_jobs=n_jobs)
+                             init=code, n_jobs=n_jobs, positive=positive_code)
         # Update dictionary
         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,
                                              verbose=verbose, return_r2=True,
-                                             random_state=random_state)
+                                             random_state=random_state,
+                                             positive=positive_dict)
         dictionary = dictionary.T
 
         # Cost function
@@ -563,7 +606,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
                          batch_size=3, verbose=False, shuffle=True, n_jobs=1,
                          method='lars', iter_offset=0, random_state=None,
                          return_inner_stats=False, inner_stats=None,
-                         return_n_iter=False):
+                         return_n_iter=False, positive_dict=False,
+                         positive_code=False):
     """Solves a dictionary learning matrix factorization problem online.
 
     Finds the best dictionary and the corresponding sparse code for
@@ -647,6 +691,16 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
     return_n_iter : bool
         Whether or not to return the number of iterations.
 
+    positive_dict : bool
+        Whether to enforce positivity when finding the dictionary.
+
+        .. versionadded:: 0.20
+
+    positive_code : bool
+        Whether to enforce positivity when finding the code.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     code : array of shape (n_samples, n_components),
@@ -738,7 +792,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
                       % (ii, dt, dt / 60))
 
         this_code = sparse_encode(this_X, dictionary.T, algorithm=method,
-                                  alpha=alpha, n_jobs=n_jobs).T
+                                  alpha=alpha, n_jobs=n_jobs,
+                                  positive=positive_code).T
 
         # Update the auxiliary variables
         if ii < batch_size - 1:
@@ -754,7 +809,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
 
         # Update dictionary
         dictionary = _update_dict(dictionary, B, A, verbose=verbose,
-                                  random_state=random_state)
+                                  random_state=random_state,
+                                  positive=positive_dict)
         # XXX: Can the residuals be of any use?
 
         # Maybe we need a stopping criteria based on the amount of
@@ -773,7 +829,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         elif verbose == 1:
             print('|', end=' ')
         code = sparse_encode(X, dictionary.T, algorithm=method, alpha=alpha,
-                             n_jobs=n_jobs, check_input=False)
+                             n_jobs=n_jobs, check_input=False,
+                             positive=positive_code)
         if verbose > 1:
             dt = (time.time() - t0)
             print('done (total time: % 3is, % 4.1fmn)' % (dt, dt / 60))
@@ -795,13 +852,14 @@ def _set_sparse_coding_params(self, n_components,
                                   transform_algorithm='omp',
                                   transform_n_nonzero_coefs=None,
                                   transform_alpha=None, split_sign=False,
-                                  n_jobs=1):
+                                  n_jobs=1, positive_code=False):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
         self.transform_alpha = transform_alpha
         self.split_sign = split_sign
         self.n_jobs = n_jobs
+        self.positive_code = positive_code
 
     def transform(self, X):
         """Encode the data as a sparse combination of the dictionary atoms.
@@ -828,7 +886,8 @@ def transform(self, X):
         code = sparse_encode(
             X, self.components_, algorithm=self.transform_algorithm,
             n_nonzero_coefs=self.transform_n_nonzero_coefs,
-            alpha=self.transform_alpha, n_jobs=self.n_jobs)
+            alpha=self.transform_alpha, n_jobs=self.n_jobs,
+            positive=self.positive_code)
 
         if self.split_sign:
             # feature vector is split into a positive and negative side
@@ -894,6 +953,11 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
     n_jobs : int,
         number of parallel jobs to run
 
+    positive_code : bool
+        Whether to enforce positivity when finding the code.
+
+        .. versionadded:: 0.20
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -911,11 +975,12 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
     def __init__(self, dictionary, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 split_sign=False, n_jobs=1):
+                 split_sign=False, n_jobs=1, positive_code=False):
         self._set_sparse_coding_params(dictionary.shape[0],
                                        transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code)
         self.components_ = dictionary
 
     def fit(self, X, y=None):
@@ -1028,6 +1093,16 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
         If None, the random number generator is the RandomState instance used
         by `np.random`.
 
+    positive_code : bool
+        Whether to enforce positivity when finding the code.
+
+        .. versionadded:: 0.20
+
+    positive_dict : bool
+        Whether to enforce positivity when finding the dictionary
+
+        .. versionadded:: 0.20
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -1057,11 +1132,13 @@ def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
                  fit_algorithm='lars', transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
                  n_jobs=1, code_init=None, dict_init=None, verbose=False,
-                 split_sign=False, random_state=None):
+                 split_sign=False, random_state=None,
+                 positive_code=False, positive_dict=False):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
@@ -1070,6 +1147,7 @@ def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
         self.dict_init = dict_init
         self.verbose = verbose
         self.random_state = random_state
+        self.positive_dict = positive_dict
 
     def fit(self, X, y=None):
         """Fit the model from data in X.
@@ -1103,7 +1181,9 @@ def fit(self, X, y=None):
             dict_init=self.dict_init,
             verbose=self.verbose,
             random_state=random_state,
-            return_n_iter=True)
+            return_n_iter=True,
+            positive_dict=self.positive_dict,
+            positive_code=self.positive_code)
         self.components_ = U
         self.error_ = E
         return self
@@ -1193,6 +1273,16 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
         If None, the random number generator is the RandomState instance used
         by `np.random`.
 
+    positive_code : bool
+        Whether to enforce positivity when finding the code.
+
+        .. versionadded:: 0.20
+
+    positive_dict : bool
+        Whether to enforce positivity when finding the dictionary.
+
+        .. versionadded:: 0.20
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -1228,11 +1318,13 @@ def __init__(self, n_components=None, alpha=1, n_iter=1000,
                  fit_algorithm='lars', n_jobs=1, batch_size=3,
                  shuffle=True, dict_init=None, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 verbose=False, split_sign=False, random_state=None):
+                 verbose=False, split_sign=False, random_state=None,
+                 positive_code=False, positive_dict=False):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code)
         self.alpha = alpha
         self.n_iter = n_iter
         self.fit_algorithm = fit_algorithm
@@ -1242,6 +1334,7 @@ def __init__(self, n_components=None, alpha=1, n_iter=1000,
         self.batch_size = batch_size
         self.split_sign = split_sign
         self.random_state = random_state
+        self.positive_dict = positive_dict
 
     def fit(self, X, y=None):
         """Fit the model from data in X.
@@ -1270,7 +1363,9 @@ def fit(self, X, y=None):
             batch_size=self.batch_size, shuffle=self.shuffle,
             verbose=self.verbose, random_state=random_state,
             return_inner_stats=True,
-            return_n_iter=True)
+            return_n_iter=True,
+            positive_dict=self.positive_dict,
+            positive_code=self.positive_code)
         self.components_ = U
         # Keep track of the state of the algorithm to be able to do
         # some online fitting (partial_fit)
@@ -1317,7 +1412,9 @@ def partial_fit(self, X, y=None, iter_offset=None):
             batch_size=len(X), shuffle=False,
             verbose=self.verbose, return_code=False,
             iter_offset=iter_offset, random_state=self.random_state_,
-            return_inner_stats=True, inner_stats=inner_stats)
+            return_inner_stats=True, inner_stats=inner_stats,
+            positive_dict=self.positive_dict,
+            positive_code=self.positive_code)
         self.components_ = U
 
         # Keep track of the state of the algorithm to be able to do
diff --git a/sklearn/decomposition/incremental_pca.py b/sklearn/decomposition/incremental_pca.py
index 13e51090dd82..a398a5dc7bf4 100644
--- a/sklearn/decomposition/incremental_pca.py
+++ b/sklearn/decomposition/incremental_pca.py
@@ -243,9 +243,10 @@ def partial_fit(self, X, y=None, check_input=True):
 
         # Update stats - they are 0 if this is the fisrt step
         col_mean, col_var, n_total_samples = \
-            _incremental_mean_and_var(X, last_mean=self.mean_,
-                                      last_variance=self.var_,
-                                      last_sample_count=self.n_samples_seen_)
+            _incremental_mean_and_var(
+                X, last_mean=self.mean_, last_variance=self.var_,
+                last_sample_count=np.repeat(self.n_samples_seen_, X.shape[1]))
+        n_total_samples = n_total_samples[0]
 
         # Whitening
         if self.n_samples_seen_ == 0:
diff --git a/sklearn/decomposition/pca.py b/sklearn/decomposition/pca.py
index 1c93f6b00134..a8f040927392 100644
--- a/sklearn/decomposition/pca.py
+++ b/sklearn/decomposition/pca.py
@@ -389,25 +389,25 @@ def _fit(self, X):
             n_components = self.n_components
 
         # Handle svd_solver
-        svd_solver = self.svd_solver
-        if svd_solver == 'auto':
+        self._fit_svd_solver = self.svd_solver
+        if self._fit_svd_solver == 'auto':
             # Small problem or n_components == 'mle', just call full PCA
             if max(X.shape) <= 500 or n_components == 'mle':
-                svd_solver = 'full'
+                self._fit_svd_solver = 'full'
             elif n_components >= 1 and n_components < .8 * min(X.shape):
-                svd_solver = 'randomized'
+                self._fit_svd_solver = 'randomized'
             # This is also the case of n_components in (0,1)
             else:
-                svd_solver = 'full'
+                self._fit_svd_solver = 'full'
 
         # Call different fits for either full or truncated SVD
-        if svd_solver == 'full':
+        if self._fit_svd_solver == 'full':
             return self._fit_full(X, n_components)
-        elif svd_solver in ['arpack', 'randomized']:
-            return self._fit_truncated(X, n_components, svd_solver)
+        elif self._fit_svd_solver in ['arpack', 'randomized']:
+            return self._fit_truncated(X, n_components, self._fit_svd_solver)
         else:
             raise ValueError("Unrecognized svd_solver='{0}'"
-                             "".format(svd_solver))
+                             "".format(self._fit_svd_solver))
 
     def _fit_full(self, X, n_components):
         """Fit the model by computing full SVD on X"""
diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index df3c32632d2e..0bf62cbc8d77 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -1,3 +1,5 @@
+import pytest
+
 import numpy as np
 import itertools
 
@@ -55,6 +57,38 @@ def test_dict_learning_overcomplete():
     assert_true(dico.components_.shape == (n_components, n_features))
 
 
+@pytest.mark.parametrize("transform_algorithm", [
+    "lasso_lars",
+    "lasso_cd",
+    "lars",
+    "threshold",
+])
+@pytest.mark.parametrize("positive_code", [
+    False,
+    True,
+])
+@pytest.mark.parametrize("positive_dict", [
+    False,
+    True,
+])
+def test_dict_learning_positivity(transform_algorithm,
+                                  positive_code,
+                                  positive_dict):
+    n_components = 5
+    dico = DictionaryLearning(
+        n_components, transform_algorithm=transform_algorithm, random_state=0,
+        positive_code=positive_code, positive_dict=positive_dict).fit(X)
+    code = dico.transform(X)
+    if positive_dict:
+        assert_true((dico.components_ >= 0).all())
+    else:
+        assert_true((dico.components_ < 0).any())
+    if positive_code:
+        assert_true((code >= 0).all())
+    else:
+        assert_true((code < 0).any())
+
+
 def test_dict_learning_reconstruction():
     n_components = 12
     dico = DictionaryLearning(n_components, transform_algorithm='omp',
@@ -135,6 +169,53 @@ def test_dict_learning_online_shapes():
     assert_equal(np.dot(code, dictionary).shape, X.shape)
 
 
+@pytest.mark.parametrize("transform_algorithm", [
+    "lasso_lars",
+    "lasso_cd",
+    "lars",
+    "threshold",
+])
+@pytest.mark.parametrize("positive_code", [
+    False,
+    True,
+])
+@pytest.mark.parametrize("positive_dict", [
+    False,
+    True,
+])
+def test_dict_learning_online_positivity(transform_algorithm,
+                                         positive_code,
+                                         positive_dict):
+    rng = np.random.RandomState(0)
+    n_components = 8
+
+    dico = MiniBatchDictionaryLearning(
+        n_components, transform_algorithm=transform_algorithm, random_state=0,
+        positive_code=positive_code, positive_dict=positive_dict).fit(X)
+    code = dico.transform(X)
+    if positive_dict:
+        assert_true((dico.components_ >= 0).all())
+    else:
+        assert_true((dico.components_ < 0).any())
+    if positive_code:
+        assert_true((code >= 0).all())
+    else:
+        assert_true((code < 0).any())
+
+    code, dictionary = dict_learning_online(X, n_components=n_components,
+                                            alpha=1, random_state=rng,
+                                            positive_dict=positive_dict,
+                                            positive_code=positive_code)
+    if positive_dict:
+        assert_true((dictionary >= 0).all())
+    else:
+        assert_true((dictionary < 0).any())
+    if positive_code:
+        assert_true((code >= 0).all())
+    else:
+        assert_true((code < 0).any())
+
+
 def test_dict_learning_online_verbosity():
     n_components = 5
     # test verbosity
@@ -215,6 +296,29 @@ def test_sparse_encode_shapes():
         assert_equal(code.shape, (n_samples, n_components))
 
 
+@pytest.mark.parametrize("positive", [
+    False,
+    True,
+])
+def test_sparse_encode_positivity(positive):
+    n_components = 12
+    rng = np.random.RandomState(0)
+    V = rng.randn(n_components, n_features)  # random init
+    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]
+    for algo in ('lasso_lars', 'lasso_cd', 'lars', 'threshold'):
+        code = sparse_encode(X, V, algorithm=algo, positive=positive)
+        if positive:
+            assert_true((code >= 0).all())
+        else:
+            assert_true((code < 0).any())
+
+    try:
+        sparse_encode(X, V, algorithm='omp', positive=positive)
+    except ValueError:
+        if not positive:
+            raise
+
+
 def test_sparse_encode_input():
     n_components = 100
     rng = np.random.RandomState(0)
diff --git a/sklearn/decomposition/tests/test_truncated_svd.py b/sklearn/decomposition/tests/test_truncated_svd.py
index f08648bb4c46..205944883a41 100644
--- a/sklearn/decomposition/tests/test_truncated_svd.py
+++ b/sklearn/decomposition/tests/test_truncated_svd.py
@@ -5,11 +5,11 @@
 
 import pytest
 
-from sklearn.decomposition import TruncatedSVD
+from sklearn.decomposition import TruncatedSVD, PCA
 from sklearn.utils import check_random_state
 from sklearn.utils.testing import (assert_array_almost_equal, assert_equal,
                                    assert_raises, assert_greater,
-                                   assert_array_less)
+                                   assert_array_less, assert_allclose)
 
 
 # Make an X that looks somewhat like a small tf-idf matrix.
@@ -222,3 +222,21 @@ def test_singular_values():
     rpca.fit(X_hat_rpca)
     assert_array_almost_equal(apca.singular_values_, [3.142, 2.718, 1.0], 14)
     assert_array_almost_equal(rpca.singular_values_, [3.142, 2.718, 1.0], 14)
+
+
+def test_truncated_svd_eq_pca():
+    # TruncatedSVD should be equal to PCA on centered data
+
+    X_c = X - X.mean(axis=0)
+
+    params = dict(n_components=10, random_state=42)
+
+    svd = TruncatedSVD(algorithm='arpack', **params)
+    pca = PCA(svd_solver='arpack', **params)
+
+    Xt_svd = svd.fit_transform(X_c)
+    Xt_pca = pca.fit_transform(X_c)
+
+    assert_allclose(Xt_svd, Xt_pca, rtol=1e-9)
+    assert_allclose(pca.mean_, 0, atol=1e-9)
+    assert_allclose(svd.components_, pca.components_)
diff --git a/sklearn/ensemble/bagging.py b/sklearn/ensemble/bagging.py
index a57d29b6cc29..30324d6e0c87 100644
--- a/sklearn/ensemble/bagging.py
+++ b/sklearn/ensemble/bagging.py
@@ -500,7 +500,7 @@ class BaggingClassifier(BaseBagging, ClassifierMixin):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the building process.
+        Controls the verbosity when fitting and predicting.
 
     Attributes
     ----------
@@ -876,7 +876,7 @@ class BaggingRegressor(BaseBagging, RegressorMixin):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the building process.
+        Controls the verbosity when fitting and predicting.
 
     Attributes
     ----------
diff --git a/sklearn/ensemble/forest.py b/sklearn/ensemble/forest.py
index 05ba33faab37..b7a349d4b5a8 100644
--- a/sklearn/ensemble/forest.py
+++ b/sklearn/ensemble/forest.py
@@ -861,15 +861,15 @@ class RandomForestClassifier(ForestClassifier):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the tree building process.
+        Controls the verbosity when fitting and predicting.
 
     warm_start : bool, optional (default=False)
         When set to ``True``, reuse the solution of the previous call to fit
         and add more estimators to the ensemble, otherwise, just fit a whole
         new forest. See :term:`the Glossary <warm_start>`.
 
-    class_weight : dict, list of dicts, "balanced",
-        "balanced_subsample" or None, optional (default=None)
+    class_weight : dict, list of dicts, "balanced", "balanced_subsample" or \
+    None, optional (default=None)
         Weights associated with classes in the form ``{class_label: weight}``.
         If not given, all classes are supposed to have weight one. For
         multi-output problems, a list of dicts can be provided in the same
@@ -1139,7 +1139,7 @@ class RandomForestRegressor(ForestRegressor):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the tree building process.
+        Controls the verbosity when fitting and predicting.
 
     warm_start : bool, optional (default=False)
         When set to ``True``, reuse the solution of the previous call to fit
@@ -1370,14 +1370,15 @@ class ExtraTreesClassifier(ForestClassifier):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the tree building process.
+        Controls the verbosity when fitting and predicting.
 
     warm_start : bool, optional (default=False)
         When set to ``True``, reuse the solution of the previous call to fit
         and add more estimators to the ensemble, otherwise, just fit a whole
         new forest. See :term:`the Glossary <warm_start>`.
 
-    class_weight : dict, list of dicts, "balanced", "balanced_subsample" or None, optional (default=None)
+    class_weight : dict, list of dicts, "balanced", "balanced_subsample" or \
+    None, optional (default=None)
         Weights associated with classes in the form ``{class_label: weight}``.
         If not given, all classes are supposed to have weight one. For
         multi-output problems, a list of dicts can be provided in the same
@@ -1618,7 +1619,7 @@ class ExtraTreesRegressor(ForestRegressor):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the tree building process.
+        Controls the verbosity when fitting and predicting.
 
     warm_start : bool, optional (default=False)
         When set to ``True``, reuse the solution of the previous call to fit
@@ -1809,7 +1810,7 @@ class RandomTreesEmbedding(BaseForest):
         by `np.random`.
 
     verbose : int, optional (default=0)
-        Controls the verbosity of the tree building process.
+        Controls the verbosity when fitting and predicting.
 
     warm_start : bool, optional (default=False)
         When set to ``True``, reuse the solution of the previous call to fit
@@ -1931,7 +1932,8 @@ def fit_transform(self, X, y=None, sample_weight=None):
         super(RandomTreesEmbedding, self).fit(X, y,
                                               sample_weight=sample_weight)
 
-        self.one_hot_encoder_ = OneHotEncoder(sparse=self.sparse_output)
+        self.one_hot_encoder_ = OneHotEncoder(sparse=self.sparse_output,
+                                              categories='auto')
         return self.one_hot_encoder_.fit_transform(self.apply(X))
 
     def transform(self, X):
diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
index d4fedd763ada..4edf4dd1fa68 100644
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -1229,11 +1229,12 @@ def feature_importances_(self):
 
         total_sum = np.zeros((self.n_features_, ), dtype=np.float64)
         for stage in self.estimators_:
-            stage_sum = sum(tree.feature_importances_
-                            for tree in stage) / len(stage)
+            stage_sum = sum(tree.tree_.compute_feature_importances(
+                normalize=False) for tree in stage) / len(stage)
             total_sum += stage_sum
 
         importances = total_sum / len(self.estimators_)
+        importances /= importances.sum()
         return importances
 
     def _validate_y(self, y, sample_weight):
diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py
index dc89d18af6da..a1eb7ccd286b 100644
--- a/sklearn/ensemble/iforest.py
+++ b/sklearn/ensemble/iforest.py
@@ -109,7 +109,7 @@ class IsolationForest(BaseBagging, OutlierMixin):
 
     offset_ : float
         Offset used to define the decision function from the raw scores.
-        We have the relation: decision_function = score_samples - offset_.
+        We have the relation: ``decision_function = score_samples - offset_``.
         When the contamination parameter is set to "auto", the offset is equal
         to -0.5 as the scores of inliers are close to 0 and the scores of
         outliers are close to -1. When a contamination parameter different
diff --git a/sklearn/ensemble/tests/test_gradient_boosting.py b/sklearn/ensemble/tests/test_gradient_boosting.py
index c18008d0b31c..6f7654c7d606 100644
--- a/sklearn/ensemble/tests/test_gradient_boosting.py
+++ b/sklearn/ensemble/tests/test_gradient_boosting.py
@@ -12,7 +12,7 @@
 
 from sklearn import datasets
 from sklearn.base import clone
-from sklearn.datasets import make_classification
+from sklearn.datasets import make_classification, fetch_california_housing
 from sklearn.ensemble import GradientBoostingClassifier
 from sklearn.ensemble import GradientBoostingRegressor
 from sklearn.ensemble.gradient_boosting import ZeroEstimator
@@ -452,6 +452,34 @@ def test_max_feature_regression():
     assert_true(deviance < 0.5, "GB failed with deviance %.4f" % deviance)
 
 
+def test_feature_importance_regression():
+    """Test that Gini importance is calculated correctly.
+
+    This test follows the example from [1]_ (pg. 373).
+
+    .. [1] Friedman, J., Hastie, T., & Tibshirani, R. (2001). The elements
+       of statistical learning. New York: Springer series in statistics.
+    """
+    california = fetch_california_housing()
+    X, y = california.data, california.target
+    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
+
+    reg = GradientBoostingRegressor(loss='huber', learning_rate=0.1,
+                                    max_leaf_nodes=6, n_estimators=100,
+                                    random_state=0)
+    reg.fit(X_train, y_train)
+    sorted_idx = np.argsort(reg.feature_importances_)[::-1]
+    sorted_features = [california.feature_names[s] for s in sorted_idx]
+
+    # The most important feature is the median income by far.
+    assert sorted_features[0] == 'MedInc'
+
+    # The three subsequent features are the following. Their relative ordering
+    # might change a bit depending on the randomness of the trees and the
+    # train / test split.
+    assert set(sorted_features[1:4]) == {'Longitude', 'AveOccup', 'Latitude'}
+
+
 def test_max_feature_auto():
     # Test if max features is set properly for floats and str.
     X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)
diff --git a/sklearn/ensemble/voting_classifier.py b/sklearn/ensemble/voting_classifier.py
index 81db37de290d..2b0d63d2140b 100644
--- a/sklearn/ensemble/voting_classifier.py
+++ b/sklearn/ensemble/voting_classifier.py
@@ -282,13 +282,16 @@ def transform(self, X):
 
         Returns
         -------
-        If `voting='soft'` and `flatten_transform=True`:
-          array-like = (n_classifiers, n_samples * n_classes)
-          otherwise array-like = (n_classifiers, n_samples, n_classes)
-            Class probabilities calculated by each classifier.
-        If `voting='hard'`:
-          array-like = [n_samples, n_classifiers]
-            Class labels predicted by each classifier.
+        probabilities_or_labels
+            If `voting='soft'` and `flatten_transform=True`:
+                returns array-like of shape (n_classifiers, n_samples *
+                n_classes), being class probabilities calculated by each
+                classifier.
+            If `voting='soft' and `flatten_transform=False`:
+                array-like of shape (n_classifiers, n_samples, n_classes)
+            If `voting='hard'`:
+                array-like of shape (n_samples, n_classifiers), being
+                class labels predicted by each classifier.
         """
         check_is_fitted(self, 'estimators_')
 
diff --git a/sklearn/exceptions.py b/sklearn/exceptions.py
index e58f42760663..9cf207e40fdd 100644
--- a/sklearn/exceptions.py
+++ b/sklearn/exceptions.py
@@ -30,7 +30,7 @@ class NotFittedError(ValueError, AttributeError):
     ... except NotFittedError as e:
     ...     print(repr(e))
     ...                        # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
-    NotFittedError('This LinearSVC instance is not fitted yet',)
+    NotFittedError('This LinearSVC instance is not fitted yet'...)
 
     .. versionchanged:: 0.18
        Moved from sklearn.utils.validation.
@@ -121,7 +121,7 @@ class FitFailedWarning(RuntimeWarning):
     ... # doctest: +NORMALIZE_WHITESPACE
     FitFailedWarning('Estimator fit failed. The score on this train-test
     partition for these parameters will be set to 0.000000.
-    Details: \\nValueError: Penalty term must be positive; got (C=-2)\\n',)
+    Details: \\nValueError: Penalty term must be positive; got (C=-2)\\n'...)
 
     .. versionchanged:: 0.18
        Moved from sklearn.cross_validation.
diff --git a/sklearn/feature_extraction/dict_vectorizer.py b/sklearn/feature_extraction/dict_vectorizer.py
index 5b8f932e889c..3ab717d1cf29 100644
--- a/sklearn/feature_extraction/dict_vectorizer.py
+++ b/sklearn/feature_extraction/dict_vectorizer.py
@@ -39,7 +39,7 @@ class DictVectorizer(BaseEstimator, TransformerMixin):
     However, note that this transformer will only do a binary one-hot encoding
     when feature values are of type string. If categorical features are
     represented as numeric values such as int, the DictVectorizer can be
-    followed by :class:`sklearn.preprocessing.CategoricalEncoder` to complete
+    followed by :class:`sklearn.preprocessing.OneHotEncoder` to complete
     binary one-hot encoding.
 
     Features that do not occur in a sample (mapping) will have a zero value
@@ -89,7 +89,7 @@ class DictVectorizer(BaseEstimator, TransformerMixin):
     See also
     --------
     FeatureHasher : performs vectorization using only a hash function.
-    sklearn.preprocessing.CategoricalEncoder : handles nominal/categorical
+    sklearn.preprocessing.OrdinalEncoder : handles nominal/categorical
       features encoded as columns of arbitrary data types.
     """
 
diff --git a/sklearn/feature_extraction/hashing.py b/sklearn/feature_extraction/hashing.py
index d586e6302e54..9795d30aa675 100644
--- a/sklearn/feature_extraction/hashing.py
+++ b/sklearn/feature_extraction/hashing.py
@@ -81,8 +81,7 @@ class FeatureHasher(BaseEstimator, TransformerMixin):
     See also
     --------
     DictVectorizer : vectorizes string-valued features using a hash table.
-    sklearn.preprocessing.OneHotEncoder : handles nominal/categorical features
-        encoded as columns of integers.
+    sklearn.preprocessing.OneHotEncoder : handles nominal/categorical features.
     """
 
     def __init__(self, n_features=(2 ** 20), input_type="dict",
diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py
index b0209f6bbe3a..9d39f01945b1 100644
--- a/sklearn/feature_extraction/tests/test_text.py
+++ b/sklearn/feature_extraction/tests/test_text.py
@@ -1,6 +1,9 @@
 from __future__ import unicode_literals
 import warnings
 
+import pytest
+from scipy import sparse
+
 from sklearn.feature_extraction.text import strip_tags
 from sklearn.feature_extraction.text import strip_accents_unicode
 from sklearn.feature_extraction.text import strip_accents_ascii
@@ -28,15 +31,14 @@
                                    assert_in, assert_less, assert_greater,
                                    assert_warns_message, assert_raise_message,
                                    clean_warning_registry, ignore_warnings,
-                                   SkipTest, assert_raises)
+                                   SkipTest, assert_raises,
+                                   assert_allclose_dense_sparse)
 
 from collections import defaultdict, Mapping
 from functools import partial
 import pickle
 from io import StringIO
 
-import pytest
-
 JUNK_FOOD_DOCS = (
     "the pizza pizza beer copyright",
     "the pizza burger beer copyright",
@@ -1038,6 +1040,42 @@ def test_vectorizer_string_object_as_input(Vectorizer):
     assert_raise_message(ValueError, message, vec.transform, "hello world!")
 
 
+@pytest.mark.parametrize("X_dtype", [np.float32, np.float64])
+def test_tfidf_transformer_type(X_dtype):
+    X = sparse.rand(10, 20000, dtype=X_dtype, random_state=42)
+    X_trans = TfidfTransformer().fit_transform(X)
+    assert X_trans.dtype == X.dtype
+
+
+def test_tfidf_transformer_sparse():
+    X = sparse.rand(10, 20000, dtype=np.float64, random_state=42)
+    X_csc = sparse.csc_matrix(X)
+    X_csr = sparse.csr_matrix(X)
+
+    X_trans_csc = TfidfTransformer().fit_transform(X_csc)
+    X_trans_csr = TfidfTransformer().fit_transform(X_csr)
+    assert_allclose_dense_sparse(X_trans_csc, X_trans_csr)
+    assert X_trans_csc.format == X_trans_csr.format
+
+
+@pytest.mark.parametrize(
+    "vectorizer_dtype, output_dtype, expected_warning, msg_warning",
+    [(np.int32, np.float64, UserWarning, "'dtype' should be used."),
+     (np.int64, np.float64, UserWarning, "'dtype' should be used."),
+     (np.float32, np.float32, None, None),
+     (np.float64, np.float64, None, None)]
+)
+def test_tfidf_vectorizer_type(vectorizer_dtype, output_dtype,
+                               expected_warning, msg_warning):
+    X = np.array(["numpy", "scipy", "sklearn"])
+    vectorizer = TfidfVectorizer(dtype=vectorizer_dtype)
+    with pytest.warns(expected_warning, match=msg_warning) as record:
+            X_idf = vectorizer.fit_transform(X)
+    if expected_warning is None:
+        assert len(record) == 0
+    assert X_idf.dtype == output_dtype
+
+
 @pytest.mark.parametrize("vec", [
         HashingVectorizer(ngram_range=(2, 1)),
         CountVectorizer(ngram_range=(2, 1)),
diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py
index df0582d3d4f5..e96693599da7 100644
--- a/sklearn/feature_extraction/text.py
+++ b/sklearn/feature_extraction/text.py
@@ -11,7 +11,7 @@
 The :mod:`sklearn.feature_extraction.text` submodule gathers utilities to
 build feature vectors from text documents.
 """
-from __future__ import unicode_literals
+from __future__ import unicode_literals, division
 
 import array
 from collections import Mapping, defaultdict
@@ -19,6 +19,7 @@
 from operator import itemgetter
 import re
 import unicodedata
+import warnings
 
 import numpy as np
 import scipy.sparse as sp
@@ -29,7 +30,7 @@
 from ..preprocessing import normalize
 from .hashing import FeatureHasher
 from .stop_words import ENGLISH_STOP_WORDS
-from ..utils.validation import check_is_fitted
+from ..utils.validation import check_is_fitted, check_array, FLOAT_DTYPES
 from ..utils.fixes import sp_version
 
 __all__ = ['CountVectorizer',
@@ -573,7 +574,7 @@ def _document_frequency(X):
     if sp.isspmatrix_csr(X):
         return np.bincount(X.indices, minlength=X.shape[1])
     else:
-        return np.diff(sp.csc_matrix(X, copy=False).indptr)
+        return np.diff(X.indptr)
 
 
 class CountVectorizer(BaseEstimator, VectorizerMixin):
@@ -1117,11 +1118,14 @@ def fit(self, X, y=None):
         X : sparse matrix, [n_samples, n_features]
             a matrix of term/token counts
         """
+        X = check_array(X, accept_sparse=('csr', 'csc'))
         if not sp.issparse(X):
-            X = sp.csc_matrix(X)
+            X = sp.csr_matrix(X)
+        dtype = X.dtype if X.dtype in FLOAT_DTYPES else np.float64
+
         if self.use_idf:
             n_samples, n_features = X.shape
-            df = _document_frequency(X)
+            df = _document_frequency(X).astype(dtype)
 
             # perform idf smoothing if required
             df += int(self.smooth_idf)
@@ -1129,9 +1133,11 @@ def fit(self, X, y=None):
 
             # log+1 instead of log makes sure terms with zero idf don't get
             # suppressed entirely.
-            idf = np.log(float(n_samples) / df) + 1.0
-            self._idf_diag = sp.spdiags(idf, diags=0, m=n_features,
-                                        n=n_features, format='csr')
+            idf = np.log(n_samples / df) + 1
+            self._idf_diag = sp.diags(idf, offsets=0,
+                                      shape=(n_features, n_features),
+                                      format='csr',
+                                      dtype=dtype)
 
         return self
 
@@ -1151,12 +1157,9 @@ def transform(self, X, copy=True):
         -------
         vectors : sparse matrix, [n_samples, n_features]
         """
-        if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.floating):
-            # preserve float family dtype
-            X = sp.csr_matrix(X, copy=copy)
-        else:
-            # convert counts or binary occurrences to floats
-            X = sp.csr_matrix(X, dtype=np.float64, copy=copy)
+        X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy)
+        if not sp.issparse(X):
+            X = sp.csr_matrix(X, dtype=np.float64)
 
         n_samples, n_features = X.shape
 
@@ -1367,7 +1370,7 @@ def __init__(self, input='content', encoding='utf-8',
                  stop_words=None, token_pattern=r"(?u)\b\w\w+\b",
                  ngram_range=(1, 1), max_df=1.0, min_df=1,
                  max_features=None, vocabulary=None, binary=False,
-                 dtype=np.int64, norm='l2', use_idf=True, smooth_idf=True,
+                 dtype=np.float64, norm='l2', use_idf=True, smooth_idf=True,
                  sublinear_tf=False):
 
         super(TfidfVectorizer, self).__init__(
@@ -1432,6 +1435,13 @@ def idf_(self, value):
                                  (len(value), len(self.vocabulary)))
         self._tfidf.idf_ = value
 
+    def _check_params(self):
+        if self.dtype not in FLOAT_DTYPES:
+            warnings.warn("Only {} 'dtype' should be used. {} 'dtype' will "
+                          "be converted to np.float64."
+                          .format(FLOAT_DTYPES, self.dtype),
+                          UserWarning)
+
     def fit(self, raw_documents, y=None):
         """Learn vocabulary and idf from training set.
 
@@ -1444,6 +1454,7 @@ def fit(self, raw_documents, y=None):
         -------
         self : TfidfVectorizer
         """
+        self._check_params()
         X = super(TfidfVectorizer, self).fit_transform(raw_documents)
         self._tfidf.fit(X)
         return self
@@ -1464,6 +1475,7 @@ def fit_transform(self, raw_documents, y=None):
         X : sparse matrix, [n_samples, n_features]
             Tf-idf-weighted document-term matrix.
         """
+        self._check_params()
         X = super(TfidfVectorizer, self).fit_transform(raw_documents)
         self._tfidf.fit(X)
         # X is already a transformed view of raw_documents so
diff --git a/sklearn/gaussian_process/tests/test_gaussian_process.py b/sklearn/gaussian_process/tests/test_gaussian_process.py
index 6d6fa3ab8119..2cacd217cc98 100644
--- a/sklearn/gaussian_process/tests/test_gaussian_process.py
+++ b/sklearn/gaussian_process/tests/test_gaussian_process.py
@@ -15,6 +15,7 @@
 from sklearn.datasets import make_regression
 from sklearn.utils.testing import assert_greater, assert_true, assert_raises
 
+pytestmark = pytest.mark.filterwarnings('ignore', category=DeprecationWarning)
 
 f = lambda x: x * np.sin(x)
 X = np.atleast_2d([1., 3., 5., 6., 7., 8.]).T
diff --git a/sklearn/impute.py b/sklearn/impute.py
index fe772d6a3a0c..f9fb156103ff 100644
--- a/sklearn/impute.py
+++ b/sklearn/impute.py
@@ -7,6 +7,7 @@
 
 import warnings
 from time import time
+import numbers
 
 import numpy as np
 import numpy.ma as ma
@@ -21,28 +22,40 @@
 from .utils.sparsefuncs import _get_median
 from .utils.validation import check_is_fitted
 from .utils.validation import FLOAT_DTYPES
+from .utils.fixes import _object_dtype_isnan
+from .utils import is_scalar_nan
 
 from .externals import six
 
 zip = six.moves.zip
 map = six.moves.map
 
-MICETriplet = namedtuple('MICETriplet', ['feat_idx',
-                                         'neighbor_feat_idx',
-                                         'predictor'])
+ImputerTriplet = namedtuple('ImputerTriplet', ['feat_idx',
+                                               'neighbor_feat_idx',
+                                               'predictor'])
 
 __all__ = [
     'SimpleImputer',
-    'MICEImputer',
+    'ChainedImputer',
 ]
 
 
 def _get_mask(X, value_to_mask):
     """Compute the boolean mask X == missing_values."""
-    if value_to_mask == "NaN" or np.isnan(value_to_mask):
-        return np.isnan(X)
+    if value_to_mask is np.nan:
+        if X.dtype.kind == "f":
+            return np.isnan(X)
+        elif X.dtype.kind in ("i", "u"):
+            # can't have NaNs in integer array.
+            return np.zeros(X.shape, dtype=bool)
+        else:
+            # np.isnan does not work on object dtypes.
+            return _object_dtype_isnan(X)
+
     else:
-        return X == value_to_mask
+        # X == value_to_mask with object dytpes does not always perform
+        # element-wise for old versions of numpy
+        return np.equal(X, value_to_mask)
 
 
 def _most_frequent(array, extra_value, n_repeat):
@@ -51,7 +64,13 @@ def _most_frequent(array, extra_value, n_repeat):
        of the array."""
     # Compute the most frequent value in array only
     if array.size > 0:
-        mode = stats.mode(array)
+        with warnings.catch_warnings():
+            # stats.mode raises a warning when input array contains objects due
+            # to incapacity to detect NaNs. Irrelevant here since input array
+            # has already been NaN-masked.
+            warnings.simplefilter("ignore", RuntimeWarning)
+            mode = stats.mode(array)
+
         most_frequent_value = mode[0][0]
         most_frequent_count = mode[1][0]
     else:
@@ -80,20 +99,30 @@ class SimpleImputer(BaseEstimator, TransformerMixin):
 
     Parameters
     ----------
-    missing_values : integer or "NaN", optional (default="NaN")
+    missing_values : number, string, np.nan (default) or None
         The placeholder for the missing values. All occurrences of
-        `missing_values` will be imputed. For missing values encoded as np.nan,
-        use the string value "NaN".
+        `missing_values` will be imputed.
 
     strategy : string, optional (default="mean")
         The imputation strategy.
 
         - If "mean", then replace missing values using the mean along
-          each column.
+          each column. Can only be used with numeric data.
         - If "median", then replace missing values using the median along
-          each column.
+          each column. Can only be used with numeric data.
         - If "most_frequent", then replace missing using the most frequent
-          value along each column.
+          value along each column. Can be used with strings or numeric data.
+        - If "constant", then replace missing values with fill_value. Can be
+          used with strings or numeric data.
+
+        .. versionadded:: 0.20
+           strategy="constant" for fixed value imputation.
+
+    fill_value : string or numerical value, optional
+        When strategy == "constant", fill_value is used to replace all
+        occurrences of missing_values.
+        If left to the default, fill_value will be 0 when imputing numerical
+        data and "missing_value" for strings or object data types.
 
     verbose : integer, optional (default=0)
         Controls the verbosity of the imputer.
@@ -115,16 +144,55 @@ class SimpleImputer(BaseEstimator, TransformerMixin):
     Notes
     -----
     Columns which only contained missing values at `fit` are discarded upon
-    `transform`.
+    `transform` if strategy is not "constant".
 
     """
-    def __init__(self, missing_values="NaN", strategy="mean",
-                 verbose=0, copy=True):
+    def __init__(self, missing_values=np.nan, strategy="mean",
+                 fill_value=None, verbose=0, copy=True):
         self.missing_values = missing_values
         self.strategy = strategy
+        self.fill_value = fill_value
         self.verbose = verbose
         self.copy = copy
 
+    def _validate_input(self, X):
+        allowed_strategies = ["mean", "median", "most_frequent", "constant"]
+        if self.strategy not in allowed_strategies:
+            raise ValueError("Can only use these strategies: {0} "
+                             " got strategy={1}".format(allowed_strategies,
+                                                        self.strategy))
+
+        if self.strategy in ("most_frequent", "constant"):
+            dtype = None
+        else:
+            dtype = FLOAT_DTYPES
+
+        if not is_scalar_nan(self.missing_values):
+            force_all_finite = True
+        else:
+            force_all_finite = "allow-nan"
+
+        try:
+            X = check_array(X, accept_sparse='csc', dtype=dtype,
+                            force_all_finite=force_all_finite, copy=self.copy)
+        except ValueError as ve:
+            if "could not convert" in str(ve):
+                raise ValueError("Cannot use {0} strategy with non-numeric "
+                                 "data. Received datatype :{1}."
+                                 "".format(self.strategy, X.dtype.kind))
+            else:
+                raise ve
+
+        if X.dtype.kind not in ("i", "u", "f", "O"):
+            raise ValueError("SimpleImputer does not support data with dtype "
+                             "{0}. Please provide either a numeric array (with"
+                             " a floating point or integer dtype) or "
+                             "categorical data represented either as an array "
+                             "with integer dtype or an array of string values "
+                             "with an object dtype.".format(X.dtype))
+
+        return X
+
     def fit(self, X, y=None):
         """Fit the imputer on X.
 
@@ -138,30 +206,40 @@ def fit(self, X, y=None):
         -------
         self : SimpleImputer
         """
-        # Check parameters
-        allowed_strategies = ["mean", "median", "most_frequent"]
-        if self.strategy not in allowed_strategies:
-            raise ValueError("Can only use these strategies: {0} "
-                             " got strategy={1}".format(allowed_strategies,
-                                                        self.strategy))
+        X = self._validate_input(X)
 
-        X = check_array(X, accept_sparse='csc', dtype=FLOAT_DTYPES,
-                        force_all_finite='allow-nan'
-                        if self.missing_values == 'NaN'
-                        or np.isnan(self.missing_values) else True)
+        # default fill_value is 0 for numerical input and "missing_value"
+        # otherwise
+        if self.fill_value is None:
+            if X.dtype.kind in ("i", "u", "f"):
+                fill_value = 0
+            else:
+                fill_value = "missing_value"
+        else:
+            fill_value = self.fill_value
+
+        # fill_value should be numerical in case of numerical input
+        if (self.strategy == "constant" and
+                X.dtype.kind in ("i", "u", "f") and
+                not isinstance(fill_value, numbers.Real)):
+            raise ValueError("'fill_value'={0} is invalid. Expected a "
+                             "numerical value when imputing numerical "
+                             "data".format(fill_value))
 
         if sparse.issparse(X):
             self.statistics_ = self._sparse_fit(X,
                                                 self.strategy,
-                                                self.missing_values)
+                                                self.missing_values,
+                                                fill_value)
         else:
             self.statistics_ = self._dense_fit(X,
                                                self.strategy,
-                                               self.missing_values)
+                                               self.missing_values,
+                                               fill_value)
 
         return self
 
-    def _sparse_fit(self, X, strategy, missing_values):
+    def _sparse_fit(self, X, strategy, missing_values, fill_value):
         """Fit the transformer on sparse data."""
         # Count the zeros
         if missing_values == 0:
@@ -203,7 +281,7 @@ def _sparse_fit(self, X, strategy, missing_values):
             with np.errstate(all="ignore"):
                 return np.ravel(sums) / np.ravel(n_non_missing)
 
-        # Median + Most frequent
+        # Median + Most frequent + Constant
         else:
             # Remove the missing values, for each column
             columns_all = np.hsplit(X.data, X.indptr[1:-1])
@@ -234,11 +312,12 @@ def _sparse_fit(self, X, strategy, missing_values):
 
                 return most_frequent
 
-    def _dense_fit(self, X, strategy, missing_values):
+            # Constant
+            elif strategy == "constant":
+                return np.full(X.shape[1], fill_value)
+
+    def _dense_fit(self, X, strategy, missing_values, fill_value):
         """Fit the transformer on dense data."""
-        X = check_array(X, force_all_finite='allow-nan'
-                        if self.missing_values == 'NaN'
-                        or np.isnan(self.missing_values) else True)
         mask = _get_mask(X, missing_values)
         masked_X = ma.masked_array(X, mask=mask)
 
@@ -271,7 +350,10 @@ def _dense_fit(self, X, strategy, missing_values):
             X = X.transpose()
             mask = mask.transpose()
 
-            most_frequent = np.empty(X.shape[0])
+            if X.dtype.kind == "O":
+                most_frequent = np.empty(X.shape[0], dtype=object)
+            else:
+                most_frequent = np.empty(X.shape[0])
 
             for i, (row, row_mask) in enumerate(zip(X[:], mask[:])):
                 row_mask = np.logical_not(row_mask).astype(np.bool)
@@ -280,6 +362,10 @@ def _dense_fit(self, X, strategy, missing_values):
 
             return most_frequent
 
+        # Constant
+        elif strategy == "constant":
+            return np.full(X.shape[1], fill_value, dtype=X.dtype)
+
     def transform(self, X):
         """Impute all missing values in X.
 
@@ -289,28 +375,31 @@ def transform(self, X):
             The input data to complete.
         """
         check_is_fitted(self, 'statistics_')
-        X = check_array(X, accept_sparse='csc', dtype=FLOAT_DTYPES,
-                        force_all_finite='allow-nan'
-                        if self.missing_values == 'NaN'
-                        or np.isnan(self.missing_values) else True,
-                        copy=self.copy)
+
+        X = self._validate_input(X)
+
         statistics = self.statistics_
+
         if X.shape[1] != statistics.shape[0]:
             raise ValueError("X has %d features per sample, expected %d"
                              % (X.shape[1], self.statistics_.shape[0]))
 
-        # Delete the invalid columns
-        invalid_mask = np.isnan(statistics)
-        valid_mask = np.logical_not(invalid_mask)
-        valid_statistics = statistics[valid_mask]
-        valid_statistics_indexes = np.flatnonzero(valid_mask)
-        missing = np.arange(X.shape[1])[invalid_mask]
-
-        if invalid_mask.any():
-            if self.verbose:
-                warnings.warn("Deleting features without "
-                              "observed values: %s" % missing)
-            X = X[:, valid_statistics_indexes]
+        # Delete the invalid columns if strategy is not constant
+        if self.strategy == "constant":
+            valid_statistics = statistics
+        else:
+            # same as np.isnan but also works for object dtypes
+            invalid_mask = _get_mask(statistics, np.nan)
+            valid_mask = np.logical_not(invalid_mask)
+            valid_statistics = statistics[valid_mask]
+            valid_statistics_indexes = np.flatnonzero(valid_mask)
+
+            if invalid_mask.any():
+                missing = np.arange(X.shape[1])[invalid_mask]
+                if self.verbose:
+                    warnings.warn("Deleting features without "
+                                  "observed values: %s" % missing)
+                X = X[:, valid_statistics_indexes]
 
         # Do actual imputation
         if sparse.issparse(X) and self.missing_values != 0:
@@ -327,7 +416,6 @@ def transform(self, X):
             mask = _get_mask(X, self.missing_values)
             n_missing = np.sum(mask, axis=0)
             values = np.repeat(valid_statistics, n_missing)
-
             coordinates = np.where(mask.transpose())[::-1]
 
             X[coordinates] = values
@@ -335,21 +423,20 @@ def transform(self, X):
         return X
 
 
-class MICEImputer(BaseEstimator, TransformerMixin):
-    """MICE transformer to impute missing values.
+class ChainedImputer(BaseEstimator, TransformerMixin):
+    """Chained imputer transformer to impute missing values.
 
-    Basic implementation of MICE (Multivariate Imputations by Chained
-    Equations) package from R. This version assumes all of the features are
-    Gaussian.
+    Basic implementation of chained imputer from MICE (Multivariate
+    Imputations by Chained Equations) package from R. This version assumes all
+    of the features are Gaussian.
 
     Read more in the :ref:`User Guide <mice>`.
 
     Parameters
     ----------
-    missing_values : int or "NaN", optional (default="NaN")
+    missing_values : int, np.nan, optional (default=np.nan)
         The placeholder for the missing values. All occurrences of
-        ``missing_values`` will be imputed. For missing values encoded as
-        np.nan, use the string value "NaN".
+        ``missing_values`` will be imputed.
 
     imputation_order : str, optional (default="ascending")
         The order in which the features will be imputed. Possible values:
@@ -366,11 +453,11 @@ class MICEImputer(BaseEstimator, TransformerMixin):
             A random order for each round.
 
     n_imputations : int, optional (default=100)
-        Number of MICE rounds to perform, the results of which will be
-        used in the final average.
+        Number of chained imputation rounds to perform, the results of which
+        will be used in the final average.
 
     n_burn_in : int, optional (default=10)
-        Number of initial MICE rounds to perform the results of which
+        Number of initial imputation rounds to perform the results of which
         will not be returned.
 
     predictor : estimator object, default=BayesianRidge()
@@ -386,8 +473,8 @@ class MICEImputer(BaseEstimator, TransformerMixin):
 
     initial_strategy : str, optional (default="mean")
         Which strategy to use to initialize the missing values. Same as the
-        ``strategy`` parameter in :class:`sklearn.preprocessing.Imputer`
-        Valid values: {"mean", "median", or "most_frequent"}.
+        ``strategy`` parameter in :class:`sklearn.impute.SimpleImputer`
+        Valid values: {"mean", "median", "most_frequent", or "constant"}.
 
     min_value : float, optional (default=None)
         Minimum possible imputed value. Default of ``None`` will set minimum
@@ -444,7 +531,7 @@ class MICEImputer(BaseEstimator, TransformerMixin):
     """
 
     def __init__(self,
-                 missing_values='NaN',
+                 missing_values=np.nan,
                  imputation_order='ascending',
                  n_imputations=100,
                  n_burn_in=10,
@@ -694,10 +781,13 @@ def _initial_imputation(self, X):
             Input data's missing indicator matrix, where "n_samples" is the
             number of samples and "n_features" is the number of features.
         """
+        if is_scalar_nan(self.missing_values):
+            force_all_finite = "allow-nan"
+        else:
+            force_all_finite = True
+
         X = check_array(X, dtype=FLOAT_DTYPES, order="F",
-                        force_all_finite='allow-nan'
-                        if self.missing_values == 'NaN'
-                        or np.isnan(self.missing_values) else True)
+                        force_all_finite=force_all_finite)
 
         mask_missing_values = _get_mask(X, self.missing_values)
         if self.initial_imputer_ is None:
@@ -768,7 +858,8 @@ def fit_transform(self, X, y=None):
         Xt = np.zeros((n_samples, n_features), dtype=X.dtype)
         self.imputation_sequence_ = []
         if self.verbose > 0:
-            print("[MICE] Completing matrix with shape %s" % (X.shape,))
+            print("[ChainedImputer] Completing matrix with shape %s"
+                  % (X.shape,))
         start_t = time()
         for i_rnd in range(n_rounds):
             if self.imputation_order == 'random':
@@ -781,15 +872,15 @@ def fit_transform(self, X, y=None):
                 X_filled, predictor = self._impute_one_feature(
                     X_filled, mask_missing_values, feat_idx, neighbor_feat_idx,
                     predictor=None, fit_mode=True)
-                predictor_triplet = MICETriplet(feat_idx,
-                                                neighbor_feat_idx,
-                                                predictor)
+                predictor_triplet = ImputerTriplet(feat_idx,
+                                                   neighbor_feat_idx,
+                                                   predictor)
                 self.imputation_sequence_.append(predictor_triplet)
 
             if i_rnd >= self.n_burn_in:
                 Xt += X_filled
             if self.verbose > 0:
-                print('[MICE] Ending imputation round '
+                print('[ChainedImputer] Ending imputation round '
                       '%d/%d, elapsed time %0.2f'
                       % (i_rnd + 1, n_rounds, time() - start_t))
 
@@ -831,7 +922,8 @@ def transform(self, X):
         i_rnd = 0
         Xt = np.zeros(X.shape, dtype=X.dtype)
         if self.verbose > 0:
-            print("[MICE] Completing matrix with shape %s" % (X.shape,))
+            print("[ChainedImputer] Completing matrix with shape %s"
+                  % (X.shape,))
         start_t = time()
         for it, predictor_triplet in enumerate(self.imputation_sequence_):
             X_filled, _ = self._impute_one_feature(
@@ -846,7 +938,7 @@ def transform(self, X):
                 if i_rnd >= self.n_burn_in:
                     Xt += X_filled
                 if self.verbose > 1:
-                    print('[MICE] Ending imputation round '
+                    print('[ChainedImputer] Ending imputation round '
                           '%d/%d, elapsed time %0.2f'
                           % (i_rnd + 1, n_rounds, time() - start_t))
                 i_rnd += 1
diff --git a/sklearn/linear_model/coordinate_descent.py b/sklearn/linear_model/coordinate_descent.py
index 0bbfb87ebe4c..bdad75bc6197 100644
--- a/sklearn/linear_model/coordinate_descent.py
+++ b/sklearn/linear_model/coordinate_descent.py
@@ -126,7 +126,7 @@ def _alpha_grid(X, y, Xy=None, l1_ratio=1.0, fit_intercept=True,
 def lasso_path(X, y, eps=1e-3, n_alphas=100, alphas=None,
                precompute='auto', Xy=None, copy_X=True, coef_init=None,
                verbose=False, return_n_iter=False, positive=False, **params):
-    r"""Compute Lasso path with coordinate descent
+    """Compute Lasso path with coordinate descent
 
     The Lasso optimization function varies for mono and multi-outputs.
 
@@ -140,7 +140,7 @@ def lasso_path(X, y, eps=1e-3, n_alphas=100, alphas=None,
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
@@ -269,7 +269,7 @@ def enet_path(X, y, l1_ratio=0.5, eps=1e-3, n_alphas=100, alphas=None,
               precompute='auto', Xy=None, copy_X=True, coef_init=None,
               verbose=False, return_n_iter=False, positive=False,
               check_input=True, **params):
-    r"""Compute elastic net path with coordinate descent
+    """Compute elastic net path with coordinate descent
 
     The elastic net optimization function varies for mono and multi-outputs.
 
@@ -287,7 +287,7 @@ def enet_path(X, y, l1_ratio=0.5, eps=1e-3, n_alphas=100, alphas=None,
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
@@ -1599,7 +1599,7 @@ def __init__(self, l1_ratio=0.5, eps=1e-3, n_alphas=100, alphas=None,
 
 
 class MultiTaskElasticNet(Lasso):
-    r"""Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer
+    """Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer
 
     The optimization objective for MultiTaskElasticNet is::
 
@@ -1609,7 +1609,7 @@ class MultiTaskElasticNet(Lasso):
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
@@ -1676,7 +1676,7 @@ class MultiTaskElasticNet(Lasso):
         Independent term in decision function.
 
     coef_ : array, shape (n_tasks, n_features)
-        Parameter vector (W in the cost function formula). If a 1D y is \
+        Parameter vector (W in the cost function formula). If a 1D y is
         passed in at fit (non multi-task usage), ``coef_`` is then a 1D array.
         Note that ``coef_`` stores the transpose of ``W``, ``W.T``.
 
@@ -1798,7 +1798,7 @@ def fit(self, X, y):
 
 
 class MultiTaskLasso(MultiTaskElasticNet):
-    r"""Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer
+    """Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer
 
     The optimization objective for Lasso is::
 
@@ -1806,7 +1806,7 @@ class MultiTaskLasso(MultiTaskElasticNet):
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
@@ -1917,7 +1917,7 @@ def __init__(self, alpha=1.0, fit_intercept=True, normalize=False,
 
 
 class MultiTaskElasticNetCV(LinearModelCV, RegressorMixin):
-    r"""Multi-task L1/L2 ElasticNet with built-in cross-validation.
+    """Multi-task L1/L2 ElasticNet with built-in cross-validation.
 
     The optimization objective for MultiTaskElasticNet is::
 
@@ -1927,7 +1927,7 @@ class MultiTaskElasticNetCV(LinearModelCV, RegressorMixin):
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
@@ -2098,7 +2098,7 @@ def __init__(self, l1_ratio=0.5, eps=1e-3, n_alphas=100, alphas=None,
 
 
 class MultiTaskLassoCV(LinearModelCV, RegressorMixin):
-    r"""Multi-task L1/L2 Lasso with built-in cross-validation.
+    """Multi-task L1/L2 Lasso with built-in cross-validation.
 
     The optimization objective for MultiTaskLasso is::
 
@@ -2106,7 +2106,7 @@ class MultiTaskLassoCV(LinearModelCV, RegressorMixin):
 
     Where::
 
-        ||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
+        ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}
 
     i.e. the sum of norm of each row.
 
diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index 3e8a104d57d7..a43444b52c7f 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -29,7 +29,8 @@
 from ..utils.fixes import logsumexp
 from ..utils.optimize import newton_cg
 from ..utils.validation import check_X_y
-from ..exceptions import NotFittedError, ConvergenceWarning
+from ..exceptions import (NotFittedError, ConvergenceWarning,
+                          ChangedBehaviorWarning)
 from ..utils.multiclass import check_classification_targets
 from ..externals.joblib import Parallel, delayed
 from ..model_selection import check_cv
@@ -1083,8 +1084,8 @@ class LogisticRegression(BaseEstimator, LinearClassifierMixin,
 
     n_jobs : int, default: 1
         Number of CPU cores used when parallelizing over classes if
-        multi_class='ovr'". This parameter is ignored when the ``solver``is set
-        to 'liblinear' regardless of whether 'multi_class' is specified or
+        multi_class='ovr'". This parameter is ignored when the ``solver`` is
+        set to 'liblinear' regardless of whether 'multi_class' is specified or
         not. If given a value of -1, all cores are used.
 
     Attributes
@@ -1789,3 +1790,37 @@ def fit(self, X, y, sample_weight=None):
 
         self.C_ = np.asarray(self.C_)
         return self
+
+    def score(self, X, y, sample_weight=None):
+        """Returns the score using the `scoring` option on the given
+        test data and labels.
+
+        Parameters
+        ----------
+        X : array-like, shape = (n_samples, n_features)
+            Test samples.
+
+        y : array-like, shape = (n_samples,)
+            True labels for X.
+
+        sample_weight : array-like, shape = [n_samples], optional
+            Sample weights.
+
+        Returns
+        -------
+        score : float
+            Score of self.predict(X) wrt. y.
+
+        """
+
+        if self.scoring is not None:
+            warnings.warn("The long-standing behavior to use the "
+                          "accuracy score has changed. The scoring "
+                          "parameter is now used. "
+                          "This warning will disappear in version 0.22.",
+                          ChangedBehaviorWarning)
+        scoring = self.scoring or 'accuracy'
+        if isinstance(scoring, six.string_types):
+            scoring = get_scorer(scoring)
+
+        return scoring(self, X, y, sample_weight=sample_weight)
diff --git a/sklearn/linear_model/tests/test_coordinate_descent.py b/sklearn/linear_model/tests/test_coordinate_descent.py
index a3b35f40a88d..fb65d800e78b 100644
--- a/sklearn/linear_model/tests/test_coordinate_descent.py
+++ b/sklearn/linear_model/tests/test_coordinate_descent.py
@@ -706,17 +706,17 @@ def test_overrided_gram_matrix():
                          clf.fit, X, y)
 
 
-def test_lasso_non_float_y():
+@pytest.mark.parametrize('model', [ElasticNet, Lasso])
+def test_lasso_non_float_y(model):
     X = [[0, 0], [1, 1], [-1, -1]]
     y = [0, 1, 2]
     y_float = [0.0, 1.0, 2.0]
 
-    for model in [ElasticNet, Lasso]:
-        clf = model(fit_intercept=False)
-        clf.fit(X, y)
-        clf_float = model(fit_intercept=False)
-        clf_float.fit(X, y_float)
-        assert_array_equal(clf.coef_, clf_float.coef_)
+    clf = model(fit_intercept=False)
+    clf.fit(X, y)
+    clf_float = model(fit_intercept=False)
+    clf_float.fit(X, y_float)
+    assert_array_equal(clf.coef_, clf_float.coef_)
 
 
 def test_enet_float_precision():
diff --git a/sklearn/linear_model/tests/test_least_angle.py b/sklearn/linear_model/tests/test_least_angle.py
index e41df9cce117..630559fe4fef 100644
--- a/sklearn/linear_model/tests/test_least_angle.py
+++ b/sklearn/linear_model/tests/test_least_angle.py
@@ -3,6 +3,8 @@
 import numpy as np
 from scipy import linalg
 
+import pytest
+
 from sklearn.model_selection import train_test_split
 from sklearn.utils.testing import assert_equal
 from sklearn.utils.testing import assert_array_almost_equal
@@ -172,18 +174,20 @@ def test_no_path_all_precomputed():
     assert_true(alpha_ == alphas_[-1])
 
 
-def test_lars_precompute():
+@pytest.mark.parametrize(
+        'classifier',
+        [linear_model.Lars, linear_model.LarsCV, linear_model.LassoLarsIC])
+def test_lars_precompute(classifier):
     # Check for different values of precompute
     X, y = diabetes.data, diabetes.target
     G = np.dot(X.T, X)
-    for classifier in [linear_model.Lars, linear_model.LarsCV,
-                       linear_model.LassoLarsIC]:
-        clf = classifier(precompute=G)
-        output_1 = ignore_warnings(clf.fit)(X, y).coef_
-        for precompute in [True, False, 'auto', None]:
-            clf = classifier(precompute=precompute)
-            output_2 = clf.fit(X, y).coef_
-            assert_array_almost_equal(output_1, output_2, decimal=8)
+
+    clf = classifier(precompute=G)
+    output_1 = ignore_warnings(clf.fit)(X, y).coef_
+    for precompute in [True, False, 'auto', None]:
+        clf = classifier(precompute=precompute)
+        output_2 = clf.fit(X, y).coef_
+        assert_array_almost_equal(output_1, output_2, decimal=8)
 
 
 def test_singular_matrix():
diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py
index a179c89e199a..9939644f4d4e 100644
--- a/sklearn/linear_model/tests/test_logistic.py
+++ b/sklearn/linear_model/tests/test_logistic.py
@@ -1,6 +1,9 @@
 import numpy as np
 import scipy.sparse as sp
 from scipy import linalg, optimize, sparse
+
+import pytest
+
 from sklearn.datasets import load_iris, make_classification
 from sklearn.metrics import log_loss
 from sklearn.model_selection import StratifiedKFold
@@ -19,6 +22,7 @@
 from sklearn.utils.testing import assert_warns_message
 
 from sklearn.exceptions import ConvergenceWarning
+from sklearn.exceptions import ChangedBehaviorWarning
 from sklearn.linear_model.logistic import (
     LogisticRegression,
     logistic_regression_path, LogisticRegressionCV,
@@ -89,6 +93,49 @@ def test_error():
         assert_raise_message(ValueError, msg, LR(max_iter="test").fit, X, Y1)
 
 
+def test_logistic_cv_mock_scorer():
+
+    class MockScorer(object):
+        def __init__(self):
+            self.calls = 0
+            self.scores = [0.1, 0.4, 0.8, 0.5]
+
+        def __call__(self, model, X, y, sample_weight=None):
+            score = self.scores[self.calls % len(self.scores)]
+            self.calls += 1
+            return score
+
+    mock_scorer = MockScorer()
+    Cs = [1, 2, 3, 4]
+    cv = 2
+
+    lr = LogisticRegressionCV(Cs=Cs, scoring=mock_scorer, cv=cv)
+    lr.fit(X, Y1)
+
+    # Cs[2] has the highest score (0.8) from MockScorer
+    assert lr.C_[0] == Cs[2]
+
+    # scorer called 8 times (cv*len(Cs))
+    assert mock_scorer.calls == cv * len(Cs)
+
+    # reset mock_scorer
+    mock_scorer.calls = 0
+    with pytest.warns(ChangedBehaviorWarning):
+        custom_score = lr.score(X, lr.predict(X))
+
+    assert custom_score == mock_scorer.scores[0]
+    assert mock_scorer.calls == 1
+
+
+def test_logistic_cv_score_does_not_warn_by_default():
+    lr = LogisticRegressionCV(cv=2)
+    lr.fit(X, Y1)
+
+    with pytest.warns(None) as record:
+        lr.score(X, lr.predict(X))
+    assert len(record) == 0
+
+
 def test_lr_liblinear_warning():
     n_samples, n_features = iris.data.shape
     target = iris.target_names[iris.target]
@@ -139,63 +186,63 @@ def test_predict_iris():
         assert_greater(np.mean(pred == target), .95)
 
 
-def test_multinomial_validation():
-    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:
-        lr = LogisticRegression(C=-1, solver=solver, multi_class='multinomial')
-        assert_raises(ValueError, lr.fit, [[0, 1], [1, 0]], [0, 1])
+@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])
+def test_multinomial_validation(solver):
+    lr = LogisticRegression(C=-1, solver=solver, multi_class='multinomial')
+    assert_raises(ValueError, lr.fit, [[0, 1], [1, 0]], [0, 1])
 
 
-def test_check_solver_option():
+@pytest.mark.parametrize('LR', [LogisticRegression, LogisticRegressionCV])
+def test_check_solver_option(LR):
     X, y = iris.data, iris.target
-    for LR in [LogisticRegression, LogisticRegressionCV]:
 
-        msg = ('Logistic Regression supports only liblinear, newton-cg, '
-               'lbfgs, sag and saga solvers, got wrong_name')
-        lr = LR(solver="wrong_name")
+    msg = ('Logistic Regression supports only liblinear, newton-cg, '
+           'lbfgs, sag and saga solvers, got wrong_name')
+    lr = LR(solver="wrong_name")
+    assert_raise_message(ValueError, msg, lr.fit, X, y)
+
+    msg = "multi_class should be either multinomial or ovr, got wrong_name"
+    lr = LR(solver='newton-cg', multi_class="wrong_name")
+    assert_raise_message(ValueError, msg, lr.fit, X, y)
+
+    # only 'liblinear' solver
+    msg = "Solver liblinear does not support a multinomial backend."
+    lr = LR(solver='liblinear', multi_class='multinomial')
+    assert_raise_message(ValueError, msg, lr.fit, X, y)
+
+    # all solvers except 'liblinear'
+    for solver in ['newton-cg', 'lbfgs', 'sag']:
+        msg = ("Solver %s supports only l2 penalties, got l1 penalty." %
+               solver)
+        lr = LR(solver=solver, penalty='l1')
         assert_raise_message(ValueError, msg, lr.fit, X, y)
-
-        msg = "multi_class should be either multinomial or ovr, got wrong_name"
-        lr = LR(solver='newton-cg', multi_class="wrong_name")
-        assert_raise_message(ValueError, msg, lr.fit, X, y)
-
-        # only 'liblinear' solver
-        msg = "Solver liblinear does not support a multinomial backend."
-        lr = LR(solver='liblinear', multi_class='multinomial')
+    for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:
+        msg = ("Solver %s supports only dual=False, got dual=True" %
+               solver)
+        lr = LR(solver=solver, dual=True)
         assert_raise_message(ValueError, msg, lr.fit, X, y)
 
-        # all solvers except 'liblinear'
-        for solver in ['newton-cg', 'lbfgs', 'sag']:
-            msg = ("Solver %s supports only l2 penalties, got l1 penalty." %
-                   solver)
-            lr = LR(solver=solver, penalty='l1')
-            assert_raise_message(ValueError, msg, lr.fit, X, y)
-        for solver in ['newton-cg', 'lbfgs', 'sag', 'saga']:
-            msg = ("Solver %s supports only dual=False, got dual=True" %
-                   solver)
-            lr = LR(solver=solver, dual=True)
-            assert_raise_message(ValueError, msg, lr.fit, X, y)
 
-
-def test_multinomial_binary():
+@pytest.mark.parametrize('solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])
+def test_multinomial_binary(solver):
     # Test multinomial LR on a binary problem.
     target = (iris.target > 0).astype(np.intp)
     target = np.array(["setosa", "not-setosa"])[target]
 
-    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:
-        clf = LogisticRegression(solver=solver, multi_class='multinomial',
-                                 random_state=42, max_iter=2000)
-        clf.fit(iris.data, target)
+    clf = LogisticRegression(solver=solver, multi_class='multinomial',
+                             random_state=42, max_iter=2000)
+    clf.fit(iris.data, target)
 
-        assert_equal(clf.coef_.shape, (1, iris.data.shape[1]))
-        assert_equal(clf.intercept_.shape, (1,))
-        assert_array_equal(clf.predict(iris.data), target)
+    assert_equal(clf.coef_.shape, (1, iris.data.shape[1]))
+    assert_equal(clf.intercept_.shape, (1,))
+    assert_array_equal(clf.predict(iris.data), target)
 
-        mlr = LogisticRegression(solver=solver, multi_class='multinomial',
-                                 random_state=42, fit_intercept=False)
-        mlr.fit(iris.data, target)
-        pred = clf.classes_[np.argmax(clf.predict_log_proba(iris.data),
-                                      axis=1)]
-        assert_greater(np.mean(pred == target), .9)
+    mlr = LogisticRegression(solver=solver, multi_class='multinomial',
+                             random_state=42, fit_intercept=False)
+    mlr.fit(iris.data, target)
+    pred = clf.classes_[np.argmax(clf.predict_log_proba(iris.data),
+                                  axis=1)]
+    assert_greater(np.mean(pred == target), .9)
 
 
 def test_multinomial_binary_probabilities():
@@ -1043,7 +1090,9 @@ def test_max_iter():
                 assert_equal(lr.n_iter_[0], max_iter)
 
 
-def test_n_iter():
+@pytest.mark.parametrize('solver',
+                         ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs'])
+def test_n_iter(solver):
     # Test that self.n_iter_ has the correct format.
     X, y = iris.data, iris.target
     y_bin = y.copy()
@@ -1052,76 +1101,73 @@ def test_n_iter():
     n_Cs = 4
     n_cv_fold = 2
 
-    for solver in ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']:
-        # OvR case
-        n_classes = 1 if solver == 'liblinear' else np.unique(y).shape[0]
-        clf = LogisticRegression(tol=1e-2, multi_class='ovr',
-                                 solver=solver, C=1.,
-                                 random_state=42, max_iter=100)
-        clf.fit(X, y)
-        assert_equal(clf.n_iter_.shape, (n_classes,))
+    # OvR case
+    n_classes = 1 if solver == 'liblinear' else np.unique(y).shape[0]
+    clf = LogisticRegression(tol=1e-2, multi_class='ovr',
+                             solver=solver, C=1.,
+                             random_state=42, max_iter=100)
+    clf.fit(X, y)
+    assert_equal(clf.n_iter_.shape, (n_classes,))
 
-        n_classes = np.unique(y).shape[0]
-        clf = LogisticRegressionCV(tol=1e-2, multi_class='ovr',
-                                   solver=solver, Cs=n_Cs, cv=n_cv_fold,
-                                   random_state=42, max_iter=100)
-        clf.fit(X, y)
-        assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))
-        clf.fit(X, y_bin)
-        assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))
-
-        # multinomial case
-        n_classes = 1
-        if solver in ('liblinear', 'sag', 'saga'):
-            break
-
-        clf = LogisticRegression(tol=1e-2, multi_class='multinomial',
-                                 solver=solver, C=1.,
-                                 random_state=42, max_iter=100)
-        clf.fit(X, y)
-        assert_equal(clf.n_iter_.shape, (n_classes,))
+    n_classes = np.unique(y).shape[0]
+    clf = LogisticRegressionCV(tol=1e-2, multi_class='ovr',
+                               solver=solver, Cs=n_Cs, cv=n_cv_fold,
+                               random_state=42, max_iter=100)
+    clf.fit(X, y)
+    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))
+    clf.fit(X, y_bin)
+    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))
+
+    # multinomial case
+    n_classes = 1
+    if solver in ('liblinear', 'sag', 'saga'):
+        return
+
+    clf = LogisticRegression(tol=1e-2, multi_class='multinomial',
+                             solver=solver, C=1.,
+                             random_state=42, max_iter=100)
+    clf.fit(X, y)
+    assert_equal(clf.n_iter_.shape, (n_classes,))
 
-        clf = LogisticRegressionCV(tol=1e-2, multi_class='multinomial',
-                                   solver=solver, Cs=n_Cs, cv=n_cv_fold,
-                                   random_state=42, max_iter=100)
-        clf.fit(X, y)
-        assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))
-        clf.fit(X, y_bin)
-        assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))
+    clf = LogisticRegressionCV(tol=1e-2, multi_class='multinomial',
+                               solver=solver, Cs=n_Cs, cv=n_cv_fold,
+                               random_state=42, max_iter=100)
+    clf.fit(X, y)
+    assert_equal(clf.n_iter_.shape, (n_classes, n_cv_fold, n_Cs))
+    clf.fit(X, y_bin)
+    assert_equal(clf.n_iter_.shape, (1, n_cv_fold, n_Cs))
 
 
-def test_warm_start():
+@pytest.mark.parametrize('solver', ('newton-cg', 'sag', 'saga', 'lbfgs'))
+@pytest.mark.parametrize('warm_start', (True, False))
+@pytest.mark.parametrize('fit_intercept', (True, False))
+@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])
+def test_warm_start(solver, warm_start, fit_intercept, multi_class):
     # A 1-iteration second fit on same data should give almost same result
     # with warm starting, and quite different result without warm starting.
     # Warm starting does not work with liblinear solver.
     X, y = iris.data, iris.target
 
-    solvers = ['newton-cg', 'sag', 'saga', 'lbfgs']
-
-    for warm_start in [True, False]:
-        for fit_intercept in [True, False]:
-            for solver in solvers:
-                for multi_class in ['ovr', 'multinomial']:
-                    clf = LogisticRegression(tol=1e-4, multi_class=multi_class,
-                                             warm_start=warm_start,
-                                             solver=solver,
-                                             random_state=42, max_iter=100,
-                                             fit_intercept=fit_intercept)
-                    with ignore_warnings(category=ConvergenceWarning):
-                        clf.fit(X, y)
-                        coef_1 = clf.coef_
-
-                        clf.max_iter = 1
-                        clf.fit(X, y)
-                    cum_diff = np.sum(np.abs(coef_1 - clf.coef_))
-                    msg = ("Warm starting issue with %s solver in %s mode "
-                           "with fit_intercept=%s and warm_start=%s"
-                           % (solver, multi_class, str(fit_intercept),
-                              str(warm_start)))
-                    if warm_start:
-                        assert_greater(2.0, cum_diff, msg)
-                    else:
-                        assert_greater(cum_diff, 2.0, msg)
+    clf = LogisticRegression(tol=1e-4, multi_class=multi_class,
+                             warm_start=warm_start,
+                             solver=solver,
+                             random_state=42, max_iter=100,
+                             fit_intercept=fit_intercept)
+    with ignore_warnings(category=ConvergenceWarning):
+        clf.fit(X, y)
+        coef_1 = clf.coef_
+
+        clf.max_iter = 1
+        clf.fit(X, y)
+    cum_diff = np.sum(np.abs(coef_1 - clf.coef_))
+    msg = ("Warm starting issue with %s solver in %s mode "
+           "with fit_intercept=%s and warm_start=%s"
+           % (solver, multi_class, str(fit_intercept),
+              str(warm_start)))
+    if warm_start:
+        assert_greater(2.0, cum_diff, msg)
+    else:
+        assert_greater(cum_diff, 2.0, msg)
 
 
 def test_saga_vs_liblinear():
diff --git a/sklearn/linear_model/tests/test_passive_aggressive.py b/sklearn/linear_model/tests/test_passive_aggressive.py
index 5620c29e1837..ee519b7390c5 100644
--- a/sklearn/linear_model/tests/test_passive_aggressive.py
+++ b/sklearn/linear_model/tests/test_passive_aggressive.py
@@ -2,6 +2,8 @@
 import numpy as np
 import scipy.sparse as sp
 
+import pytest
+
 from sklearn.utils.testing import assert_less
 from sklearn.utils.testing import assert_greater
 from sklearn.utils.testing import assert_array_almost_equal, assert_array_equal
@@ -111,23 +113,22 @@ def test_classifier_refit():
     assert_array_equal(clf.classes_, iris.target_names)
 
 
-def test_classifier_correctness():
+@pytest.mark.parametrize('loss', ("hinge", "squared_hinge"))
+def test_classifier_correctness(loss):
     y_bin = y.copy()
     y_bin[y != 1] = -1
 
-    for loss in ("hinge", "squared_hinge"):
-
-        clf1 = MyPassiveAggressive(
-            C=1.0, loss=loss, fit_intercept=True, n_iter=2)
-        clf1.fit(X, y_bin)
+    clf1 = MyPassiveAggressive(
+        C=1.0, loss=loss, fit_intercept=True, n_iter=2)
+    clf1.fit(X, y_bin)
 
-        for data in (X, X_csr):
-            clf2 = PassiveAggressiveClassifier(
-                C=1.0, loss=loss, fit_intercept=True, max_iter=2,
-                shuffle=False, tol=None)
-            clf2.fit(data, y_bin)
+    for data in (X, X_csr):
+        clf2 = PassiveAggressiveClassifier(
+            C=1.0, loss=loss, fit_intercept=True, max_iter=2,
+            shuffle=False, tol=None)
+        clf2.fit(data, y_bin)
 
-            assert_array_almost_equal(clf1.w, clf2.coef_.ravel(), decimal=2)
+        assert_array_almost_equal(clf1.w, clf2.coef_.ravel(), decimal=2)
 
 
 def test_classifier_undefined_methods():
@@ -248,22 +249,24 @@ def test_regressor_partial_fit():
                 assert_true(hasattr(reg, 'standard_coef_'))
 
 
-def test_regressor_correctness():
+@pytest.mark.parametrize(
+        'loss',
+        ("epsilon_insensitive", "squared_epsilon_insensitive"))
+def test_regressor_correctness(loss):
     y_bin = y.copy()
     y_bin[y != 1] = -1
 
-    for loss in ("epsilon_insensitive", "squared_epsilon_insensitive"):
-        reg1 = MyPassiveAggressive(
-            C=1.0, loss=loss, fit_intercept=True, n_iter=2)
-        reg1.fit(X, y_bin)
+    reg1 = MyPassiveAggressive(
+        C=1.0, loss=loss, fit_intercept=True, n_iter=2)
+    reg1.fit(X, y_bin)
 
-        for data in (X, X_csr):
-            reg2 = PassiveAggressiveRegressor(
-                C=1.0, tol=None, loss=loss, fit_intercept=True, max_iter=2,
-                shuffle=False)
-            reg2.fit(data, y_bin)
+    for data in (X, X_csr):
+        reg2 = PassiveAggressiveRegressor(
+            C=1.0, tol=None, loss=loss, fit_intercept=True, max_iter=2,
+            shuffle=False)
+        reg2.fit(data, y_bin)
 
-            assert_array_almost_equal(reg1.w, reg2.coef_.ravel(), decimal=2)
+        assert_array_almost_equal(reg1.w, reg2.coef_.ravel(), decimal=2)
 
 
 def test_regressor_undefined_methods():
diff --git a/sklearn/linear_model/tests/test_ridge.py b/sklearn/linear_model/tests/test_ridge.py
index a2f2a135b3ae..2f574b88ba7b 100644
--- a/sklearn/linear_model/tests/test_ridge.py
+++ b/sklearn/linear_model/tests/test_ridge.py
@@ -3,6 +3,8 @@
 from scipy import linalg
 from itertools import product
 
+import pytest
+
 from sklearn.utils.testing import assert_true
 from sklearn.utils.testing import assert_almost_equal
 from sklearn.utils.testing import assert_array_almost_equal
@@ -57,41 +59,42 @@
 SPARSE_FILTER = lambda X: sp.csr_matrix(X)
 
 
-def test_ridge():
+@pytest.mark.parametrize('solver',
+                         ("svd", "sparse_cg", "cholesky", "lsqr", "sag"))
+def test_ridge(solver):
     # Ridge regression convergence test using score
     # TODO: for this test to be robust, we should use a dataset instead
     # of np.random.
     rng = np.random.RandomState(0)
     alpha = 1.0
 
-    for solver in ("svd", "sparse_cg", "cholesky", "lsqr", "sag"):
-        # With more samples than features
-        n_samples, n_features = 6, 5
-        y = rng.randn(n_samples)
-        X = rng.randn(n_samples, n_features)
+    # With more samples than features
+    n_samples, n_features = 6, 5
+    y = rng.randn(n_samples)
+    X = rng.randn(n_samples, n_features)
 
-        ridge = Ridge(alpha=alpha, solver=solver)
-        ridge.fit(X, y)
-        assert_equal(ridge.coef_.shape, (X.shape[1], ))
-        assert_greater(ridge.score(X, y), 0.47)
+    ridge = Ridge(alpha=alpha, solver=solver)
+    ridge.fit(X, y)
+    assert_equal(ridge.coef_.shape, (X.shape[1], ))
+    assert_greater(ridge.score(X, y), 0.47)
 
-        if solver in ("cholesky", "sag"):
-            # Currently the only solvers to support sample_weight.
-            ridge.fit(X, y, sample_weight=np.ones(n_samples))
-            assert_greater(ridge.score(X, y), 0.47)
+    if solver in ("cholesky", "sag"):
+        # Currently the only solvers to support sample_weight.
+        ridge.fit(X, y, sample_weight=np.ones(n_samples))
+        assert_greater(ridge.score(X, y), 0.47)
 
-        # With more features than samples
-        n_samples, n_features = 5, 10
-        y = rng.randn(n_samples)
-        X = rng.randn(n_samples, n_features)
-        ridge = Ridge(alpha=alpha, solver=solver)
-        ridge.fit(X, y)
-        assert_greater(ridge.score(X, y), .9)
+    # With more features than samples
+    n_samples, n_features = 5, 10
+    y = rng.randn(n_samples)
+    X = rng.randn(n_samples, n_features)
+    ridge = Ridge(alpha=alpha, solver=solver)
+    ridge.fit(X, y)
+    assert_greater(ridge.score(X, y), .9)
 
-        if solver in ("cholesky", "sag"):
-            # Currently the only solvers to support sample_weight.
-            ridge.fit(X, y, sample_weight=np.ones(n_samples))
-            assert_greater(ridge.score(X, y), 0.9)
+    if solver in ("cholesky", "sag"):
+        # Currently the only solvers to support sample_weight.
+        ridge.fit(X, y, sample_weight=np.ones(n_samples))
+        assert_greater(ridge.score(X, y), 0.9)
 
 
 def test_primal_dual_relationship():
@@ -153,6 +156,8 @@ def test_ridge_regression_convergence_fail():
 
 def test_ridge_sample_weights():
     # TODO: loop over sparse data as well
+    # Note: parametrizing this test with pytest results in failed
+    #       assertions, meaning that is is not extremely robust
 
     rng = np.random.RandomState(0)
     param_grid = product((1.0, 1e-2), (True, False),
@@ -483,15 +488,13 @@ def check_dense_sparse(test_func):
         assert_array_almost_equal(ret_dense, ret_sparse, decimal=3)
 
 
-def test_dense_sparse():
-    for test_func in (_test_ridge_loo,
-                      _test_ridge_cv,
-                      _test_ridge_cv_normalize,
-                      _test_ridge_diabetes,
-                      _test_multi_ridge_diabetes,
-                      _test_ridge_classifiers,
-                      _test_tolerance):
-        yield check_dense_sparse, test_func
+@pytest.mark.parametrize(
+        'test_func',
+        (_test_ridge_loo, _test_ridge_cv, _test_ridge_cv_normalize,
+         _test_ridge_diabetes, _test_multi_ridge_diabetes,
+         _test_ridge_classifiers, _test_tolerance))
+def test_dense_sparse(test_func):
+    check_dense_sparse(test_func)
 
 
 def test_ridge_cv_sparse_svd():
@@ -543,33 +546,33 @@ def test_class_weights():
     assert_array_almost_equal(reg.intercept_, rega.intercept_)
 
 
-def test_class_weight_vs_sample_weight():
+@pytest.mark.parametrize('reg', (RidgeClassifier, RidgeClassifierCV))
+def test_class_weight_vs_sample_weight(reg):
     """Check class_weights resemble sample_weights behavior."""
-    for reg in (RidgeClassifier, RidgeClassifierCV):
-
-        # Iris is balanced, so no effect expected for using 'balanced' weights
-        reg1 = reg()
-        reg1.fit(iris.data, iris.target)
-        reg2 = reg(class_weight='balanced')
-        reg2.fit(iris.data, iris.target)
-        assert_almost_equal(reg1.coef_, reg2.coef_)
-
-        # Inflate importance of class 1, check against user-defined weights
-        sample_weight = np.ones(iris.target.shape)
-        sample_weight[iris.target == 1] *= 100
-        class_weight = {0: 1., 1: 100., 2: 1.}
-        reg1 = reg()
-        reg1.fit(iris.data, iris.target, sample_weight)
-        reg2 = reg(class_weight=class_weight)
-        reg2.fit(iris.data, iris.target)
-        assert_almost_equal(reg1.coef_, reg2.coef_)
-
-        # Check that sample_weight and class_weight are multiplicative
-        reg1 = reg()
-        reg1.fit(iris.data, iris.target, sample_weight ** 2)
-        reg2 = reg(class_weight=class_weight)
-        reg2.fit(iris.data, iris.target, sample_weight)
-        assert_almost_equal(reg1.coef_, reg2.coef_)
+
+    # Iris is balanced, so no effect expected for using 'balanced' weights
+    reg1 = reg()
+    reg1.fit(iris.data, iris.target)
+    reg2 = reg(class_weight='balanced')
+    reg2.fit(iris.data, iris.target)
+    assert_almost_equal(reg1.coef_, reg2.coef_)
+
+    # Inflate importance of class 1, check against user-defined weights
+    sample_weight = np.ones(iris.target.shape)
+    sample_weight[iris.target == 1] *= 100
+    class_weight = {0: 1., 1: 100., 2: 1.}
+    reg1 = reg()
+    reg1.fit(iris.data, iris.target, sample_weight)
+    reg2 = reg(class_weight=class_weight)
+    reg2.fit(iris.data, iris.target)
+    assert_almost_equal(reg1.coef_, reg2.coef_)
+
+    # Check that sample_weight and class_weight are multiplicative
+    reg1 = reg()
+    reg1.fit(iris.data, iris.target, sample_weight ** 2)
+    reg2 = reg(class_weight=class_weight)
+    reg2.fit(iris.data, iris.target, sample_weight)
+    assert_almost_equal(reg1.coef_, reg2.coef_)
 
 
 def test_class_weights_cv():
diff --git a/sklearn/linear_model/tests/test_sgd.py b/sklearn/linear_model/tests/test_sgd.py
index 9f372f706ca7..18bc07313965 100644
--- a/sklearn/linear_model/tests/test_sgd.py
+++ b/sklearn/linear_model/tests/test_sgd.py
@@ -1174,16 +1174,16 @@ def test_numerical_stability_large_gradient():
     assert_true(np.isfinite(model.coef_).all())
 
 
-def test_large_regularization():
+@pytest.mark.parametrize('penalty', ['l2', 'l1', 'elasticnet'])
+def test_large_regularization(penalty):
     # Non regression tests for numerical stability issues caused by large
     # regularization parameters
-    for penalty in ['l2', 'l1', 'elasticnet']:
-        model = SGDClassifier(alpha=1e5, learning_rate='constant', eta0=0.1,
-                              penalty=penalty, shuffle=False,
-                              tol=None, max_iter=6)
-        with np.errstate(all='raise'):
-            model.fit(iris.data, iris.target)
-        assert_array_almost_equal(model.coef_, np.zeros_like(model.coef_))
+    model = SGDClassifier(alpha=1e5, learning_rate='constant', eta0=0.1,
+                          penalty=penalty, shuffle=False,
+                          tol=None, max_iter=6)
+    with np.errstate(all='raise'):
+        model.fit(iris.data, iris.target)
+    assert_array_almost_equal(model.coef_, np.zeros_like(model.coef_))
 
 
 def test_tol_parameter():
diff --git a/sklearn/manifold/tests/test_t_sne.py b/sklearn/manifold/tests/test_t_sne.py
index 6b1d87bb18bf..cc692ae0d0cd 100644
--- a/sklearn/manifold/tests/test_t_sne.py
+++ b/sklearn/manifold/tests/test_t_sne.py
@@ -3,6 +3,8 @@
 import numpy as np
 import scipy.sparse as sp
 
+import pytest
+
 from sklearn.neighbors import BallTree
 from sklearn.neighbors import NearestNeighbors
 from sklearn.utils.testing import assert_less_equal
@@ -596,35 +598,35 @@ def test_no_sparse_on_barnes_hut():
                          tsne.fit_transform, X_csr)
 
 
-def test_64bit():
+@pytest.mark.parametrize('method', ['barnes_hut', 'exact'])
+@pytest.mark.parametrize('dt', [np.float32, np.float64])
+def test_64bit(method, dt):
     # Ensure 64bit arrays are handled correctly.
     random_state = check_random_state(0)
-    methods = ['barnes_hut', 'exact']
-    for method in methods:
-        for dt in [np.float32, np.float64]:
-            X = random_state.randn(50, 2).astype(dt)
-            tsne = TSNE(n_components=2, perplexity=2, learning_rate=100.0,
-                        random_state=0, method=method, verbose=0)
-            X_embedded = tsne.fit_transform(X)
-            effective_type = X_embedded.dtype
 
-            # tsne cython code is only single precision, so the output will
-            # always be single precision, irrespectively of the input dtype
-            assert effective_type == np.float32
+    X = random_state.randn(50, 2).astype(dt)
+    tsne = TSNE(n_components=2, perplexity=2, learning_rate=100.0,
+                random_state=0, method=method, verbose=0)
+    X_embedded = tsne.fit_transform(X)
+    effective_type = X_embedded.dtype
 
+    # tsne cython code is only single precision, so the output will
+    # always be single precision, irrespectively of the input dtype
+    assert effective_type == np.float32
 
-def test_kl_divergence_not_nan():
+
+@pytest.mark.parametrize('method', ['barnes_hut', 'exact'])
+def test_kl_divergence_not_nan(method):
     # Ensure kl_divergence_ is computed at last iteration
     # even though n_iter % n_iter_check != 0, i.e. 1003 % 50 != 0
     random_state = check_random_state(0)
-    methods = ['barnes_hut', 'exact']
-    for method in methods:
-        X = random_state.randn(50, 2)
-        tsne = TSNE(n_components=2, perplexity=2, learning_rate=100.0,
-                    random_state=0, method=method, verbose=0, n_iter=1003)
-        tsne.fit_transform(X)
 
-        assert not np.isnan(tsne.kl_divergence_)
+    X = random_state.randn(50, 2)
+    tsne = TSNE(n_components=2, perplexity=2, learning_rate=100.0,
+                random_state=0, method=method, verbose=0, n_iter=1003)
+    tsne.fit_transform(X)
+
+    assert not np.isnan(tsne.kl_divergence_)
 
 
 def test_barnes_hut_angle():
@@ -807,9 +809,9 @@ def assert_uniform_grid(Y, try_name=None):
     assert_less(largest_to_mean, 2, msg=try_name)
 
 
-def test_uniform_grid():
-    for method in ['barnes_hut', 'exact']:
-        yield check_uniform_grid, method
+@pytest.mark.parametrize('method', ['barnes_hut', 'exact'])
+def test_uniform_grid(method):
+    check_uniform_grid(method)
 
 
 def test_bh_match_exact():
diff --git a/sklearn/metrics/classification.py b/sklearn/metrics/classification.py
index 88cbeeae196c..ed0805c0850e 100644
--- a/sklearn/metrics/classification.py
+++ b/sklearn/metrics/classification.py
@@ -1460,7 +1460,8 @@ def classification_report(y_true, y_pred, labels=None, target_names=None,
     report : string / dict
         Text summary of the precision, recall, F1 score for each class.
         Dictionary returned if output_dict is True. Dictionary has the
-        following structure:
+        following structure::
+
             {'label 1': {'precision':0.5,
                          'recall':1.0,
                          'f1-score':0.67,
diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py
index 19bc461c9e9f..db73380fafbf 100644
--- a/sklearn/metrics/cluster/supervised.py
+++ b/sklearn/metrics/cluster/supervised.py
@@ -528,7 +528,7 @@ def v_measure_score(labels_true, labels_pred):
 
 
 def mutual_info_score(labels_true, labels_pred, contingency=None):
-    r"""Mutual Information between two clusterings.
+    """Mutual Information between two clusterings.
 
     The Mutual Information is a measure of the similarity between two labels of
     the same data. Where :math:`|U_i|` is the number of the samples
@@ -538,8 +538,8 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):
 
     .. math::
 
-        MI(U,V)=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \\frac{|U_i\cap V_j|}{N}
-        \log\\frac{N|U_i \cap V_j|}{|U_i||V_j|}
+        MI(U,V)=\\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i\\cap V_j|}{N}
+        \\log\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}
 
     This metric is independent of the absolute values of the labels:
     a permutation of the class or cluster label values won't change the
@@ -560,7 +560,7 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):
     labels_pred : array, shape = [n_samples]
         A clustering of the data into disjoint subsets.
 
-    contingency : {None, array, sparse matrix},
+    contingency : {None, array, sparse matrix}, \
                   shape = [n_classes_true, n_classes_pred]
         A contingency matrix given by the :func:`contingency_matrix` function.
         If value is ``None``, it will be computed, otherwise the given value is
diff --git a/sklearn/metrics/cluster/tests/test_common.py b/sklearn/metrics/cluster/tests/test_common.py
index 71534380fe6e..a7e54d22cc7c 100644
--- a/sklearn/metrics/cluster/tests/test_common.py
+++ b/sklearn/metrics/cluster/tests/test_common.py
@@ -101,10 +101,7 @@ def test_non_symmetry(metric_name, y1, y2):
     assert metric(y1, y2) != pytest.approx(metric(y2, y1))
 
 
-@pytest.mark.parametrize(
-    "metric_name",
-    [name for name in NORMALIZED_METRICS]
-)
+@pytest.mark.parametrize("metric_name", NORMALIZED_METRICS)
 def test_normalized_output(metric_name):
     upper_bound_1 = [0, 0, 0, 1, 1, 1]
     upper_bound_2 = [0, 0, 0, 1, 1, 1]
@@ -126,7 +123,7 @@ def test_normalized_output(metric_name):
 # that is when 0 and 1 exchanged.
 @pytest.mark.parametrize(
     "metric_name",
-    [name for name in dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)]
+    dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
 )
 def test_permute_labels(metric_name):
     y_label = np.array([0, 0, 0, 1, 1, 0, 1])
@@ -147,7 +144,7 @@ def test_permute_labels(metric_name):
 # For all clustering metrics Input parameters can be both
 @pytest.mark.parametrize(
     "metric_name",
-    [name for name in dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)]
+    dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
 )
 # in the form of arrays lists, positive, negetive or string
 def test_format_invariance(metric_name):
diff --git a/sklearn/metrics/cluster/unsupervised.py b/sklearn/metrics/cluster/unsupervised.py
index 4fd2afef95bd..7c954acea518 100644
--- a/sklearn/metrics/cluster/unsupervised.py
+++ b/sklearn/metrics/cluster/unsupervised.py
@@ -302,9 +302,11 @@ def davies_bouldin_score(X, labels):
 
     References
     ----------
-    .. [1] `Davies, David L.; Bouldin, Donald W. (1979).
-       "A Cluster Separation Measure". IEEE Transactions on
-       Pattern Analysis and Machine Intelligence. PAMI-1 (2): 224-227`_
+    .. [1] Davies, David L.; Bouldin, Donald W. (1979).
+       `"A Cluster Separation Measure"
+       <http://ieeexplore.ieee.org/document/4766909>`__.
+       IEEE Transactions on Pattern Analysis and Machine Intelligence.
+       PAMI-1 (2): 224-227
     """
     X, labels = check_X_y(X, labels)
     le = LabelEncoder()
diff --git a/sklearn/metrics/tests/test_classification.py b/sklearn/metrics/tests/test_classification.py
index 1705510cc1ea..923f60994dac 100644
--- a/sklearn/metrics/tests/test_classification.py
+++ b/sklearn/metrics/tests/test_classification.py
@@ -6,6 +6,8 @@
 from itertools import product
 import warnings
 
+import pytest
+
 from sklearn import datasets
 from sklearn import svm
 
@@ -520,7 +522,8 @@ def test_matthews_corrcoef_multiclass():
     assert_almost_equal(mcc, 0.)
 
 
-def test_matthews_corrcoef_overflow():
+@pytest.mark.parametrize('n_points', [100, 10000, 1000000])
+def test_matthews_corrcoef_overflow(n_points):
     # https://github.com/scikit-learn/scikit-learn/issues/9622
     rng = np.random.RandomState(20170906)
 
@@ -543,16 +546,15 @@ def random_ys(n_points):    # binary
         y_pred = (x_pred > 0.5)
         return y_true, y_pred
 
-    for n_points in [100, 10000, 1000000]:
-        arr = np.repeat([0., 1.], n_points)  # binary
-        assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)
-        arr = np.repeat([0., 1., 2.], n_points)  # multiclass
-        assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)
+    arr = np.repeat([0., 1.], n_points)  # binary
+    assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)
+    arr = np.repeat([0., 1., 2.], n_points)  # multiclass
+    assert_almost_equal(matthews_corrcoef(arr, arr), 1.0)
 
-        y_true, y_pred = random_ys(n_points)
-        assert_almost_equal(matthews_corrcoef(y_true, y_true), 1.0)
-        assert_almost_equal(matthews_corrcoef(y_true, y_pred),
-                            mcc_safe(y_true, y_pred))
+    y_true, y_pred = random_ys(n_points)
+    assert_almost_equal(matthews_corrcoef(y_true, y_true), 1.0)
+    assert_almost_equal(matthews_corrcoef(y_true, y_pred),
+                        mcc_safe(y_true, y_pred))
 
 
 def test_precision_recall_f1_score_multiclass():
@@ -610,18 +612,19 @@ def test_precision_recall_f1_score_multiclass():
     assert_array_equal(s, [24, 20, 31])
 
 
-def test_precision_refcall_f1_score_multilabel_unordered_labels():
+@pytest.mark.parametrize('average',
+                         ['samples', 'micro', 'macro', 'weighted', None])
+def test_precision_refcall_f1_score_multilabel_unordered_labels(average):
     # test that labels need not be sorted in the multilabel case
     y_true = np.array([[1, 1, 0, 0]])
     y_pred = np.array([[0, 0, 1, 1]])
-    for average in ['samples', 'micro', 'macro', 'weighted', None]:
-        p, r, f, s = precision_recall_fscore_support(
-            y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average)
-        assert_array_equal(p, 0)
-        assert_array_equal(r, 0)
-        assert_array_equal(f, 0)
-        if average is None:
-            assert_array_equal(s, [0, 1, 1, 0])
+    p, r, f, s = precision_recall_fscore_support(
+        y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=average)
+    assert_array_equal(p, 0)
+    assert_array_equal(r, 0)
+    assert_array_equal(f, 0)
+    if average is None:
+        assert_array_equal(s, [0, 1, 1, 0])
 
 
 def test_precision_recall_f1_score_binary_averaged():
@@ -1207,10 +1210,33 @@ def test_precision_recall_f1_score_with_an_empty_prediction():
                         0.333, 2)
 
 
-def test_precision_recall_f1_no_labels():
+@pytest.mark.parametrize('beta', [1])
+@pytest.mark.parametrize('average', ["macro", "micro", "weighted", "samples"])
+def test_precision_recall_f1_no_labels(beta, average):
+    y_true = np.zeros((20, 3))
+    y_pred = np.zeros_like(y_true)
+
+    p, r, f, s = assert_warns(UndefinedMetricWarning,
+                              precision_recall_fscore_support,
+                              y_true, y_pred, average=average,
+                              beta=beta)
+    assert_almost_equal(p, 0)
+    assert_almost_equal(r, 0)
+    assert_almost_equal(f, 0)
+    assert_equal(s, None)
+
+    fbeta = assert_warns(UndefinedMetricWarning, fbeta_score,
+                         y_true, y_pred,
+                         beta=beta, average=average)
+    assert_almost_equal(fbeta, 0)
+
+
+def test_precision_recall_f1_no_labels_average_none():
     y_true = np.zeros((20, 3))
     y_pred = np.zeros_like(y_true)
 
+    beta = 1
+
     # tp = [0, 0, 0]
     # fn = [0, 0, 0]
     # fp = [0, 0, 0]
@@ -1219,33 +1245,17 @@ def test_precision_recall_f1_no_labels():
     # |y_i| = [0, 0, 0]
     # |y_hat_i| = [0, 0, 0]
 
-    for beta in [1]:
-        p, r, f, s = assert_warns(UndefinedMetricWarning,
-                                  precision_recall_fscore_support,
-                                  y_true, y_pred, average=None, beta=beta)
-        assert_array_almost_equal(p, [0, 0, 0], 2)
-        assert_array_almost_equal(r, [0, 0, 0], 2)
-        assert_array_almost_equal(f, [0, 0, 0], 2)
-        assert_array_almost_equal(s, [0, 0, 0], 2)
-
-        fbeta = assert_warns(UndefinedMetricWarning, fbeta_score,
-                             y_true, y_pred, beta=beta, average=None)
-        assert_array_almost_equal(fbeta, [0, 0, 0], 2)
-
-        for average in ["macro", "micro", "weighted", "samples"]:
-            p, r, f, s = assert_warns(UndefinedMetricWarning,
-                                      precision_recall_fscore_support,
-                                      y_true, y_pred, average=average,
-                                      beta=beta)
-            assert_almost_equal(p, 0)
-            assert_almost_equal(r, 0)
-            assert_almost_equal(f, 0)
-            assert_equal(s, None)
-
-            fbeta = assert_warns(UndefinedMetricWarning, fbeta_score,
-                                 y_true, y_pred,
-                                 beta=beta, average=average)
-            assert_almost_equal(fbeta, 0)
+    p, r, f, s = assert_warns(UndefinedMetricWarning,
+                              precision_recall_fscore_support,
+                              y_true, y_pred, average=None, beta=beta)
+    assert_array_almost_equal(p, [0, 0, 0], 2)
+    assert_array_almost_equal(r, [0, 0, 0], 2)
+    assert_array_almost_equal(f, [0, 0, 0], 2)
+    assert_array_almost_equal(s, [0, 0, 0], 2)
+
+    fbeta = assert_warns(UndefinedMetricWarning, fbeta_score,
+                         y_true, y_pred, beta=beta, average=None)
+    assert_array_almost_equal(fbeta, [0, 0, 0], 2)
 
 
 def test_prf_warnings():
diff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py
index 680b78c3dd43..f835fdd50776 100644
--- a/sklearn/metrics/tests/test_common.py
+++ b/sklearn/metrics/tests/test_common.py
@@ -2,10 +2,13 @@
 
 from functools import partial
 from itertools import product
+from itertools import chain
 
 import numpy as np
 import scipy.sparse as sp
 
+import pytest
+
 from sklearn.datasets import make_multilabel_classification
 from sklearn.preprocessing import LabelBinarizer
 from sklearn.utils.multiclass import type_of_target
@@ -193,7 +196,7 @@
 # is already written.
 
 # Those metrics don't support binary inputs
-METRIC_UNDEFINED_BINARY = [
+METRIC_UNDEFINED_BINARY = {
     "samples_f0.5_score",
     "samples_f1_score",
     "samples_f2_score",
@@ -209,10 +212,10 @@
 
     "label_ranking_loss",
     "label_ranking_average_precision_score",
-]
+}
 
 # Those metrics don't support multiclass inputs
-METRIC_UNDEFINED_MULTICLASS = [
+METRIC_UNDEFINED_MULTICLASS = {
     "brier_score_loss",
     "balanced_accuracy_score",
 
@@ -229,24 +232,24 @@
     "f1_score",
     "f2_score",
     "f0.5_score",
-]
+}
 
 # Metric undefined with "binary" or "multiclass" input
-METRIC_UNDEFINED_BINARY_MULTICLASS = set(METRIC_UNDEFINED_BINARY).union(
-    set(METRIC_UNDEFINED_MULTICLASS))
+METRIC_UNDEFINED_BINARY_MULTICLASS = METRIC_UNDEFINED_BINARY.union(
+    METRIC_UNDEFINED_MULTICLASS)
 
 # Metrics with an "average" argument
-METRICS_WITH_AVERAGING = [
+METRICS_WITH_AVERAGING = {
     "precision_score", "recall_score", "f1_score", "f2_score", "f0.5_score"
-]
+}
 
 # Threshold-based metrics with an "average" argument
-THRESHOLDED_METRICS_WITH_AVERAGING = [
+THRESHOLDED_METRICS_WITH_AVERAGING = {
     "roc_auc_score", "average_precision_score", "partial_roc_auc",
-]
+}
 
 # Metrics with a "pos_label" argument
-METRICS_WITH_POS_LABEL = [
+METRICS_WITH_POS_LABEL = {
     "roc_curve",
 
     "brier_score_loss",
@@ -262,12 +265,12 @@
 
     "macro_f0.5_score", "macro_f1_score", "macro_f2_score",
     "macro_precision_score", "macro_recall_score",
-]
+}
 
 # Metrics with a "labels" argument
 # TODO: Handle multi_class metrics that has a labels argument as well as a
 # decision function argument. e.g hinge_loss
-METRICS_WITH_LABELS = [
+METRICS_WITH_LABELS = {
     "confusion_matrix",
 
     "hamming_loss",
@@ -284,17 +287,17 @@
     "macro_precision_score", "macro_recall_score",
 
     "cohen_kappa_score",
-]
+}
 
 # Metrics with a "normalize" option
-METRICS_WITH_NORMALIZE_OPTION = [
+METRICS_WITH_NORMALIZE_OPTION = {
     "accuracy_score",
     "jaccard_similarity_score",
     "zero_one_loss",
-]
+}
 
 # Threshold-based metrics with "multilabel-indicator" format support
-THRESHOLDED_MULTILABEL_METRICS = [
+THRESHOLDED_MULTILABEL_METRICS = {
     "log_loss",
     "unnormalized_log_loss",
 
@@ -307,10 +310,10 @@
 
     "coverage_error", "label_ranking_loss",
     "label_ranking_average_precision_score",
-]
+}
 
 # Classification metrics with  "multilabel-indicator" format
-MULTILABELS_METRICS = [
+MULTILABELS_METRICS = {
     "accuracy_score", "unnormalized_accuracy_score",
     "hamming_loss",
     "jaccard_similarity_score", "unnormalized_jaccard_similarity_score",
@@ -327,17 +330,17 @@
 
     "samples_f0.5_score", "samples_f1_score", "samples_f2_score",
     "samples_precision_score", "samples_recall_score",
-]
+}
 
 # Regression metrics with "multioutput-continuous" format support
-MULTIOUTPUT_METRICS = [
+MULTIOUTPUT_METRICS = {
     "mean_absolute_error", "mean_squared_error", "r2_score",
     "explained_variance_score"
-]
+}
 
 # Symmetric with respect to their input arguments y_true and y_pred
 # metric(y_true, y_pred) == metric(y_pred, y_true).
-SYMMETRIC_METRICS = [
+SYMMETRIC_METRICS = {
     "accuracy_score", "unnormalized_accuracy_score",
     "hamming_loss",
     "jaccard_similarity_score", "unnormalized_jaccard_similarity_score",
@@ -353,11 +356,11 @@
     "median_absolute_error",
 
     "cohen_kappa_score",
-]
+}
 
 # Asymmetric with respect to their input arguments y_true and y_pred
 # metric(y_true, y_pred) != metric(y_pred, y_true).
-NOT_SYMMETRIC_METRICS = [
+NOT_SYMMETRIC_METRICS = {
     "balanced_accuracy_score",
     "explained_variance_score",
     "r2_score",
@@ -370,18 +373,18 @@
 
     "macro_f0.5_score", "macro_f2_score", "macro_precision_score",
     "macro_recall_score", "log_loss", "hinge_loss"
-]
+}
 
 
 # No Sample weight support
-METRICS_WITHOUT_SAMPLE_WEIGHT = [
+METRICS_WITHOUT_SAMPLE_WEIGHT = {
     "confusion_matrix", # Left this one here because the tests in this file do
                         # not work for confusion_matrix, as its output is a
                         # matrix instead of a number. Testing of
                         # confusion_matrix with sample_weight is in
                         # test_classification.py
     "median_absolute_error",
-]
+}
 
 
 @ignore_warnings
@@ -392,13 +395,13 @@ def test_symmetry():
     y_pred = random_state.randint(0, 2, size=(20, ))
 
     # We shouldn't forget any metrics
-    assert_equal(set(SYMMETRIC_METRICS).union(
-        NOT_SYMMETRIC_METRICS, THRESHOLDED_METRICS,
+    assert_equal(SYMMETRIC_METRICS.union(
+        NOT_SYMMETRIC_METRICS, set(THRESHOLDED_METRICS),
         METRIC_UNDEFINED_BINARY_MULTICLASS),
         set(ALL_METRICS))
 
     assert_equal(
-        set(SYMMETRIC_METRICS).intersection(set(NOT_SYMMETRIC_METRICS)),
+        SYMMETRIC_METRICS.intersection(NOT_SYMMETRIC_METRICS),
         set([]))
 
     # Symmetric metric
@@ -415,17 +418,17 @@ def test_symmetry():
                     msg="%s seems to be symmetric" % name)
 
 
-@ignore_warnings
-def test_sample_order_invariance():
+@pytest.mark.parametrize(
+        'name',
+        set(ALL_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS)
+def test_sample_order_invariance(name):
     random_state = check_random_state(0)
     y_true = random_state.randint(0, 2, size=(20, ))
     y_pred = random_state.randint(0, 2, size=(20, ))
     y_true_shuffle, y_pred_shuffle = shuffle(y_true, y_pred, random_state=0)
 
-    for name, metric in ALL_METRICS.items():
-        if name in METRIC_UNDEFINED_BINARY_MULTICLASS:
-            continue
-
+    with ignore_warnings():
+        metric = ALL_METRICS[name]
         assert_almost_equal(metric(y_true, y_pred),
                             metric(y_true_shuffle, y_pred_shuffle),
                             err_msg="%s is not sample order invariant"
@@ -472,8 +475,10 @@ def test_sample_order_invariance_multilabel_and_multioutput():
                                     % name)
 
 
-@ignore_warnings
-def test_format_invariance_with_1d_vectors():
+@pytest.mark.parametrize(
+        'name',
+        set(ALL_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS)
+def test_format_invariance_with_1d_vectors(name):
     random_state = check_random_state(0)
     y1 = random_state.randint(0, 2, size=(20, ))
     y2 = random_state.randint(0, 2, size=(20, ))
@@ -489,9 +494,8 @@ def test_format_invariance_with_1d_vectors():
     y1_row = np.reshape(y1_1d, (1, -1))
     y2_row = np.reshape(y2_1d, (1, -1))
 
-    for name, metric in ALL_METRICS.items():
-        if name in METRIC_UNDEFINED_BINARY_MULTICLASS:
-            continue
+    with ignore_warnings():
+        metric = ALL_METRICS[name]
 
         measure = metric(y1, y2)
 
@@ -546,14 +550,16 @@ def test_format_invariance_with_1d_vectors():
 
         # NB: We do not test for y1_row, y2_row as these may be
         # interpreted as multilabel or multioutput data.
-        if (name not in (MULTIOUTPUT_METRICS + THRESHOLDED_MULTILABEL_METRICS +
+        if (name not in (MULTIOUTPUT_METRICS | THRESHOLDED_MULTILABEL_METRICS |
                          MULTILABELS_METRICS)):
             assert_raises(ValueError, metric, y1_row, y2_row)
 
 
-@ignore_warnings
-def test_invariance_string_vs_numbers_labels():
-    # Ensure that classification metrics with string labels
+@pytest.mark.parametrize(
+       'name',
+       set(CLASSIFICATION_METRICS) - METRIC_UNDEFINED_BINARY_MULTICLASS)
+def test_classification_invariance_string_vs_numbers_labels(name):
+    # Ensure that classification metrics with string labels are invariant
     random_state = check_random_state(0)
     y1 = random_state.randint(0, 2, size=(20, ))
     y2 = random_state.randint(0, 2, size=(20, ))
@@ -564,10 +570,8 @@ def test_invariance_string_vs_numbers_labels():
     pos_label_str = "spam"
     labels_str = ["eggs", "spam"]
 
-    for name, metric in CLASSIFICATION_METRICS.items():
-        if name in METRIC_UNDEFINED_BINARY_MULTICLASS:
-            continue
-
+    with ignore_warnings():
+        metric = CLASSIFICATION_METRICS[name]
         measure_with_number = metric(y1, y2)
 
         # Ugly, but handle case with a pos_label and label
@@ -600,7 +604,20 @@ def test_invariance_string_vs_numbers_labels():
                                err_msg="{0} failed string vs number  "
                                        "invariance test".format(name))
 
-    for name, metric in THRESHOLDED_METRICS.items():
+
+@pytest.mark.parametrize('name', THRESHOLDED_METRICS)
+def test_thresholded_invariance_string_vs_numbers_labels(name):
+    # Ensure that thresholded metrics with string labels are invariant
+    random_state = check_random_state(0)
+    y1 = random_state.randint(0, 2, size=(20, ))
+    y2 = random_state.randint(0, 2, size=(20, ))
+
+    y1_str = np.array(["eggs", "spam"])[y1]
+
+    pos_label_str = "spam"
+
+    with ignore_warnings():
+        metric = THRESHOLDED_METRICS[name]
         if name not in METRIC_UNDEFINED_BINARY:
             # Ugly, but handle case with a pos_label and label
             metric_str = metric
@@ -623,28 +640,30 @@ def test_invariance_string_vs_numbers_labels():
             assert_raises(ValueError, metric, y1_str.astype('O'), y2)
 
 
-def test_inf_nan_input():
-    invalids =[([0, 1], [np.inf, np.inf]),
-               ([0, 1], [np.nan, np.nan]),
-               ([0, 1], [np.nan, np.inf])]
+invalids = [([0, 1], [np.inf, np.inf]),
+            ([0, 1], [np.nan, np.nan]),
+            ([0, 1], [np.nan, np.inf])]
+
+
+@pytest.mark.parametrize(
+        'metric',
+        chain(THRESHOLDED_METRICS.values(), REGRESSION_METRICS.values()))
+def test_regression_thresholded_inf_nan_input(metric):
 
-    METRICS = dict()
-    METRICS.update(THRESHOLDED_METRICS)
-    METRICS.update(REGRESSION_METRICS)
+    for y_true, y_score in invalids:
+        assert_raise_message(ValueError,
+                             "contains NaN, infinity",
+                             metric, y_true, y_score)
 
-    for metric in METRICS.values():
-        for y_true, y_score in invalids:
-            assert_raise_message(ValueError,
-                                 "contains NaN, infinity",
-                                 metric, y_true, y_score)
 
+@pytest.mark.parametrize('metric', CLASSIFICATION_METRICS.values())
+def test_classification_inf_nan_input(metric):
     # Classification metrics all raise a mixed input exception
-    for metric in CLASSIFICATION_METRICS.values():
-        for y_true, y_score in invalids:
-            assert_raise_message(ValueError,
-                                 "Classification metrics can't handle a mix "
-                                 "of binary and continuous targets",
-                                 metric, y_true, y_score)
+    for y_true, y_score in invalids:
+        assert_raise_message(ValueError,
+                             "Classification metrics can't handle a mix "
+                             "of binary and continuous targets",
+                             metric, y_true, y_score)
 
 
 @ignore_warnings
@@ -667,45 +686,47 @@ def check_single_sample_multioutput(name):
         metric(np.array([[i, j]]), np.array([[k, l]]))
 
 
-def test_single_sample():
-    for name in ALL_METRICS:
-        if (name in METRIC_UNDEFINED_BINARY_MULTICLASS or
-                name in THRESHOLDED_METRICS):
-            # Those metrics are not always defined with one sample
-            # or in multiclass classification
-            continue
+@pytest.mark.parametrize(
+        'name',
+        (set(ALL_METRICS)
+         # Those metrics are not always defined with one sample
+         # or in multiclass classification
+         - METRIC_UNDEFINED_BINARY_MULTICLASS
+         - set(THRESHOLDED_METRICS)))
+def test_single_sample(name):
+    check_single_sample(name)
 
-        yield check_single_sample, name
 
-    for name in MULTIOUTPUT_METRICS + MULTILABELS_METRICS:
-        yield check_single_sample_multioutput, name
+@pytest.mark.parametrize('name', MULTIOUTPUT_METRICS | MULTILABELS_METRICS)
+def test_single_sample_multioutput(name):
+    check_single_sample_multioutput(name)
 
 
-def test_multioutput_number_of_output_differ():
+@pytest.mark.parametrize('name', MULTIOUTPUT_METRICS)
+def test_multioutput_number_of_output_differ(name):
     y_true = np.array([[1, 0, 0, 1], [0, 1, 1, 1], [1, 1, 0, 1]])
     y_pred = np.array([[0, 0], [1, 0], [0, 0]])
 
-    for name in MULTIOUTPUT_METRICS:
-        metric = ALL_METRICS[name]
-        assert_raises(ValueError, metric, y_true, y_pred)
+    metric = ALL_METRICS[name]
+    assert_raises(ValueError, metric, y_true, y_pred)
 
 
-def test_multioutput_regression_invariance_to_dimension_shuffling():
+@pytest.mark.parametrize('name', MULTIOUTPUT_METRICS)
+def test_multioutput_regression_invariance_to_dimension_shuffling(name):
     # test invariance to dimension shuffling
     random_state = check_random_state(0)
     y_true = random_state.uniform(0, 2, size=(20, 5))
     y_pred = random_state.uniform(0, 2, size=(20, 5))
 
-    for name in MULTIOUTPUT_METRICS:
-        metric = ALL_METRICS[name]
-        error = metric(y_true, y_pred)
+    metric = ALL_METRICS[name]
+    error = metric(y_true, y_pred)
 
-        for _ in range(3):
-            perm = random_state.permutation(y_true.shape[1])
-            assert_almost_equal(metric(y_true[:, perm], y_pred[:, perm]),
-                                error,
-                                err_msg="%s is not dimension shuffling "
-                                        "invariant" % name)
+    for _ in range(3):
+        perm = random_state.permutation(y_true.shape[1])
+        assert_almost_equal(metric(y_true[:, perm], y_pred[:, perm]),
+                            error,
+                            err_msg="%s is not dimension shuffling "
+                                    "invariant" % name)
 
 
 @ignore_warnings
@@ -747,7 +768,8 @@ def test_multilabel_representation_invariance():
                                     "formats." % name)
 
 
-def test_raise_value_error_multilabel_sequences():
+@pytest.mark.parametrize('name', MULTILABELS_METRICS)
+def test_raise_value_error_multilabel_sequences(name):
     # make sure the multilabel-sequence format raises ValueError
     multilabel_sequences = [
         [[0, 1]],
@@ -757,41 +779,41 @@ def test_raise_value_error_multilabel_sequences():
         [()],
         np.array([[], [1, 2]], dtype='object')]
 
-    for name in MULTILABELS_METRICS:
-        metric = ALL_METRICS[name]
-        for seq in multilabel_sequences:
-            assert_raises(ValueError, metric, seq, seq)
+    metric = ALL_METRICS[name]
+    for seq in multilabel_sequences:
+        assert_raises(ValueError, metric, seq, seq)
 
 
-def test_normalize_option_binary_classification(n_samples=20):
+@pytest.mark.parametrize('name', METRICS_WITH_NORMALIZE_OPTION)
+def test_normalize_option_binary_classification(name):
     # Test in the binary case
+    n_samples = 20
     random_state = check_random_state(0)
     y_true = random_state.randint(0, 2, size=(n_samples, ))
     y_pred = random_state.randint(0, 2, size=(n_samples, ))
 
-    for name in METRICS_WITH_NORMALIZE_OPTION:
-        metrics = ALL_METRICS[name]
-        measure = metrics(y_true, y_pred, normalize=True)
-        assert_greater(measure, 0,
-                       msg="We failed to test correctly the normalize option")
-        assert_almost_equal(metrics(y_true, y_pred, normalize=False)
-                            / n_samples, measure)
+    metrics = ALL_METRICS[name]
+    measure = metrics(y_true, y_pred, normalize=True)
+    assert_greater(measure, 0,
+                   msg="We failed to test correctly the normalize option")
+    assert_almost_equal(metrics(y_true, y_pred, normalize=False)
+                        / n_samples, measure)
 
 
-def test_normalize_option_multiclass_classification():
+@pytest.mark.parametrize('name', METRICS_WITH_NORMALIZE_OPTION)
+def test_normalize_option_multiclass_classification(name):
     # Test in the multiclass case
     random_state = check_random_state(0)
     y_true = random_state.randint(0, 4, size=(20, ))
     y_pred = random_state.randint(0, 4, size=(20, ))
     n_samples = y_true.shape[0]
 
-    for name in METRICS_WITH_NORMALIZE_OPTION:
-        metrics = ALL_METRICS[name]
-        measure = metrics(y_true, y_pred, normalize=True)
-        assert_greater(measure, 0,
-                       msg="We failed to test correctly the normalize option")
-        assert_almost_equal(metrics(y_true, y_pred, normalize=False)
-                            / n_samples, measure)
+    metrics = ALL_METRICS[name]
+    measure = metrics(y_true, y_pred, normalize=True)
+    assert_greater(measure, 0,
+                   msg="We failed to test correctly the normalize option")
+    assert_almost_equal(metrics(y_true, y_pred, normalize=False)
+                        / n_samples, measure)
 
 
 def test_normalize_option_multilabel_classification():
@@ -886,7 +908,9 @@ def check_averaging(name, y_true, y_true_binarize, y_pred, y_pred_binarize,
         raise ValueError("Metric is not recorded as having an average option")
 
 
-def test_averaging_multiclass(n_samples=50, n_classes=3):
+@pytest.mark.parametrize('name', METRICS_WITH_AVERAGING)
+def test_averaging_multiclass(name):
+    n_samples, n_classes = 50, 3
     random_state = check_random_state(0)
     y_true = random_state.randint(0, n_classes, size=(n_samples, ))
     y_pred = random_state.randint(0, n_classes, size=(n_samples, ))
@@ -896,12 +920,14 @@ def test_averaging_multiclass(n_samples=50, n_classes=3):
     y_true_binarize = lb.transform(y_true)
     y_pred_binarize = lb.transform(y_pred)
 
-    for name in METRICS_WITH_AVERAGING:
-        yield (check_averaging, name, y_true, y_true_binarize,
-               y_pred, y_pred_binarize, y_score)
+    check_averaging(name, y_true, y_true_binarize,
+                    y_pred, y_pred_binarize, y_score)
 
 
-def test_averaging_multilabel(n_classes=5, n_samples=40):
+@pytest.mark.parametrize(
+        'name', METRICS_WITH_AVERAGING | THRESHOLDED_METRICS_WITH_AVERAGING)
+def test_averaging_multilabel(name):
+    n_samples, n_classes = 40, 5
     _, y = make_multilabel_classification(n_features=1, n_classes=n_classes,
                                           random_state=5, n_samples=n_samples,
                                           allow_unlabeled=False)
@@ -911,22 +937,27 @@ def test_averaging_multilabel(n_classes=5, n_samples=40):
     y_true_binarize = y_true
     y_pred_binarize = y_pred
 
-    for name in METRICS_WITH_AVERAGING + THRESHOLDED_METRICS_WITH_AVERAGING:
-        yield (check_averaging, name, y_true, y_true_binarize,
-               y_pred, y_pred_binarize, y_score)
+    check_averaging(name, y_true, y_true_binarize,
+                    y_pred, y_pred_binarize, y_score)
 
 
-def test_averaging_multilabel_all_zeroes():
+@pytest.mark.parametrize('name', METRICS_WITH_AVERAGING)
+def test_averaging_multilabel_all_zeroes(name):
     y_true = np.zeros((20, 3))
     y_pred = np.zeros((20, 3))
     y_score = np.zeros((20, 3))
     y_true_binarize = y_true
     y_pred_binarize = y_pred
 
-    for name in METRICS_WITH_AVERAGING:
-        yield (check_averaging, name, y_true, y_true_binarize,
-               y_pred, y_pred_binarize, y_score)
+    check_averaging(name, y_true, y_true_binarize,
+                    y_pred, y_pred_binarize, y_score)
+
 
+def test_averaging_binary_multilabel_all_zeroes():
+    y_true = np.zeros((20, 3))
+    y_pred = np.zeros((20, 3))
+    y_true_binarize = y_true
+    y_pred_binarize = y_pred
     # Test _average_binary_score for weight.sum() == 0
     binary_metric = (lambda y_true, y_score, average="macro":
                      _average_binary_score(
@@ -935,16 +966,16 @@ def test_averaging_multilabel_all_zeroes():
                      y_pred_binarize, is_multilabel=True)
 
 
-def test_averaging_multilabel_all_ones():
+@pytest.mark.parametrize('name', METRICS_WITH_AVERAGING)
+def test_averaging_multilabel_all_ones(name):
     y_true = np.ones((20, 3))
     y_pred = np.ones((20, 3))
     y_score = np.ones((20, 3))
     y_true_binarize = y_true
     y_pred_binarize = y_pred
 
-    for name in METRICS_WITH_AVERAGING:
-        yield (check_averaging, name, y_true, y_true_binarize,
-               y_pred, y_pred_binarize, y_score)
+    check_averaging(name, y_true, y_true_binarize,
+                    y_pred, y_pred_binarize, y_score)
 
 
 @ignore_warnings
@@ -1022,54 +1053,64 @@ def check_sample_weight_invariance(name, metric, y1, y2):
                                                   sample_weight]))
 
 
-def test_sample_weight_invariance(n_samples=50):
+@pytest.mark.parametrize(
+        'name',
+        (set(ALL_METRICS).intersection(set(REGRESSION_METRICS))
+         - METRICS_WITHOUT_SAMPLE_WEIGHT))
+def test_regression_sample_weight_invariance(name):
+    n_samples = 50
     random_state = check_random_state(0)
     # regression
     y_true = random_state.random_sample(size=(n_samples,))
     y_pred = random_state.random_sample(size=(n_samples,))
-    for name in ALL_METRICS:
-        if name not in REGRESSION_METRICS:
-            continue
-        if name in METRICS_WITHOUT_SAMPLE_WEIGHT:
-            continue
-        metric = ALL_METRICS[name]
-        yield check_sample_weight_invariance, name, metric, y_true, y_pred
+    metric = ALL_METRICS[name]
+    check_sample_weight_invariance(name, metric, y_true, y_pred)
+
 
+@pytest.mark.parametrize(
+        'name',
+        (set(ALL_METRICS) - set(REGRESSION_METRICS)
+         - METRICS_WITHOUT_SAMPLE_WEIGHT - METRIC_UNDEFINED_BINARY))
+def test_binary_sample_weight_invariance(name):
     # binary
+    n_samples = 50
     random_state = check_random_state(0)
     y_true = random_state.randint(0, 2, size=(n_samples, ))
     y_pred = random_state.randint(0, 2, size=(n_samples, ))
     y_score = random_state.random_sample(size=(n_samples,))
-    for name in ALL_METRICS:
-        if name in REGRESSION_METRICS:
-            continue
-        if (name in METRICS_WITHOUT_SAMPLE_WEIGHT or
-                name in METRIC_UNDEFINED_BINARY):
-            continue
-        metric = ALL_METRICS[name]
-        if name in THRESHOLDED_METRICS:
-            yield check_sample_weight_invariance, name, metric, y_true, y_score
-        else:
-            yield check_sample_weight_invariance, name, metric, y_true, y_pred
+    metric = ALL_METRICS[name]
+    if name in THRESHOLDED_METRICS:
+        check_sample_weight_invariance(name, metric, y_true, y_score)
+    else:
+        check_sample_weight_invariance(name, metric, y_true, y_pred)
+
 
+@pytest.mark.parametrize(
+        'name',
+        (set(ALL_METRICS) - set(REGRESSION_METRICS)
+         - METRICS_WITHOUT_SAMPLE_WEIGHT
+         - METRIC_UNDEFINED_BINARY_MULTICLASS))
+def test_multiclass_sample_weight_invariance(name):
     # multiclass
+    n_samples = 50
     random_state = check_random_state(0)
     y_true = random_state.randint(0, 5, size=(n_samples, ))
     y_pred = random_state.randint(0, 5, size=(n_samples, ))
     y_score = random_state.random_sample(size=(n_samples, 5))
-    for name in ALL_METRICS:
-        if name in REGRESSION_METRICS:
-            continue
-        if (name in METRICS_WITHOUT_SAMPLE_WEIGHT or
-                name in METRIC_UNDEFINED_BINARY_MULTICLASS):
-            continue
-        metric = ALL_METRICS[name]
-        if name in THRESHOLDED_METRICS:
-            yield check_sample_weight_invariance, name, metric, y_true, y_score
-        else:
-            yield check_sample_weight_invariance, name, metric, y_true, y_pred
+    metric = ALL_METRICS[name]
+    if name in THRESHOLDED_METRICS:
+        check_sample_weight_invariance(name, metric, y_true, y_score)
+    else:
+        check_sample_weight_invariance(name, metric, y_true, y_pred)
 
+
+@pytest.mark.parametrize(
+        'name',
+        (MULTILABELS_METRICS | THRESHOLDED_MULTILABEL_METRICS |
+         MULTIOUTPUT_METRICS) - METRICS_WITHOUT_SAMPLE_WEIGHT)
+def test_multilabel_sample_weight_invariance(name):
     # multilabel indicator
+    random_state = check_random_state(0)
     _, ya = make_multilabel_classification(n_features=1, n_classes=20,
                                            random_state=0, n_samples=100,
                                            allow_unlabeled=False)
@@ -1080,18 +1121,11 @@ def test_sample_weight_invariance(n_samples=50):
     y_pred = np.vstack([ya, ya])
     y_score = random_state.randint(1, 4, size=y_true.shape)
 
-    for name in (MULTILABELS_METRICS + THRESHOLDED_MULTILABEL_METRICS +
-                 MULTIOUTPUT_METRICS):
-        if name in METRICS_WITHOUT_SAMPLE_WEIGHT:
-            continue
-
-        metric = ALL_METRICS[name]
-        if name in THRESHOLDED_METRICS:
-            yield (check_sample_weight_invariance, name, metric,
-                   y_true, y_score)
-        else:
-            yield (check_sample_weight_invariance, name, metric,
-                   y_true, y_pred)
+    metric = ALL_METRICS[name]
+    if name in THRESHOLDED_METRICS:
+        check_sample_weight_invariance(name, metric, y_true, y_score)
+    else:
+        check_sample_weight_invariance(name, metric, y_true, y_pred)
 
 
 @ignore_warnings
diff --git a/sklearn/metrics/tests/test_pairwise.py b/sklearn/metrics/tests/test_pairwise.py
index 0ef089c7a361..e63219a817be 100644
--- a/sklearn/metrics/tests/test_pairwise.py
+++ b/sklearn/metrics/tests/test_pairwise.py
@@ -2,11 +2,12 @@
 
 import numpy as np
 from numpy import linalg
-import pytest
 
 from scipy.sparse import dok_matrix, csr_matrix, issparse
 from scipy.spatial.distance import cosine, cityblock, minkowski, wminkowski
 
+import pytest
+
 from sklearn.utils.testing import assert_greater
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_allclose
@@ -129,52 +130,52 @@ def test_pairwise_distances():
     assert_raises(ValueError, pairwise_distances, X, Y, metric="blah")
 
 
-# ignore conversion to boolean in pairwise_distances
-@ignore_warnings(category=DataConversionWarning)
-def test_pairwise_boolean_distance():
+@pytest.mark.parametrize('metric', PAIRWISE_BOOLEAN_FUNCTIONS)
+def test_pairwise_boolean_distance(metric):
     # test that we convert to boolean arrays for boolean distances
     rng = np.random.RandomState(0)
     X = rng.randn(5, 4)
     Y = X.copy()
     Y[0, 0] = 1 - Y[0, 0]
 
-    for metric in PAIRWISE_BOOLEAN_FUNCTIONS:
+    # ignore conversion to boolean in pairwise_distances
+    with ignore_warnings(category=DataConversionWarning):
         for Z in [Y, None]:
             res = pairwise_distances(X, Z, metric=metric)
             res[np.isnan(res)] = 0
             assert_true(np.sum(res != 0) == 0)
 
 
-def test_pairwise_precomputed():
-    for func in [pairwise_distances, pairwise_kernels]:
-        # Test correct shape
-        assert_raises_regexp(ValueError, '.* shape .*',
-                             func, np.zeros((5, 3)), metric='precomputed')
-        # with two args
-        assert_raises_regexp(ValueError, '.* shape .*',
-                             func, np.zeros((5, 3)), np.zeros((4, 4)),
-                             metric='precomputed')
-        # even if shape[1] agrees (although thus second arg is spurious)
-        assert_raises_regexp(ValueError, '.* shape .*',
-                             func, np.zeros((5, 3)), np.zeros((4, 3)),
-                             metric='precomputed')
-
-        # Test not copied (if appropriate dtype)
-        S = np.zeros((5, 5))
-        S2 = func(S, metric="precomputed")
-        assert_true(S is S2)
-        # with two args
-        S = np.zeros((5, 3))
-        S2 = func(S, np.zeros((3, 3)), metric="precomputed")
-        assert_true(S is S2)
-
-        # Test always returns float dtype
-        S = func(np.array([[1]], dtype='int'), metric='precomputed')
-        assert_equal('f', S.dtype.kind)
-
-        # Test converts list to array-like
-        S = func([[1.]], metric='precomputed')
-        assert_true(isinstance(S, np.ndarray))
+@pytest.mark.parametrize('func', [pairwise_distances, pairwise_kernels])
+def test_pairwise_precomputed(func):
+    # Test correct shape
+    assert_raises_regexp(ValueError, '.* shape .*',
+                         func, np.zeros((5, 3)), metric='precomputed')
+    # with two args
+    assert_raises_regexp(ValueError, '.* shape .*',
+                         func, np.zeros((5, 3)), np.zeros((4, 4)),
+                         metric='precomputed')
+    # even if shape[1] agrees (although thus second arg is spurious)
+    assert_raises_regexp(ValueError, '.* shape .*',
+                         func, np.zeros((5, 3)), np.zeros((4, 3)),
+                         metric='precomputed')
+
+    # Test not copied (if appropriate dtype)
+    S = np.zeros((5, 5))
+    S2 = func(S, metric="precomputed")
+    assert_true(S is S2)
+    # with two args
+    S = np.zeros((5, 3))
+    S2 = func(S, np.zeros((3, 3)), metric="precomputed")
+    assert_true(S is S2)
+
+    # Test always returns float dtype
+    S = func(np.array([[1]], dtype='int'), metric='precomputed')
+    assert_equal('f', S.dtype.kind)
+
+    # Test converts list to array-like
+    S = func([[1.]], metric='precomputed')
+    assert_true(isinstance(S, np.ndarray))
 
 
 def check_pairwise_parallel(func, metric, kwds):
@@ -202,16 +203,24 @@ def check_pairwise_parallel(func, metric, kwds):
         assert_array_almost_equal(S, S2)
 
 
-def test_pairwise_parallel():
-    wminkowski_kwds = {'w': np.arange(1, 5).astype('double'), 'p': 1}
-    metrics = [(pairwise_distances, 'euclidean', {}),
-               (pairwise_distances, wminkowski, wminkowski_kwds),
-               (pairwise_distances, 'wminkowski', wminkowski_kwds),
-               (pairwise_kernels, 'polynomial', {'degree': 1}),
-               (pairwise_kernels, callable_rbf_kernel, {'gamma': .1}),
-               ]
-    for func, metric, kwds in metrics:
-        yield check_pairwise_parallel, func, metric, kwds
+_wminkowski_kwds = {'w': np.arange(1, 5).astype('double'), 'p': 1}
+
+
+def callable_rbf_kernel(x, y, **kwds):
+    # Callable version of pairwise.rbf_kernel.
+    K = rbf_kernel(np.atleast_2d(x), np.atleast_2d(y), **kwds)
+    return K
+
+
+@pytest.mark.parametrize(
+        'func, metric, kwds',
+        [(pairwise_distances, 'euclidean', {}),
+         (pairwise_distances, wminkowski, _wminkowski_kwds),
+         (pairwise_distances, 'wminkowski', _wminkowski_kwds),
+         (pairwise_kernels, 'polynomial', {'degree': 1}),
+         (pairwise_kernels, callable_rbf_kernel, {'gamma': .1})])
+def test_pairwise_parallel(func, metric, kwds):
+    check_pairwise_parallel(func, metric, kwds)
 
 
 def test_pairwise_callable_nonstrict_metric():
@@ -221,47 +230,51 @@ def test_pairwise_callable_nonstrict_metric():
     assert_equal(pairwise_distances([[1.]], metric=lambda x, y: 5)[0, 0], 5)
 
 
-def callable_rbf_kernel(x, y, **kwds):
-    # Callable version of pairwise.rbf_kernel.
-    K = rbf_kernel(np.atleast_2d(x), np.atleast_2d(y), **kwds)
-    return K
+# Test with all metrics that should be in PAIRWISE_KERNEL_FUNCTIONS.
+@pytest.mark.parametrize(
+        'metric',
+        ["rbf", "laplacian", "sigmoid", "polynomial", "linear",
+         "chi2", "additive_chi2"])
+def test_pairwise_kernels(metric):
+    # Test the pairwise_kernels helper function.
+
+    rng = np.random.RandomState(0)
+    X = rng.random_sample((5, 4))
+    Y = rng.random_sample((2, 4))
+    function = PAIRWISE_KERNEL_FUNCTIONS[metric]
+    # Test with Y=None
+    K1 = pairwise_kernels(X, metric=metric)
+    K2 = function(X)
+    assert_array_almost_equal(K1, K2)
+    # Test with Y=Y
+    K1 = pairwise_kernels(X, Y=Y, metric=metric)
+    K2 = function(X, Y=Y)
+    assert_array_almost_equal(K1, K2)
+    # Test with tuples as X and Y
+    X_tuples = tuple([tuple([v for v in row]) for row in X])
+    Y_tuples = tuple([tuple([v for v in row]) for row in Y])
+    K2 = pairwise_kernels(X_tuples, Y_tuples, metric=metric)
+    assert_array_almost_equal(K1, K2)
 
+    # Test with sparse X and Y
+    X_sparse = csr_matrix(X)
+    Y_sparse = csr_matrix(Y)
+    if metric in ["chi2", "additive_chi2"]:
+        # these don't support sparse matrices yet
+        assert_raises(ValueError, pairwise_kernels,
+                      X_sparse, Y=Y_sparse, metric=metric)
+        return
+    K1 = pairwise_kernels(X_sparse, Y=Y_sparse, metric=metric)
+    assert_array_almost_equal(K1, K2)
 
-def test_pairwise_kernels():    # Test the pairwise_kernels helper function.
 
+def test_pairwise_kernels_callable():
+    # Test the pairwise_kernels helper function
+    # with a callable function, with given keywords.
     rng = np.random.RandomState(0)
     X = rng.random_sample((5, 4))
     Y = rng.random_sample((2, 4))
-    # Test with all metrics that should be in PAIRWISE_KERNEL_FUNCTIONS.
-    test_metrics = ["rbf", "laplacian", "sigmoid", "polynomial", "linear",
-                    "chi2", "additive_chi2"]
-    for metric in test_metrics:
-        function = PAIRWISE_KERNEL_FUNCTIONS[metric]
-        # Test with Y=None
-        K1 = pairwise_kernels(X, metric=metric)
-        K2 = function(X)
-        assert_array_almost_equal(K1, K2)
-        # Test with Y=Y
-        K1 = pairwise_kernels(X, Y=Y, metric=metric)
-        K2 = function(X, Y=Y)
-        assert_array_almost_equal(K1, K2)
-        # Test with tuples as X and Y
-        X_tuples = tuple([tuple([v for v in row]) for row in X])
-        Y_tuples = tuple([tuple([v for v in row]) for row in Y])
-        K2 = pairwise_kernels(X_tuples, Y_tuples, metric=metric)
-        assert_array_almost_equal(K1, K2)
 
-        # Test with sparse X and Y
-        X_sparse = csr_matrix(X)
-        Y_sparse = csr_matrix(Y)
-        if metric in ["chi2", "additive_chi2"]:
-            # these don't support sparse matrices yet
-            assert_raises(ValueError, pairwise_kernels,
-                          X_sparse, Y=Y_sparse, metric=metric)
-            continue
-        K1 = pairwise_kernels(X_sparse, Y=Y_sparse, metric=metric)
-        assert_array_almost_equal(K1, K2)
-    # Test with a callable function, with given keywords.
     metric = callable_rbf_kernel
     kwds = {'gamma': 0.1}
     K1 = pairwise_kernels(X, Y=Y, metric=metric, **kwds)
@@ -286,27 +299,37 @@ def test_pairwise_kernels_filter_param():
     assert_raises(TypeError, pairwise_kernels, X, Y, "rbf", **params)
 
 
-def test_paired_distances():
+@pytest.mark.parametrize('metric, func', iteritems(PAIRED_DISTANCES))
+def test_paired_distances(metric, func):
     # Test the pairwise_distance helper function.
     rng = np.random.RandomState(0)
     # Euclidean distance should be equivalent to calling the function.
     X = rng.random_sample((5, 4))
     # Euclidean distance, with Y != X.
     Y = rng.random_sample((5, 4))
-    for metric, func in iteritems(PAIRED_DISTANCES):
-        S = paired_distances(X, Y, metric=metric)
-        S2 = func(X, Y)
-        assert_array_almost_equal(S, S2)
-        S3 = func(csr_matrix(X), csr_matrix(Y))
-        assert_array_almost_equal(S, S3)
-        if metric in PAIRWISE_DISTANCE_FUNCTIONS:
-            # Check the pairwise_distances implementation
-            # gives the same value
-            distances = PAIRWISE_DISTANCE_FUNCTIONS[metric](X, Y)
-            distances = np.diag(distances)
-            assert_array_almost_equal(distances, S)
-
-    # Check the callable implementation
+
+    S = paired_distances(X, Y, metric=metric)
+    S2 = func(X, Y)
+    assert_array_almost_equal(S, S2)
+    S3 = func(csr_matrix(X), csr_matrix(Y))
+    assert_array_almost_equal(S, S3)
+    if metric in PAIRWISE_DISTANCE_FUNCTIONS:
+        # Check the pairwise_distances implementation
+        # gives the same value
+        distances = PAIRWISE_DISTANCE_FUNCTIONS[metric](X, Y)
+        distances = np.diag(distances)
+        assert_array_almost_equal(distances, S)
+
+
+def test_paired_distances_callable():
+    # Test the pairwise_distance helper function
+    # with the callable implementation
+    rng = np.random.RandomState(0)
+    # Euclidean distance should be equivalent to calling the function.
+    X = rng.random_sample((5, 4))
+    # Euclidean distance, with Y != X.
+    Y = rng.random_sample((5, 4))
+
     S = paired_distances(X, Y, metric='manhattan')
     S2 = paired_distances(X, Y, metric=lambda x, y: np.abs(x - y).sum(axis=0))
     assert_array_almost_equal(S, S2)
@@ -637,25 +660,29 @@ def test_chi_square_kernel():
                   csr_matrix(X), csr_matrix(Y))
 
 
-def test_kernel_symmetry():
+@pytest.mark.parametrize(
+        'kernel',
+        (linear_kernel, polynomial_kernel, rbf_kernel,
+         laplacian_kernel, sigmoid_kernel, cosine_similarity))
+def test_kernel_symmetry(kernel):
     # Valid kernels should be symmetric
     rng = np.random.RandomState(0)
     X = rng.random_sample((5, 4))
-    for kernel in (linear_kernel, polynomial_kernel, rbf_kernel,
-                   laplacian_kernel, sigmoid_kernel, cosine_similarity):
-        K = kernel(X, X)
-        assert_array_almost_equal(K, K.T, 15)
+    K = kernel(X, X)
+    assert_array_almost_equal(K, K.T, 15)
 
 
-def test_kernel_sparse():
+@pytest.mark.parametrize(
+        'kernel',
+        (linear_kernel, polynomial_kernel, rbf_kernel,
+         laplacian_kernel, sigmoid_kernel, cosine_similarity))
+def test_kernel_sparse(kernel):
     rng = np.random.RandomState(0)
     X = rng.random_sample((5, 4))
     X_sparse = csr_matrix(X)
-    for kernel in (linear_kernel, polynomial_kernel, rbf_kernel,
-                   laplacian_kernel, sigmoid_kernel, cosine_similarity):
-        K = kernel(X, X)
-        K2 = kernel(X_sparse, X_sparse)
-        assert_array_almost_equal(K, K2)
+    K = kernel(X, X)
+    K2 = kernel(X_sparse, X_sparse)
+    assert_array_almost_equal(K, K2)
 
 
 def test_linear_kernel():
diff --git a/sklearn/metrics/tests/test_ranking.py b/sklearn/metrics/tests/test_ranking.py
index 07c35c609358..28b79e9b8474 100644
--- a/sklearn/metrics/tests/test_ranking.py
+++ b/sklearn/metrics/tests/test_ranking.py
@@ -2,7 +2,6 @@
 
 import pytest
 import numpy as np
-from itertools import product
 import warnings
 from scipy.sparse import csr_matrix
 
@@ -177,19 +176,19 @@ def _partial_roc(y_true, y_predict, max_fpr):
     return 0.5 * (1 + (partial_auc - min_area) / (max_area - min_area))
 
 
-def test_roc_curve():
+@pytest.mark.parametrize('drop', [True, False])
+def test_roc_curve(drop):
     # Test Area under Receiver Operating Characteristic (ROC) curve
     y_true, _, probas_pred = make_prediction(binary=True)
     expected_auc = _auc(y_true, probas_pred)
 
-    for drop in [True, False]:
-        fpr, tpr, thresholds = roc_curve(y_true, probas_pred,
-                                         drop_intermediate=drop)
-        roc_auc = auc(fpr, tpr)
-        assert_array_almost_equal(roc_auc, expected_auc, decimal=2)
-        assert_almost_equal(roc_auc, roc_auc_score(y_true, probas_pred))
-        assert_equal(fpr.shape, tpr.shape)
-        assert_equal(fpr.shape, thresholds.shape)
+    fpr, tpr, thresholds = roc_curve(y_true, probas_pred,
+                                     drop_intermediate=drop)
+    roc_auc = auc(fpr, tpr)
+    assert_array_almost_equal(roc_auc, expected_auc, decimal=2)
+    assert_almost_equal(roc_auc, roc_auc_score(y_true, probas_pred))
+    assert_equal(fpr.shape, tpr.shape)
+    assert_equal(fpr.shape, thresholds.shape)
 
 
 def test_roc_curve_end_points():
@@ -923,18 +922,29 @@ def check_alternative_lrap_implementation(lrap_score, n_classes=5,
     assert_almost_equal(score_lrap, score_my_lrap)
 
 
-def test_label_ranking_avp():
-    for fn in [label_ranking_average_precision_score, _my_lrap]:
-        yield check_lrap_toy, fn
-        yield check_lrap_without_tie_and_increasing_score, fn
-        yield check_lrap_only_ties, fn
-        yield check_zero_or_all_relevant_labels, fn
-        yield check_lrap_error_raised, label_ranking_average_precision_score
+@pytest.mark.parametrize(
+        'check',
+        (check_lrap_toy,
+         check_lrap_without_tie_and_increasing_score,
+         check_lrap_only_ties,
+         check_zero_or_all_relevant_labels))
+@pytest.mark.parametrize(
+        'func',
+        (label_ranking_average_precision_score, _my_lrap))
+def test_label_ranking_avp(check, func):
+    check(func)
+
+
+def test_lrap_error_raised():
+    check_lrap_error_raised(label_ranking_average_precision_score)
+
+
+@pytest.mark.parametrize('n_samples', (1, 2, 8, 20))
+@pytest.mark.parametrize('n_classes', (2, 5, 10))
+@pytest.mark.parametrize('random_state', range(1))
+def test_alternative_lrap_implementation(n_samples, n_classes, random_state):
 
-    for n_samples, n_classes, random_state in product((1, 2, 8, 20),
-                                                      (2, 5, 10),
-                                                      range(1)):
-        yield (check_alternative_lrap_implementation,
+    check_alternative_lrap_implementation(
                label_ranking_average_precision_score,
                n_classes, n_samples, random_state)
 
diff --git a/sklearn/metrics/tests/test_score_objects.py b/sklearn/metrics/tests/test_score_objects.py
index 6af6418635d5..8bb3c3c137dc 100644
--- a/sklearn/metrics/tests/test_score_objects.py
+++ b/sklearn/metrics/tests/test_score_objects.py
@@ -6,6 +6,8 @@
 
 import numpy as np
 
+import pytest
+
 from sklearn.utils.testing import assert_almost_equal
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_equal
@@ -491,12 +493,12 @@ def check_scorer_memmap(scorer_name):
     assert isinstance(score, numbers.Number), scorer_name
 
 
-def test_scorer_memmap_input():
+@pytest.mark.parametrize('name', SCORERS)
+def test_scorer_memmap_input(name):
     # Non-regression test for #6147: some score functions would
     # return singleton memmap when computed on memmap data instead of scalar
     # float values.
-    for name in SCORERS.keys():
-        yield check_scorer_memmap, name
+    check_scorer_memmap(name)
 
 
 def test_deprecated_names():
diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py
index d58a9e326c69..5673db5f98a0 100644
--- a/sklearn/mixture/gaussian_mixture.py
+++ b/sklearn/mixture/gaussian_mixture.py
@@ -448,15 +448,18 @@ class GaussianMixture(BaseMixture):
     n_components : int, defaults to 1.
         The number of mixture components.
 
-    covariance_type : {'full', 'tied', 'diag', 'spherical'},
-            defaults to 'full'.
+    covariance_type : {'full' (default), 'tied', 'diag', 'spherical'}
         String describing the type of covariance parameters to use.
-        Must be one of::
-
-            'full' (each component has its own general covariance matrix),
-            'tied' (all components share the same general covariance matrix),
-            'diag' (each component has its own diagonal covariance matrix),
-            'spherical' (each component has its own single variance).
+        Must be one of:
+
+        'full'
+            each component has its own general covariance matrix
+        'tied'
+            all components share the same general covariance matrix
+        'diag'
+            each component has its own diagonal covariance matrix
+        'spherical'
+            each component has its own single variance
 
     tol : float, defaults to 1e-3.
         The convergence threshold. EM iterations will stop when the
diff --git a/sklearn/mixture/tests/test_gmm.py b/sklearn/mixture/tests/test_gmm.py
index 137703adfcad..134c0493cf55 100644
--- a/sklearn/mixture/tests/test_gmm.py
+++ b/sklearn/mixture/tests/test_gmm.py
@@ -8,6 +8,8 @@
 import copy
 import sys
 
+import pytest
+
 import numpy as np
 from numpy.testing import assert_array_equal, assert_array_almost_equal
 
@@ -160,7 +162,6 @@ def test_GMM_attributes():
     assert_raises(ValueError, g._set_covars, [])
     assert_raises(ValueError, g._set_covars,
                   np.zeros((n_components - 2, n_features)))
-
     assert_raises(ValueError, mixture.GMM, n_components=20,
                   covariance_type='badcovariance_type')
 
@@ -496,10 +497,11 @@ def check_positive_definite_covars(covariance_type):
             assert_greater(np.linalg.det(c), 0)
 
 
-def test_positive_definite_covars():
+@pytest.mark.parametrize('covariance_type',
+                         ["full", "tied", "diag", "spherical"])
+def test_positive_definite_covars(covariance_type):
     # Check positive definiteness for all covariance types
-    for covariance_type in ["full", "tied", "diag", "spherical"]:
-        yield check_positive_definite_covars, covariance_type
+    check_positive_definite_covars(covariance_type)
 
 
 # This function tests the deprecated old GMM class
diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index 99d6096af73d..864d104abb53 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -17,6 +17,7 @@
 from functools import partial, reduce
 from itertools import product
 import operator
+import time
 import warnings
 
 import numpy as np
@@ -766,10 +767,13 @@ def _store(key_name, array, weights=None, splits=False, rank=False):
         if self.refit:
             self.best_estimator_ = clone(base_estimator).set_params(
                 **self.best_params_)
+            refit_start_time = time.time()
             if y is not None:
                 self.best_estimator_.fit(X, y, **fit_params)
             else:
                 self.best_estimator_.fit(X, **fit_params)
+            refit_end_time = time.time()
+            self.refit_time_ = refit_end_time - refit_start_time
 
         # Store the only scorer not as a dict for single metric evaluation
         self.scorer_ = scorers if self.multimetric_ else scorers['score']
@@ -894,10 +898,11 @@ class GridSearchCV(BaseSearchCV):
     cv : int, cross-validation generator or an iterable, optional
         Determines the cross-validation splitting strategy.
         Possible inputs for cv are:
-          - None, to use the default 3-fold cross validation,
-          - integer, to specify the number of folds in a `(Stratified)KFold`,
-          - An object to be used as a cross-validation generator.
-          - An iterable yielding train, test splits.
+
+        - None, to use the default 3-fold cross validation,
+        - integer, to specify the number of folds in a `(Stratified)KFold`,
+        - An object to be used as a cross-validation generator.
+        - An iterable yielding train, test splits.
 
         For integer/None inputs, if the estimator is a classifier and ``y`` is
         either binary or multiclass, :class:`StratifiedKFold` is used. In all
@@ -1076,6 +1081,11 @@ class GridSearchCV(BaseSearchCV):
     n_splits_ : int
         The number of cross-validation splits (folds/iterations).
 
+    refit_time_ : float
+        Seconds used for refitting the best model on the whole dataset.
+
+        This is present only if ``refit`` is not False.
+
     Notes
     ------
     The parameters selected are those that maximize the score of the left out
@@ -1228,10 +1238,11 @@ class RandomizedSearchCV(BaseSearchCV):
     cv : int, cross-validation generator or an iterable, optional
         Determines the cross-validation splitting strategy.
         Possible inputs for cv are:
-          - None, to use the default 3-fold cross validation,
-          - integer, to specify the number of folds in a `(Stratified)KFold`,
-          - An object to be used as a cross-validation generator.
-          - An iterable yielding train, test splits.
+
+        - None, to use the default 3-fold cross validation,
+        - integer, to specify the number of folds in a `(Stratified)KFold`,
+        - An object to be used as a cross-validation generator.
+        - An iterable yielding train, test splits.
 
         For integer/None inputs, if the estimator is a classifier and ``y`` is
         either binary or multiclass, :class:`StratifiedKFold` is used. In all
@@ -1387,6 +1398,11 @@ class RandomizedSearchCV(BaseSearchCV):
     n_splits_ : int
         The number of cross-validation splits (folds/iterations).
 
+    refit_time_ : float
+        Seconds used for refitting the best model on the whole dataset.
+
+        This is present only if ``refit`` is not False.
+
     Notes
     -----
     The parameters selected are those that maximize the score of the held-out
diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py
index 866cb4cc53aa..399f8df3a0ee 100644
--- a/sklearn/model_selection/_split.py
+++ b/sklearn/model_selection/_split.py
@@ -76,8 +76,8 @@ def split(self, X, y=None, groups=None):
             Group labels for the samples used while splitting the dataset into
             train/test set.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -301,8 +301,8 @@ def split(self, X, y=None, groups=None):
             Group labels for the samples used while splitting the dataset into
             train/test set.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -647,8 +647,8 @@ def split(self, X, y, groups=None):
         groups : object
             Always ignored, exists for compatibility.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -734,8 +734,8 @@ def split(self, X, y=None, groups=None):
         groups : array-like, with shape (n_samples,), optional
             Always ignored, exists for compatibility.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -1006,8 +1006,8 @@ def split(self, X, y=None, groups=None):
             Group labels for the samples used while splitting the dataset into
             train/test set.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -1182,8 +1182,8 @@ def split(self, X, y=None, groups=None):
             Group labels for the samples used while splitting the dataset into
             train/test set.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -1603,8 +1603,8 @@ def split(self, X, y, groups=None):
         groups : object
             Always ignored, exists for compatibility.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -1763,8 +1763,8 @@ def split(self, X=None, y=None, groups=None):
         groups : object
             Always ignored, exists for compatibility.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
@@ -1847,8 +1847,8 @@ def split(self, X=None, y=None, groups=None):
         groups : object
             Always ignored, exists for compatibility.
 
-        Returns
-        -------
+        Yields
+        ------
         train : ndarray
             The training set indices for that split.
 
diff --git a/sklearn/model_selection/_validation.py b/sklearn/model_selection/_validation.py
index 50af9b5dd550..9241d05fd432 100644
--- a/sklearn/model_selection/_validation.py
+++ b/sklearn/model_selection/_validation.py
@@ -79,10 +79,11 @@ def cross_validate(estimator, X, y=None, groups=None, scoring=None, cv=None,
     cv : int, cross-validation generator or an iterable, optional
         Determines the cross-validation splitting strategy.
         Possible inputs for cv are:
-          - None, to use the default 3-fold cross validation,
-          - integer, to specify the number of folds in a `(Stratified)KFold`,
-          - An object to be used as a cross-validation generator.
-          - An iterable yielding train, test splits.
+
+        - None, to use the default 3-fold cross validation,
+        - integer, to specify the number of folds in a `(Stratified)KFold`,
+        - An object to be used as a cross-validation generator.
+        - An iterable yielding train, test splits.
 
         For integer/None inputs, if the estimator is a classifier and ``y`` is
         either binary or multiclass, :class:`StratifiedKFold` is used. In all
diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
index f436c7b55cf3..c25729ed8eb1 100644
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -26,6 +26,7 @@
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_almost_equal
+from sklearn.utils.testing import assert_greater_equal
 from sklearn.utils.testing import ignore_warnings
 from sklearn.utils.mocking import CheckingClassifier, MockDataFrame
 
@@ -1172,6 +1173,10 @@ def test_search_cv_timing():
             assert_true(search.cv_results_[key][0] == 0.0)
             assert_true(np.all(search.cv_results_[key] < 1))
 
+        assert_true(hasattr(search, "refit_time_"))
+        assert_true(isinstance(search.refit_time_, float))
+        assert_greater_equal(search.refit_time_, 0)
+
 
 def test_grid_search_correct_score_results():
     # test that correct scores are used
@@ -1313,7 +1318,7 @@ def test_grid_search_allows_nans():
     X[2, :] = np.nan
     y = [0, 0, 1, 1, 1]
     p = Pipeline([
-        ('imputer', SimpleImputer(strategy='mean', missing_values='NaN')),
+        ('imputer', SimpleImputer(strategy='mean', missing_values=np.nan)),
         ('classifier', MockClassifier()),
     ])
     GridSearchCV(p, {'classifier__foo_param': [1, 2, 3]}, cv=2).fit(X, y)
diff --git a/sklearn/model_selection/tests/test_validation.py b/sklearn/model_selection/tests/test_validation.py
index 292991661976..6b3fcd0bab97 100644
--- a/sklearn/model_selection/tests/test_validation.py
+++ b/sklearn/model_selection/tests/test_validation.py
@@ -387,8 +387,8 @@ def test_cross_validate():
         scores = (train_mse_scores, test_mse_scores, train_r2_scores,
                   test_r2_scores, fitted_estimators)
 
-        yield check_cross_validate_single_metric, est, X, y, scores
-        yield check_cross_validate_multi_metric, est, X, y, scores
+        check_cross_validate_single_metric(est, X, y, scores)
+        check_cross_validate_multi_metric(est, X, y, scores)
 
 
 def test_cross_validate_return_train_score_warn():
@@ -744,7 +744,7 @@ def test_permutation_test_score_allow_nans():
     X[2, :] = np.nan
     y = np.repeat([0, 1], X.shape[0] / 2)
     p = Pipeline([
-        ('imputer', SimpleImputer(strategy='mean', missing_values='NaN')),
+        ('imputer', SimpleImputer(strategy='mean', missing_values=np.nan)),
         ('classifier', MockClassifier()),
     ])
     permutation_test_score(p, X, y, cv=5)
@@ -756,7 +756,7 @@ def test_cross_val_score_allow_nans():
     X[2, :] = np.nan
     y = np.repeat([0, 1], X.shape[0] / 2)
     p = Pipeline([
-        ('imputer', SimpleImputer(strategy='mean', missing_values='NaN')),
+        ('imputer', SimpleImputer(strategy='mean', missing_values=np.nan)),
         ('classifier', MockClassifier()),
     ])
     cross_val_score(p, X, y, cv=5)
diff --git a/sklearn/multioutput.py b/sklearn/multioutput.py
index 14707f8d460e..4d9b9e10f4fb 100644
--- a/sklearn/multioutput.py
+++ b/sklearn/multioutput.py
@@ -508,9 +508,10 @@ class ClassifierChain(_BaseChain, ClassifierMixin, MetaEstimatorMixin):
         labels for the results of previous estimators in the chain.
         If cv is None the true labels are used when fitting. Otherwise
         possible inputs for cv are:
-            * integer, to specify the number of folds in a (Stratified)KFold,
-            * An object to be used as a cross-validation generator.
-            * An iterable yielding train, test splits.
+
+        * integer, to specify the number of folds in a (Stratified)KFold,
+        * An object to be used as a cross-validation generator.
+        * An iterable yielding train, test splits.
 
     random_state : int, RandomState instance or None, optional (default=None)
         If int, random_state is the seed used by the random number generator;
@@ -547,6 +548,7 @@ class labels for each estimator in the chain.
 
     def fit(self, X, Y):
         """Fit the model to data matrix X and targets Y.
+
         Parameters
         ----------
         X : {array-like, sparse matrix}, shape (n_samples, n_features)
@@ -662,9 +664,10 @@ class RegressorChain(_BaseChain, RegressorMixin, MetaEstimatorMixin):
         labels for the results of previous estimators in the chain.
         If cv is None the true labels are used when fitting. Otherwise
         possible inputs for cv are:
-            * integer, to specify the number of folds in a (Stratified)KFold,
-            * An object to be used as a cross-validation generator.
-            * An iterable yielding train, test splits.
+
+        * integer, to specify the number of folds in a (Stratified)KFold,
+        * An object to be used as a cross-validation generator.
+        * An iterable yielding train, test splits.
 
     random_state : int, RandomState instance or None, optional (default=None)
         If int, random_state is the seed used by the random number generator;
diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py
index d983c124679f..14810e65b016 100644
--- a/sklearn/neighbors/base.py
+++ b/sklearn/neighbors/base.py
@@ -6,6 +6,8 @@
 #          Multi-output support by Arnaud Joly <a.joly@ulg.ac.be>
 #
 # License: BSD 3 clause (C) INRIA, University of Amsterdam
+from functools import partial
+
 import warnings
 from abc import ABCMeta, abstractmethod
 
@@ -15,7 +17,7 @@
 from .ball_tree import BallTree
 from .kd_tree import KDTree
 from ..base import BaseEstimator
-from ..metrics import pairwise_distances
+from ..metrics import pairwise_distances_chunked
 from ..metrics.pairwise import PAIRWISE_DISTANCE_FUNCTIONS
 from ..utils import check_X_y, check_array, _get_n_jobs, gen_even_slices
 from ..utils.multiclass import check_classification_targets
@@ -276,9 +278,43 @@ def _pairwise(self):
 class KNeighborsMixin(object):
     """Mixin for k-neighbors searches"""
 
+    def _kneighbors_reduce_func(self, dist, start,
+                                n_neighbors, return_distance):
+        """Reduce a chunk of distances to the nearest neighbors
+
+        Callback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`
+
+        Parameters
+        ----------
+        dist : array of shape (n_samples_chunk, n_samples)
+        start : int
+            The index in X which the first row of dist corresponds to.
+        n_neighbors : int
+        return_distance : bool
+
+        Returns
+        -------
+        dist : array of shape (n_samples_chunk, n_neighbors), optional
+            Returned only if return_distance
+        neigh : array of shape (n_samples_chunk, n_neighbors)
+        """
+        sample_range = np.arange(dist.shape[0])[:, None]
+        neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)
+        neigh_ind = neigh_ind[:, :n_neighbors]
+        # argpartition doesn't guarantee sorted order, so we sort again
+        neigh_ind = neigh_ind[
+            sample_range, np.argsort(dist[sample_range, neigh_ind])]
+        if return_distance:
+            if self.effective_metric_ == 'euclidean':
+                result = np.sqrt(dist[sample_range, neigh_ind]), neigh_ind
+            else:
+                result = dist[sample_range, neigh_ind], neigh_ind
+        else:
+            result = neigh_ind
+        return result
+
     def kneighbors(self, X=None, n_neighbors=None, return_distance=True):
         """Finds the K-neighbors of a point.
-
         Returns indices of and distances to the neighbors of each point.
 
         Parameters
@@ -367,28 +403,19 @@ class from an array representing our data set and ask who's
 
         n_jobs = _get_n_jobs(self.n_jobs)
         if self._fit_method == 'brute':
-            # for efficiency, use squared euclidean distances
-            if self.effective_metric_ == 'euclidean':
-                dist = pairwise_distances(X, self._fit_X, 'euclidean',
-                                          n_jobs=n_jobs, squared=True)
-            else:
-                dist = pairwise_distances(
-                    X, self._fit_X, self.effective_metric_, n_jobs=n_jobs,
-                    **self.effective_metric_params_)
 
-            neigh_ind = np.argpartition(dist, n_neighbors - 1, axis=1)
-            neigh_ind = neigh_ind[:, :n_neighbors]
-            # argpartition doesn't guarantee sorted order, so we sort again
-            neigh_ind = neigh_ind[
-                sample_range, np.argsort(dist[sample_range, neigh_ind])]
+            reduce_func = partial(self._kneighbors_reduce_func,
+                                  n_neighbors=n_neighbors,
+                                  return_distance=return_distance)
 
-            if return_distance:
-                if self.effective_metric_ == 'euclidean':
-                    result = np.sqrt(dist[sample_range, neigh_ind]), neigh_ind
-                else:
-                    result = dist[sample_range, neigh_ind], neigh_ind
-            else:
-                result = neigh_ind
+            # for efficiency, use squared euclidean distances
+            kwds = ({'squared': True} if self.effective_metric_ == 'euclidean'
+                    else self.effective_metric_params_)
+
+            result = pairwise_distances_chunked(
+                X, self._fit_X, reduce_func=reduce_func,
+                metric=self.effective_metric_, n_jobs=n_jobs,
+                **kwds)
 
         elif self._fit_method in ['ball_tree', 'kd_tree']:
             if issparse(X):
@@ -400,14 +427,15 @@ class from an array representing our data set and ask who's
                     X[s], n_neighbors, return_distance)
                 for s in gen_even_slices(X.shape[0], n_jobs)
             )
-            if return_distance:
-                dist, neigh_ind = tuple(zip(*result))
-                result = np.vstack(dist), np.vstack(neigh_ind)
-            else:
-                result = np.vstack(result)
         else:
             raise ValueError("internal: _fit_method not recognized")
 
+        if return_distance:
+            dist, neigh_ind = zip(*result)
+            result = np.vstack(dist), np.vstack(neigh_ind)
+        else:
+            result = np.vstack(result)
+
         if not query_is_train:
             return result
         else:
@@ -519,6 +547,40 @@ def kneighbors_graph(self, X=None, n_neighbors=None,
 class RadiusNeighborsMixin(object):
     """Mixin for radius-based neighbors searches"""
 
+    def _radius_neighbors_reduce_func(self, dist, start,
+                                      radius, return_distance):
+        """Reduce a chunk of distances to the nearest neighbors
+
+        Callback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`
+
+        Parameters
+        ----------
+        dist : array of shape (n_samples_chunk, n_samples)
+        start : int
+            The index in X which the first row of dist corresponds to.
+        radius : float
+        return_distance : bool
+
+        Returns
+        -------
+        dist : list of n_samples_chunk 1d arrays, optional
+            Returned only if return_distance
+        neigh : list of n_samples_chunk 1d arrays
+        """
+        neigh_ind = [np.where(d <= radius)[0] for d in dist]
+
+        if return_distance:
+            if self.effective_metric_ == 'euclidean':
+                dist = [np.sqrt(d[neigh_ind[i]])
+                        for i, d in enumerate(dist)]
+            else:
+                dist = [d[neigh_ind[i]]
+                        for i, d in enumerate(dist)]
+            results = dist, neigh_ind
+        else:
+            results = neigh_ind
+        return results
+
     def radius_neighbors(self, X=None, radius=None, return_distance=True):
         """Finds the neighbors within a given radius of a point or points.
 
@@ -597,39 +659,37 @@ class from an array representing our data set and ask who's
         if radius is None:
             radius = self.radius
 
-        n_samples = X.shape[0]
         if self._fit_method == 'brute':
             # for efficiency, use squared euclidean distances
             if self.effective_metric_ == 'euclidean':
-                dist = pairwise_distances(X, self._fit_X, 'euclidean',
-                                          n_jobs=self.n_jobs, squared=True)
                 radius *= radius
+                kwds = {'squared': True}
             else:
-                dist = pairwise_distances(X, self._fit_X,
-                                          self.effective_metric_,
-                                          n_jobs=self.n_jobs,
-                                          **self.effective_metric_params_)
-
-            neigh_ind_list = [np.where(d <= radius)[0] for d in dist]
+                kwds = self.effective_metric_params_
 
-            # See https://github.com/numpy/numpy/issues/5456
-            # if you want to understand why this is initialized this way.
-            neigh_ind = np.empty(n_samples, dtype='object')
-            neigh_ind[:] = neigh_ind_list
+            reduce_func = partial(self._radius_neighbors_reduce_func,
+                                  radius=radius,
+                                  return_distance=return_distance)
 
+            results = pairwise_distances_chunked(
+                X, self._fit_X, reduce_func=reduce_func,
+                metric=self.effective_metric_, n_jobs=self.n_jobs,
+                **kwds)
             if return_distance:
-                dist_array = np.empty(n_samples, dtype='object')
-                if self.effective_metric_ == 'euclidean':
-                    dist_list = [np.sqrt(d[neigh_ind[i]])
-                                 for i, d in enumerate(dist)]
-                else:
-                    dist_list = [d[neigh_ind[i]]
-                                 for i, d in enumerate(dist)]
-                dist_array[:] = dist_list
-
-                results = dist_array, neigh_ind
+                dist_chunks, neigh_ind_chunks = zip(*results)
+                dist_list = sum(dist_chunks, [])
+                neigh_ind_list = sum(neigh_ind_chunks, [])
+                # See https://github.com/numpy/numpy/issues/5456
+                # if you want to understand why this is initialized this way.
+                dist = np.empty(len(dist_list), dtype='object')
+                dist[:] = dist_list
+                neigh_ind = np.empty(len(neigh_ind_list), dtype='object')
+                neigh_ind[:] = neigh_ind_list
+                results = dist, neigh_ind
             else:
-                results = neigh_ind
+                neigh_ind_list = sum(results, [])
+                results = np.empty(len(neigh_ind_list), dtype='object')
+                results[:] = neigh_ind_list
 
         elif self._fit_method in ['ball_tree', 'kd_tree']:
             if issparse(X):
diff --git a/sklearn/neighbors/lof.py b/sklearn/neighbors/lof.py
index f7f1a16ebeb2..a2589f792331 100644
--- a/sklearn/neighbors/lof.py
+++ b/sklearn/neighbors/lof.py
@@ -110,7 +110,7 @@ class LocalOutlierFactor(NeighborsBase, KNeighborsMixin, UnsupervisedMixin,
     ----------
     negative_outlier_factor_ : numpy array, shape (n_samples,)
         The opposite LOF of the training samples. The higher, the more normal.
-        Inliers tend to have a LOF score close to 1 (negative_outlier_factor_
+        Inliers tend to have a LOF score close to 1 (`negative_outlier_factor_`
         close to -1), while outliers tend to have a larger LOF score.
 
         The local outlier factor (LOF) of a sample captures its
@@ -123,8 +123,8 @@ class LocalOutlierFactor(NeighborsBase, KNeighborsMixin, UnsupervisedMixin,
 
     offset_ : float
         Offset used to obtain binary labels from the raw scores.
-        Observations having a negative_outlier_factor smaller than offset_ are
-        detected as abnormal.
+        Observations having a negative_outlier_factor smaller than `offset_`
+        are detected as abnormal.
         The offset is set to -1.5 (inliers score around -1), except when a
         contamination parameter different than "auto" is provided. In that
         case, the offset is defined in such a way we obtain the expected
diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py
index 5b55a4a09c5b..c657af1f84bb 100644
--- a/sklearn/neighbors/nca.py
+++ b/sklearn/neighbors/nca.py
@@ -407,7 +407,7 @@ def _initialize(self, X, init):
         if self.warm_start and hasattr(self, 'components_'):
             transformation = self.components_
 
-        if isinstance(init, np.ndarray):
+        elif isinstance(init, np.ndarray):
             pass
         else:
             n_components = self.n_components or X.shape[1]
diff --git a/sklearn/neighbors/tests/test_ball_tree.py b/sklearn/neighbors/tests/test_ball_tree.py
index a91e4ac4edd2..de0d166fb889 100644
--- a/sklearn/neighbors/tests/test_ball_tree.py
+++ b/sklearn/neighbors/tests/test_ball_tree.py
@@ -1,12 +1,15 @@
 import pickle
+import itertools
+
 import numpy as np
+import pytest
 from numpy.testing import assert_array_almost_equal
 from sklearn.neighbors.ball_tree import (BallTree, NeighborsHeap,
                                          simultaneous_sort, kernel_norm,
                                          nodeheap_sort, DTYPE, ITYPE)
 from sklearn.neighbors.dist_metrics import DistanceMetric
 from sklearn.utils import check_random_state
-from sklearn.utils.testing import SkipTest, assert_allclose
+from sklearn.utils.testing import assert_allclose
 
 rng = np.random.RandomState(10)
 V_mahalanobis = rng.rand(3, 3)
@@ -42,60 +45,44 @@ def brute_force_neighbors(X, Y, k, metric, **kwargs):
     return dist, ind
 
 
-def test_ball_tree_query():
+@pytest.mark.parametrize('metric', METRICS)
+@pytest.mark.parametrize('k', (1, 3, 5))
+@pytest.mark.parametrize('dualtree', (True, False))
+@pytest.mark.parametrize('breadth_first', (True, False))
+def test_ball_tree_query(metric, k, dualtree, breadth_first):
     rng = check_random_state(0)
     X = rng.random_sample((40, DIMENSION))
     Y = rng.random_sample((10, DIMENSION))
 
-    def check_neighbors(dualtree, breadth_first, k, metric, kwargs):
-        bt = BallTree(X, leaf_size=1, metric=metric, **kwargs)
-        dist1, ind1 = bt.query(Y, k, dualtree=dualtree,
-                               breadth_first=breadth_first)
-        dist2, ind2 = brute_force_neighbors(X, Y, k, metric, **kwargs)
+    kwargs = METRICS[metric]
 
-        # don't check indices here: if there are any duplicate distances,
-        # the indices may not match.  Distances should not have this problem.
-        assert_array_almost_equal(dist1, dist2)
+    bt = BallTree(X, leaf_size=1, metric=metric, **kwargs)
+    dist1, ind1 = bt.query(Y, k, dualtree=dualtree,
+                           breadth_first=breadth_first)
+    dist2, ind2 = brute_force_neighbors(X, Y, k, metric, **kwargs)
 
-    for (metric, kwargs) in METRICS.items():
-        for k in (1, 3, 5):
-            for dualtree in (True, False):
-                for breadth_first in (True, False):
-                    yield (check_neighbors,
-                           dualtree, breadth_first,
-                           k, metric, kwargs)
+    # don't check indices here: if there are any duplicate distances,
+    # the indices may not match.  Distances should not have this problem.
+    assert_array_almost_equal(dist1, dist2)
 
 
-def test_ball_tree_query_boolean_metrics():
+@pytest.mark.parametrize('metric',
+                         itertools.chain(BOOLEAN_METRICS, DISCRETE_METRICS))
+def test_ball_tree_query_metrics(metric):
     rng = check_random_state(0)
-    X = rng.random_sample((40, 10)).round(0)
-    Y = rng.random_sample((10, 10)).round(0)
-    k = 5
-
-    def check_neighbors(metric):
-        bt = BallTree(X, leaf_size=1, metric=metric)
-        dist1, ind1 = bt.query(Y, k)
-        dist2, ind2 = brute_force_neighbors(X, Y, k, metric)
-        assert_array_almost_equal(dist1, dist2)
+    if metric in BOOLEAN_METRICS:
+        X = rng.random_sample((40, 10)).round(0)
+        Y = rng.random_sample((10, 10)).round(0)
+    elif metric in DISCRETE_METRICS:
+        X = (4 * rng.random_sample((40, 10))).round(0)
+        Y = (4 * rng.random_sample((10, 10))).round(0)
 
-    for metric in BOOLEAN_METRICS:
-        yield check_neighbors, metric
-
-
-def test_ball_tree_query_discrete_metrics():
-    rng = check_random_state(0)
-    X = (4 * rng.random_sample((40, 10))).round(0)
-    Y = (4 * rng.random_sample((10, 10))).round(0)
     k = 5
 
-    def check_neighbors(metric):
-        bt = BallTree(X, leaf_size=1, metric=metric)
-        dist1, ind1 = bt.query(Y, k)
-        dist2, ind2 = brute_force_neighbors(X, Y, k, metric)
-        assert_array_almost_equal(dist1, dist2)
-
-    for metric in DISCRETE_METRICS:
-        yield check_neighbors, metric
+    bt = BallTree(X, leaf_size=1, metric=metric)
+    dist1, ind1 = bt.query(Y, k)
+    dist2, ind2 = brute_force_neighbors(X, Y, k, metric)
+    assert_array_almost_equal(dist1, dist2)
 
 
 def test_ball_tree_query_radius(n_samples=100, n_features=10):
@@ -157,7 +144,21 @@ def compute_kernel_slow(Y, X, kernel, h):
         raise ValueError('kernel not recognized')
 
 
-def check_results(kernel, h, atol, rtol, breadth_first, bt, Y, dens_true):
+@pytest.mark.parametrize("kernel", ['gaussian', 'tophat', 'epanechnikov',
+                                    'exponential', 'linear', 'cosine'])
+@pytest.mark.parametrize("h", [0.01, 0.1, 1])
+@pytest.mark.parametrize("rtol", [0, 1E-5])
+@pytest.mark.parametrize("atol", [1E-6, 1E-2])
+@pytest.mark.parametrize("breadth_first", [True, False])
+def test_ball_tree_kde(kernel, h, rtol, atol, breadth_first, n_samples=100,
+                       n_features=3):
+    np.random.seed(0)
+    X = np.random.random((n_samples, n_features))
+    Y = np.random.random((n_samples, n_features))
+    bt = BallTree(X, leaf_size=10)
+
+    dens_true = compute_kernel_slow(Y, X, kernel, h)
+
     dens = bt.kernel_density(Y, h, atol=atol, rtol=rtol,
                              kernel=kernel,
                              breadth_first=breadth_first)
@@ -165,24 +166,6 @@ def check_results(kernel, h, atol, rtol, breadth_first, bt, Y, dens_true):
                     atol=atol, rtol=max(rtol, 1e-7))
 
 
-def test_ball_tree_kde(n_samples=100, n_features=3):
-    rng = check_random_state(0)
-    X = rng.random_sample((n_samples, n_features))
-    Y = rng.random_sample((n_samples, n_features))
-    bt = BallTree(X, leaf_size=10)
-
-    for kernel in ['gaussian', 'tophat', 'epanechnikov',
-                   'exponential', 'linear', 'cosine']:
-        for h in [0.01, 0.1, 1]:
-            dens_true = compute_kernel_slow(Y, X, kernel, h)
-
-            for rtol in [0, 1E-5]:
-                for atol in [1E-6, 1E-2]:
-                    for breadth_first in (True, False):
-                        yield (check_results, kernel, h, atol, rtol,
-                               breadth_first, bt, Y, dens_true)
-
-
 def test_gaussian_kde(n_samples=1000):
     # Compare gaussian KDE results to scipy.stats.gaussian_kde
     from scipy.stats import gaussian_kde
@@ -215,7 +198,7 @@ def check_two_point(r, dualtree):
         assert_array_almost_equal(counts, counts_true)
 
     for dualtree in (True, False):
-        yield check_two_point, r, dualtree
+        check_two_point(r, dualtree)
 
 
 def test_ball_tree_pickle():
@@ -246,7 +229,7 @@ def check_pickle_protocol(protocol):
         assert_array_almost_equal(dist1_pyfunc, dist2_pyfunc)
 
     for protocol in (0, 1, 2):
-        yield check_pickle_protocol, protocol
+        check_pickle_protocol(protocol)
 
 
 def test_neighbors_heap(n_pts=5, n_nbrs=10):
diff --git a/sklearn/neighbors/tests/test_dist_metrics.py b/sklearn/neighbors/tests/test_dist_metrics.py
index 23b7656cb313..f4d6dc3e74c5 100644
--- a/sklearn/neighbors/tests/test_dist_metrics.py
+++ b/sklearn/neighbors/tests/test_dist_metrics.py
@@ -4,6 +4,8 @@
 import numpy as np
 from numpy.testing import assert_array_almost_equal
 
+import pytest
+
 from scipy.spatial.distance import cdist
 from sklearn.neighbors.dist_metrics import DistanceMetric
 from sklearn.neighbors import BallTree
@@ -15,107 +17,117 @@ def dist_func(x1, x2, p):
     return np.sum((x1 - x2) ** p) ** (1. / p)
 
 
-class TestMetrics(object):
-    n1 = 20
-    n2 = 25
-    d = 4
-    zero_frac = 0.5
-    rseed = 0
-    dtype = np.float64
-    rng = check_random_state(rseed)
-    X1 = rng.random_sample((n1, d)).astype(dtype)
-    X2 = rng.random_sample((n2, d)).astype(dtype)
-
-    # make boolean arrays: ones and zeros
-    X1_bool = X1.round(0)
-    X2_bool = X2.round(0)
-
-    V = rng.random_sample((d, d))
-    VI = np.dot(V, V.T)
-
-    metrics = {'euclidean': {},
-               'cityblock': {},
-               'minkowski': dict(p=(1, 1.5, 2, 3)),
-               'chebyshev': {},
-               'seuclidean': dict(V=(rng.random_sample(d),)),
-               'wminkowski': dict(p=(1, 1.5, 3),
-                                  w=(rng.random_sample(d),)),
-               'mahalanobis': dict(VI=(VI,)),
-               'hamming': {},
-               'canberra': {},
-               'braycurtis': {}}
-
-    bool_metrics = ['matching', 'jaccard', 'dice',
-                    'kulsinski', 'rogerstanimoto', 'russellrao',
-                    'sokalmichener', 'sokalsneath']
-
-    def test_cdist(self):
-        for metric, argdict in self.metrics.items():
-            keys = argdict.keys()
-            for vals in itertools.product(*argdict.values()):
-                kwargs = dict(zip(keys, vals))
-                D_true = cdist(self.X1, self.X2, metric, **kwargs)
-                yield self.check_cdist, metric, kwargs, D_true
-
-        for metric in self.bool_metrics:
-            D_true = cdist(self.X1_bool, self.X2_bool, metric)
-            yield self.check_cdist_bool, metric, D_true
-
-    def check_cdist(self, metric, kwargs, D_true):
-        dm = DistanceMetric.get_metric(metric, **kwargs)
-        D12 = dm.pairwise(self.X1, self.X2)
-        assert_array_almost_equal(D12, D_true)
-
-    def check_cdist_bool(self, metric, D_true):
-        dm = DistanceMetric.get_metric(metric)
-        D12 = dm.pairwise(self.X1_bool, self.X2_bool)
-        assert_array_almost_equal(D12, D_true)
-
-    def test_pdist(self):
-        for metric, argdict in self.metrics.items():
-            keys = argdict.keys()
-            for vals in itertools.product(*argdict.values()):
-                kwargs = dict(zip(keys, vals))
-                D_true = cdist(self.X1, self.X1, metric, **kwargs)
-                yield self.check_pdist, metric, kwargs, D_true
-
-        for metric in self.bool_metrics:
-            D_true = cdist(self.X1_bool, self.X1_bool, metric)
-            yield self.check_pdist_bool, metric, D_true
-
-    def check_pdist(self, metric, kwargs, D_true):
-        dm = DistanceMetric.get_metric(metric, **kwargs)
-        D12 = dm.pairwise(self.X1)
-        assert_array_almost_equal(D12, D_true)
-
-    def check_pdist_bool(self, metric, D_true):
-        dm = DistanceMetric.get_metric(metric)
-        D12 = dm.pairwise(self.X1_bool)
-        assert_array_almost_equal(D12, D_true)
-
-    def test_pickle(self):
-        for metric, argdict in self.metrics.items():
-            keys = argdict.keys()
-            for vals in itertools.product(*argdict.values()):
-                kwargs = dict(zip(keys, vals))
-                yield self.check_pickle, metric, kwargs
-
-        for metric in self.bool_metrics:
-            yield self.check_pickle_bool, metric
-
-    def check_pickle_bool(self, metric):
-        dm = DistanceMetric.get_metric(metric)
-        D1 = dm.pairwise(self.X1_bool)
-        dm2 = pickle.loads(pickle.dumps(dm))
-        D2 = dm2.pairwise(self.X1_bool)
-        assert_array_almost_equal(D1, D2)
-
-    def check_pickle(self, metric, kwargs):
-        dm = DistanceMetric.get_metric(metric, **kwargs)
-        D1 = dm.pairwise(self.X1)
-        dm2 = pickle.loads(pickle.dumps(dm))
-        D2 = dm2.pairwise(self.X1)
-        assert_array_almost_equal(D1, D2)
+rng = check_random_state(0)
+d = 4
+n1 = 20
+n2 = 25
+X1 = rng.random_sample((n1, d)).astype('float64')
+X2 = rng.random_sample((n2, d)).astype('float64')
+
+# make boolean arrays: ones and zeros
+X1_bool = X1.round(0)
+X2_bool = X2.round(0)
+
+V = rng.random_sample((d, d))
+VI = np.dot(V, V.T)
+
+BOOL_METRICS = ['matching', 'jaccard', 'dice',
+                'kulsinski', 'rogerstanimoto', 'russellrao',
+                'sokalmichener', 'sokalsneath']
+
+METRICS_DEFAULT_PARAMS = {'euclidean': {},
+                          'cityblock': {},
+                          'minkowski': dict(p=(1, 1.5, 2, 3)),
+                          'chebyshev': {},
+                          'seuclidean': dict(V=(rng.random_sample(d),)),
+                          'wminkowski': dict(p=(1, 1.5, 3),
+                                             w=(rng.random_sample(d),)),
+                          'mahalanobis': dict(VI=(VI,)),
+                          'hamming': {},
+                          'canberra': {},
+                          'braycurtis': {}}
+
+
+@pytest.mark.parametrize('metric', METRICS_DEFAULT_PARAMS)
+def test_cdist(metric):
+    argdict = METRICS_DEFAULT_PARAMS[metric]
+    keys = argdict.keys()
+    for vals in itertools.product(*argdict.values()):
+        kwargs = dict(zip(keys, vals))
+        D_true = cdist(X1, X2, metric, **kwargs)
+        check_cdist(metric, kwargs, D_true)
+
+
+@pytest.mark.parametrize('metric', BOOL_METRICS)
+def test_cdist_bool_metric(metric):
+    D_true = cdist(X1_bool, X2_bool, metric)
+    check_cdist_bool(metric, D_true)
+
+
+def check_cdist(metric, kwargs, D_true):
+    dm = DistanceMetric.get_metric(metric, **kwargs)
+    D12 = dm.pairwise(X1, X2)
+    assert_array_almost_equal(D12, D_true)
+
+
+def check_cdist_bool(metric, D_true):
+    dm = DistanceMetric.get_metric(metric)
+    D12 = dm.pairwise(X1_bool, X2_bool)
+    assert_array_almost_equal(D12, D_true)
+
+
+@pytest.mark.parametrize('metric', METRICS_DEFAULT_PARAMS)
+def test_pdist(metric):
+    argdict = METRICS_DEFAULT_PARAMS[metric]
+    keys = argdict.keys()
+    for vals in itertools.product(*argdict.values()):
+        kwargs = dict(zip(keys, vals))
+        D_true = cdist(X1, X1, metric, **kwargs)
+        check_pdist(metric, kwargs, D_true)
+
+
+@pytest.mark.parametrize('metric', BOOL_METRICS)
+def test_pdist_bool_metrics(metric):
+    D_true = cdist(X1_bool, X1_bool, metric)
+    check_pdist_bool(metric, D_true)
+
+
+def check_pdist(metric, kwargs, D_true):
+    dm = DistanceMetric.get_metric(metric, **kwargs)
+    D12 = dm.pairwise(X1)
+    assert_array_almost_equal(D12, D_true)
+
+
+def check_pdist_bool(metric, D_true):
+    dm = DistanceMetric.get_metric(metric)
+    D12 = dm.pairwise(X1_bool)
+    assert_array_almost_equal(D12, D_true)
+
+
+@pytest.mark.parametrize('metric', METRICS_DEFAULT_PARAMS)
+def test_pickle(metric):
+    argdict = METRICS_DEFAULT_PARAMS[metric]
+    keys = argdict.keys()
+    for vals in itertools.product(*argdict.values()):
+        kwargs = dict(zip(keys, vals))
+        check_pickle(metric, kwargs)
+
+
+@pytest.mark.parametrize('metric', BOOL_METRICS)
+def test_pickle_bool_metrics(metric):
+    dm = DistanceMetric.get_metric(metric)
+    D1 = dm.pairwise(X1_bool)
+    dm2 = pickle.loads(pickle.dumps(dm))
+    D2 = dm2.pairwise(X1_bool)
+    assert_array_almost_equal(D1, D2)
+
+
+def check_pickle(metric, kwargs):
+    dm = DistanceMetric.get_metric(metric, **kwargs)
+    D1 = dm.pairwise(X1)
+    dm2 = pickle.loads(pickle.dumps(dm))
+    D2 = dm2.pairwise(X1)
+    assert_array_almost_equal(D1, D2)
 
 
 def test_haversine_metric():
diff --git a/sklearn/neighbors/tests/test_kd_tree.py b/sklearn/neighbors/tests/test_kd_tree.py
index e1b7cb196598..46cddc711e76 100644
--- a/sklearn/neighbors/tests/test_kd_tree.py
+++ b/sklearn/neighbors/tests/test_kd_tree.py
@@ -1,5 +1,8 @@
 import numpy as np
 from numpy.testing import assert_array_almost_equal
+
+import pytest
+
 from sklearn.neighbors.kd_tree import (KDTree, NeighborsHeap,
                                        simultaneous_sort, kernel_norm,
                                        nodeheap_sort, DTYPE, ITYPE)
@@ -37,18 +40,17 @@ def check_neighbors(dualtree, breadth_first, k, metric, X, Y, kwargs):
     assert_array_almost_equal(dist1, dist2)
 
 
-def test_kd_tree_query():
+@pytest.mark.parametrize('metric', METRICS)
+@pytest.mark.parametrize('k', (1, 3, 5))
+@pytest.mark.parametrize('dualtree', (True, False))
+@pytest.mark.parametrize('breadth_first', (True, False))
+def test_kd_tree_query(metric, k, dualtree, breadth_first):
     rng = check_random_state(0)
     X = rng.random_sample((40, DIMENSION))
     Y = rng.random_sample((10, DIMENSION))
 
-    for (metric, kwargs) in METRICS.items():
-        for k in (1, 3, 5):
-            for dualtree in (True, False):
-                for breadth_first in (True, False):
-                    yield (check_neighbors,
-                           dualtree, breadth_first,
-                           k, metric, X, Y, kwargs)
+    kwargs = METRICS[metric]
+    check_neighbors(dualtree, breadth_first, k, metric, X, Y, kwargs)
 
 
 def test_kd_tree_query_radius(n_samples=100, n_features=10):
@@ -118,22 +120,24 @@ def check_results(kernel, h, atol, rtol, breadth_first, Y, kdt, dens_true):
                     rtol=max(rtol, 1e-7))
 
 
-def test_kd_tree_kde(n_samples=100, n_features=3):
+@pytest.mark.parametrize('kernel',
+                         ['gaussian', 'tophat', 'epanechnikov',
+                          'exponential', 'linear', 'cosine'])
+@pytest.mark.parametrize('h', [0.01, 0.1, 1])
+def test_kd_tree_kde(kernel, h):
+    n_samples, n_features = (100, 3)
     rng = check_random_state(0)
     X = rng.random_sample((n_samples, n_features))
     Y = rng.random_sample((n_samples, n_features))
     kdt = KDTree(X, leaf_size=10)
 
-    for kernel in ['gaussian', 'tophat', 'epanechnikov',
-                   'exponential', 'linear', 'cosine']:
-        for h in [0.01, 0.1, 1]:
-            dens_true = compute_kernel_slow(Y, X, kernel, h)
+    dens_true = compute_kernel_slow(Y, X, kernel, h)
 
-            for rtol in [0, 1E-5]:
-                for atol in [1E-6, 1E-2]:
-                    for breadth_first in (True, False):
-                        yield (check_results, kernel, h, atol, rtol,
-                               breadth_first, Y, kdt, dens_true)
+    for rtol in [0, 1E-5]:
+        for atol in [1E-6, 1E-2]:
+            for breadth_first in (True, False):
+                check_results(kernel, h, atol, rtol,
+                              breadth_first, Y, kdt, dens_true)
 
 
 def test_gaussian_kde(n_samples=1000):
@@ -153,7 +157,9 @@ def test_gaussian_kde(n_samples=1000):
         assert_array_almost_equal(dens_kdt, dens_gkde, decimal=3)
 
 
-def test_kd_tree_two_point(n_samples=100, n_features=3):
+@pytest.mark.parametrize('dualtree', (True, False))
+def test_kd_tree_two_point(dualtree):
+    n_samples, n_features = (100, 3)
     rng = check_random_state(0)
     X = rng.random_sample((n_samples, n_features))
     Y = rng.random_sample((n_samples, n_features))
@@ -163,15 +169,12 @@ def test_kd_tree_two_point(n_samples=100, n_features=3):
     D = DistanceMetric.get_metric("euclidean").pairwise(Y, X)
     counts_true = [(D <= ri).sum() for ri in r]
 
-    def check_two_point(r, dualtree):
-        counts = kdt.two_point_correlation(Y, r=r, dualtree=dualtree)
-        assert_array_almost_equal(counts, counts_true)
-
-    for dualtree in (True, False):
-        yield check_two_point, r, dualtree
+    counts = kdt.two_point_correlation(Y, r=r, dualtree=dualtree)
+    assert_array_almost_equal(counts, counts_true)
 
 
-def test_kd_tree_pickle():
+@pytest.mark.parametrize('protocol', (0, 1, 2))
+def test_kd_tree_pickle(protocol):
     import pickle
     rng = check_random_state(0)
     X = rng.random_sample((10, 3))
@@ -185,8 +188,7 @@ def check_pickle_protocol(protocol):
         assert_array_almost_equal(ind1, ind2)
         assert_array_almost_equal(dist1, dist2)
 
-    for protocol in (0, 1, 2):
-        yield check_pickle_protocol, protocol
+    check_pickle_protocol(protocol)
 
 
 def test_neighbors_heap(n_pts=5, n_nbrs=10):
diff --git a/sklearn/neighbors/tests/test_kde.py b/sklearn/neighbors/tests/test_kde.py
index 60f294a3df0a..caffb662608e 100644
--- a/sklearn/neighbors/tests/test_kde.py
+++ b/sklearn/neighbors/tests/test_kde.py
@@ -1,4 +1,7 @@
 import numpy as np
+
+import pytest
+
 from sklearn.utils.testing import (assert_allclose, assert_raises,
                                    assert_equal)
 from sklearn.neighbors import KernelDensity, KDTree, NearestNeighbors
@@ -40,21 +43,25 @@ def check_results(kernel, bandwidth, atol, rtol, X, Y, dens_true):
                     atol=atol, rtol=max(1E-7, rtol))
 
 
-def test_kernel_density(n_samples=100, n_features=3):
+@pytest.mark.parametrize(
+        'kernel',
+        ['gaussian', 'tophat', 'epanechnikov',
+         'exponential', 'linear', 'cosine'])
+@pytest.mark.parametrize('bandwidth', [0.01, 0.1, 1])
+def test_kernel_density(kernel, bandwidth):
+    n_samples, n_features = (100, 3)
+
     rng = np.random.RandomState(0)
     X = rng.randn(n_samples, n_features)
     Y = rng.randn(n_samples, n_features)
 
-    for kernel in ['gaussian', 'tophat', 'epanechnikov',
-                   'exponential', 'linear', 'cosine']:
-        for bandwidth in [0.01, 0.1, 1]:
-            dens_true = compute_kernel_slow(Y, X, kernel, bandwidth)
+    dens_true = compute_kernel_slow(Y, X, kernel, bandwidth)
 
-            for rtol in [0, 1E-5]:
-                for atol in [1E-6, 1E-2]:
-                    for breadth_first in (True, False):
-                        yield (check_results, kernel, bandwidth, atol, rtol,
-                               X, Y, dens_true)
+    for rtol in [0, 1E-5]:
+        for atol in [1E-6, 1E-2]:
+            for breadth_first in (True, False):
+                check_results(kernel, bandwidth, atol, rtol,
+                              X, Y, dens_true)
 
 
 def test_kernel_density_sampling(n_samples=100, n_features=3):
@@ -91,23 +98,24 @@ def test_kernel_density_sampling(n_samples=100, n_features=3):
     assert_equal(kde.sample().shape, (1, 1))
 
 
-def test_kde_algorithm_metric_choice():
+@pytest.mark.parametrize('algorithm', ['auto', 'ball_tree', 'kd_tree'])
+@pytest.mark.parametrize('metric',
+                         ['euclidean', 'minkowski', 'manhattan',
+                          'chebyshev', 'haversine'])
+def test_kde_algorithm_metric_choice(algorithm, metric):
     # Smoke test for various metrics and algorithms
     rng = np.random.RandomState(0)
     X = rng.randn(10, 2)    # 2 features required for haversine dist.
     Y = rng.randn(10, 2)
 
-    for algorithm in ['auto', 'ball_tree', 'kd_tree']:
-        for metric in ['euclidean', 'minkowski', 'manhattan',
-                       'chebyshev', 'haversine']:
-            if algorithm == 'kd_tree' and metric not in KDTree.valid_metrics:
-                assert_raises(ValueError, KernelDensity,
-                              algorithm=algorithm, metric=metric)
-            else:
-                kde = KernelDensity(algorithm=algorithm, metric=metric)
-                kde.fit(X)
-                y_dens = kde.score_samples(Y)
-                assert_equal(y_dens.shape, Y.shape[:1])
+    if algorithm == 'kd_tree' and metric not in KDTree.valid_metrics:
+        assert_raises(ValueError, KernelDensity,
+                      algorithm=algorithm, metric=metric)
+    else:
+        kde = KernelDensity(algorithm=algorithm, metric=metric)
+        kde.fit(X)
+        y_dens = kde.score_samples(Y)
+        assert_equal(y_dens.shape, Y.shape[:1])
 
 
 def test_kde_score(n_samples=100, n_features=3):
diff --git a/sklearn/neighbors/tests/test_nca.py b/sklearn/neighbors/tests/test_nca.py
index 53e331bcad88..6cc4e059d82d 100644
--- a/sklearn/neighbors/tests/test_nca.py
+++ b/sklearn/neighbors/tests/test_nca.py
@@ -274,20 +274,16 @@ def test_warm_start_effectiveness():
     # A 1-iteration second fit on same data should give almost same result
     # with warm starting, and quite different result without warm starting.
 
-    X, y = make_classification(n_samples=30, n_features=5,
-                               n_redundant=0, random_state=0)
-    n_iter = 10
+    X, y = load_iris(return_X_y=True)
 
-    nca_warm = NeighborhoodComponentsAnalysis(warm_start=True,
-                                              max_iter=n_iter, random_state=0)
+    nca_warm = NeighborhoodComponentsAnalysis(warm_start=True, random_state=0)
     nca_warm.fit(X, y)
     transformation_warm = nca_warm.components_
     nca_warm.max_iter = 1
     nca_warm.fit(X, y)
     transformation_warm_plus_one = nca_warm.components_
 
-    nca_cold = NeighborhoodComponentsAnalysis(warm_start=False,
-                                              max_iter=n_iter, random_state=0)
+    nca_cold = NeighborhoodComponentsAnalysis(warm_start=False, random_state=0)
     nca_cold.fit(X, y)
     transformation_cold = nca_cold.components_
     nca_cold.max_iter = 1
@@ -299,7 +295,7 @@ def test_warm_start_effectiveness():
     diff_cold = np.sum(np.abs(transformation_cold_plus_one -
                               transformation_cold))
 
-    assert_true(diff_warm < 2.0,
+    assert_true(diff_warm < 3.0,
                 "Transformer changed significantly after one iteration even "
                 "though it was warm-started.")
 
diff --git a/sklearn/neighbors/tests/test_neighbors.py b/sklearn/neighbors/tests/test_neighbors.py
index a95a906ad3cb..e1acaa4c6f13 100644
--- a/sklearn/neighbors/tests/test_neighbors.py
+++ b/sklearn/neighbors/tests/test_neighbors.py
@@ -4,6 +4,8 @@
 from scipy.sparse import (bsr_matrix, coo_matrix, csc_matrix, csr_matrix,
                           dok_matrix, lil_matrix, issparse)
 
+import pytest
+
 from sklearn import metrics
 from sklearn import neighbors, datasets
 from sklearn.exceptions import DataConversionWarning
@@ -1260,63 +1262,57 @@ def test_include_self_neighbors_graph():
     assert_array_equal(rng_not_self, [[0., 1.], [1., 0.]])
 
 
-def test_same_knn_parallel():
+@pytest.mark.parametrize('algorithm', ALGORITHMS)
+def test_same_knn_parallel(algorithm):
     X, y = datasets.make_classification(n_samples=30, n_features=5,
                                         n_redundant=0, random_state=0)
     X_train, X_test, y_train, y_test = train_test_split(X, y)
 
-    def check_same_knn_parallel(algorithm):
-        clf = neighbors.KNeighborsClassifier(n_neighbors=3,
-                                             algorithm=algorithm)
-        clf.fit(X_train, y_train)
-        y = clf.predict(X_test)
-        dist, ind = clf.kneighbors(X_test)
-        graph = clf.kneighbors_graph(X_test, mode='distance').toarray()
-
-        clf.set_params(n_jobs=3)
-        clf.fit(X_train, y_train)
-        y_parallel = clf.predict(X_test)
-        dist_parallel, ind_parallel = clf.kneighbors(X_test)
-        graph_parallel = \
-            clf.kneighbors_graph(X_test, mode='distance').toarray()
-
-        assert_array_equal(y, y_parallel)
-        assert_array_almost_equal(dist, dist_parallel)
-        assert_array_equal(ind, ind_parallel)
-        assert_array_almost_equal(graph, graph_parallel)
+    clf = neighbors.KNeighborsClassifier(n_neighbors=3,
+                                         algorithm=algorithm)
+    clf.fit(X_train, y_train)
+    y = clf.predict(X_test)
+    dist, ind = clf.kneighbors(X_test)
+    graph = clf.kneighbors_graph(X_test, mode='distance').toarray()
 
-    for algorithm in ALGORITHMS:
-        yield check_same_knn_parallel, algorithm
+    clf.set_params(n_jobs=3)
+    clf.fit(X_train, y_train)
+    y_parallel = clf.predict(X_test)
+    dist_parallel, ind_parallel = clf.kneighbors(X_test)
+    graph_parallel = \
+        clf.kneighbors_graph(X_test, mode='distance').toarray()
+
+    assert_array_equal(y, y_parallel)
+    assert_array_almost_equal(dist, dist_parallel)
+    assert_array_equal(ind, ind_parallel)
+    assert_array_almost_equal(graph, graph_parallel)
 
 
-def test_same_radius_neighbors_parallel():
+@pytest.mark.parametrize('algorithm', ALGORITHMS)
+def test_same_radius_neighbors_parallel(algorithm):
     X, y = datasets.make_classification(n_samples=30, n_features=5,
                                         n_redundant=0, random_state=0)
     X_train, X_test, y_train, y_test = train_test_split(X, y)
 
-    def check_same_radius_neighbors_parallel(algorithm):
-        clf = neighbors.RadiusNeighborsClassifier(radius=10,
-                                                  algorithm=algorithm)
-        clf.fit(X_train, y_train)
-        y = clf.predict(X_test)
-        dist, ind = clf.radius_neighbors(X_test)
-        graph = clf.radius_neighbors_graph(X_test, mode='distance').toarray()
-
-        clf.set_params(n_jobs=3)
-        clf.fit(X_train, y_train)
-        y_parallel = clf.predict(X_test)
-        dist_parallel, ind_parallel = clf.radius_neighbors(X_test)
-        graph_parallel = \
-            clf.radius_neighbors_graph(X_test, mode='distance').toarray()
-
-        assert_array_equal(y, y_parallel)
-        for i in range(len(dist)):
-            assert_array_almost_equal(dist[i], dist_parallel[i])
-            assert_array_equal(ind[i], ind_parallel[i])
-        assert_array_almost_equal(graph, graph_parallel)
-
-    for algorithm in ALGORITHMS:
-        yield check_same_radius_neighbors_parallel, algorithm
+    clf = neighbors.RadiusNeighborsClassifier(radius=10,
+                                              algorithm=algorithm)
+    clf.fit(X_train, y_train)
+    y = clf.predict(X_test)
+    dist, ind = clf.radius_neighbors(X_test)
+    graph = clf.radius_neighbors_graph(X_test, mode='distance').toarray()
+
+    clf.set_params(n_jobs=3)
+    clf.fit(X_train, y_train)
+    y_parallel = clf.predict(X_test)
+    dist_parallel, ind_parallel = clf.radius_neighbors(X_test)
+    graph_parallel = \
+        clf.radius_neighbors_graph(X_test, mode='distance').toarray()
+
+    assert_array_equal(y, y_parallel)
+    for i in range(len(dist)):
+        assert_array_almost_equal(dist[i], dist_parallel[i])
+        assert_array_equal(ind[i], ind_parallel[i])
+    assert_array_almost_equal(graph, graph_parallel)
 
 
 def test_dtype_convert():
diff --git a/sklearn/neighbors/tests/test_quad_tree.py b/sklearn/neighbors/tests/test_quad_tree.py
index 6cfa4bcc562e..156bfc232a55 100644
--- a/sklearn/neighbors/tests/test_quad_tree.py
+++ b/sklearn/neighbors/tests/test_quad_tree.py
@@ -1,5 +1,8 @@
 import pickle
 import numpy as np
+
+import pytest
+
 from sklearn.neighbors.quad_tree import _QuadTree
 from sklearn.utils import check_random_state
 
@@ -58,50 +61,43 @@ def test_quadtree_similar_point():
         tree._check_coherence()
 
 
-def test_quad_tree_pickle():
+@pytest.mark.parametrize('n_dimensions', (2, 3))
+@pytest.mark.parametrize('protocol', (0, 1, 2))
+def test_quad_tree_pickle(n_dimensions, protocol):
     rng = check_random_state(0)
 
-    for n_dimensions in (2, 3):
-        X = rng.random_sample((10, n_dimensions))
-
-        tree = _QuadTree(n_dimensions=n_dimensions, verbose=0)
-        tree.build_tree(X)
+    X = rng.random_sample((10, n_dimensions))
 
-        def check_pickle_protocol(protocol):
-            s = pickle.dumps(tree, protocol=protocol)
-            bt2 = pickle.loads(s)
+    tree = _QuadTree(n_dimensions=n_dimensions, verbose=0)
+    tree.build_tree(X)
 
-            for x in X:
-                cell_x_tree = tree.get_cell(x)
-                cell_x_bt2 = bt2.get_cell(x)
-                assert cell_x_tree == cell_x_bt2
+    s = pickle.dumps(tree, protocol=protocol)
+    bt2 = pickle.loads(s)
 
-        for protocol in (0, 1, 2):
-            yield check_pickle_protocol, protocol
+    for x in X:
+        cell_x_tree = tree.get_cell(x)
+        cell_x_bt2 = bt2.get_cell(x)
+        assert cell_x_tree == cell_x_bt2
 
 
-def test_qt_insert_duplicate():
+@pytest.mark.parametrize('n_dimensions', (2, 3))
+def test_qt_insert_duplicate(n_dimensions):
     rng = check_random_state(0)
 
-    def check_insert_duplicate(n_dimensions=2):
-
-        X = rng.random_sample((10, n_dimensions))
-        Xd = np.r_[X, X[:5]]
-        tree = _QuadTree(n_dimensions=n_dimensions, verbose=0)
-        tree.build_tree(Xd)
-
-        cumulative_size = tree.cumulative_size
-        leafs = tree.leafs
+    X = rng.random_sample((10, n_dimensions))
+    Xd = np.r_[X, X[:5]]
+    tree = _QuadTree(n_dimensions=n_dimensions, verbose=0)
+    tree.build_tree(Xd)
 
-        # Assert that the first 5 are indeed duplicated and that the next
-        # ones are single point leaf
-        for i, x in enumerate(X):
-            cell_id = tree.get_cell(x)
-            assert leafs[cell_id]
-            assert cumulative_size[cell_id] == 1 + (i < 5)
+    cumulative_size = tree.cumulative_size
+    leafs = tree.leafs
 
-    for n_dimensions in (2, 3):
-        yield check_insert_duplicate, n_dimensions
+    # Assert that the first 5 are indeed duplicated and that the next
+    # ones are single point leaf
+    for i, x in enumerate(X):
+        cell_id = tree.get_cell(x)
+        assert leafs[cell_id]
+        assert cumulative_size[cell_id] == 1 + (i < 5)
 
 
 def test_summarize():
diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py
index bdb839a11a3b..1e99dd54615a 100644
--- a/sklearn/pipeline.py
+++ b/sklearn/pipeline.py
@@ -644,12 +644,12 @@ class FeatureUnion(_BaseComposition, TransformerMixin):
     --------
     >>> from sklearn.pipeline import FeatureUnion
     >>> from sklearn.decomposition import PCA, TruncatedSVD
-    >>> union = FeatureUnion([("pca", PCA(n_components=2)),
+    >>> union = FeatureUnion([("pca", PCA(n_components=1)),
     ...                       ("svd", TruncatedSVD(n_components=2))])
     >>> X = [[0., 1., 3], [2., 2., 5]]
     >>> union.fit_transform(X)    # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
-    array([[ 1.5       ,  0.        ,  3.0...,  0.8...],
-           [-1.5       ,  0.        ,  5.7..., -0.4...]])
+    array([[ 1.5       ,  3.0...,  0.8...],
+           [-1.5       ,  5.7..., -0.4...]])
     """
     def __init__(self, transformer_list, n_jobs=1, transformer_weights=None):
         self.transformer_list = transformer_list
diff --git a/sklearn/preprocessing/__init__.py b/sklearn/preprocessing/__init__.py
index ba0884613c12..85bade9b81c1 100644
--- a/sklearn/preprocessing/__init__.py
+++ b/sklearn/preprocessing/__init__.py
@@ -22,11 +22,12 @@
 from .data import minmax_scale
 from .data import quantile_transform
 from .data import power_transform
-from .data import OneHotEncoder
 from .data import PowerTransformer
-from .data import CategoricalEncoder
 from .data import PolynomialFeatures
 
+from ._encoders import OneHotEncoder
+from ._encoders import OrdinalEncoder
+
 from .label import label_binarize
 from .label import LabelBinarizer
 from .label import LabelEncoder
@@ -34,6 +35,8 @@
 
 from .imputation import Imputer
 
+# stub, remove in version 0.21
+from .data import CategoricalEncoder  # noqa
 
 __all__ = [
     'Binarizer',
@@ -48,7 +51,7 @@
     'QuantileTransformer',
     'Normalizer',
     'OneHotEncoder',
-    'CategoricalEncoder',
+    'OrdinalEncoder',
     'PowerTransformer',
     'RobustScaler',
     'StandardScaler',
diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
new file mode 100644
index 000000000000..b2aca044e036
--- /dev/null
+++ b/sklearn/preprocessing/_encoders.py
@@ -0,0 +1,835 @@
+# Authors: Andreas Mueller <amueller@ais.uni-bonn.de>
+#          Joris Van den Bossche <jorisvandenbossche@gmail.com>
+# License: BSD 3 clause
+
+from __future__ import division
+
+import numbers
+import warnings
+
+import numpy as np
+from scipy import sparse
+
+from ..base import BaseEstimator, TransformerMixin
+from ..externals import six
+from ..utils import check_array
+from ..utils import deprecated
+from ..utils.fixes import _argmax
+from ..utils.validation import check_is_fitted, FLOAT_DTYPES
+from .label import LabelEncoder
+
+
+range = six.moves.range
+
+
+__all__ = [
+    'OneHotEncoder',
+    'OrdinalEncoder'
+]
+
+
+def _transform_selected(X, transform, dtype, selected="all", copy=True):
+    """Apply a transform function to portion of selected features
+
+    Parameters
+    ----------
+    X : {array-like, sparse matrix}, shape [n_samples, n_features]
+        Dense array or sparse matrix.
+
+    transform : callable
+        A callable transform(X) -> X_transformed
+
+    dtype : number type
+        Desired dtype of output.
+
+    copy : boolean, optional
+        Copy X even if it could be avoided.
+
+    selected: "all" or array of indices or mask
+        Specify which features to apply the transform to.
+
+    Returns
+    -------
+    X : array or sparse matrix, shape=(n_samples, n_features_new)
+    """
+    X = check_array(X, accept_sparse='csc', copy=copy, dtype=FLOAT_DTYPES)
+
+    if isinstance(selected, six.string_types) and selected == "all":
+        return transform(X)
+
+    if len(selected) == 0:
+        return X
+
+    n_features = X.shape[1]
+    ind = np.arange(n_features)
+    sel = np.zeros(n_features, dtype=bool)
+    sel[np.asarray(selected)] = True
+    not_sel = np.logical_not(sel)
+    n_selected = np.sum(sel)
+
+    if n_selected == 0:
+        # No features selected.
+        return X
+    elif n_selected == n_features:
+        # All features selected.
+        return transform(X)
+    else:
+        X_sel = transform(X[:, ind[sel]])
+        # The columns of X which are not transformed need
+        # to be casted to the desire dtype before concatenation.
+        # Otherwise, the stacking will cast to the higher-precision dtype.
+        X_not_sel = X[:, ind[not_sel]].astype(dtype)
+
+        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):
+            return sparse.hstack((X_sel, X_not_sel))
+        else:
+            return np.hstack((X_sel, X_not_sel))
+
+
+class _BaseEncoder(BaseEstimator, TransformerMixin):
+    """
+    Base class for encoders that includes the code to categorize and
+    transform the input features.
+
+    """
+
+    def _fit(self, X, handle_unknown='error'):
+
+        X_temp = check_array(X, dtype=None)
+        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+            X = check_array(X, dtype=np.object)
+        else:
+            X = X_temp
+
+        n_samples, n_features = X.shape
+
+        if self._categories != 'auto':
+            for cats in self._categories:
+                if not np.all(np.sort(cats) == np.array(cats)):
+                    raise ValueError("Unsorted categories are not yet "
+                                     "supported")
+            if len(self._categories) != n_features:
+                raise ValueError("Shape mismatch: if n_values is an array,"
+                                 " it has to be of shape (n_features,).")
+
+        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]
+
+        for i in range(n_features):
+            le = self._label_encoders_[i]
+            Xi = X[:, i]
+            if self._categories == 'auto':
+                le.fit(Xi)
+            else:
+                if handle_unknown == 'error':
+                    valid_mask = np.in1d(Xi, self._categories[i])
+                    if not np.all(valid_mask):
+                        diff = np.unique(Xi[~valid_mask])
+                        msg = ("Found unknown categories {0} in column {1}"
+                               " during fit".format(diff, i))
+                        raise ValueError(msg)
+                le.classes_ = np.array(self._categories[i])
+
+        self.categories_ = [le.classes_ for le in self._label_encoders_]
+
+    def _transform(self, X, handle_unknown='error'):
+
+        X_temp = check_array(X, dtype=None)
+        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+            X = check_array(X, dtype=np.object)
+        else:
+            X = X_temp
+
+        _, n_features = X.shape
+        X_int = np.zeros_like(X, dtype=np.int)
+        X_mask = np.ones_like(X, dtype=np.bool)
+
+        for i in range(n_features):
+            Xi = X[:, i]
+            valid_mask = np.in1d(Xi, self.categories_[i])
+
+            if not np.all(valid_mask):
+                if handle_unknown == 'error':
+                    diff = np.unique(X[~valid_mask, i])
+                    msg = ("Found unknown categories {0} in column {1}"
+                           " during transform".format(diff, i))
+                    raise ValueError(msg)
+                else:
+                    # Set the problematic rows to an acceptable value and
+                    # continue `The rows are marked `X_mask` and will be
+                    # removed later.
+                    X_mask[:, i] = valid_mask
+                    Xi = Xi.copy()
+                    Xi[~valid_mask] = self.categories_[i][0]
+            X_int[:, i] = self._label_encoders_[i].transform(Xi)
+
+        return X_int, X_mask
+
+
+class OneHotEncoder(_BaseEncoder):
+    """Encode categorical integer features as a one-hot numeric array.
+
+    The input to this transformer should be an array-like of integers or
+    strings, denoting the values taken on by categorical (discrete) features.
+    The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')
+    encoding scheme. This creates a binary column for each category and
+    returns a sparse matrix or dense array.
+
+    By default, the encoder derives the categories based on the unique values
+    in each feature. Alternatively, you can also specify the `categories`
+    manually.
+    The OneHotEncoder previously assumed that the input features take on
+    values in the range [0, max(values)). This behaviour is deprecated.
+
+    This encoding is needed for feeding categorical data to many scikit-learn
+    estimators, notably linear models and SVMs with the standard kernels.
+
+    Note: a one-hot encoding of y labels should use a LabelBinarizer
+    instead.
+
+    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.
+
+    Parameters
+    ----------
+    categories : 'auto' or a list of lists/arrays of values.
+        Categories (unique values) per feature:
+
+        - 'auto' : Determine categories automatically from the training data.
+        - list : ``categories[i]`` holds the categories expected in the ith
+          column. The passed categories must be sorted and should not mix
+          strings and numeric values.
+
+        The used categories can be found in the ``categories_`` attribute.
+
+    sparse : boolean, default=True
+        Will return sparse matrix if set True else will return an array.
+
+    dtype : number type, default=np.float
+        Desired dtype of output.
+
+    handle_unknown : 'error' (default) or 'ignore'
+        Whether to raise an error or ignore if an unknown categorical feature
+        is present during transform (default is to raise). When this parameter
+        is set to 'ignore' and an unknown category is encountered during
+        transform, the resulting one-hot encoded columns for this feature
+        will be all zeros. In the inverse transform, an unknown category
+        will be denoted as None.
+
+    n_values : 'auto', int or array of ints
+        Number of values per feature.
+
+        - 'auto' : determine value range from training data.
+        - int : number of categorical values per feature.
+                Each feature value should be in ``range(n_values)``
+        - array : ``n_values[i]`` is the number of categorical values in
+                  ``X[:, i]``. Each feature value should be
+                  in ``range(n_values[i])``
+
+        .. deprecated:: 0.20
+            The `n_values` keyword was deprecated in version 0.20 and will
+            be removed in 0.22. Use `categories` instead.
+
+    categorical_features : "all" or array of indices or mask
+        Specify what features are treated as categorical.
+
+        - 'all' (default): All features are treated as categorical.
+        - array of indices: Array of categorical feature indices.
+        - mask: Array of length n_features and with dtype=bool.
+
+        Non-categorical features are always stacked to the right of the matrix.
+
+        .. deprecated:: 0.20
+            The `categorical_features` keyword was deprecated in version
+            0.20 and will be removed in 0.22.
+            You can use the ``ColumnTransformer`` instead.
+
+    Attributes
+    ----------
+    categories_ : list of arrays
+        The categories of each feature determined during fitting
+        (in order of the features in X and corresponding with the output
+        of ``transform``).
+
+    active_features_ : array
+        Indices for active features, meaning values that actually occur
+        in the training set. Only available when n_values is ``'auto'``.
+
+        .. deprecated:: 0.20
+            The `active_features_` attribute was deprecated in version
+            0.20 and will be removed in 0.22.
+
+    feature_indices_ : array of shape (n_features,)
+        Indices to feature ranges.
+        Feature ``i`` in the original data is mapped to features
+        from ``feature_indices_[i]`` to ``feature_indices_[i+1]``
+        (and then potentially masked by `active_features_` afterwards)
+
+        .. deprecated:: 0.20
+            The `feature_indices_` attribute was deprecated in version
+            0.20 and will be removed in 0.22.
+
+    n_values_ : array of shape (n_features,)
+        Maximum number of values per feature.
+
+        .. deprecated:: 0.20
+            The `n_values_` attribute was deprecated in version
+            0.20 and will be removed in 0.22.
+
+    Examples
+    --------
+    Given a dataset with two features, we let the encoder find the unique
+    values per feature and transform the data to a binary one-hot encoding.
+
+    >>> from sklearn.preprocessing import OneHotEncoder
+    >>> enc = OneHotEncoder(handle_unknown='ignore')
+    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]
+    >>> enc.fit(X)
+    ... # doctest: +ELLIPSIS
+    OneHotEncoder(categorical_features=None, categories=None,
+           dtype=<... 'numpy.float64'>, handle_unknown='ignore',
+           n_values=None, sparse=True)
+
+    >>> enc.categories_
+    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
+    >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()
+    array([[1., 0., 1., 0., 0.],
+           [0., 1., 0., 0., 0.]])
+    >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])
+    array([['Male', 1],
+           [None, 2]], dtype=object)
+
+    See also
+    --------
+    sklearn.preprocessing.OrdinalEncoder : performs an ordinal (integer)
+      encoding of the categorical features.
+    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of
+      dictionary items (also handles string-valued features).
+    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot
+      encoding of dictionary items or strings.
+    sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all
+      fashion.
+    sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of
+      iterables and a multilabel format, e.g. a (samples x classes) binary
+      matrix indicating the presence of a class label.
+    """
+
+    def __init__(self, n_values=None, categorical_features=None,
+                 categories=None, sparse=True, dtype=np.float64,
+                 handle_unknown='error'):
+        self.categories = categories
+        self.sparse = sparse
+        self.dtype = dtype
+        self.handle_unknown = handle_unknown
+        self.n_values = n_values
+        self.categorical_features = categorical_features
+
+    # Deprecated attributes
+
+    @property
+    @deprecated("The 'active_features_' attribute was deprecated in version "
+                "0.20 and will be removed 0.22.")
+    def active_features_(self):
+        check_is_fitted(self, 'categories_')
+        return self._active_features_
+
+    @property
+    @deprecated("The 'feature_indices_' attribute was deprecated in version "
+                "0.20 and will be removed 0.22.")
+    def feature_indices_(self):
+        check_is_fitted(self, 'categories_')
+        return self._feature_indices_
+
+    @property
+    @deprecated("The 'n_values_' attribute was deprecated in version "
+                "0.20 and will be removed 0.22.")
+    def n_values_(self):
+        check_is_fitted(self, 'categories_')
+        return self._n_values_
+
+    def _handle_deprecations(self, X):
+
+        # internal version of the attributes to handle deprecations
+        self._categories = getattr(self, '_categories', None)
+        self._categorical_features = getattr(self, '_categorical_features',
+                                             None)
+
+        # user manually set the categories or second fit -> never legacy mode
+        if self.categories is not None or self._categories is not None:
+            self._legacy_mode = False
+            if self.categories is not None:
+                self._categories = self.categories
+
+        # categories not set -> infer if we need legacy mode or not
+        elif self.n_values is not None and self.n_values != 'auto':
+            msg = (
+                "Passing 'n_values' is deprecated in version 0.20 and will be "
+                "removed in 0.22. You can use the 'categories' keyword "
+                "instead. 'n_values=n' corresponds to 'categories=[range(n)]'."
+            )
+            warnings.warn(msg, DeprecationWarning)
+            self._legacy_mode = True
+
+        else:  # n_values = 'auto'
+            if self.handle_unknown == 'ignore':
+                # no change in behaviour, no need to raise deprecation warning
+                self._legacy_mode = False
+                self._categories = 'auto'
+                if self.n_values == 'auto':
+                    # user manually specified this
+                    msg = (
+                        "Passing 'n_values' is deprecated in version 0.20 and "
+                        "will be removed in 0.22. n_values='auto' can be "
+                        "replaced with categories='auto'."
+                    )
+                    warnings.warn(msg, DeprecationWarning)
+            else:
+
+                # check if we have integer or categorical input
+                try:
+                    X = check_array(X, dtype=np.int)
+                except ValueError:
+                    self._legacy_mode = False
+                    self._categories = 'auto'
+                else:
+                    msg = (
+                        "The handling of integer data will change in version "
+                        "0.22. Currently, the categories are determined "
+                        "based on the range [0, max(values)], while in the "
+                        "future they will be determined based on the unique "
+                        "values.\nIf you want the future behaviour and "
+                        "silence this warning, you can specify "
+                        "\"categories='auto'\".\n"
+                        "In case you used a LabelEncoder before this "
+                        "OneHotEncoder to convert the categories to integers, "
+                        "then you can now use the OneHotEncoder directly."
+                    )
+                    warnings.warn(msg, FutureWarning)
+                    self._legacy_mode = True
+                    self.n_values = 'auto'
+
+        # if user specified categorical_features -> always use legacy mode
+        if self.categorical_features is not None:
+            if (isinstance(self.categorical_features, six.string_types)
+                    and self.categorical_features == 'all'):
+                warnings.warn(
+                    "The 'categorical_features' keyword is deprecated in "
+                    "version 0.20 and will be removed in 0.22. The passed "
+                    "value of 'all' is the default and can simply be removed.",
+                    DeprecationWarning)
+            else:
+                if self.categories is not None:
+                    raise ValueError(
+                        "The 'categorical_features' keyword is deprecated, "
+                        "and cannot be used together with specifying "
+                        "'categories'.")
+                warnings.warn(
+                    "The 'categorical_features' keyword is deprecated in "
+                    "version 0.20 and will be removed in 0.22. You can "
+                    "use the ColumnTransformer instead.", DeprecationWarning)
+                self._legacy_mode = True
+            self._categorical_features = self.categorical_features
+        else:
+            self._categorical_features = 'all'
+
+    def fit(self, X, y=None):
+        """Fit OneHotEncoder to X.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_feature]
+            The data to determine the categories of each feature.
+
+        Returns
+        -------
+        self
+        """
+        if self.handle_unknown not in ('error', 'ignore'):
+            msg = ("handle_unknown should be either 'error' or 'ignore', "
+                   "got {0}.".format(self.handle_unknown))
+            raise ValueError(msg)
+
+        self._handle_deprecations(X)
+
+        if self._legacy_mode:
+            _transform_selected(X, self._legacy_fit_transform, self.dtype,
+                                self._categorical_features,
+                                copy=True)
+            return self
+        else:
+            self._fit(X, handle_unknown=self.handle_unknown)
+            return self
+
+    def _legacy_fit_transform(self, X):
+        """Assumes X contains only categorical features."""
+        dtype = getattr(X, 'dtype', None)
+        X = check_array(X, dtype=np.int)
+        if np.any(X < 0):
+            raise ValueError("X needs to contain only non-negative integers.")
+        n_samples, n_features = X.shape
+        if (isinstance(self.n_values, six.string_types) and
+                self.n_values == 'auto'):
+            n_values = np.max(X, axis=0) + 1
+        elif isinstance(self.n_values, numbers.Integral):
+            if (np.max(X, axis=0) >= self.n_values).any():
+                raise ValueError("Feature out of bounds for n_values=%d"
+                                 % self.n_values)
+            n_values = np.empty(n_features, dtype=np.int)
+            n_values.fill(self.n_values)
+        else:
+            try:
+                n_values = np.asarray(self.n_values, dtype=int)
+            except (ValueError, TypeError):
+                raise TypeError("Wrong type for parameter `n_values`. Expected"
+                                " 'auto', int or array of ints, got %r"
+                                % type(X))
+            if n_values.ndim < 1 or n_values.shape[0] != X.shape[1]:
+                raise ValueError("Shape mismatch: if n_values is an array,"
+                                 " it has to be of shape (n_features,).")
+
+        self._n_values_ = n_values
+        self.categories_ = [np.arange(n_val - 1, dtype=dtype)
+                            for n_val in n_values]
+        n_values = np.hstack([[0], n_values])
+        indices = np.cumsum(n_values)
+        self._feature_indices_ = indices
+
+        column_indices = (X + indices[:-1]).ravel()
+        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
+                                n_features)
+        data = np.ones(n_samples * n_features)
+        out = sparse.coo_matrix((data, (row_indices, column_indices)),
+                                shape=(n_samples, indices[-1]),
+                                dtype=self.dtype).tocsr()
+
+        if (isinstance(self.n_values, six.string_types) and
+                self.n_values == 'auto'):
+            mask = np.array(out.sum(axis=0)).ravel() != 0
+            active_features = np.where(mask)[0]
+            out = out[:, active_features]
+            self._active_features_ = active_features
+
+            self.categories_ = [
+                np.unique(X[:, i]).astype(dtype) if dtype
+                else np.unique(X[:, i]) for i in range(n_features)]
+
+        return out if self.sparse else out.toarray()
+
+    def fit_transform(self, X, y=None):
+        """Fit OneHotEncoder to X, then transform X.
+
+        Equivalent to self.fit(X).transform(X), but more convenient and more
+        efficient. See fit for the parameters, transform for the return value.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_feature]
+            Input array of type int.
+        """
+        if self.handle_unknown not in ('error', 'ignore'):
+            msg = ("handle_unknown should be either 'error' or 'ignore', "
+                   "got {0}.".format(self.handle_unknown))
+            raise ValueError(msg)
+
+        self._handle_deprecations(X)
+
+        if self._legacy_mode:
+            return _transform_selected(
+                X, self._legacy_fit_transform, self.dtype,
+                self._categorical_features, copy=True)
+        else:
+            return self.fit(X).transform(X)
+
+    def _legacy_transform(self, X):
+        """Assumes X contains only categorical features."""
+        X = check_array(X, dtype=np.int)
+        if np.any(X < 0):
+            raise ValueError("X needs to contain only non-negative integers.")
+        n_samples, n_features = X.shape
+
+        indices = self._feature_indices_
+        if n_features != indices.shape[0] - 1:
+            raise ValueError("X has different shape than during fitting."
+                             " Expected %d, got %d."
+                             % (indices.shape[0] - 1, n_features))
+
+        # We use only those categorical features of X that are known using fit.
+        # i.e lesser than n_values_ using mask.
+        # This means, if self.handle_unknown is "ignore", the row_indices and
+        # col_indices corresponding to the unknown categorical feature are
+        # ignored.
+        mask = (X < self._n_values_).ravel()
+        if np.any(~mask):
+            if self.handle_unknown not in ['error', 'ignore']:
+                raise ValueError("handle_unknown should be either error or "
+                                 "unknown got %s" % self.handle_unknown)
+            if self.handle_unknown == 'error':
+                raise ValueError("unknown categorical feature present %s "
+                                 "during transform." % X.ravel()[~mask])
+
+        column_indices = (X + indices[:-1]).ravel()[mask]
+        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
+                                n_features)[mask]
+        data = np.ones(np.sum(mask))
+        out = sparse.coo_matrix((data, (row_indices, column_indices)),
+                                shape=(n_samples, indices[-1]),
+                                dtype=self.dtype).tocsr()
+        if (isinstance(self.n_values, six.string_types) and
+                self.n_values == 'auto'):
+            out = out[:, self._active_features_]
+
+        return out if self.sparse else out.toarray()
+
+    def _transform_new(self, X):
+        """New implementation assuming categorical input"""
+        X_temp = check_array(X, dtype=None)
+        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
+            X = check_array(X, dtype=np.object)
+        else:
+            X = X_temp
+
+        n_samples, n_features = X.shape
+
+        X_int, X_mask = self._transform(X, handle_unknown=self.handle_unknown)
+
+        mask = X_mask.ravel()
+        n_values = [cats.shape[0] for cats in self.categories_]
+        n_values = np.array([0] + n_values)
+        feature_indices = np.cumsum(n_values)
+
+        indices = (X_int + feature_indices[:-1]).ravel()[mask]
+        indptr = X_mask.sum(axis=1).cumsum()
+        indptr = np.insert(indptr, 0, 0)
+        data = np.ones(n_samples * n_features)[mask]
+
+        out = sparse.csr_matrix((data, indices, indptr),
+                                shape=(n_samples, feature_indices[-1]),
+                                dtype=self.dtype)
+        if not self.sparse:
+            return out.toarray()
+        else:
+            return out
+
+    def transform(self, X):
+        """Transform X using one-hot encoding.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            The data to encode.
+
+        Returns
+        -------
+        X_out : sparse matrix if sparse=True else a 2-d array
+            Transformed input.
+        """
+        if self._legacy_mode:
+            return _transform_selected(X, self._legacy_transform, self.dtype,
+                                       self._categorical_features,
+                                       copy=True)
+        else:
+            return self._transform_new(X)
+
+    def inverse_transform(self, X):
+        """Convert the back data to the original representation.
+
+        In case unknown categories are encountered (all zero's in the
+        one-hot encoding), ``None`` is used to represent this category.
+
+        Parameters
+        ----------
+        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]
+            The transformed data.
+
+        Returns
+        -------
+        X_tr : array-like, shape [n_samples, n_features]
+            Inverse transformed array.
+
+        """
+        # if self._legacy_mode:
+        #     raise ValueError("only supported for categorical features")
+
+        check_is_fitted(self, 'categories_')
+        X = check_array(X, accept_sparse='csr')
+
+        n_samples, _ = X.shape
+        n_features = len(self.categories_)
+        n_transformed_features = sum([len(cats) for cats in self.categories_])
+
+        # validate shape of passed X
+        msg = ("Shape of the passed X data is not correct. Expected {0} "
+               "columns, got {1}.")
+        if X.shape[1] != n_transformed_features:
+            raise ValueError(msg.format(n_transformed_features, X.shape[1]))
+
+        # create resulting array of appropriate dtype
+        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])
+        X_tr = np.empty((n_samples, n_features), dtype=dt)
+
+        j = 0
+        found_unknown = {}
+
+        for i in range(n_features):
+            n_categories = len(self.categories_[i])
+            sub = X[:, j:j + n_categories]
+
+            # for sparse X argmax returns 2D matrix, ensure 1D array
+            labels = np.asarray(_argmax(sub, axis=1)).flatten()
+            X_tr[:, i] = self.categories_[i][labels]
+
+            if self.handle_unknown == 'ignore':
+                # ignored unknown categories: we have a row of all zero's
+                unknown = np.asarray(sub.sum(axis=1) == 0).flatten()
+                if unknown.any():
+                    found_unknown[i] = unknown
+
+            j += n_categories
+
+        # if ignored are found: potentially need to upcast result to
+        # insert None values
+        if found_unknown:
+            if X_tr.dtype != object:
+                X_tr = X_tr.astype(object)
+
+            for idx, mask in found_unknown.items():
+                X_tr[mask, idx] = None
+
+        return X_tr
+
+
+class OrdinalEncoder(_BaseEncoder):
+    """Encode categorical features as an integer array.
+
+    The input to this transformer should be an array-like of integers or
+    strings, denoting the values taken on by categorical (discrete) features.
+    The features are converted to ordinal integers. This results in
+    a single column of integers (0 to n_categories - 1) per feature.
+
+    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.
+
+    Parameters
+    ----------
+    categories : 'auto' or a list of lists/arrays of values.
+        Categories (unique values) per feature:
+
+        - 'auto' : Determine categories automatically from the training data.
+        - list : ``categories[i]`` holds the categories expected in the ith
+          column. The passed categories must be sorted and should not mix
+          strings and numeric values.
+
+        The used categories can be found in the ``categories_`` attribute.
+
+    dtype : number type, default np.float64
+        Desired dtype of output.
+
+    Attributes
+    ----------
+    categories_ : list of arrays
+        The categories of each feature determined during fitting
+        (in order of the features in X and corresponding with the output
+        of ``transform``).
+
+    Examples
+    --------
+    Given a dataset with two features, we let the encoder find the unique
+    values per feature and transform the data to an ordinal encoding.
+
+    >>> from sklearn.preprocessing import OrdinalEncoder
+    >>> enc = OrdinalEncoder()
+    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]
+    >>> enc.fit(X)
+    ... # doctest: +ELLIPSIS
+    OrdinalEncoder(categories='auto', dtype=<... 'numpy.float64'>)
+    >>> enc.categories_
+    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
+    >>> enc.transform([['Female', 3], ['Male', 1]])
+    array([[0., 2.],
+           [1., 0.]])
+
+    >>> enc.inverse_transform([[1, 0], [0, 1]])
+    array([['Male', 1],
+           ['Female', 2]], dtype=object)
+
+    See also
+    --------
+    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of
+      categorical features.
+    sklearn.preprocessing.LabelEncoder : encodes target labels with values
+      between 0 and n_classes-1.
+    """
+
+    def __init__(self, categories='auto', dtype=np.float64):
+        self.categories = categories
+        self.dtype = dtype
+
+    def fit(self, X, y=None):
+        """Fit the OrdinalEncoder to X.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            The data to determine the categories of each feature.
+
+        Returns
+        -------
+        self
+
+        """
+        # base classes uses _categories to deal with deprecations in
+        # OneHoteEncoder: can be removed once deprecations are removed
+        self._categories = self.categories
+        self._fit(X)
+
+        return self
+
+    def transform(self, X):
+        """Transform X to ordinal codes.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            The data to encode.
+
+        Returns
+        -------
+        X_out : sparse matrix or a 2-d array
+            Transformed input.
+
+        """
+        X_int, _ = self._transform(X)
+        return X_int.astype(self.dtype, copy=False)
+
+    def inverse_transform(self, X):
+        """Convert the data back to the original representation.
+
+        Parameters
+        ----------
+        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]
+            The transformed data.
+
+        Returns
+        -------
+        X_tr : array-like, shape [n_samples, n_features]
+            Inverse transformed array.
+
+        """
+        check_is_fitted(self, 'categories_')
+        X = check_array(X, accept_sparse='csr')
+
+        n_samples, _ = X.shape
+        n_features = len(self.categories_)
+
+        # validate shape of passed X
+        msg = ("Shape of the passed X data is not correct. Expected {0} "
+               "columns, got {1}.")
+        if X.shape[1] != n_features:
+            raise ValueError(msg.format(n_features, X.shape[1]))
+
+        # create resulting array of appropriate dtype
+        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])
+        X_tr = np.empty((n_samples, n_features), dtype=dt)
+
+        for i in range(n_features):
+            labels = X[:, i].astype('int64')
+            X_tr[:, i] = self.categories_[i][labels]
+
+        return X_tr
diff --git a/sklearn/preprocessing/data.py b/sklearn/preprocessing/data.py
index fb8f443e9c7a..b88b3c4cc988 100644
--- a/sklearn/preprocessing/data.py
+++ b/sklearn/preprocessing/data.py
@@ -10,7 +10,6 @@
 from __future__ import division
 
 from itertools import chain, combinations
-import numbers
 import warnings
 from itertools import combinations_with_replacement as combinations_w_r
 from distutils.version import LooseVersion
@@ -25,7 +24,7 @@
 from ..utils import check_array
 from ..utils.extmath import row_norms
 from ..utils.extmath import _incremental_mean_and_var
-from ..utils.fixes import _argmax, nanpercentile
+from ..utils.fixes import boxcox, nanpercentile
 from ..utils.sparsefuncs_fast import (inplace_csr_row_normalize_l1,
                                       inplace_csr_row_normalize_l2)
 from ..utils.sparsefuncs import (inplace_column_scale,
@@ -33,7 +32,8 @@
                                  min_max_axis)
 from ..utils.validation import (check_is_fitted, check_random_state,
                                 FLOAT_DTYPES)
-from .label import LabelEncoder
+
+from ._encoders import OneHotEncoder
 
 
 BOUNDS_THRESHOLD = 1e-7
@@ -126,6 +126,9 @@ def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
 
     To avoid memory copy the caller should pass a CSC matrix.
 
+    NaNs are treated as missing values: disregarded to compute the statistics,
+    and maintained during the data transformation.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -138,7 +141,7 @@ def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
     """  # noqa
     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,
                     warn_on_dtype=True, estimator='the scale function',
-                    dtype=FLOAT_DTYPES)
+                    dtype=FLOAT_DTYPES, force_all_finite='allow-nan')
     if sparse.issparse(X):
         if with_mean:
             raise ValueError(
@@ -154,15 +157,15 @@ def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
     else:
         X = np.asarray(X)
         if with_mean:
-            mean_ = np.mean(X, axis)
+            mean_ = np.nanmean(X, axis)
         if with_std:
-            scale_ = np.std(X, axis)
+            scale_ = np.nanstd(X, axis)
         # Xr is a view on the original array that enables easy use of
         # broadcasting on the axis in which we are interested in
         Xr = np.rollaxis(X, axis)
         if with_mean:
             Xr -= mean_
-            mean_1 = Xr.mean(axis=0)
+            mean_1 = np.nanmean(Xr, axis=0)
             # Verify that mean_1 is 'close to zero'. If X contains very
             # large values, mean_1 can also be very large, due to a lack of
             # precision of mean_. In this case, a pre-scaling of the
@@ -179,7 +182,7 @@ def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
             scale_ = _handle_zeros_in_scale(scale_, copy=False)
             Xr /= scale_
             if with_mean:
-                mean_2 = Xr.mean(axis=0)
+                mean_2 = np.nanmean(Xr, axis=0)
                 # If mean_2 is not 'close to zero', it comes from the fact that
                 # scale_ is very small so that mean_2 = mean_1/scale_ > 0, even
                 # if mean_1 was close to zero. The problem is thus essentially
@@ -455,7 +458,7 @@ def minmax_scale(X, feature_range=(0, 1), axis=0, copy=True):
     # Unlike the scaler object, this function allows 1d input.
     # If copy is required, it will be done inside the scaler object.
     X = check_array(X, copy=False, ensure_2d=False, warn_on_dtype=True,
-                    dtype=FLOAT_DTYPES)
+                    dtype=FLOAT_DTYPES, force_all_finite='allow-nan')
     original_ndim = X.ndim
 
     if original_ndim == 1:
@@ -520,27 +523,31 @@ class StandardScaler(BaseEstimator, TransformerMixin):
 
     Attributes
     ----------
-    scale_ : ndarray, shape (n_features,)
-        Per feature relative scaling of the data.
+    scale_ : ndarray or None, shape (n_features,)
+        Per feature relative scaling of the data. Equal to ``None`` when
+        ``with_std=False``.
 
         .. versionadded:: 0.17
            *scale_*
 
-    mean_ : array of floats with shape [n_features]
+    mean_ : ndarray or None, shape (n_features,)
         The mean value for each feature in the training set.
+        Equal to ``None`` when ``with_mean=False``.
 
-    var_ : array of floats with shape [n_features]
+    var_ : ndarray or None, shape (n_features,)
         The variance for each feature in the training set. Used to compute
-        `scale_`
+        `scale_`. Equal to ``None`` when ``with_std=False``.
 
-    n_samples_seen_ : int
-        The number of samples processed by the estimator. Will be reset on
-        new calls to fit, but increments across ``partial_fit`` calls.
+    n_samples_seen_ : int or array, shape (n_features,)
+        The number of samples processed by the estimator for each feature.
+        If there are not missing samples, the ``n_samples_seen`` will be an
+        integer, otherwise it will be an array.
+        Will be reset on new calls to fit, but increments across
+        ``partial_fit`` calls.
 
     Examples
     --------
     >>> from sklearn.preprocessing import StandardScaler
-    >>>
     >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]
     >>> scaler = StandardScaler()
     >>> print(scaler.fit(data))
@@ -564,6 +571,9 @@ class StandardScaler(BaseEstimator, TransformerMixin):
 
     Notes
     -----
+    NaNs are treated as missing values: disregarded in fit, and maintained in
+    transform.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -626,22 +636,41 @@ def partial_fit(self, X, y=None):
             Ignored
         """
         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,
-                        warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)
+                        warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES,
+                        force_all_finite='allow-nan')
 
         # Even in the case of `with_mean=False`, we update the mean anyway
         # This is needed for the incremental computation of the var
         # See incr_mean_variance_axis and _incremental_mean_variance_axis
 
+        # if n_samples_seen_ is an integer (i.e. no missing values), we need to
+        # transform it to a NumPy array of shape (n_features,) required by
+        # incr_mean_variance_axis and _incremental_variance_axis
+        if (hasattr(self, 'n_samples_seen_') and
+                isinstance(self.n_samples_seen_, (int, np.integer))):
+            self.n_samples_seen_ = np.repeat(self.n_samples_seen_,
+                                             X.shape[1]).astype(np.int64)
+
         if sparse.issparse(X):
             if self.with_mean:
                 raise ValueError(
                     "Cannot center sparse matrices: pass `with_mean=False` "
                     "instead. See docstring for motivation and alternatives.")
+
+            sparse_constructor = (sparse.csr_matrix
+                                  if X.format == 'csr' else sparse.csc_matrix)
+            counts_nan = sparse_constructor(
+                        (np.isnan(X.data), X.indices, X.indptr),
+                        shape=X.shape).sum(axis=0).A.ravel()
+
+            if not hasattr(self, 'n_samples_seen_'):
+                self.n_samples_seen_ = (X.shape[0] -
+                                        counts_nan).astype(np.int64)
+
             if self.with_std:
                 # First pass
-                if not hasattr(self, 'n_samples_seen_'):
+                if not hasattr(self, 'scale_'):
                     self.mean_, self.var_ = mean_variance_axis(X, axis=0)
-                    self.n_samples_seen_ = X.shape[0]
                 # Next passes
                 else:
                     self.mean_, self.var_, self.n_samples_seen_ = \
@@ -652,19 +681,34 @@ def partial_fit(self, X, y=None):
             else:
                 self.mean_ = None
                 self.var_ = None
+                if hasattr(self, 'scale_'):
+                    self.n_samples_seen_ += X.shape[0] - counts_nan
         else:
-            # First pass
             if not hasattr(self, 'n_samples_seen_'):
+                self.n_samples_seen_ = np.zeros(X.shape[1], dtype=np.int64)
+
+            # First pass
+            if not hasattr(self, 'scale_'):
                 self.mean_ = .0
-                self.n_samples_seen_ = 0
                 if self.with_std:
                     self.var_ = .0
                 else:
                     self.var_ = None
 
-            self.mean_, self.var_, self.n_samples_seen_ = \
-                _incremental_mean_and_var(X, self.mean_, self.var_,
-                                          self.n_samples_seen_)
+            if not self.with_mean and not self.with_std:
+                self.mean_ = None
+                self.var_ = None
+                self.n_samples_seen_ += X.shape[0] - np.isnan(X).sum(axis=0)
+            else:
+                self.mean_, self.var_, self.n_samples_seen_ = \
+                    _incremental_mean_and_var(X, self.mean_, self.var_,
+                                              self.n_samples_seen_)
+
+        # for backward-compatibility, reduce n_samples_seen_ to an integer
+        # if the number of samples is the same for each feature (i.e. no
+        # missing values)
+        if np.ptp(self.n_samples_seen_) == 0:
+            self.n_samples_seen_ = self.n_samples_seen_[0]
 
         if self.with_std:
             self.scale_ = _handle_zeros_in_scale(np.sqrt(self.var_))
@@ -695,7 +739,8 @@ def transform(self, X, y='deprecated', copy=None):
 
         copy = copy if copy is not None else self.copy
         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,
-                        estimator=self, dtype=FLOAT_DTYPES)
+                        estimator=self, dtype=FLOAT_DTYPES,
+                        force_all_finite='allow-nan')
 
         if sparse.issparse(X):
             if self.with_mean:
@@ -791,6 +836,9 @@ class MaxAbsScaler(BaseEstimator, TransformerMixin):
 
     Notes
     -----
+    NaNs are treated as missing values: disregarded in fit, and maintained in
+    transform.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -928,6 +976,9 @@ def maxabs_scale(X, axis=0, copy=True):
 
     Notes
     -----
+    NaNs are treated as missing values: disregarded to compute the statistics,
+    and maintained during the data transformation.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -1825,302 +1876,6 @@ def add_dummy_feature(X, value=1.0):
         return np.hstack((np.ones((n_samples, 1)) * value, X))
 
 
-def _transform_selected(X, transform, selected="all", copy=True):
-    """Apply a transform function to portion of selected features
-
-    Parameters
-    ----------
-    X : {array-like, sparse matrix}, shape [n_samples, n_features]
-        Dense array or sparse matrix.
-
-    transform : callable
-        A callable transform(X) -> X_transformed
-
-    copy : boolean, optional
-        Copy X even if it could be avoided.
-
-    selected: "all" or array of indices or mask
-        Specify which features to apply the transform to.
-
-    Returns
-    -------
-    X : array or sparse matrix, shape=(n_samples, n_features_new)
-    """
-    X = check_array(X, accept_sparse='csc', copy=copy, dtype=FLOAT_DTYPES)
-
-    if isinstance(selected, six.string_types) and selected == "all":
-        return transform(X)
-
-    if len(selected) == 0:
-        return X
-
-    n_features = X.shape[1]
-    ind = np.arange(n_features)
-    sel = np.zeros(n_features, dtype=bool)
-    sel[np.asarray(selected)] = True
-    not_sel = np.logical_not(sel)
-    n_selected = np.sum(sel)
-
-    if n_selected == 0:
-        # No features selected.
-        return X
-    elif n_selected == n_features:
-        # All features selected.
-        return transform(X)
-    else:
-        X_sel = transform(X[:, ind[sel]])
-        X_not_sel = X[:, ind[not_sel]]
-
-        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):
-            return sparse.hstack((X_sel, X_not_sel))
-        else:
-            return np.hstack((X_sel, X_not_sel))
-
-
-class OneHotEncoder(BaseEstimator, TransformerMixin):
-    """Encode categorical integer features using a one-hot aka one-of-K scheme.
-
-    The input to this transformer should be a matrix of integers, denoting
-    the values taken on by categorical (discrete) features. The output will be
-    a sparse matrix where each column corresponds to one possible value of one
-    feature. It is assumed that input features take on values in the range
-    [0, n_values). For an encoder based on the unique values of the input
-    features of any type, see the
-    :class:`~sklearn.preprocessing.CategoricalEncoder`.
-
-    This encoding is needed for feeding categorical data to many scikit-learn
-    estimators, notably linear models and SVMs with the standard kernels.
-
-    Note: a one-hot encoding of y labels should use a LabelBinarizer
-    instead.
-
-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.
-
-    Parameters
-    ----------
-    n_values : 'auto', int or array of ints
-        Number of values per feature.
-
-        - 'auto' : determine value range from training data.
-        - int : number of categorical values per feature.
-                Each feature value should be in ``range(n_values)``
-        - array : ``n_values[i]`` is the number of categorical values in
-                  ``X[:, i]``. Each feature value should be
-                  in ``range(n_values[i])``
-
-    categorical_features : "all" or array of indices or mask
-        Specify what features are treated as categorical.
-
-        - 'all' (default): All features are treated as categorical.
-        - array of indices: Array of categorical feature indices.
-        - mask: Array of length n_features and with dtype=bool.
-
-        Non-categorical features are always stacked to the right of the matrix.
-
-    dtype : number type, default=np.float
-        Desired dtype of output.
-
-    sparse : boolean, default=True
-        Will return sparse matrix if set True else will return an array.
-
-    handle_unknown : str, 'error' or 'ignore'
-        Whether to raise an error or ignore if a unknown categorical feature is
-        present during transform.
-
-    Attributes
-    ----------
-    active_features_ : array
-        Indices for active features, meaning values that actually occur
-        in the training set. Only available when n_values is ``'auto'``.
-
-    feature_indices_ : array of shape (n_features,)
-        Indices to feature ranges.
-        Feature ``i`` in the original data is mapped to features
-        from ``feature_indices_[i]`` to ``feature_indices_[i+1]``
-        (and then potentially masked by `active_features_` afterwards)
-
-    n_values_ : array of shape (n_features,)
-        Maximum number of values per feature.
-
-    Examples
-    --------
-    Given a dataset with three features and four samples, we let the encoder
-    find the maximum value per feature and transform the data to a binary
-    one-hot encoding.
-
-    >>> from sklearn.preprocessing import OneHotEncoder
-    >>> enc = OneHotEncoder()
-    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], \
-[1, 0, 2]])  # doctest: +ELLIPSIS
-    OneHotEncoder(categorical_features='all', dtype=<... 'numpy.float64'>,
-           handle_unknown='error', n_values='auto', sparse=True)
-    >>> enc.n_values_
-    array([2, 3, 4])
-    >>> enc.feature_indices_
-    array([0, 2, 5, 9])
-    >>> enc.transform([[0, 1, 1]]).toarray()
-    array([[1., 0., 0., 1., 0., 0., 1., 0., 0.]])
-
-    See also
-    --------
-    sklearn.preprocessing.CategoricalEncoder : performs a one-hot or ordinal
-      encoding of all features (also handles string-valued features). This
-      encoder derives the categories based on the unique values in each
-      feature.
-    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of
-      dictionary items (also handles string-valued features).
-    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot
-      encoding of dictionary items or strings.
-    sklearn.preprocessing.LabelBinarizer : binarizes labels in a one-vs-all
-      fashion.
-    sklearn.preprocessing.MultiLabelBinarizer : transforms between iterable of
-      iterables and a multilabel format, e.g. a (samples x classes) binary
-      matrix indicating the presence of a class label.
-    sklearn.preprocessing.LabelEncoder : encodes labels with values between 0
-      and n_classes-1.
-    """
-    def __init__(self, n_values="auto", categorical_features="all",
-                 dtype=np.float64, sparse=True, handle_unknown='error'):
-        self.n_values = n_values
-        self.categorical_features = categorical_features
-        self.dtype = dtype
-        self.sparse = sparse
-        self.handle_unknown = handle_unknown
-
-    def fit(self, X, y=None):
-        """Fit OneHotEncoder to X.
-
-        Parameters
-        ----------
-        X : array-like, shape [n_samples, n_feature]
-            Input array of type int.
-
-        Returns
-        -------
-        self
-        """
-        self.fit_transform(X)
-        return self
-
-    def _fit_transform(self, X):
-        """Assumes X contains only categorical features."""
-        X = check_array(X, dtype=np.int)
-        if np.any(X < 0):
-            raise ValueError("X needs to contain only non-negative integers.")
-        n_samples, n_features = X.shape
-        if (isinstance(self.n_values, six.string_types) and
-                self.n_values == 'auto'):
-            n_values = np.max(X, axis=0) + 1
-        elif isinstance(self.n_values, numbers.Integral):
-            if (np.max(X, axis=0) >= self.n_values).any():
-                raise ValueError("Feature out of bounds for n_values=%d"
-                                 % self.n_values)
-            n_values = np.empty(n_features, dtype=np.int)
-            n_values.fill(self.n_values)
-        else:
-            try:
-                n_values = np.asarray(self.n_values, dtype=int)
-            except (ValueError, TypeError):
-                raise TypeError("Wrong type for parameter `n_values`. Expected"
-                                " 'auto', int or array of ints, got %r"
-                                % type(X))
-            if n_values.ndim < 1 or n_values.shape[0] != X.shape[1]:
-                raise ValueError("Shape mismatch: if n_values is an array,"
-                                 " it has to be of shape (n_features,).")
-
-        self.n_values_ = n_values
-        n_values = np.hstack([[0], n_values])
-        indices = np.cumsum(n_values)
-        self.feature_indices_ = indices
-
-        column_indices = (X + indices[:-1]).ravel()
-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
-                                n_features)
-        data = np.ones(n_samples * n_features)
-        out = sparse.coo_matrix((data, (row_indices, column_indices)),
-                                shape=(n_samples, indices[-1]),
-                                dtype=self.dtype).tocsr()
-
-        if (isinstance(self.n_values, six.string_types) and
-                self.n_values == 'auto'):
-            mask = np.array(out.sum(axis=0)).ravel() != 0
-            active_features = np.where(mask)[0]
-            out = out[:, active_features]
-            self.active_features_ = active_features
-
-        return out if self.sparse else out.toarray()
-
-    def fit_transform(self, X, y=None):
-        """Fit OneHotEncoder to X, then transform X.
-
-        Equivalent to self.fit(X).transform(X), but more convenient and more
-        efficient. See fit for the parameters, transform for the return value.
-
-        Parameters
-        ----------
-        X : array-like, shape [n_samples, n_feature]
-            Input array of type int.
-        """
-        return _transform_selected(X, self._fit_transform,
-                                   self.categorical_features, copy=True)
-
-    def _transform(self, X):
-        """Assumes X contains only categorical features."""
-        X = check_array(X, dtype=np.int)
-        if np.any(X < 0):
-            raise ValueError("X needs to contain only non-negative integers.")
-        n_samples, n_features = X.shape
-
-        indices = self.feature_indices_
-        if n_features != indices.shape[0] - 1:
-            raise ValueError("X has different shape than during fitting."
-                             " Expected %d, got %d."
-                             % (indices.shape[0] - 1, n_features))
-
-        # We use only those categorical features of X that are known using fit.
-        # i.e lesser than n_values_ using mask.
-        # This means, if self.handle_unknown is "ignore", the row_indices and
-        # col_indices corresponding to the unknown categorical feature are
-        # ignored.
-        mask = (X < self.n_values_).ravel()
-        if np.any(~mask):
-            if self.handle_unknown not in ['error', 'ignore']:
-                raise ValueError("handle_unknown should be either error or "
-                                 "unknown got %s" % self.handle_unknown)
-            if self.handle_unknown == 'error':
-                raise ValueError("unknown categorical feature present %s "
-                                 "during transform." % X.ravel()[~mask])
-
-        column_indices = (X + indices[:-1]).ravel()[mask]
-        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),
-                                n_features)[mask]
-        data = np.ones(np.sum(mask))
-        out = sparse.coo_matrix((data, (row_indices, column_indices)),
-                                shape=(n_samples, indices[-1]),
-                                dtype=self.dtype).tocsr()
-        if (isinstance(self.n_values, six.string_types) and
-                self.n_values == 'auto'):
-            out = out[:, self.active_features_]
-
-        return out if self.sparse else out.toarray()
-
-    def transform(self, X):
-        """Transform X using one-hot encoding.
-
-        Parameters
-        ----------
-        X : array-like, shape [n_samples, n_features]
-            Input array of type int.
-
-        Returns
-        -------
-        X_out : sparse matrix if sparse=True else a 2-d array, dtype=int
-            Transformed input.
-        """
-        return _transform_selected(X, self._transform,
-                                   self.categorical_features, copy=True)
-
-
 class QuantileTransformer(BaseEstimator, TransformerMixin):
     """Transform features using quantiles information.
 
@@ -2680,6 +2435,9 @@ class PowerTransformer(BaseEstimator, TransformerMixin):
 
     Notes
     -----
+    NaNs are treated as missing values: disregarded in fit, and maintained in
+    transform.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -2719,7 +2477,10 @@ def fit(self, X, y=None):
         transformed = []
 
         for col in X.T:
-            col_trans, lmbda = stats.boxcox(col, lmbda=None)
+            # the computation of lambda is influenced by NaNs and we need to
+            # get rid of them to compute them.
+            _, lmbda = stats.boxcox(col[~np.isnan(col)], lmbda=None)
+            col_trans = boxcox(col, lmbda)
             self.lambdas_.append(lmbda)
             transformed.append(col_trans)
 
@@ -2744,7 +2505,7 @@ def transform(self, X):
         X = self._check_input(X, check_positive=True, check_shape=True)
 
         for i, lmbda in enumerate(self.lambdas_):
-            X[:, i] = stats.boxcox(X[:, i], lmbda=lmbda)
+            X[:, i] = boxcox(X[:, i], lmbda)
 
         if self.standardize:
             X = self._scaler.transform(X)
@@ -2799,9 +2560,10 @@ def _check_input(self, X, check_positive=False, check_shape=False,
         check_method : bool
             If True, check that the transformation method is valid.
         """
-        X = check_array(X, ensure_2d=True, dtype=FLOAT_DTYPES, copy=self.copy)
+        X = check_array(X, ensure_2d=True, dtype=FLOAT_DTYPES, copy=self.copy,
+                        force_all_finite='allow-nan')
 
-        if check_positive and self.method == 'box-cox' and np.any(X <= 0):
+        if check_positive and self.method == 'box-cox' and np.nanmin(X) <= 0:
             raise ValueError("The Box-Cox transformation can only be applied "
                              "to strictly positive data")
 
@@ -2873,6 +2635,9 @@ def power_transform(X, method='box-cox', standardize=True, copy=True):
 
     Notes
     -----
+    NaNs are treated as missing values: disregarded to compute the statistics,
+    and maintained during the data transformation.
+
     For a comparison of the different scalers, transformers, and normalizers,
     see :ref:`examples/preprocessing/plot_all_scaling.py
     <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.
@@ -2886,297 +2651,15 @@ def power_transform(X, method='box-cox', standardize=True, copy=True):
     return pt.fit_transform(X)
 
 
-class CategoricalEncoder(BaseEstimator, TransformerMixin):
-    """Encode categorical features as a numeric array.
-
-    The input to this transformer should be an array-like of integers or
-    strings, denoting the values taken on by categorical (discrete) features.
-    The features can be encoded using a one-hot (aka one-of-K or dummy)
-    encoding scheme (``encoding='onehot'``, the default) or converted
-    to ordinal integers (``encoding='ordinal'``).
-
-    This encoding is needed for feeding categorical data to many scikit-learn
-    estimators, notably linear models and SVMs with the standard kernels.
-
-    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.
-
-    Parameters
-    ----------
-    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'
-        The type of encoding to use (default is 'onehot'):
-
-        - 'onehot': encode the features using a one-hot aka one-of-K scheme
-          (or also called 'dummy' encoding). This creates a binary column for
-          each category and returns a sparse matrix.
-        - 'onehot-dense': the same as 'onehot' but returns a dense array
-          instead of a sparse matrix.
-        - 'ordinal': encode the features as ordinal integers. This results in
-          a single column of integers (0 to n_categories - 1) per feature.
-
-    categories : 'auto' or a list of lists/arrays of values.
-        Categories (unique values) per feature:
-
-        - 'auto' : Determine categories automatically from the training data.
-        - list : ``categories[i]`` holds the categories expected in the ith
-          column. The passed categories must be sorted and should not mix
-          strings and numeric values.
-
-        The used categories can be found in the ``categories_`` attribute.
-
-    dtype : number type, default np.float64
-        Desired dtype of output.
-
-    handle_unknown : 'error' (default) or 'ignore'
-        Whether to raise an error or ignore if a unknown categorical feature is
-        present during transform (default is to raise). When this parameter
-        is set to 'ignore' and an unknown category is encountered during
-        transform, the resulting one-hot encoded columns for this feature
-        will be all zeros. In the inverse transform, an unknown category
-        will be denoted as None.
-        Ignoring unknown categories is not supported for
-        ``encoding='ordinal'``.
-
-    Attributes
-    ----------
-    categories_ : list of arrays
-        The categories of each feature determined during fitting
-        (in order corresponding with output of ``transform``).
-
-    Examples
-    --------
-    Given a dataset with two features, we let the encoder find the unique
-    values per feature and transform the data to a binary one-hot encoding.
-
-    >>> from sklearn.preprocessing import CategoricalEncoder
-    >>> enc = CategoricalEncoder(handle_unknown='ignore')
-    >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]
-    >>> enc.fit(X)
-    ... # doctest: +ELLIPSIS
-    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,
-              encoding='onehot', handle_unknown='ignore')
-    >>> enc.categories_
-    [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
-    >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()
-    array([[1., 0., 1., 0., 0.],
-           [0., 1., 0., 0., 0.]])
-    >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])
-    array([['Male', 1],
-           [None, 2]], dtype=object)
-
-    See also
-    --------
-    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of
-      integer ordinal features. The ``OneHotEncoder assumes`` that input
-      features take on values in the range ``[0, max(feature)]`` instead of
-      using the unique values.
-    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of
-      dictionary items (also handles string-valued features).
-    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot
-      encoding of dictionary items or strings.
+class CategoricalEncoder:
+    """
+    CategoricalEncoder briefly existed in 0.20dev. Its functionality
+    has been rolled into the OneHotEncoder and OrdinalEncoder.
+    This stub will be removed in version 0.21.
     """
 
-    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,
-                 handle_unknown='error'):
-        self.encoding = encoding
-        self.categories = categories
-        self.dtype = dtype
-        self.handle_unknown = handle_unknown
-
-    def fit(self, X, y=None):
-        """Fit the CategoricalEncoder to X.
-
-        Parameters
-        ----------
-        X : array-like, shape [n_samples, n_features]
-            The data to determine the categories of each feature.
-
-        Returns
-        -------
-        self
-
-        """
-        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:
-            template = ("encoding should be either 'onehot', 'onehot-dense' "
-                        "or 'ordinal', got %s")
-            raise ValueError(template % self.handle_unknown)
-
-        if self.handle_unknown not in ['error', 'ignore']:
-            template = ("handle_unknown should be either 'error' or "
-                        "'ignore', got %s")
-            raise ValueError(template % self.handle_unknown)
-
-        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':
-            raise ValueError("handle_unknown='ignore' is not supported for"
-                             " encoding='ordinal'")
-
-        if self.categories != 'auto':
-            for cats in self.categories:
-                if not np.all(np.sort(cats) == np.array(cats)):
-                    raise ValueError("Unsorted categories are not yet "
-                                     "supported")
-
-        X_temp = check_array(X, dtype=None)
-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
-            X = check_array(X, dtype=np.object)
-        else:
-            X = X_temp
-
-        n_samples, n_features = X.shape
-
-        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]
-
-        for i in range(n_features):
-            le = self._label_encoders_[i]
-            Xi = X[:, i]
-            if self.categories == 'auto':
-                le.fit(Xi)
-            else:
-                if self.handle_unknown == 'error':
-                    valid_mask = np.in1d(Xi, self.categories[i])
-                    if not np.all(valid_mask):
-                        diff = np.unique(Xi[~valid_mask])
-                        msg = ("Found unknown categories {0} in column {1}"
-                               " during fit".format(diff, i))
-                        raise ValueError(msg)
-                le.classes_ = np.array(self.categories[i])
-
-        self.categories_ = [le.classes_ for le in self._label_encoders_]
-
-        return self
-
-    def transform(self, X):
-        """Transform X using specified encoding scheme.
-
-        Parameters
-        ----------
-        X : array-like, shape [n_samples, n_features]
-            The data to encode.
-
-        Returns
-        -------
-        X_out : sparse matrix or a 2-d array
-            Transformed input.
-
-        """
-        X_temp = check_array(X, dtype=None)
-        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):
-            X = check_array(X, dtype=np.object)
-        else:
-            X = X_temp
-
-        n_samples, n_features = X.shape
-        X_int = np.zeros_like(X, dtype=np.int)
-        X_mask = np.ones_like(X, dtype=np.bool)
-
-        for i in range(n_features):
-            Xi = X[:, i]
-            valid_mask = np.in1d(Xi, self.categories_[i])
-
-            if not np.all(valid_mask):
-                if self.handle_unknown == 'error':
-                    diff = np.unique(X[~valid_mask, i])
-                    msg = ("Found unknown categories {0} in column {1}"
-                           " during transform".format(diff, i))
-                    raise ValueError(msg)
-                else:
-                    # Set the problematic rows to an acceptable value and
-                    # continue `The rows are marked `X_mask` and will be
-                    # removed later.
-                    X_mask[:, i] = valid_mask
-                    Xi = Xi.copy()
-                    Xi[~valid_mask] = self.categories_[i][0]
-            X_int[:, i] = self._label_encoders_[i].transform(Xi)
-
-        if self.encoding == 'ordinal':
-            return X_int.astype(self.dtype, copy=False)
-
-        mask = X_mask.ravel()
-        n_values = [cats.shape[0] for cats in self.categories_]
-        n_values = np.array([0] + n_values)
-        feature_indices = np.cumsum(n_values)
-
-        indices = (X_int + feature_indices[:-1]).ravel()[mask]
-        indptr = X_mask.sum(axis=1).cumsum()
-        indptr = np.insert(indptr, 0, 0)
-        data = np.ones(n_samples * n_features)[mask]
-
-        out = sparse.csr_matrix((data, indices, indptr),
-                                shape=(n_samples, feature_indices[-1]),
-                                dtype=self.dtype)
-        if self.encoding == 'onehot-dense':
-            return out.toarray()
-        else:
-            return out
-
-    def inverse_transform(self, X):
-        """Convert back the data to the original representation.
-
-        In case unknown categories are encountered (all zero's in the
-        one-hot encoding), ``None`` is used to represent this category.
-
-        Parameters
-        ----------
-        X : array-like or sparse matrix, shape [n_samples, n_encoded_features]
-            The transformed data.
-
-        Returns
-        -------
-        X_tr : array-like, shape [n_samples, n_features]
-            Inverse transformed array.
-
-        """
-        check_is_fitted(self, 'categories_')
-        X = check_array(X, accept_sparse='csr')
-
-        n_samples, _ = X.shape
-        n_features = len(self.categories_)
-        n_transformed_features = sum([len(cats) for cats in self.categories_])
-
-        # validate shape of passed X
-        msg = ("Shape of the passed X data is not correct. Expected {0} "
-               "columns, got {1}.")
-        if self.encoding == 'ordinal' and X.shape[1] != n_features:
-            raise ValueError(msg.format(n_features, X.shape[1]))
-        elif (self.encoding.startswith('onehot')
-                and X.shape[1] != n_transformed_features):
-            raise ValueError(msg.format(n_transformed_features, X.shape[1]))
-
-        # create resulting array of appropriate dtype
-        dt = np.find_common_type([cat.dtype for cat in self.categories_], [])
-        X_tr = np.empty((n_samples, n_features), dtype=dt)
-
-        if self.encoding == 'ordinal':
-            for i in range(n_features):
-                labels = X[:, i].astype('int64')
-                X_tr[:, i] = self.categories_[i][labels]
-
-        else:  # encoding == 'onehot' / 'onehot-dense'
-            j = 0
-            found_unknown = {}
-
-            for i in range(n_features):
-                n_categories = len(self.categories_[i])
-                sub = X[:, j:j + n_categories]
-
-                # for sparse X argmax returns 2D matrix, ensure 1D array
-                labels = np.asarray(_argmax(sub, axis=1)).flatten()
-                X_tr[:, i] = self.categories_[i][labels]
-
-                if self.handle_unknown == 'ignore':
-                    # ignored unknown categories: we have a row of all zero's
-                    unknown = np.asarray(sub.sum(axis=1) == 0).flatten()
-                    if unknown.any():
-                        found_unknown[i] = unknown
-
-                j += n_categories
-
-            # if ignored are found: potentially need to upcast result to
-            # insert None values
-            if found_unknown:
-                if X_tr.dtype != object:
-                    X_tr = X_tr.astype(object)
-
-                for idx, mask in found_unknown.items():
-                    X_tr[mask, idx] = None
-
-        return X_tr
+    def __init__(*args, **kwargs):
+        raise RuntimeError(
+            "CategoricalEncoder briefly existed in 0.20dev. Its functionality "
+            "has been rolled into the OneHotEncoder and OrdinalEncoder. "
+            "This stub will be removed in version 0.21.")
diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py
index 7f95a1426c87..043067fa37a8 100644
--- a/sklearn/preprocessing/label.py
+++ b/sklearn/preprocessing/label.py
@@ -16,7 +16,7 @@
 
 from ..base import BaseEstimator, TransformerMixin
 
-from ..utils.fixes import sparse_min_max
+from ..utils.sparsefuncs import min_max_axis
 from ..utils import column_or_1d
 from ..utils.validation import check_array
 from ..utils.validation import check_is_fitted
@@ -77,7 +77,7 @@ class LabelEncoder(BaseEstimator, TransformerMixin):
 
     See also
     --------
-    sklearn.preprocessing.CategoricalEncoder : encode categorical features
+    sklearn.preprocessing.OrdinalEncoder : encode categorical features
         using a one-hot or ordinal encoding scheme.
     """
 
@@ -251,7 +251,7 @@ class LabelBinarizer(BaseEstimator, TransformerMixin):
     --------
     label_binarize : function to perform the transform operation of
         LabelBinarizer with fixed classes.
-    sklearn.preprocessing.OneHotEncoder : encode categorical integer features
+    sklearn.preprocessing.OneHotEncoder : encode categorical features
         using a one-hot aka one-of-K scheme.
     """
 
@@ -567,7 +567,7 @@ def _inverse_binarize_multiclass(y, classes):
         y = y.tocsr()
         n_samples, n_outputs = y.shape
         outputs = np.arange(n_outputs)
-        row_max = sparse_min_max(y, 1)[1]
+        row_max = min_max_axis(y, 1)[1]
         row_nnz = np.diff(y.indptr)
 
         y_data_repeated_max = np.repeat(row_max, row_nnz)
@@ -682,7 +682,7 @@ class MultiLabelBinarizer(BaseEstimator, TransformerMixin):
 
     See also
     --------
-    sklearn.preprocessing.OneHotEncoder : encode categorical integer features
+    sklearn.preprocessing.OneHotEncoder : encode categorical features
         using a one-hot aka one-of-K scheme.
     """
 
diff --git a/sklearn/preprocessing/tests/test_common.py b/sklearn/preprocessing/tests/test_common.py
index 1488ceaba12c..97e5a457a030 100644
--- a/sklearn/preprocessing/tests/test_common.py
+++ b/sklearn/preprocessing/tests/test_common.py
@@ -8,8 +8,15 @@
 
 from sklearn.base import clone
 
-from sklearn.preprocessing import QuantileTransformer
+from sklearn.preprocessing import minmax_scale
+from sklearn.preprocessing import scale
+from sklearn.preprocessing import power_transform
+from sklearn.preprocessing import quantile_transform
+
 from sklearn.preprocessing import MinMaxScaler
+from sklearn.preprocessing import StandardScaler
+from sklearn.preprocessing import PowerTransformer
+from sklearn.preprocessing import QuantileTransformer
 
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_allclose
@@ -23,17 +30,22 @@ def _get_valid_samples_by_column(X, col):
 
 
 @pytest.mark.parametrize(
-    "est, support_sparse",
-    [(MinMaxScaler(), False),
-     (QuantileTransformer(n_quantiles=10, random_state=42), True)]
+    "est, func, support_sparse, strictly_positive",
+    [(MinMaxScaler(), minmax_scale, False, False),
+     (StandardScaler(), scale, False, False),
+     (StandardScaler(with_mean=False), scale, True, False),
+     (PowerTransformer(), power_transform, False, True),
+     (QuantileTransformer(n_quantiles=10), quantile_transform, True, False)]
 )
-def test_missing_value_handling(est, support_sparse):
+def test_missing_value_handling(est, func, support_sparse, strictly_positive):
     # check that the preprocessing method let pass nan
     rng = np.random.RandomState(42)
     X = iris.data.copy()
     n_missing = 50
     X[rng.randint(X.shape[0], size=n_missing),
       rng.randint(X.shape[1], size=n_missing)] = np.nan
+    if strictly_positive:
+        X += np.nanmin(X) + 0.1
     X_train, X_test = train_test_split(X, random_state=1)
     # sanity check
     assert not np.all(np.isnan(X_train), axis=0).any()
@@ -45,6 +57,12 @@ def test_missing_value_handling(est, support_sparse):
     # missing values should still be missing, and only them
     assert_array_equal(np.isnan(Xt), np.isnan(X_test))
 
+    # check that the function leads to the same results as the class
+    Xt_class = est.transform(X_train)
+    Xt_func = func(X_train, **est.get_params())
+    assert_array_equal(np.isnan(Xt_func), np.isnan(Xt_class))
+    assert_allclose(Xt_func[~np.isnan(Xt_func)], Xt_class[~np.isnan(Xt_class)])
+
     # check that the inverse transform keep NaN
     Xt_inv = est.inverse_transform(Xt)
     assert_array_equal(np.isnan(Xt_inv), np.isnan(X_test))
@@ -57,7 +75,7 @@ def test_missing_value_handling(est, support_sparse):
         est.fit(_get_valid_samples_by_column(X_train, i))
         # check transforming with NaN works even when training without NaN
         Xt_col = est.transform(X_test[:, [i]])
-        assert_array_equal(Xt_col, Xt[:, [i]])
+        assert_allclose(Xt_col, Xt[:, [i]])
         # check non-NaN is handled as before - the 1st column is all nan
         if not np.isnan(X_test[:, i]).all():
             Xt_col_nonan = est.transform(
diff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py
index e3bf4096750d..f90fbee278c0 100644
--- a/sklearn/preprocessing/tests/test_data.py
+++ b/sklearn/preprocessing/tests/test_data.py
@@ -7,6 +7,7 @@
 
 import warnings
 import re
+import itertools
 
 import numpy as np
 import numpy.linalg as la
@@ -32,18 +33,15 @@
 from sklearn.utils.testing import assert_warns_message
 from sklearn.utils.testing import assert_no_warnings
 from sklearn.utils.testing import assert_allclose
+from sklearn.utils.testing import assert_allclose_dense_sparse
 from sklearn.utils.testing import skip_if_32bit
-from sklearn.utils.testing import SkipTest
 
 from sklearn.utils.sparsefuncs import mean_variance_axis
-from sklearn.preprocessing.data import _transform_selected
 from sklearn.preprocessing.data import _handle_zeros_in_scale
 from sklearn.preprocessing.data import Binarizer
 from sklearn.preprocessing.data import KernelCenterer
 from sklearn.preprocessing.data import Normalizer
 from sklearn.preprocessing.data import normalize
-from sklearn.preprocessing.data import OneHotEncoder
-from sklearn.preprocessing.data import CategoricalEncoder
 from sklearn.preprocessing.data import StandardScaler
 from sklearn.preprocessing.data import scale
 from sklearn.preprocessing.data import MinMaxScaler
@@ -60,6 +58,7 @@
 from sklearn.preprocessing.data import power_transform
 from sklearn.exceptions import DataConversionWarning, NotFittedError
 
+from sklearn.base import clone
 from sklearn.pipeline import Pipeline
 from sklearn.model_selection import cross_val_predict
 from sklearn.svm import SVR
@@ -701,6 +700,85 @@ def test_scaler_without_centering():
     assert_array_almost_equal(X_csc_scaled_back.toarray(), X)
 
 
+@pytest.mark.parametrize("with_mean", [True, False])
+@pytest.mark.parametrize("with_std", [True, False])
+@pytest.mark.parametrize("array_constructor",
+                         [np.asarray, sparse.csc_matrix, sparse.csr_matrix])
+def test_scaler_n_samples_seen_with_nan(with_mean, with_std,
+                                        array_constructor):
+    X = np.array([[0, 1, 3],
+                  [np.nan, 6, 10],
+                  [5, 4, np.nan],
+                  [8, 0, np.nan]],
+                 dtype=np.float64)
+    X = array_constructor(X)
+
+    if sparse.issparse(X) and with_mean:
+        pytest.skip("'with_mean=True' cannot be used with sparse matrix.")
+
+    transformer = StandardScaler(with_mean=with_mean, with_std=with_std)
+    transformer.fit(X)
+
+    assert_array_equal(transformer.n_samples_seen_, np.array([3, 4, 2]))
+
+
+def _check_identity_scalers_attributes(scaler_1, scaler_2):
+    assert scaler_1.mean_ is scaler_2.mean_ is None
+    assert scaler_1.var_ is scaler_2.var_ is None
+    assert scaler_1.scale_ is scaler_2.scale_ is None
+    assert scaler_1.n_samples_seen_ == scaler_2.n_samples_seen_
+
+
+def test_scaler_return_identity():
+    # test that the scaler return identity when with_mean and with_std are
+    # False
+    X_dense = np.array([[0, 1, 3],
+                        [5, 6, 0],
+                        [8, 0, 10]],
+                       dtype=np.float64)
+    X_csr = sparse.csr_matrix(X_dense)
+    X_csc = X_csr.tocsc()
+
+    transformer_dense = StandardScaler(with_mean=False, with_std=False)
+    X_trans_dense = transformer_dense.fit_transform(X_dense)
+
+    transformer_csr = clone(transformer_dense)
+    X_trans_csr = transformer_csr.fit_transform(X_csr)
+
+    transformer_csc = clone(transformer_dense)
+    X_trans_csc = transformer_csc.fit_transform(X_csc)
+
+    assert_allclose_dense_sparse(X_trans_csr, X_csr)
+    assert_allclose_dense_sparse(X_trans_csc, X_csc)
+    assert_allclose(X_trans_dense, X_dense)
+
+    for trans_1, trans_2 in itertools.combinations([transformer_dense,
+                                                    transformer_csr,
+                                                    transformer_csc],
+                                                   2):
+        _check_identity_scalers_attributes(trans_1, trans_2)
+
+    transformer_dense.partial_fit(X_dense)
+    transformer_csr.partial_fit(X_csr)
+    transformer_csc.partial_fit(X_csc)
+
+    for trans_1, trans_2 in itertools.combinations([transformer_dense,
+                                                    transformer_csr,
+                                                    transformer_csc],
+                                                   2):
+        _check_identity_scalers_attributes(trans_1, trans_2)
+
+    transformer_dense.fit(X_dense)
+    transformer_csr.fit(X_csr)
+    transformer_csc.fit(X_csc)
+
+    for trans_1, trans_2 in itertools.combinations([transformer_dense,
+                                                    transformer_csr,
+                                                    transformer_csc],
+                                                   2):
+        _check_identity_scalers_attributes(trans_1, trans_2)
+
+
 def test_scaler_int():
     # test that scaler converts integer input to floating
     # for both sparse and dense matrices
@@ -822,14 +900,9 @@ def test_scale_sparse_with_mean_raise_exception():
 
 def test_scale_input_finiteness_validation():
     # Check if non finite inputs raise ValueError
-    X = [[np.nan, 5, 6, 7, 8]]
-    assert_raises_regex(ValueError,
-                        "Input contains NaN, infinity or a value too large",
-                        scale, X)
-
     X = [[np.inf, 5, 6, 7, 8]]
     assert_raises_regex(ValueError,
-                        "Input contains NaN, infinity or a value too large",
+                        "Input contains infinity or a value too large",
                         scale, X)
 
 
@@ -1836,416 +1909,6 @@ def test_add_dummy_feature_csr():
     assert_array_equal(X.toarray(), [[1, 1, 0], [1, 0, 1], [1, 0, 1]])
 
 
-def test_one_hot_encoder_sparse():
-    # Test OneHotEncoder's fit and transform.
-    X = [[3, 2, 1], [0, 1, 1]]
-    enc = OneHotEncoder()
-    # discover max values automatically
-    X_trans = enc.fit_transform(X).toarray()
-    assert_equal(X_trans.shape, (2, 5))
-    assert_array_equal(enc.active_features_,
-                       np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])
-    assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])
-
-    # check outcome
-    assert_array_equal(X_trans,
-                       [[0., 1., 0., 1., 1.],
-                        [1., 0., 1., 0., 1.]])
-
-    # max value given as 3
-    enc = OneHotEncoder(n_values=4)
-    X_trans = enc.fit_transform(X)
-    assert_equal(X_trans.shape, (2, 4 * 3))
-    assert_array_equal(enc.feature_indices_, [0, 4, 8, 12])
-
-    # max value given per feature
-    enc = OneHotEncoder(n_values=[3, 2, 2])
-    X = [[1, 0, 1], [0, 1, 1]]
-    X_trans = enc.fit_transform(X)
-    assert_equal(X_trans.shape, (2, 3 + 2 + 2))
-    assert_array_equal(enc.n_values_, [3, 2, 2])
-    # check that testing with larger feature works:
-    X = np.array([[2, 0, 1], [0, 1, 1]])
-    enc.transform(X)
-
-    # test that an error is raised when out of bounds:
-    X_too_large = [[0, 2, 1], [0, 1, 1]]
-    assert_raises(ValueError, enc.transform, X_too_large)
-    error_msg = r"unknown categorical feature present \[2\] during transform."
-    assert_raises_regex(ValueError, error_msg, enc.transform, X_too_large)
-    assert_raises(ValueError, OneHotEncoder(n_values=2).fit_transform, X)
-
-    # test that error is raised when wrong number of features
-    assert_raises(ValueError, enc.transform, X[:, :-1])
-    # test that error is raised when wrong number of features in fit
-    # with prespecified n_values
-    assert_raises(ValueError, enc.fit, X[:, :-1])
-    # test exception on wrong init param
-    assert_raises(TypeError, OneHotEncoder(n_values=np.int).fit, X)
-
-    enc = OneHotEncoder()
-    # test negative input to fit
-    assert_raises(ValueError, enc.fit, [[0], [-1]])
-
-    # test negative input to transform
-    enc.fit([[0], [1]])
-    assert_raises(ValueError, enc.transform, [[0], [-1]])
-
-
-def test_one_hot_encoder_dense():
-    # check for sparse=False
-    X = [[3, 2, 1], [0, 1, 1]]
-    enc = OneHotEncoder(sparse=False)
-    # discover max values automatically
-    X_trans = enc.fit_transform(X)
-    assert_equal(X_trans.shape, (2, 5))
-    assert_array_equal(enc.active_features_,
-                       np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])
-    assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])
-
-    # check outcome
-    assert_array_equal(X_trans,
-                       np.array([[0., 1., 0., 1., 1.],
-                                 [1., 0., 1., 0., 1.]]))
-
-
-def _check_transform_selected(X, X_expected, sel):
-    for M in (X, sparse.csr_matrix(X)):
-        Xtr = _transform_selected(M, Binarizer().transform, sel)
-        assert_array_equal(toarray(Xtr), X_expected)
-
-
-def test_transform_selected():
-    X = [[3, 2, 1], [0, 1, 1]]
-
-    X_expected = [[1, 2, 1], [0, 1, 1]]
-    _check_transform_selected(X, X_expected, [0])
-    _check_transform_selected(X, X_expected, [True, False, False])
-
-    X_expected = [[1, 1, 1], [0, 1, 1]]
-    _check_transform_selected(X, X_expected, [0, 1, 2])
-    _check_transform_selected(X, X_expected, [True, True, True])
-    _check_transform_selected(X, X_expected, "all")
-
-    _check_transform_selected(X, X, [])
-    _check_transform_selected(X, X, [False, False, False])
-
-
-def test_transform_selected_copy_arg():
-    # transformer that alters X
-    def _mutating_transformer(X):
-        X[0, 0] = X[0, 0] + 1
-        return X
-
-    original_X = np.asarray([[1, 2], [3, 4]])
-    expected_Xtr = [[2, 2], [3, 4]]
-
-    X = original_X.copy()
-    Xtr = _transform_selected(X, _mutating_transformer, copy=True,
-                              selected='all')
-
-    assert_array_equal(toarray(X), toarray(original_X))
-    assert_array_equal(toarray(Xtr), expected_Xtr)
-
-
-def _run_one_hot(X, X2, cat):
-    enc = OneHotEncoder(categorical_features=cat)
-    Xtr = enc.fit_transform(X)
-    X2tr = enc.transform(X2)
-    return Xtr, X2tr
-
-
-def _check_one_hot(X, X2, cat, n_features):
-    ind = np.where(cat)[0]
-    # With mask
-    A, B = _run_one_hot(X, X2, cat)
-    # With indices
-    C, D = _run_one_hot(X, X2, ind)
-    # Check shape
-    assert_equal(A.shape, (2, n_features))
-    assert_equal(B.shape, (1, n_features))
-    assert_equal(C.shape, (2, n_features))
-    assert_equal(D.shape, (1, n_features))
-    # Check that mask and indices give the same results
-    assert_array_equal(toarray(A), toarray(C))
-    assert_array_equal(toarray(B), toarray(D))
-
-
-def test_one_hot_encoder_categorical_features():
-    X = np.array([[3, 2, 1], [0, 1, 1]])
-    X2 = np.array([[1, 1, 1]])
-
-    cat = [True, False, False]
-    _check_one_hot(X, X2, cat, 4)
-
-    # Edge case: all non-categorical
-    cat = [False, False, False]
-    _check_one_hot(X, X2, cat, 3)
-
-    # Edge case: all categorical
-    cat = [True, True, True]
-    _check_one_hot(X, X2, cat, 5)
-
-
-def test_one_hot_encoder_unknown_transform():
-    X = np.array([[0, 2, 1], [1, 0, 3], [1, 0, 2]])
-    y = np.array([[4, 1, 1]])
-
-    # Test that one hot encoder raises error for unknown features
-    # present during transform.
-    oh = OneHotEncoder(handle_unknown='error')
-    oh.fit(X)
-    assert_raises(ValueError, oh.transform, y)
-
-    # Test the ignore option, ignores unknown features.
-    oh = OneHotEncoder(handle_unknown='ignore')
-    oh.fit(X)
-    assert_array_equal(
-        oh.transform(y).toarray(),
-        np.array([[0.,  0.,  0.,  0.,  1.,  0.,  0.]]))
-
-    # Raise error if handle_unknown is neither ignore or error.
-    oh = OneHotEncoder(handle_unknown='42')
-    oh.fit(X)
-    assert_raises(ValueError, oh.transform, y)
-
-
-def check_categorical_onehot(X):
-    enc = CategoricalEncoder(encoding='onehot')
-    Xtr1 = enc.fit_transform(X)
-
-    enc = CategoricalEncoder(encoding='onehot-dense')
-    Xtr2 = enc.fit_transform(X)
-
-    assert_allclose(Xtr1.toarray(), Xtr2)
-
-    assert sparse.isspmatrix_csr(Xtr1)
-    return Xtr1.toarray()
-
-
-def test_categorical_encoder_onehot():
-    X = [['abc', 1, 55], ['def', 2, 55]]
-
-    Xtr = check_categorical_onehot(np.array(X)[:, [0]])
-    assert_allclose(Xtr, [[1, 0], [0, 1]])
-
-    Xtr = check_categorical_onehot(np.array(X)[:, [0, 1]])
-    assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
-
-    Xtr = CategoricalEncoder().fit_transform(X)
-    assert_allclose(Xtr.toarray(), [[1, 0, 1, 0,  1], [0, 1, 0, 1, 1]])
-
-
-def test_categorical_encoder_onehot_inverse():
-    for encoding in ['onehot', 'onehot-dense']:
-        X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
-        enc = CategoricalEncoder(encoding=encoding)
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X, dtype=object)
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
-
-        X = [[2, 55], [1, 55], [3, 55]]
-        enc = CategoricalEncoder(encoding=encoding)
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X)
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
-
-        # with unknown categories
-        X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
-        enc = CategoricalEncoder(encoding=encoding, handle_unknown='ignore',
-                                 categories=[['abc', 'def'], [1, 2],
-                                             [54, 55, 56]])
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X, dtype=object)
-        exp[2, 1] = None
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
-
-        # with an otherwise numerical output, still object if unknown
-        X = [[2, 55], [1, 55], [3, 55]]
-        enc = CategoricalEncoder(encoding=encoding,
-                                 categories=[[1, 2], [54, 56]],
-                                 handle_unknown='ignore')
-        X_tr = enc.fit_transform(X)
-        exp = np.array(X, dtype=object)
-        exp[2, 0] = None
-        exp[:, 1] = None
-        assert_array_equal(enc.inverse_transform(X_tr), exp)
-
-        # incorrect shape raises
-        X_tr = np.array([[0, 1, 1], [1, 0, 1]])
-        msg = re.escape('Shape of the passed X data is not correct')
-        assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
-
-
-def test_categorical_encoder_handle_unknown():
-    X = np.array([[1, 2, 3], [4, 5, 6]])
-    X2 = np.array([[7, 5, 3]])
-
-    # Test that encoder raises error for unknown features during transform.
-    enc = CategoricalEncoder()
-    enc.fit(X)
-    msg = re.escape('unknown categories [7] in column 0')
-    assert_raises_regex(ValueError, msg, enc.transform, X2)
-
-    # With 'ignore' you get all 0's in result
-    enc = CategoricalEncoder(handle_unknown='ignore')
-    enc.fit(X)
-    X2_passed = X2.copy()
-    Xtr = enc.transform(X2_passed)
-    assert_allclose(Xtr.toarray(), [[0, 0, 0, 1, 1, 0]])
-    # ensure transformed data was not modified in place
-    assert_allclose(X2, X2_passed)
-
-    # Invalid option
-    enc = CategoricalEncoder(handle_unknown='invalid')
-    assert_raises(ValueError, enc.fit, X)
-
-
-def test_categorical_encoder_categories():
-    X = [['abc', 1, 55], ['def', 2, 55]]
-
-    # order of categories should not depend on order of samples
-    for Xi in [X, X[::-1]]:
-        enc = CategoricalEncoder()
-        enc.fit(Xi)
-        assert enc.categories == 'auto'
-        assert isinstance(enc.categories_, list)
-        cat_exp = [['abc', 'def'], [1, 2], [55]]
-        for res, exp in zip(enc.categories_, cat_exp):
-            assert res.tolist() == exp
-
-
-def test_categorical_encoder_specified_categories():
-    X = np.array([['a', 'b']], dtype=object).T
-
-    enc = CategoricalEncoder(categories=[['a', 'b', 'c']])
-    exp = np.array([[1., 0., 0.],
-                    [0., 1., 0.]])
-    assert_array_equal(enc.fit_transform(X).toarray(), exp)
-    assert enc.categories[0] == ['a', 'b', 'c']
-    assert enc.categories_[0].tolist() == ['a', 'b', 'c']
-    assert np.issubdtype(enc.categories_[0].dtype, np.str_)
-
-    # unsorted passed categories raises for now
-    enc = CategoricalEncoder(categories=[['c', 'b', 'a']])
-    msg = re.escape('Unsorted categories are not yet supported')
-    assert_raises_regex(ValueError, msg, enc.fit_transform, X)
-
-    # multiple columns
-    X = np.array([['a', 'b'], [0, 2]], dtype=object).T
-    enc = CategoricalEncoder(categories=[['a', 'b', 'c'], [0, 1, 2]])
-    exp = np.array([[1., 0., 0., 1., 0., 0.],
-                    [0., 1., 0., 0., 0., 1.]])
-    assert_array_equal(enc.fit_transform(X).toarray(), exp)
-    assert enc.categories_[0].tolist() == ['a', 'b', 'c']
-    assert np.issubdtype(enc.categories_[0].dtype, np.str_)
-    assert enc.categories_[1].tolist() == [0, 1, 2]
-    assert np.issubdtype(enc.categories_[1].dtype, np.integer)
-
-    # when specifying categories manually, unknown categories should already
-    # raise when fitting
-    X = np.array([['a', 'b', 'c']]).T
-    enc = CategoricalEncoder(categories=[['a', 'b']])
-    assert_raises(ValueError, enc.fit, X)
-    enc = CategoricalEncoder(categories=[['a', 'b']], handle_unknown='ignore')
-    exp = np.array([[1., 0.], [0., 1.], [0., 0.]])
-    assert_array_equal(enc.fit(X).transform(X).toarray(), exp)
-
-
-def test_categorical_encoder_pandas():
-    try:
-        import pandas as pd
-    except ImportError:
-        raise SkipTest("pandas is not installed")
-
-    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})
-
-    Xtr = check_categorical_onehot(X_df)
-    assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
-
-
-def test_categorical_encoder_ordinal():
-    X = [['abc', 2, 55], ['def', 1, 55]]
-
-    enc = CategoricalEncoder(encoding='other')
-    assert_raises(ValueError, enc.fit, X)
-
-    enc = CategoricalEncoder(encoding='ordinal', handle_unknown='ignore')
-    assert_raises(ValueError, enc.fit, X)
-
-    enc = CategoricalEncoder(encoding='ordinal')
-    exp = np.array([[0, 1, 0],
-                    [1, 0, 0]], dtype='int64')
-    assert_array_equal(enc.fit_transform(X), exp.astype('float64'))
-    enc = CategoricalEncoder(encoding='ordinal', dtype='int64')
-    assert_array_equal(enc.fit_transform(X), exp)
-
-
-def test_categorical_encoder_ordinal_inverse():
-    X = [['abc', 2, 55], ['def', 1, 55]]
-    enc = CategoricalEncoder(encoding='ordinal')
-    X_tr = enc.fit_transform(X)
-    exp = np.array(X, dtype=object)
-    assert_array_equal(enc.inverse_transform(X_tr), exp)
-
-    # incorrect shape raises
-    X_tr = np.array([[0, 1, 1, 2], [1, 0, 1, 0]])
-    msg = re.escape('Shape of the passed X data is not correct')
-    assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
-
-
-def test_categorical_encoder_dtypes():
-    # check that dtypes are preserved when determining categories
-    enc = CategoricalEncoder()
-    exp = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')
-
-    for X in [np.array([[1, 2], [3, 4]], dtype='int64'),
-              np.array([[1, 2], [3, 4]], dtype='float64'),
-              np.array([['a', 'b'], ['c', 'd']]),  # string dtype
-              np.array([[1, 'a'], [3, 'b']], dtype='object')]:
-        enc.fit(X)
-        assert all([enc.categories_[i].dtype == X.dtype for i in range(2)])
-        assert_array_equal(enc.transform(X).toarray(), exp)
-
-    X = [[1, 2], [3, 4]]
-    enc.fit(X)
-    assert all([np.issubdtype(enc.categories_[i].dtype, np.integer)
-                for i in range(2)])
-    assert_array_equal(enc.transform(X).toarray(), exp)
-
-    X = [[1, 'a'], [3, 'b']]
-    enc.fit(X)
-    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])
-    assert_array_equal(enc.transform(X).toarray(), exp)
-
-
-def test_categorical_encoder_dtypes_pandas():
-    # check dtype (similar to test_categorical_encoder_dtypes for dataframes)
-    try:
-        import pandas as pd
-    except ImportError:
-        raise SkipTest("pandas is not installed")
-
-    enc = CategoricalEncoder()
-    exp = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')
-
-    X = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}, dtype='int64')
-    enc.fit(X)
-    assert all([enc.categories_[i].dtype == 'int64' for i in range(2)])
-    assert_array_equal(enc.transform(X).toarray(), exp)
-
-    X = pd.DataFrame({'A': [1, 2], 'B': ['a', 'b']})
-    enc.fit(X)
-    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])
-    assert_array_equal(enc.transform(X).toarray(), exp)
-
-
-def test_categorical_encoder_warning():
-    enc = CategoricalEncoder()
-    X = [['Male', 1], ['Female', 3]]
-    np.testing.assert_no_warnings(enc.fit_transform, X)
-
-
 def test_fit_cold_start():
     X = iris.data
     X_2d = X[:, :2]
diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py
new file mode 100644
index 000000000000..e9abce28c863
--- /dev/null
+++ b/sklearn/preprocessing/tests/test_encoders.py
@@ -0,0 +1,542 @@
+from __future__ import division
+
+import re
+
+import numpy as np
+from scipy import sparse
+import pytest
+
+from sklearn.utils.testing import assert_array_equal
+from sklearn.utils.testing import assert_equal
+from sklearn.utils.testing import assert_raises
+from sklearn.utils.testing import assert_raises_regex
+from sklearn.utils.testing import assert_allclose
+from sklearn.utils.testing import ignore_warnings
+from sklearn.utils.testing import assert_warns
+from sklearn.utils.testing import assert_warns_message
+from sklearn.utils.testing import assert_no_warnings
+
+from sklearn.preprocessing._encoders import _transform_selected
+from sklearn.preprocessing.data import Binarizer
+from sklearn.preprocessing import OneHotEncoder
+from sklearn.preprocessing import OrdinalEncoder
+
+
+def toarray(a):
+    if hasattr(a, "toarray"):
+        a = a.toarray()
+    return a
+
+
+def test_one_hot_encoder_sparse():
+    # Test OneHotEncoder's fit and transform.
+    X = [[3, 2, 1], [0, 1, 1]]
+    enc = OneHotEncoder()
+    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
+        # discover max values automatically
+        X_trans = enc.fit_transform(X).toarray()
+        assert_equal(X_trans.shape, (2, 5))
+        assert_array_equal(enc.active_features_,
+                           np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])
+        assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])
+
+        # check outcome
+        assert_array_equal(X_trans,
+                           [[0., 1., 0., 1., 1.],
+                            [1., 0., 1., 0., 1.]])
+
+    # max value given as 3
+    # enc = assert_warns(DeprecationWarning, OneHotEncoder, n_values=4)
+    enc = OneHotEncoder(n_values=4)
+    with ignore_warnings(category=DeprecationWarning):
+        X_trans = enc.fit_transform(X)
+        assert_equal(X_trans.shape, (2, 4 * 3))
+        assert_array_equal(enc.feature_indices_, [0, 4, 8, 12])
+
+    # max value given per feature
+    # enc = assert_warns(DeprecationWarning, OneHotEncoder, n_values=[3, 2, 2])
+    enc = OneHotEncoder(n_values=[3, 2, 2])
+    with ignore_warnings(category=DeprecationWarning):
+        X = [[1, 0, 1], [0, 1, 1]]
+        X_trans = enc.fit_transform(X)
+        assert_equal(X_trans.shape, (2, 3 + 2 + 2))
+        assert_array_equal(enc.n_values_, [3, 2, 2])
+    # check that testing with larger feature works:
+    X = np.array([[2, 0, 1], [0, 1, 1]])
+    enc.transform(X)
+
+    # test that an error is raised when out of bounds:
+    X_too_large = [[0, 2, 1], [0, 1, 1]]
+    assert_raises(ValueError, enc.transform, X_too_large)
+    error_msg = r"unknown categorical feature present \[2\] during transform"
+    assert_raises_regex(ValueError, error_msg, enc.transform, X_too_large)
+    with ignore_warnings(category=DeprecationWarning):
+        assert_raises(
+            ValueError,
+            OneHotEncoder(n_values=2).fit_transform, X)
+
+    # test that error is raised when wrong number of features
+    assert_raises(ValueError, enc.transform, X[:, :-1])
+
+    # test that error is raised when wrong number of features in fit
+    # with prespecified n_values
+    with ignore_warnings(category=DeprecationWarning):
+        assert_raises(ValueError, enc.fit, X[:, :-1])
+    # test exception on wrong init param
+    with ignore_warnings(category=DeprecationWarning):
+        assert_raises(
+            TypeError, OneHotEncoder(n_values=np.int).fit, X)
+
+    enc = OneHotEncoder()
+    # test negative input to fit
+    with ignore_warnings(category=FutureWarning):
+        assert_raises(ValueError, enc.fit, [[0], [-1]])
+
+    # test negative input to transform
+    with ignore_warnings(category=FutureWarning):
+        enc.fit([[0], [1]])
+    assert_raises(ValueError, enc.transform, [[0], [-1]])
+
+
+def test_one_hot_encoder_dense():
+    # check for sparse=False
+    X = [[3, 2, 1], [0, 1, 1]]
+    enc = OneHotEncoder(sparse=False)
+    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
+        # discover max values automatically
+        X_trans = enc.fit_transform(X)
+        assert_equal(X_trans.shape, (2, 5))
+        assert_array_equal(enc.active_features_,
+                           np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])
+        assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])
+
+    # check outcome
+    assert_array_equal(X_trans,
+                       np.array([[0., 1., 0., 1., 1.],
+                                 [1., 0., 1., 0., 1.]]))
+
+
+def test_one_hot_encoder_deprecationwarnings():
+    for X in [[[3, 2, 1], [0, 1, 1]],
+              [[3., 2., 1.], [0., 1., 1.]]]:
+        enc = OneHotEncoder()
+        assert_warns_message(FutureWarning, "handling of integer",
+                             enc.fit, X)
+        enc = OneHotEncoder()
+        assert_warns_message(FutureWarning, "handling of integer",
+                             enc.fit_transform, X)
+
+        # check it still works correctly as well
+        with ignore_warnings(category=FutureWarning):
+            X_trans = enc.fit_transform(X).toarray()
+        res = [[0., 1., 0., 1., 1.],
+               [1., 0., 1., 0., 1.]]
+        assert_array_equal(X_trans, res)
+
+        # check deprecated attributes
+        assert_warns(DeprecationWarning, lambda: enc.active_features_)
+        assert_warns(DeprecationWarning, lambda: enc.feature_indices_)
+        assert_warns(DeprecationWarning, lambda: enc.n_values_)
+
+        # check no warning is raised if keyword is specified
+        enc = OneHotEncoder(categories='auto')
+        assert_no_warnings(enc.fit, X)
+        enc = OneHotEncoder(categories='auto')
+        assert_no_warnings(enc.fit_transform, X)
+        X_trans = enc.fit_transform(X).toarray()
+        assert_array_equal(X_trans, res)
+
+        # check there is also a warning if the default is passed
+        enc = OneHotEncoder(n_values='auto', handle_unknown='ignore')
+        assert_warns(DeprecationWarning, enc.fit, X)
+
+    X = np.array([['cat1', 'cat2']], dtype=object).T
+    enc = OneHotEncoder(categorical_features='all')
+    assert_warns(DeprecationWarning, enc.fit, X)
+
+
+def test_one_hot_encoder_force_new_behaviour():
+    # ambiguous integer case (non secutive range of categories)
+    X = np.array([[1, 2]]).T
+    X2 = np.array([[0, 1]]).T
+
+    # without argument -> by default using legacy behaviour with warnings
+    enc = OneHotEncoder()
+
+    with ignore_warnings(category=FutureWarning):
+        enc.fit(X)
+
+    res = enc.transform(X2)
+    exp = np.array([[0, 0], [1, 0]])
+    assert_array_equal(res.toarray(), exp)
+
+    # with explicit auto argument -> don't use legacy behaviour
+    # (so will raise an error on unseen value within range)
+    enc = OneHotEncoder(categories='auto')
+    enc.fit(X)
+    assert_raises(ValueError, enc.transform, X2)
+
+
+def _check_transform_selected(X, X_expected, dtype, sel):
+    for M in (X, sparse.csr_matrix(X)):
+        Xtr = _transform_selected(M, Binarizer().transform, dtype, sel)
+        assert_array_equal(toarray(Xtr), X_expected)
+
+
+@pytest.mark.parametrize("output_dtype", [np.int32, np.float32, np.float64])
+@pytest.mark.parametrize("input_dtype", [np.int32, np.float32, np.float64])
+def test_transform_selected(output_dtype, input_dtype):
+    X = np.asarray([[3, 2, 1], [0, 1, 1]], dtype=input_dtype)
+
+    X_expected = np.asarray([[1, 2, 1], [0, 1, 1]], dtype=output_dtype)
+    _check_transform_selected(X, X_expected, output_dtype, [0])
+    _check_transform_selected(X, X_expected, output_dtype,
+                              [True, False, False])
+
+    X_expected = np.asarray([[1, 1, 1], [0, 1, 1]], dtype=output_dtype)
+    _check_transform_selected(X, X_expected, output_dtype, [0, 1, 2])
+    _check_transform_selected(X, X_expected, output_dtype, [True, True, True])
+    _check_transform_selected(X, X_expected, output_dtype, "all")
+
+    _check_transform_selected(X, X, output_dtype, [])
+    _check_transform_selected(X, X, output_dtype, [False, False, False])
+
+
+@pytest.mark.parametrize("output_dtype", [np.int32, np.float32, np.float64])
+@pytest.mark.parametrize("input_dtype", [np.int32, np.float32, np.float64])
+def test_transform_selected_copy_arg(output_dtype, input_dtype):
+    # transformer that alters X
+    def _mutating_transformer(X):
+        X[0, 0] = X[0, 0] + 1
+        return X
+
+    original_X = np.asarray([[1, 2], [3, 4]], dtype=input_dtype)
+    expected_Xtr = np.asarray([[2, 2], [3, 4]], dtype=output_dtype)
+
+    X = original_X.copy()
+    Xtr = _transform_selected(X, _mutating_transformer, output_dtype,
+                              copy=True, selected='all')
+
+    assert_array_equal(toarray(X), toarray(original_X))
+    assert_array_equal(toarray(Xtr), expected_Xtr)
+
+
+def _run_one_hot(X, X2, cat):
+    # enc = assert_warns(
+    #     DeprecationWarning,
+    #     OneHotEncoder, categorical_features=cat)
+    enc = OneHotEncoder(categorical_features=cat)
+    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
+        Xtr = enc.fit_transform(X)
+    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):
+        X2tr = enc.fit(X).transform(X2)
+    return Xtr, X2tr
+
+
+def _check_one_hot(X, X2, cat, n_features):
+    ind = np.where(cat)[0]
+    # With mask
+    A, B = _run_one_hot(X, X2, cat)
+    # With indices
+    C, D = _run_one_hot(X, X2, ind)
+    # Check shape
+    assert_equal(A.shape, (2, n_features))
+    assert_equal(B.shape, (1, n_features))
+    assert_equal(C.shape, (2, n_features))
+    assert_equal(D.shape, (1, n_features))
+    # Check that mask and indices give the same results
+    assert_array_equal(toarray(A), toarray(C))
+    assert_array_equal(toarray(B), toarray(D))
+
+
+def test_one_hot_encoder_categorical_features():
+    X = np.array([[3, 2, 1], [0, 1, 1]])
+    X2 = np.array([[1, 1, 1]])
+
+    cat = [True, False, False]
+    _check_one_hot(X, X2, cat, 4)
+
+    # Edge case: all non-categorical
+    cat = [False, False, False]
+    _check_one_hot(X, X2, cat, 3)
+
+    # Edge case: all categorical
+    cat = [True, True, True]
+    _check_one_hot(X, X2, cat, 5)
+
+    # check error raised if also specifying categories
+    oh = OneHotEncoder(categories=[range(3)],
+                       categorical_features=[True, False, False])
+    assert_raises(ValueError, oh.fit, X)
+
+
+def test_one_hot_encoder_handle_unknown():
+    X = np.array([[0, 2, 1], [1, 0, 3], [1, 0, 2]])
+    X2 = np.array([[4, 1, 1]])
+
+    # Test that one hot encoder raises error for unknown features
+    # present during transform.
+    oh = OneHotEncoder(handle_unknown='error')
+    assert_warns(FutureWarning, oh.fit, X)
+    assert_raises(ValueError, oh.transform, X2)
+
+    # Test the ignore option, ignores unknown features (giving all 0's)
+    oh = OneHotEncoder(handle_unknown='ignore')
+    oh.fit(X)
+    X2_passed = X2.copy()
+    assert_array_equal(
+        oh.transform(X2_passed).toarray(),
+        np.array([[0.,  0.,  0.,  0.,  1.,  0.,  0.]]))
+    # ensure transformed data was not modified in place
+    assert_allclose(X2, X2_passed)
+
+    # Raise error if handle_unknown is neither ignore or error.
+    oh = OneHotEncoder(handle_unknown='42')
+    assert_raises(ValueError, oh.fit, X)
+
+
+@pytest.mark.parametrize("output_dtype", [np.int32, np.float32, np.float64])
+@pytest.mark.parametrize("input_dtype", [np.int32, np.float32, np.float64])
+def test_one_hot_encoder_dtype(input_dtype, output_dtype):
+    X = np.asarray([[0, 1]], dtype=input_dtype).T
+    X_expected = np.asarray([[1, 0], [0, 1]], dtype=output_dtype)
+
+    oh = OneHotEncoder(categories='auto', dtype=output_dtype)
+    assert_array_equal(oh.fit_transform(X).toarray(), X_expected)
+    assert_array_equal(oh.fit(X).transform(X).toarray(), X_expected)
+
+    oh = OneHotEncoder(categories='auto', dtype=output_dtype, sparse=False)
+    assert_array_equal(oh.fit_transform(X), X_expected)
+    assert_array_equal(oh.fit(X).transform(X), X_expected)
+
+
+@pytest.mark.parametrize("output_dtype", [np.int32, np.float32, np.float64])
+def test_one_hot_encoder_dtype_pandas(output_dtype):
+    pd = pytest.importorskip('pandas')
+
+    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})
+    X_expected = np.array([[1, 0, 1, 0], [0, 1, 0, 1]], dtype=output_dtype)
+
+    oh = OneHotEncoder(dtype=output_dtype)
+    assert_array_equal(oh.fit_transform(X_df).toarray(), X_expected)
+    assert_array_equal(oh.fit(X_df).transform(X_df).toarray(), X_expected)
+
+    oh = OneHotEncoder(dtype=output_dtype, sparse=False)
+    assert_array_equal(oh.fit_transform(X_df), X_expected)
+    assert_array_equal(oh.fit(X_df).transform(X_df), X_expected)
+
+
+def test_one_hot_encoder_set_params():
+    X = np.array([[1, 2]]).T
+    oh = OneHotEncoder()
+    # set params on not yet fitted object
+    oh.set_params(categories=[[0, 1, 2, 3]])
+    assert oh.get_params()['categories'] == [[0, 1, 2, 3]]
+    assert oh.fit_transform(X).toarray().shape == (2, 4)
+    # set params on already fitted object
+    oh.set_params(categories=[[0, 1, 2, 3, 4]])
+    assert oh.fit_transform(X).toarray().shape == (2, 5)
+
+
+def check_categorical_onehot(X):
+    enc = OneHotEncoder()
+    Xtr1 = enc.fit_transform(X)
+
+    enc = OneHotEncoder(sparse=False)
+    Xtr2 = enc.fit_transform(X)
+
+    assert_allclose(Xtr1.toarray(), Xtr2)
+
+    assert sparse.isspmatrix_csr(Xtr1)
+    return Xtr1.toarray()
+
+
+def test_one_hot_encoder():
+    X = [['abc', 1, 55], ['def', 2, 55]]
+
+    Xtr = check_categorical_onehot(np.array(X)[:, [0]])
+    assert_allclose(Xtr, [[1, 0], [0, 1]])
+
+    Xtr = check_categorical_onehot(np.array(X)[:, [0, 1]])
+    assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
+
+    Xtr = OneHotEncoder().fit_transform(X)
+    assert_allclose(Xtr.toarray(), [[1, 0, 1, 0,  1], [0, 1, 0, 1, 1]])
+
+
+def test_one_hot_encoder_inverse():
+    for sparse_ in [True, False]:
+        X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
+        enc = OneHotEncoder(sparse=sparse_)
+        X_tr = enc.fit_transform(X)
+        exp = np.array(X, dtype=object)
+        assert_array_equal(enc.inverse_transform(X_tr), exp)
+
+        X = [[2, 55], [1, 55], [3, 55]]
+        enc = OneHotEncoder(sparse=sparse_, categories='auto')
+        X_tr = enc.fit_transform(X)
+        exp = np.array(X)
+        assert_array_equal(enc.inverse_transform(X_tr), exp)
+
+        # with unknown categories
+        X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]
+        enc = OneHotEncoder(sparse=sparse_, handle_unknown='ignore',
+                            categories=[['abc', 'def'], [1, 2],
+                                        [54, 55, 56]])
+        X_tr = enc.fit_transform(X)
+        exp = np.array(X, dtype=object)
+        exp[2, 1] = None
+        assert_array_equal(enc.inverse_transform(X_tr), exp)
+
+        # with an otherwise numerical output, still object if unknown
+        X = [[2, 55], [1, 55], [3, 55]]
+        enc = OneHotEncoder(sparse=sparse_, categories=[[1, 2], [54, 56]],
+                            handle_unknown='ignore')
+        X_tr = enc.fit_transform(X)
+        exp = np.array(X, dtype=object)
+        exp[2, 0] = None
+        exp[:, 1] = None
+        assert_array_equal(enc.inverse_transform(X_tr), exp)
+
+        # incorrect shape raises
+        X_tr = np.array([[0, 1, 1], [1, 0, 1]])
+        msg = re.escape('Shape of the passed X data is not correct')
+        assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
+
+
+def test_one_hot_encoder_categories():
+    X = [['abc', 1, 55], ['def', 2, 55]]
+
+    # order of categories should not depend on order of samples
+    for Xi in [X, X[::-1]]:
+        enc = OneHotEncoder()
+        enc.fit(Xi)
+        # assert enc.categories == 'auto'
+        assert isinstance(enc.categories_, list)
+        cat_exp = [['abc', 'def'], [1, 2], [55]]
+        for res, exp in zip(enc.categories_, cat_exp):
+            assert res.tolist() == exp
+
+
+def test_one_hot_encoder_specified_categories():
+    X = np.array([['a', 'b']], dtype=object).T
+
+    enc = OneHotEncoder(categories=[['a', 'b', 'c']])
+    exp = np.array([[1., 0., 0.],
+                    [0., 1., 0.]])
+    assert_array_equal(enc.fit_transform(X).toarray(), exp)
+    assert enc.categories[0] == ['a', 'b', 'c']
+    assert enc.categories_[0].tolist() == ['a', 'b', 'c']
+    assert np.issubdtype(enc.categories_[0].dtype, np.str_)
+
+    # unsorted passed categories raises for now
+    enc = OneHotEncoder(categories=[['c', 'b', 'a']])
+    msg = re.escape('Unsorted categories are not yet supported')
+    assert_raises_regex(ValueError, msg, enc.fit_transform, X)
+
+    # multiple columns
+    X = np.array([['a', 'b'], [0, 2]], dtype=object).T
+    enc = OneHotEncoder(categories=[['a', 'b', 'c'], [0, 1, 2]])
+    exp = np.array([[1., 0., 0., 1., 0., 0.],
+                    [0., 1., 0., 0., 0., 1.]])
+    assert_array_equal(enc.fit_transform(X).toarray(), exp)
+    assert enc.categories_[0].tolist() == ['a', 'b', 'c']
+    assert np.issubdtype(enc.categories_[0].dtype, np.str_)
+    assert enc.categories_[1].tolist() == [0, 1, 2]
+    assert np.issubdtype(enc.categories_[1].dtype, np.integer)
+
+    # when specifying categories manually, unknown categories should already
+    # raise when fitting
+    X = np.array([['a', 'b', 'c']]).T
+    enc = OneHotEncoder(categories=[['a', 'b']])
+    assert_raises(ValueError, enc.fit, X)
+    enc = OneHotEncoder(categories=[['a', 'b']], handle_unknown='ignore')
+    exp = np.array([[1., 0.], [0., 1.], [0., 0.]])
+    assert_array_equal(enc.fit(X).transform(X).toarray(), exp)
+
+
+def test_one_hot_encoder_pandas():
+    pd = pytest.importorskip('pandas')
+
+    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})
+
+    Xtr = check_categorical_onehot(X_df)
+    assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
+
+
+def test_ordinal_encoder():
+    X = [['abc', 2, 55], ['def', 1, 55]]
+
+    enc = OrdinalEncoder()
+    exp = np.array([[0, 1, 0],
+                    [1, 0, 0]], dtype='int64')
+    assert_array_equal(enc.fit_transform(X), exp.astype('float64'))
+    enc = OrdinalEncoder(dtype='int64')
+    assert_array_equal(enc.fit_transform(X), exp)
+
+
+def test_ordinal_encoder_inverse():
+    X = [['abc', 2, 55], ['def', 1, 55]]
+    enc = OrdinalEncoder()
+    X_tr = enc.fit_transform(X)
+    exp = np.array(X, dtype=object)
+    assert_array_equal(enc.inverse_transform(X_tr), exp)
+
+    # incorrect shape raises
+    X_tr = np.array([[0, 1, 1, 2], [1, 0, 1, 0]])
+    msg = re.escape('Shape of the passed X data is not correct')
+    assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)
+
+
+def test_encoder_dtypes():
+    # check that dtypes are preserved when determining categories
+    enc = OneHotEncoder(categories='auto')
+    exp = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')
+
+    for X in [np.array([[1, 2], [3, 4]], dtype='int64'),
+              np.array([[1, 2], [3, 4]], dtype='float64'),
+              np.array([['a', 'b'], ['c', 'd']]),  # string dtype
+              np.array([[1, 'a'], [3, 'b']], dtype='object')]:
+        enc.fit(X)
+        assert all([enc.categories_[i].dtype == X.dtype for i in range(2)])
+        assert_array_equal(enc.transform(X).toarray(), exp)
+
+    X = [[1, 2], [3, 4]]
+    enc.fit(X)
+    assert all([np.issubdtype(enc.categories_[i].dtype, np.integer)
+                for i in range(2)])
+    assert_array_equal(enc.transform(X).toarray(), exp)
+
+    X = [[1, 'a'], [3, 'b']]
+    enc.fit(X)
+    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])
+    assert_array_equal(enc.transform(X).toarray(), exp)
+
+
+def test_encoder_dtypes_pandas():
+    # check dtype (similar to test_categorical_encoder_dtypes for dataframes)
+    pd = pytest.importorskip('pandas')
+
+    enc = OneHotEncoder(categories='auto')
+    exp = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')
+
+    X = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}, dtype='int64')
+    enc.fit(X)
+    assert all([enc.categories_[i].dtype == 'int64' for i in range(2)])
+    assert_array_equal(enc.transform(X).toarray(), exp)
+
+    X = pd.DataFrame({'A': [1, 2], 'B': ['a', 'b']})
+    enc.fit(X)
+    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])
+    assert_array_equal(enc.transform(X).toarray(), exp)
+
+
+def test_one_hot_encoder_warning():
+    enc = OneHotEncoder()
+    X = [['Male', 1], ['Female', 3]]
+    np.testing.assert_no_warnings(enc.fit_transform, X)
+
+
+def test_categorical_encoder_stub():
+    from sklearn.preprocessing import CategoricalEncoder
+    assert_raises(RuntimeError, CategoricalEncoder, encoding='ordinal')
diff --git a/sklearn/preprocessing/tests/test_label.py b/sklearn/preprocessing/tests/test_label.py
index 14788b14b521..faa0cc3ce275 100644
--- a/sklearn/preprocessing/tests/test_label.py
+++ b/sklearn/preprocessing/tests/test_label.py
@@ -482,7 +482,7 @@ def test_label_binarize_binary():
     neg_label = -1
     expected = np.array([[2, -1], [-1, 2], [2, -1]])[:, 1].reshape((-1, 1))
 
-    yield check_binarized_results, y, classes, pos_label, neg_label, expected
+    check_binarized_results(y, classes, pos_label, neg_label, expected)
 
     # Binary case where sparse_output = True will not result in a ValueError
     y = [0, 1, 0]
@@ -491,7 +491,7 @@ def test_label_binarize_binary():
     neg_label = 0
     expected = np.array([[3, 0], [0, 3], [3, 0]])[:, 1].reshape((-1, 1))
 
-    yield check_binarized_results, y, classes, pos_label, neg_label, expected
+    check_binarized_results(y, classes, pos_label, neg_label, expected)
 
 
 def test_label_binarize_multiclass():
@@ -501,7 +501,7 @@ def test_label_binarize_multiclass():
     neg_label = 0
     expected = 2 * np.eye(3)
 
-    yield check_binarized_results, y, classes, pos_label, neg_label, expected
+    check_binarized_results(y, classes, pos_label, neg_label, expected)
 
     assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,
                   pos_label=pos_label, sparse_output=True)
@@ -518,8 +518,8 @@ def test_label_binarize_multilabel():
                                       dok_matrix, lil_matrix]]
 
     for y in [y_ind] + y_sparse:
-        yield (check_binarized_results, y, classes, pos_label, neg_label,
-               expected)
+        check_binarized_results(y, classes, pos_label, neg_label,
+                                expected)
 
     assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,
                   pos_label=pos_label, sparse_output=True)
diff --git a/sklearn/svm/classes.py b/sklearn/svm/classes.py
index db9360e64fb4..b4c396b4ef76 100644
--- a/sklearn/svm/classes.py
+++ b/sklearn/svm/classes.py
@@ -1089,8 +1089,8 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):
 
     offset_ : float
         Offset used to define the decision function from the raw scores.
-        We have the relation: decision_function = score_samples - offset_.
-        The offset is the opposite of intercept_ and is provided for
+        We have the relation: decision_function = score_samples - `offset_`.
+        The offset is the opposite of `intercept_` and is provided for
         consistency with other outlier detection algorithms.
 
     """
diff --git a/sklearn/svm/tests/test_bounds.py b/sklearn/svm/tests/test_bounds.py
index e46dbb92df44..d02c53b05d8b 100644
--- a/sklearn/svm/tests/test_bounds.py
+++ b/sklearn/svm/tests/test_bounds.py
@@ -1,6 +1,8 @@
 import numpy as np
 from scipy import sparse as sp
 
+import pytest
+
 from sklearn.svm.bounds import l1_min_c
 from sklearn.svm import LinearSVC
 from sklearn.linear_model.logistic import LogisticRegression
@@ -16,25 +18,24 @@
 Y2 = [2, 1, 0, 0]
 
 
-def test_l1_min_c():
-    losses = ['squared_hinge', 'log']
+@pytest.mark.parametrize('loss', ['squared_hinge', 'log'])
+@pytest.mark.parametrize('X_label', ['sparse', 'dense'])
+@pytest.mark.parametrize('Y_label', ['two-classes', 'multi-class'])
+@pytest.mark.parametrize('intercept_label', ['no-intercept', 'fit-intercept'])
+def test_l1_min_c(loss, X_label, Y_label, intercept_label):
     Xs = {'sparse': sparse_X, 'dense': dense_X}
     Ys = {'two-classes': Y1, 'multi-class': Y2}
     intercepts = {'no-intercept': {'fit_intercept': False},
                   'fit-intercept': {'fit_intercept': True,
                                     'intercept_scaling': 10}}
 
-    for loss in losses:
-        for X_label, X in Xs.items():
-            for Y_label, Y in Ys.items():
-                for intercept_label, intercept_params in intercepts.items():
-                    check = lambda: check_l1_min_c(X, Y, loss,
-                                                   **intercept_params)
-                    check.description = ('Test l1_min_c loss=%r %s %s %s' %
-                                         (loss, X_label, Y_label,
-                                          intercept_label))
-                    yield check
+    X = Xs[X_label]
+    Y = Ys[Y_label]
+    intercept_params = intercepts[intercept_label]
+    check_l1_min_c(X, Y, loss, **intercept_params)
+
 
+def test_l1_min_c_l2_loss():
     # loss='l2' should raise ValueError
     assert_raise_message(ValueError, "loss type not in",
                          l1_min_c, dense_X, Y1, "l2")
diff --git a/sklearn/tests/test_common.py b/sklearn/tests/test_common.py
index 62a3bee5fc12..1f4c41ec8285 100644
--- a/sklearn/tests/test_common.py
+++ b/sklearn/tests/test_common.py
@@ -22,6 +22,7 @@
 from sklearn.utils.testing import assert_greater
 from sklearn.utils.testing import assert_in
 from sklearn.utils.testing import ignore_warnings
+from sklearn.exceptions import ConvergenceWarning
 
 import sklearn
 from sklearn.cluster.bicluster import BiclusterMixin
@@ -91,18 +92,22 @@ def _rename_partial(val):
 )
 def test_non_meta_estimators(name, Estimator, check):
     # Common tests for non-meta estimators
-    estimator = Estimator()
-    set_checking_parameters(estimator)
-    check(name, estimator)
+    with ignore_warnings(category=(DeprecationWarning, ConvergenceWarning,
+                                   UserWarning, FutureWarning)):
+        estimator = Estimator()
+        set_checking_parameters(estimator)
+        check(name, estimator)
 
 
 @pytest.mark.parametrize("name, Estimator",
                          _tested_non_meta_estimators())
 def test_no_attributes_set_in_init(name, Estimator):
     # input validation etc for non-meta estimators
-    estimator = Estimator()
-    # check this on class
-    check_no_attributes_set_in_init(name, estimator)
+    with ignore_warnings(category=(DeprecationWarning, ConvergenceWarning,
+                                   UserWarning, FutureWarning)):
+        estimator = Estimator()
+        # check this on class
+        check_no_attributes_set_in_init(name, estimator)
 
 
 def test_configure():
diff --git a/sklearn/tests/test_impute.py b/sklearn/tests/test_impute.py
index 954a016a835b..f5c42f744348 100644
--- a/sklearn/tests/test_impute.py
+++ b/sklearn/tests/test_impute.py
@@ -5,13 +5,15 @@
 import numpy as np
 from scipy import sparse
 
+import io
+
 from sklearn.utils.testing import assert_allclose
+from sklearn.utils.testing import assert_allclose_dense_sparse
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_array_almost_equal
-from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import assert_false
 
-from sklearn.impute import SimpleImputer, MICEImputer
+from sklearn.impute import SimpleImputer, ChainedImputer
 from sklearn.dummy import DummyRegressor
 from sklearn.linear_model import BayesianRidge, ARDRegression
 from sklearn.pipeline import Pipeline
@@ -24,18 +26,17 @@ def _check_statistics(X, X_true,
                       strategy, statistics, missing_values):
     """Utility function for testing imputation for a given strategy.
 
-    Test:
-        - along the two axes
-        - with dense and sparse arrays
+    Test with dense and sparse arrays
 
     Check that:
         - the statistics (mean, median, mode) are correct
         - the missing values are imputed correctly"""
 
     err_msg = "Parameters: strategy = %s, missing_values = %s, " \
-              "axis = {0}, sparse = {1}" % (strategy, missing_values)
+              "sparse = {0}" % (strategy, missing_values)
 
     assert_ae = assert_array_equal
+
     if X.dtype.kind == 'f' or X_true.dtype.kind == 'f':
         assert_ae = assert_array_almost_equal
 
@@ -43,8 +44,8 @@ def _check_statistics(X, X_true,
     imputer = SimpleImputer(missing_values, strategy=strategy)
     X_trans = imputer.fit(X).transform(X.copy())
     assert_ae(imputer.statistics_, statistics,
-              err_msg=err_msg.format(0, False))
-    assert_ae(X_trans, X_true, err_msg=err_msg.format(0, False))
+              err_msg=err_msg.format(False))
+    assert_ae(X_trans, X_true, err_msg=err_msg.format(False))
 
     # Sparse matrix
     imputer = SimpleImputer(missing_values, strategy=strategy)
@@ -55,8 +56,8 @@ def _check_statistics(X, X_true,
         X_trans = X_trans.toarray()
 
     assert_ae(imputer.statistics_, statistics,
-              err_msg=err_msg.format(0, True))
-    assert_ae(X_trans, X_true, err_msg=err_msg.format(0, True))
+              err_msg=err_msg.format(True))
+    assert_ae(X_trans, X_true, err_msg=err_msg.format(True))
 
 
 def test_imputation_shape():
@@ -64,18 +65,38 @@ def test_imputation_shape():
     X = np.random.randn(10, 2)
     X[::2] = np.nan
 
-    for strategy in ['mean', 'median', 'most_frequent']:
+    for strategy in ['mean', 'median', 'most_frequent', "constant"]:
         imputer = SimpleImputer(strategy=strategy)
         X_imputed = imputer.fit_transform(sparse.csr_matrix(X))
         assert X_imputed.shape == (10, 2)
         X_imputed = imputer.fit_transform(X)
         assert X_imputed.shape == (10, 2)
 
-        mice_imputer = MICEImputer(initial_strategy=strategy)
-        X_imputed = mice_imputer.fit_transform(X)
+        chained_imputer = ChainedImputer(initial_strategy=strategy)
+        X_imputed = chained_imputer.fit_transform(X)
         assert X_imputed.shape == (10, 2)
 
 
+@pytest.mark.parametrize("strategy", ["const", 101, None])
+def test_imputation_error_invalid_strategy(strategy):
+    X = np.ones((3, 5))
+    X[0, 0] = np.nan
+
+    with pytest.raises(ValueError, match=str(strategy)):
+        imputer = SimpleImputer(strategy=strategy)
+        imputer.fit_transform(X)
+
+
+@pytest.mark.parametrize("strategy", ["mean", "median", "most_frequent"])
+def test_imputation_deletion_warning(strategy):
+    X = np.ones((3, 5))
+    X[:, 0] = np.nan
+
+    with pytest.warns(UserWarning, match="Deleting"):
+        imputer = SimpleImputer(strategy=strategy, verbose=True)
+        imputer.fit_transform(X)
+
+
 def safe_median(arr, *args, **kwargs):
     # np.median([]) raises a TypeError for numpy >= 1.10.1
     length = arr.size if hasattr(arr, 'size') else len(arr)
@@ -101,9 +122,10 @@ def test_imputation_mean_median():
     values = np.arange(1, shape[0] + 1)
     values[4::2] = - values[4::2]
 
-    tests = [("mean", "NaN", lambda z, v, p: safe_mean(np.hstack((z, v)))),
+    tests = [("mean", np.nan, lambda z, v, p: safe_mean(np.hstack((z, v)))),
              ("mean", 0, lambda z, v, p: np.mean(v)),
-             ("median", "NaN", lambda z, v, p: safe_median(np.hstack((z, v)))),
+             ("median", np.nan,
+              lambda z, v, p: safe_median(np.hstack((z, v)))),
              ("median", 0, lambda z, v, p: np.median(v))]
 
     for strategy, test_missing_values, true_value_fun in tests:
@@ -184,7 +206,37 @@ def test_imputation_median_special_cases():
     statistics_median = [0, 5, 0, -2.5, 2.5, 4.5, -4.5, .5]
 
     _check_statistics(X, X_imputed_median, "median",
-                      statistics_median, 'NaN')
+                      statistics_median, np.nan)
+
+
+@pytest.mark.parametrize("strategy", ["mean", "median"])
+@pytest.mark.parametrize("dtype", [None, object, str])
+def test_imputation_mean_median_error_invalid_type(strategy, dtype):
+    X = np.array([["a", "b", 3],
+                  [4, "e", 6],
+                  ["g", "h", 9]], dtype=dtype)
+
+    with pytest.raises(ValueError, match="non-numeric data"):
+        imputer = SimpleImputer(strategy=strategy)
+        imputer.fit_transform(X)
+
+
+@pytest.mark.parametrize("strategy", ["constant", "most_frequent"])
+@pytest.mark.parametrize("dtype", [str, np.dtype('U'), np.dtype('S')])
+def test_imputation_const_mostf_error_invalid_types(strategy, dtype):
+    # Test imputation on non-numeric data using "most_frequent" and "constant"
+    # strategy
+    X = np.array([
+        [np.nan, np.nan, "a", "f"],
+        [np.nan, "c", np.nan, "d"],
+        [np.nan, "b", "d", np.nan],
+        [np.nan, "c", "d", "h"],
+    ], dtype=dtype)
+
+    err_msg = "SimpleImputer does not support data"
+    with pytest.raises(ValueError, match=err_msg):
+        imputer = SimpleImputer(strategy=strategy)
+        imputer.fit(X).transform(X)
 
 
 def test_imputation_most_frequent():
@@ -210,6 +262,169 @@ def test_imputation_most_frequent():
     _check_statistics(X, X_true, "most_frequent", [np.nan, 2, 3, 3], -1)
 
 
+@pytest.mark.parametrize("marker", [None, np.nan, "NAN", "", 0])
+def test_imputation_most_frequent_objects(marker):
+    # Test imputation using the most-frequent strategy.
+    X = np.array([
+        [marker, marker, "a", "f"],
+        [marker, "c", marker, "d"],
+        [marker, "b", "d", marker],
+        [marker, "c", "d", "h"],
+    ], dtype=object)
+
+    X_true = np.array([
+        ["c", "a", "f"],
+        ["c", "d", "d"],
+        ["b", "d", "d"],
+        ["c", "d", "h"],
+    ], dtype=object)
+
+    imputer = SimpleImputer(missing_values=marker,
+                            strategy="most_frequent")
+    X_trans = imputer.fit(X).transform(X)
+
+    assert_array_equal(X_trans, X_true)
+
+
+@pytest.mark.parametrize("dtype", [object, "category"])
+def test_imputation_most_frequent_pandas(dtype):
+    # Test imputation using the most frequent strategy on pandas df
+    pd = pytest.importorskip("pandas")
+
+    f = io.StringIO(u"Cat1,Cat2,Cat3,Cat4\n"
+                    ",i,x,\n"
+                    "a,,y,\n"
+                    "a,j,,\n"
+                    "b,j,x,")
+
+    df = pd.read_csv(f, dtype=dtype)
+
+    X_true = np.array([
+        ["a", "i", "x"],
+        ["a", "j", "y"],
+        ["a", "j", "x"],
+        ["b", "j", "x"]
+    ], dtype=object)
+
+    imputer = SimpleImputer(strategy="most_frequent")
+    X_trans = imputer.fit_transform(df)
+
+    assert_array_equal(X_trans, X_true)
+
+
+@pytest.mark.parametrize("X_data, missing_value", [(1, 0), (1., np.nan)])
+def test_imputation_constant_error_invalid_type(X_data, missing_value):
+    # Verify that exceptions are raised on invalid fill_value type
+    X = np.full((3, 5), X_data)
+    X[0, 0] = missing_value
+
+    with pytest.raises(ValueError, match="imputing numerical"):
+        imputer = SimpleImputer(missing_values=missing_value,
+                                strategy="constant",
+                                fill_value="x")
+        imputer.fit_transform(X)
+
+
+def test_imputation_constant_integer():
+    # Test imputation using the constant strategy on integers
+    X = np.array([
+        [-1, 2, 3, -1],
+        [4, -1, 5, -1],
+        [6, 7, -1, -1],
+        [8, 9, 0, -1]
+    ])
+
+    X_true = np.array([
+        [0, 2, 3, 0],
+        [4, 0, 5, 0],
+        [6, 7, 0, 0],
+        [8, 9, 0, 0]
+    ])
+
+    imputer = SimpleImputer(missing_values=-1, strategy="constant",
+                            fill_value=0)
+    X_trans = imputer.fit_transform(X)
+
+    assert_array_equal(X_trans, X_true)
+
+
+@pytest.mark.parametrize("array_constructor", [sparse.csr_matrix, np.asarray])
+def test_imputation_constant_float(array_constructor):
+    # Test imputation using the constant strategy on floats
+    X = np.array([
+        [np.nan, 1.1, 0, np.nan],
+        [1.2, np.nan, 1.3, np.nan],
+        [0, 0, np.nan, np.nan],
+        [1.4, 1.5, 0, np.nan]
+    ])
+
+    X_true = np.array([
+        [-1, 1.1, 0, -1],
+        [1.2, -1, 1.3, -1],
+        [0, 0, -1, -1],
+        [1.4, 1.5, 0, -1]
+    ])
+
+    X = array_constructor(X)
+
+    X_true = array_constructor(X_true)
+
+    imputer = SimpleImputer(strategy="constant", fill_value=-1)
+    X_trans = imputer.fit_transform(X)
+
+    assert_allclose_dense_sparse(X_trans, X_true)
+
+
+@pytest.mark.parametrize("marker", [None, np.nan, "NAN", "", 0])
+def test_imputation_constant_object(marker):
+    # Test imputation using the constant strategy on objects
+    X = np.array([
+        [marker, "a", "b", marker],
+        ["c", marker, "d", marker],
+        ["e", "f", marker, marker],
+        ["g", "h", "i", marker]
+    ], dtype=object)
+
+    X_true = np.array([
+        ["missing", "a", "b", "missing"],
+        ["c", "missing", "d", "missing"],
+        ["e", "f", "missing", "missing"],
+        ["g", "h", "i", "missing"]
+    ], dtype=object)
+
+    imputer = SimpleImputer(missing_values=marker, strategy="constant",
+                            fill_value="missing")
+    X_trans = imputer.fit_transform(X)
+
+    assert_array_equal(X_trans, X_true)
+
+
+@pytest.mark.parametrize("dtype", [object, "category"])
+def test_imputation_constant_pandas(dtype):
+    # Test imputation using the constant strategy on pandas df
+    pd = pytest.importorskip("pandas")
+
+    f = io.StringIO(u"Cat1,Cat2,Cat3,Cat4\n"
+                    ",i,x,\n"
+                    "a,,y,\n"
+                    "a,j,,\n"
+                    "b,j,x,")
+
+    df = pd.read_csv(f, dtype=dtype)
+
+    X_true = np.array([
+        ["missing_value", "i", "x", "missing_value"],
+        ["a", "missing_value", "y", "missing_value"],
+        ["a", "j", "missing_value", "missing_value"],
+        ["b", "j", "x", "missing_value"]
+    ], dtype=object)
+
+    imputer = SimpleImputer(strategy="constant")
+    X_trans = imputer.fit_transform(df)
+
+    assert_array_equal(X_trans, X_true)
+
+
 def test_imputation_pipeline_grid_search():
     # Test imputation within a pipeline + gridsearch.
     pipeline = Pipeline([('imputer', SimpleImputer(missing_values=0)),
@@ -271,7 +486,7 @@ def test_imputation_copy():
     # made, even if copy=False.
 
 
-def test_mice_rank_one():
+def test_chained_imputer_rank_one():
     rng = np.random.RandomState(0)
     d = 100
     A = rng.rand(d, 1)
@@ -281,10 +496,10 @@ def test_mice_rank_one():
     X_missing = X.copy()
     X_missing[nan_mask] = np.nan
 
-    imputer = MICEImputer(n_imputations=5,
-                          n_burn_in=5,
-                          verbose=True,
-                          random_state=rng)
+    imputer = ChainedImputer(n_imputations=5,
+                             n_burn_in=5,
+                             verbose=True,
+                             random_state=rng)
     X_filled = imputer.fit_transform(X_missing)
     assert_allclose(X_filled, X, atol=0.001)
 
@@ -293,22 +508,22 @@ def test_mice_rank_one():
     "imputation_order",
     ['random', 'roman', 'ascending', 'descending', 'arabic']
 )
-def test_mice_imputation_order(imputation_order):
+def test_chained_imputer_imputation_order(imputation_order):
     rng = np.random.RandomState(0)
     n = 100
     d = 10
     X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()
-    X[:, 0] = 1  # this column should not be discarded by MICEImputer
-
-    imputer = MICEImputer(missing_values=0,
-                          n_imputations=1,
-                          n_burn_in=1,
-                          n_nearest_features=5,
-                          min_value=0,
-                          max_value=1,
-                          verbose=False,
-                          imputation_order=imputation_order,
-                          random_state=rng)
+    X[:, 0] = 1  # this column should not be discarded by ChainedImputer
+
+    imputer = ChainedImputer(missing_values=0,
+                             n_imputations=1,
+                             n_burn_in=1,
+                             n_nearest_features=5,
+                             min_value=0,
+                             max_value=1,
+                             verbose=False,
+                             imputation_order=imputation_order,
+                             random_state=rng)
     imputer.fit_transform(X)
     ordered_idx = [i.feat_idx for i in imputer.imputation_sequence_]
     if imputation_order == 'roman':
@@ -327,18 +542,18 @@ def test_mice_imputation_order(imputation_order):
     "predictor",
     [DummyRegressor(), BayesianRidge(), ARDRegression()]
 )
-def test_mice_predictors(predictor):
+def test_chained_imputer_predictors(predictor):
     rng = np.random.RandomState(0)
 
     n = 100
     d = 10
     X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()
 
-    imputer = MICEImputer(missing_values=0,
-                          n_imputations=1,
-                          n_burn_in=1,
-                          predictor=predictor,
-                          random_state=rng)
+    imputer = ChainedImputer(missing_values=0,
+                             n_imputations=1,
+                             n_burn_in=1,
+                             predictor=predictor,
+                             random_state=rng)
     imputer.fit_transform(X)
 
     # check that types are correct for predictors
@@ -351,19 +566,19 @@ def test_mice_predictors(predictor):
     assert len(set(hashes)) == len(hashes)
 
 
-def test_mice_clip():
+def test_chained_imputer_clip():
     rng = np.random.RandomState(0)
     n = 100
     d = 10
     X = sparse_random_matrix(n, d, density=0.10,
                              random_state=rng).toarray()
 
-    imputer = MICEImputer(missing_values=0,
-                          n_imputations=1,
-                          n_burn_in=1,
-                          min_value=0.1,
-                          max_value=0.2,
-                          random_state=rng)
+    imputer = ChainedImputer(missing_values=0,
+                             n_imputations=1,
+                             n_burn_in=1,
+                             min_value=0.1,
+                             max_value=0.2,
+                             random_state=rng)
 
     Xt = imputer.fit_transform(X)
     assert_allclose(np.min(Xt[X == 0]), 0.1)
@@ -375,7 +590,7 @@ def test_mice_clip():
     "strategy",
     ["mean", "median", "most_frequent"]
 )
-def test_mice_missing_at_transform(strategy):
+def test_chained_imputer_missing_at_transform(strategy):
     rng = np.random.RandomState(0)
     n = 100
     d = 10
@@ -385,31 +600,31 @@ def test_mice_missing_at_transform(strategy):
     X_train[:, 0] = 1  # definitely no missing values in 0th column
     X_test[0, 0] = 0  # definitely missing value in 0th column
 
-    mice = MICEImputer(missing_values=0,
-                       n_imputations=1,
-                       n_burn_in=1,
-                       initial_strategy=strategy,
-                       random_state=rng).fit(X_train)
+    imputer = ChainedImputer(missing_values=0,
+                             n_imputations=1,
+                             n_burn_in=1,
+                             initial_strategy=strategy,
+                             random_state=rng).fit(X_train)
     initial_imputer = SimpleImputer(missing_values=0,
                                     strategy=strategy).fit(X_train)
 
-    # if there were no missing values at time of fit, then mice will
+    # if there were no missing values at time of fit, then imputer will
     # only use the initial imputer for that feature at transform
-    assert np.all(mice.transform(X_test)[:, 0] ==
+    assert np.all(imputer.transform(X_test)[:, 0] ==
                   initial_imputer.transform(X_test)[:, 0])
 
 
-def test_mice_transform_stochasticity():
+def test_chained_imputer_transform_stochasticity():
     rng = np.random.RandomState(0)
     n = 100
     d = 10
     X = sparse_random_matrix(n, d, density=0.10,
                              random_state=rng).toarray()
 
-    imputer = MICEImputer(missing_values=0,
-                          n_imputations=1,
-                          n_burn_in=1,
-                          random_state=rng)
+    imputer = ChainedImputer(missing_values=0,
+                             n_imputations=1,
+                             n_burn_in=1,
+                             random_state=rng)
     imputer.fit(X)
 
     X_fitted_1 = imputer.transform(X)
@@ -419,12 +634,12 @@ def test_mice_transform_stochasticity():
     assert np.mean(X_fitted_1) != pytest.approx(np.mean(X_fitted_2))
 
 
-def test_mice_no_missing():
+def test_chained_imputer_no_missing():
     rng = np.random.RandomState(0)
     X = rng.rand(100, 100)
     X[:, 0] = np.nan
-    m1 = MICEImputer(n_imputations=10, random_state=rng)
-    m2 = MICEImputer(n_imputations=10, random_state=rng)
+    m1 = ChainedImputer(n_imputations=10, random_state=rng)
+    m2 = ChainedImputer(n_imputations=10, random_state=rng)
     pred1 = m1.fit(X).transform(X)
     pred2 = m2.fit_transform(X)
     # should exclude the first column entirely
@@ -437,7 +652,7 @@ def test_mice_no_missing():
     "rank",
     [3, 5]
 )
-def test_mice_transform_recovery(rank):
+def test_chained_imputer_transform_recovery(rank):
     rng = np.random.RandomState(0)
     n = 100
     d = 100
@@ -455,15 +670,15 @@ def test_mice_transform_recovery(rank):
     X_test_filled = X_filled[n:]
     X_test = X_missing[n:]
 
-    imputer = MICEImputer(n_imputations=10,
-                          n_burn_in=10,
-                          verbose=True,
-                          random_state=rng).fit(X_train)
+    imputer = ChainedImputer(n_imputations=10,
+                             n_burn_in=10,
+                             verbose=True,
+                             random_state=rng).fit(X_train)
     X_test_est = imputer.transform(X_test)
     assert_allclose(X_test_filled, X_test_est, rtol=1e-5, atol=0.1)
 
 
-def test_mice_additive_matrix():
+def test_chained_imputer_additive_matrix():
     rng = np.random.RandomState(0)
     n = 100
     d = 10
@@ -484,9 +699,9 @@ def test_mice_additive_matrix():
     X_test_filled = X_filled[n:]
     X_test = X_missing[n:]
 
-    imputer = MICEImputer(n_imputations=25,
-                          n_burn_in=10,
-                          verbose=True,
-                          random_state=rng).fit(X_train)
+    imputer = ChainedImputer(n_imputations=25,
+                             n_burn_in=10,
+                             verbose=True,
+                             random_state=rng).fit(X_train)
     X_test_est = imputer.transform(X_test)
     assert_allclose(X_test_filled, X_test_est, atol=0.01)
diff --git a/sklearn/tests/test_naive_bayes.py b/sklearn/tests/test_naive_bayes.py
index 2f15163d09dd..6b090ce4684f 100644
--- a/sklearn/tests/test_naive_bayes.py
+++ b/sklearn/tests/test_naive_bayes.py
@@ -4,6 +4,7 @@
 from io import BytesIO
 import numpy as np
 import scipy.sparse
+import pytest
 
 from sklearn.datasets import load_digits, load_iris
 
@@ -177,51 +178,56 @@ def test_discrete_prior():
                                   clf.class_log_prior_, 8)
 
 
-def test_mnnb():
+@pytest.mark.parametrize('kind', ('dense', 'sparse'))
+def test_mnnb(kind):
     # Test Multinomial Naive Bayes classification.
     # This checks that MultinomialNB implements fit and predict and returns
     # correct values for a simple toy dataset.
 
-    for X in [X2, scipy.sparse.csr_matrix(X2)]:
-        # Check the ability to predict the learning set.
-        clf = MultinomialNB()
-        assert_raises(ValueError, clf.fit, -X, y2)
-        y_pred = clf.fit(X, y2).predict(X)
+    if kind == 'dense':
+        X = X2
+    elif kind == 'sparse':
+        X = scipy.sparse.csr_matrix(X2)
 
-        assert_array_equal(y_pred, y2)
+    # Check the ability to predict the learning set.
+    clf = MultinomialNB()
+    assert_raises(ValueError, clf.fit, -X, y2)
+    y_pred = clf.fit(X, y2).predict(X)
+
+    assert_array_equal(y_pred, y2)
 
-        # Verify that np.log(clf.predict_proba(X)) gives the same results as
-        # clf.predict_log_proba(X)
-        y_pred_proba = clf.predict_proba(X)
-        y_pred_log_proba = clf.predict_log_proba(X)
-        assert_array_almost_equal(np.log(y_pred_proba), y_pred_log_proba, 8)
+    # Verify that np.log(clf.predict_proba(X)) gives the same results as
+    # clf.predict_log_proba(X)
+    y_pred_proba = clf.predict_proba(X)
+    y_pred_log_proba = clf.predict_log_proba(X)
+    assert_array_almost_equal(np.log(y_pred_proba), y_pred_log_proba, 8)
 
-        # Check that incremental fitting yields the same results
-        clf2 = MultinomialNB()
-        clf2.partial_fit(X[:2], y2[:2], classes=np.unique(y2))
-        clf2.partial_fit(X[2:5], y2[2:5])
-        clf2.partial_fit(X[5:], y2[5:])
+    # Check that incremental fitting yields the same results
+    clf2 = MultinomialNB()
+    clf2.partial_fit(X[:2], y2[:2], classes=np.unique(y2))
+    clf2.partial_fit(X[2:5], y2[2:5])
+    clf2.partial_fit(X[5:], y2[5:])
 
-        y_pred2 = clf2.predict(X)
-        assert_array_equal(y_pred2, y2)
+    y_pred2 = clf2.predict(X)
+    assert_array_equal(y_pred2, y2)
 
-        y_pred_proba2 = clf2.predict_proba(X)
-        y_pred_log_proba2 = clf2.predict_log_proba(X)
-        assert_array_almost_equal(np.log(y_pred_proba2), y_pred_log_proba2, 8)
-        assert_array_almost_equal(y_pred_proba2, y_pred_proba)
-        assert_array_almost_equal(y_pred_log_proba2, y_pred_log_proba)
+    y_pred_proba2 = clf2.predict_proba(X)
+    y_pred_log_proba2 = clf2.predict_log_proba(X)
+    assert_array_almost_equal(np.log(y_pred_proba2), y_pred_log_proba2, 8)
+    assert_array_almost_equal(y_pred_proba2, y_pred_proba)
+    assert_array_almost_equal(y_pred_log_proba2, y_pred_log_proba)
 
-        # Partial fit on the whole data at once should be the same as fit too
-        clf3 = MultinomialNB()
-        clf3.partial_fit(X, y2, classes=np.unique(y2))
+    # Partial fit on the whole data at once should be the same as fit too
+    clf3 = MultinomialNB()
+    clf3.partial_fit(X, y2, classes=np.unique(y2))
 
-        y_pred3 = clf3.predict(X)
-        assert_array_equal(y_pred3, y2)
-        y_pred_proba3 = clf3.predict_proba(X)
-        y_pred_log_proba3 = clf3.predict_log_proba(X)
-        assert_array_almost_equal(np.log(y_pred_proba3), y_pred_log_proba3, 8)
-        assert_array_almost_equal(y_pred_proba3, y_pred_proba)
-        assert_array_almost_equal(y_pred_log_proba3, y_pred_log_proba)
+    y_pred3 = clf3.predict(X)
+    assert_array_equal(y_pred3, y2)
+    y_pred_proba3 = clf3.predict_proba(X)
+    y_pred_log_proba3 = clf3.predict_log_proba(X)
+    assert_array_almost_equal(np.log(y_pred_proba3), y_pred_log_proba3, 8)
+    assert_array_almost_equal(y_pred_proba3, y_pred_proba)
+    assert_array_almost_equal(y_pred_log_proba3, y_pred_log_proba)
 
 
 def check_partial_fit(cls):
@@ -240,9 +246,9 @@ def check_partial_fit(cls):
     assert_array_equal(clf1.feature_count_, clf3.feature_count_)
 
 
-def test_discretenb_partial_fit():
-    for cls in [MultinomialNB, BernoulliNB]:
-        yield check_partial_fit, cls
+@pytest.mark.parametrize("cls", [MultinomialNB, BernoulliNB])
+def test_discretenb_partial_fit(cls):
+    check_partial_fit(cls)
 
 
 def test_gnb_partial_fit():
@@ -259,62 +265,63 @@ def test_gnb_partial_fit():
     assert_array_almost_equal(clf.class_prior_, clf_pf2.class_prior_)
 
 
-def test_discretenb_pickle():
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB, GaussianNB])
+def test_discretenb_pickle(cls):
     # Test picklability of discrete naive Bayes classifiers
 
-    for cls in [BernoulliNB, MultinomialNB, GaussianNB]:
-        clf = cls().fit(X2, y2)
-        y_pred = clf.predict(X2)
+    clf = cls().fit(X2, y2)
+    y_pred = clf.predict(X2)
 
-        store = BytesIO()
-        pickle.dump(clf, store)
-        clf = pickle.load(BytesIO(store.getvalue()))
+    store = BytesIO()
+    pickle.dump(clf, store)
+    clf = pickle.load(BytesIO(store.getvalue()))
 
-        assert_array_equal(y_pred, clf.predict(X2))
+    assert_array_equal(y_pred, clf.predict(X2))
 
-        if cls is not GaussianNB:
-            # TODO re-enable me when partial_fit is implemented for GaussianNB
+    if cls is not GaussianNB:
+        # TODO re-enable me when partial_fit is implemented for GaussianNB
 
-            # Test pickling of estimator trained with partial_fit
-            clf2 = cls().partial_fit(X2[:3], y2[:3], classes=np.unique(y2))
-            clf2.partial_fit(X2[3:], y2[3:])
-            store = BytesIO()
-            pickle.dump(clf2, store)
-            clf2 = pickle.load(BytesIO(store.getvalue()))
-            assert_array_equal(y_pred, clf2.predict(X2))
+        # Test pickling of estimator trained with partial_fit
+        clf2 = cls().partial_fit(X2[:3], y2[:3], classes=np.unique(y2))
+        clf2.partial_fit(X2[3:], y2[3:])
+        store = BytesIO()
+        pickle.dump(clf2, store)
+        clf2 = pickle.load(BytesIO(store.getvalue()))
+        assert_array_equal(y_pred, clf2.predict(X2))
 
 
-def test_input_check_fit():
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB, GaussianNB])
+def test_input_check_fit(cls):
     # Test input checks for the fit method
-    for cls in [BernoulliNB, MultinomialNB, GaussianNB]:
-        # check shape consistency for number of samples at fit time
-        assert_raises(ValueError, cls().fit, X2, y2[:-1])
 
-        # check shape consistency for number of input features at predict time
-        clf = cls().fit(X2, y2)
-        assert_raises(ValueError, clf.predict, X2[:, :-1])
+    # check shape consistency for number of samples at fit time
+    assert_raises(ValueError, cls().fit, X2, y2[:-1])
 
+    # check shape consistency for number of input features at predict time
+    clf = cls().fit(X2, y2)
+    assert_raises(ValueError, clf.predict, X2[:, :-1])
 
-def test_input_check_partial_fit():
-    for cls in [BernoulliNB, MultinomialNB]:
-        # check shape consistency
-        assert_raises(ValueError, cls().partial_fit, X2, y2[:-1],
-                      classes=np.unique(y2))
 
-        # classes is required for first call to partial fit
-        assert_raises(ValueError, cls().partial_fit, X2, y2)
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB])
+def test_input_check_partial_fit(cls):
+    # check shape consistency
+    assert_raises(ValueError, cls().partial_fit, X2, y2[:-1],
+                  classes=np.unique(y2))
+
+    # classes is required for first call to partial fit
+    assert_raises(ValueError, cls().partial_fit, X2, y2)
 
-        # check consistency of consecutive classes values
-        clf = cls()
-        clf.partial_fit(X2, y2, classes=np.unique(y2))
-        assert_raises(ValueError, clf.partial_fit, X2, y2,
-                      classes=np.arange(42))
+    # check consistency of consecutive classes values
+    clf = cls()
+    clf.partial_fit(X2, y2, classes=np.unique(y2))
+    assert_raises(ValueError, clf.partial_fit, X2, y2,
+                  classes=np.arange(42))
 
-        # check consistency of input shape for partial_fit
-        assert_raises(ValueError, clf.partial_fit, X2[:, :-1], y2)
+    # check consistency of input shape for partial_fit
+    assert_raises(ValueError, clf.partial_fit, X2[:, :-1], y2)
 
-        # check consistency of input shape for predict
-        assert_raises(ValueError, clf.predict, X2[:, :-1])
+    # check consistency of input shape for predict
+    assert_raises(ValueError, clf.predict, X2[:, :-1])
 
 
 def test_discretenb_predict_proba():
@@ -348,34 +355,35 @@ def test_discretenb_predict_proba():
         assert_almost_equal(np.sum(np.exp(clf.intercept_)), 1)
 
 
-def test_discretenb_uniform_prior():
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB])
+def test_discretenb_uniform_prior(cls):
     # Test whether discrete NB classes fit a uniform prior
     # when fit_prior=False and class_prior=None
 
-    for cls in [BernoulliNB, MultinomialNB]:
-        clf = cls()
-        clf.set_params(fit_prior=False)
-        clf.fit([[0], [0], [1]], [0, 0, 1])
-        prior = np.exp(clf.class_log_prior_)
-        assert_array_almost_equal(prior, np.array([.5, .5]))
+    clf = cls()
+    clf.set_params(fit_prior=False)
+    clf.fit([[0], [0], [1]], [0, 0, 1])
+    prior = np.exp(clf.class_log_prior_)
+    assert_array_almost_equal(prior, np.array([.5, .5]))
 
 
-def test_discretenb_provide_prior():
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB])
+def test_discretenb_provide_prior(cls):
     # Test whether discrete NB classes use provided prior
 
-    for cls in [BernoulliNB, MultinomialNB]:
-        clf = cls(class_prior=[0.5, 0.5])
-        clf.fit([[0], [0], [1]], [0, 0, 1])
-        prior = np.exp(clf.class_log_prior_)
-        assert_array_almost_equal(prior, np.array([.5, .5]))
+    clf = cls(class_prior=[0.5, 0.5])
+    clf.fit([[0], [0], [1]], [0, 0, 1])
+    prior = np.exp(clf.class_log_prior_)
+    assert_array_almost_equal(prior, np.array([.5, .5]))
 
-        # Inconsistent number of classes with prior
-        assert_raises(ValueError, clf.fit, [[0], [1], [2]], [0, 1, 2])
-        assert_raises(ValueError, clf.partial_fit, [[0], [1]], [0, 1],
-                      classes=[0, 1, 1])
+    # Inconsistent number of classes with prior
+    assert_raises(ValueError, clf.fit, [[0], [1], [2]], [0, 1, 2])
+    assert_raises(ValueError, clf.partial_fit, [[0], [1]], [0, 1],
+                  classes=[0, 1, 1])
 
 
-def test_discretenb_provide_prior_with_partial_fit():
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB])
+def test_discretenb_provide_prior_with_partial_fit(cls):
     # Test whether discrete NB classes use provided prior
     # when using partial_fit
 
@@ -383,22 +391,21 @@ def test_discretenb_provide_prior_with_partial_fit():
     iris_data1, iris_data2, iris_target1, iris_target2 = train_test_split(
         iris.data, iris.target, test_size=0.4, random_state=415)
 
-    for cls in [BernoulliNB, MultinomialNB]:
-        for prior in [None, [0.3, 0.3, 0.4]]:
-            clf_full = cls(class_prior=prior)
-            clf_full.fit(iris.data, iris.target)
-            clf_partial = cls(class_prior=prior)
-            clf_partial.partial_fit(iris_data1, iris_target1,
-                                    classes=[0, 1, 2])
-            clf_partial.partial_fit(iris_data2, iris_target2)
-            assert_array_almost_equal(clf_full.class_log_prior_,
-                                      clf_partial.class_log_prior_)
-
-
-def test_sample_weight_multiclass():
-    for cls in [BernoulliNB, MultinomialNB]:
-        # check shape consistency for number of samples at fit time
-        yield check_sample_weight_multiclass, cls
+    for prior in [None, [0.3, 0.3, 0.4]]:
+        clf_full = cls(class_prior=prior)
+        clf_full.fit(iris.data, iris.target)
+        clf_partial = cls(class_prior=prior)
+        clf_partial.partial_fit(iris_data1, iris_target1,
+                                classes=[0, 1, 2])
+        clf_partial.partial_fit(iris_data2, iris_target2)
+        assert_array_almost_equal(clf_full.class_log_prior_,
+                                  clf_partial.class_log_prior_)
+
+
+@pytest.mark.parametrize('cls', [BernoulliNB, MultinomialNB])
+def test_sample_weight_multiclass(cls):
+    # check shape consistency for number of samples at fit time
+    check_sample_weight_multiclass(cls)
 
 
 def check_sample_weight_multiclass(cls):
diff --git a/sklearn/tests/test_random_projection.py b/sklearn/tests/test_random_projection.py
index dcbe97c7d6d7..975922a34116 100644
--- a/sklearn/tests/test_random_projection.py
+++ b/sklearn/tests/test_random_projection.py
@@ -1,7 +1,10 @@
 from __future__ import division
 
+import functools
+
 import numpy as np
 import scipy.sparse as sp
+import pytest
 
 from sklearn.metrics import euclidean_distances
 
@@ -113,21 +116,21 @@ def check_input_with_sparse_random_matrix(random_matrix):
                       random_matrix, n_components, n_features, density=density)
 
 
-def test_basic_property_of_random_matrix():
+@pytest.mark.parametrize("random_matrix", all_random_matrix)
+def test_basic_property_of_random_matrix(random_matrix):
     # Check basic properties of random matrix generation
-    for random_matrix in all_random_matrix:
-        yield check_input_size_random_matrix, random_matrix
-        yield check_size_generated, random_matrix
-        yield check_zero_mean_and_unit_norm, random_matrix
-
-    for random_matrix in all_sparse_random_matrix:
-        yield check_input_with_sparse_random_matrix, random_matrix
-
-        random_matrix_dense = \
-            lambda n_components, n_features, random_state: random_matrix(
-                n_components, n_features, random_state=random_state,
-                density=1.0)
-        yield check_zero_mean_and_unit_norm, random_matrix_dense
+    check_input_size_random_matrix(random_matrix)
+    check_size_generated(random_matrix)
+    check_zero_mean_and_unit_norm(random_matrix)
+
+
+@pytest.mark.parametrize("random_matrix", all_sparse_random_matrix)
+def test_basic_property_of_sparse_random_matrix(random_matrix):
+    check_input_with_sparse_random_matrix(random_matrix)
+
+    random_matrix_dense = functools.partial(random_matrix, density=1.0)
+
+    check_zero_mean_and_unit_norm(random_matrix_dense)
 
 
 def test_gaussian_random_matrix():
diff --git a/sklearn/tree/tests/test_tree.py b/sklearn/tree/tests/test_tree.py
index f85493543b1e..bb117d8a2986 100644
--- a/sklearn/tree/tests/test_tree.py
+++ b/sklearn/tree/tests/test_tree.py
@@ -7,6 +7,7 @@
 from itertools import product
 import struct
 
+import pytest
 import numpy as np
 from scipy.sparse import csc_matrix
 from scipy.sparse import csr_matrix
@@ -701,14 +702,14 @@ def check_min_weight_fraction_leaf(name, datasets, sparse=False):
                 name, est.min_weight_fraction_leaf))
 
 
-def test_min_weight_fraction_leaf():
-    # Check on dense input
-    for name in ALL_TREES:
-        yield check_min_weight_fraction_leaf, name, "iris"
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_min_weight_fraction_leaf_on_dense_input(name):
+    check_min_weight_fraction_leaf(name, "iris")
 
-    # Check on sparse input
-    for name in SPARSE_TREES:
-        yield check_min_weight_fraction_leaf, name, "multilabel", True
+
+@pytest.mark.parametrize("name", SPARSE_TREES)
+def test_min_weight_fraction_leaf_on_sparse_input(name):
+    check_min_weight_fraction_leaf(name, "multilabel", True)
 
 
 def check_min_weight_fraction_leaf_with_min_samples_leaf(name, datasets,
@@ -775,16 +776,15 @@ def check_min_weight_fraction_leaf_with_min_samples_leaf(name, datasets,
                                           est.min_samples_leaf))
 
 
-def test_min_weight_fraction_leaf_with_min_samples_leaf():
-    # Check on dense input
-    for name in ALL_TREES:
-        yield (check_min_weight_fraction_leaf_with_min_samples_leaf,
-               name, "iris")
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_min_weight_fraction_leaf_with_min_samples_leaf_on_dense_input(name):
+    check_min_weight_fraction_leaf_with_min_samples_leaf(name, "iris")
+
 
-    # Check on sparse input
-    for name in SPARSE_TREES:
-        yield (check_min_weight_fraction_leaf_with_min_samples_leaf,
-               name, "multilabel", True)
+@pytest.mark.parametrize("name", SPARSE_TREES)
+def test_min_weight_fraction_leaf_with_min_samples_leaf_on_sparse_input(name):
+    check_min_weight_fraction_leaf_with_min_samples_leaf(
+            name, "multilabel", True)
 
 
 def test_min_impurity_split():
@@ -1178,9 +1178,9 @@ def check_class_weights(name):
     assert_almost_equal(clf1.feature_importances_, clf2.feature_importances_)
 
 
-def test_class_weights():
-    for name in CLF_TREES:
-        yield check_class_weights, name
+@pytest.mark.parametrize("name", CLF_TREES)
+def test_class_weights(name):
+    check_class_weights(name)
 
 
 def check_class_weight_errors(name):
@@ -1202,9 +1202,9 @@ def check_class_weight_errors(name):
     assert_raises(ValueError, clf.fit, X, _y)
 
 
-def test_class_weight_errors():
-    for name in CLF_TREES:
-        yield check_class_weight_errors, name
+@pytest.mark.parametrize("name", CLF_TREES)
+def test_class_weight_errors(name):
+    check_class_weight_errors(name)
 
 
 def test_max_leaf_nodes():
@@ -1364,20 +1364,25 @@ def check_sparse_input(tree, dataset, max_depth=None):
                                           y_log_proba)
 
 
-def test_sparse_input():
-    for tree_type, dataset in product(SPARSE_TREES, ("clf_small", "toy",
-                                                     "digits", "multilabel",
-                                                     "sparse-pos",
-                                                     "sparse-neg",
-                                                     "sparse-mix", "zeros")):
-        max_depth = 3 if dataset == "digits" else None
-        yield (check_sparse_input, tree_type, dataset, max_depth)
+@pytest.mark.parametrize("tree_type", SPARSE_TREES)
+@pytest.mark.parametrize(
+        "dataset",
+        ("clf_small", "toy", "digits", "multilabel",
+         "sparse-pos", "sparse-neg", "sparse-mix",
+         "zeros")
+)
+def test_sparse_input(tree_type, dataset):
+    max_depth = 3 if dataset == "digits" else None
+    check_sparse_input(tree_type, dataset, max_depth)
 
+
+@pytest.mark.parametrize("tree_type",
+                         set(SPARSE_TREES).intersection(REG_TREES))
+@pytest.mark.parametrize("dataset", ["boston", "reg_small"])
+def test_sparse_input_reg_trees(tree_type, dataset):
     # Due to numerical instability of MSE and too strict test, we limit the
     # maximal depth
-    for tree_type, dataset in product(SPARSE_TREES, ["boston", "reg_small"]):
-        if tree_type in REG_TREES:
-            yield (check_sparse_input, tree_type, dataset, 2)
+    check_sparse_input(tree_type, dataset, 2)
 
 
 def check_sparse_parameters(tree, dataset):
@@ -1424,13 +1429,6 @@ def check_sparse_parameters(tree, dataset):
     assert_array_almost_equal(s.predict(X), d.predict(X))
 
 
-def test_sparse_parameters():
-    for tree_type, dataset in product(SPARSE_TREES, ["sparse-pos",
-                                                     "sparse-neg",
-                                                     "sparse-mix", "zeros"]):
-        yield (check_sparse_parameters, tree_type, dataset)
-
-
 def check_sparse_criterion(tree, dataset):
     TreeEstimator = ALL_TREES[tree]
     X = DATASETS[dataset]["X"]
@@ -1451,11 +1449,13 @@ def check_sparse_criterion(tree, dataset):
         assert_array_almost_equal(s.predict(X), d.predict(X))
 
 
-def test_sparse_criterion():
-    for tree_type, dataset in product(SPARSE_TREES, ["sparse-pos",
-                                                     "sparse-neg",
-                                                     "sparse-mix", "zeros"]):
-        yield (check_sparse_criterion, tree_type, dataset)
+@pytest.mark.parametrize("tree_type", SPARSE_TREES)
+@pytest.mark.parametrize("dataset",
+                         ["sparse-pos", "sparse-neg", "sparse-mix", "zeros"])
+@pytest.mark.parametrize("check",
+                         [check_sparse_parameters, check_sparse_criterion])
+def test_sparse(tree_type, dataset, check):
+    check(tree_type, dataset)
 
 
 def check_explicit_sparse_zeros(tree, max_depth=3,
@@ -1527,9 +1527,9 @@ def check_explicit_sparse_zeros(tree, max_depth=3,
                                       d.predict_proba(X2))
 
 
-def test_explicit_sparse_zeros():
-    for tree_type in SPARSE_TREES:
-        yield (check_explicit_sparse_zeros, tree_type)
+@pytest.mark.parametrize("tree_type", SPARSE_TREES)
+def test_explicit_sparse_zeros(tree_type):
+    check_explicit_sparse_zeros(tree_type)
 
 
 @ignore_warnings
@@ -1547,10 +1547,10 @@ def check_raise_error_on_1d_input(name):
     assert_raises(ValueError, est.predict, [X])
 
 
-@ignore_warnings
-def test_1d_input():
-    for name in ALL_TREES:
-        yield check_raise_error_on_1d_input, name
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_1d_input(name):
+    with ignore_warnings():
+        check_raise_error_on_1d_input(name)
 
 
 def _check_min_weight_leaf_split_level(TreeEstimator, X, y, sample_weight):
@@ -1576,9 +1576,9 @@ def check_min_weight_leaf_split_level(name):
                                            sample_weight)
 
 
-def test_min_weight_leaf_split_level():
-    for name in ALL_TREES:
-        yield check_min_weight_leaf_split_level, name
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_min_weight_leaf_split_level(name):
+    check_min_weight_leaf_split_level(name)
 
 
 def check_public_apply(name):
@@ -1599,12 +1599,14 @@ def check_public_apply_sparse(name):
                        est.tree_.apply(X_small32))
 
 
-def test_public_apply():
-    for name in ALL_TREES:
-        yield (check_public_apply, name)
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_public_apply_all_trees(name):
+    check_public_apply(name)
 
-    for name in SPARSE_TREES:
-        yield (check_public_apply_sparse, name)
+
+@pytest.mark.parametrize("name", SPARSE_TREES)
+def test_public_apply_sparse_trees(name):
+    check_public_apply_sparse(name)
 
 
 def check_presort_sparse(est, X, y):
@@ -1623,19 +1625,18 @@ def test_presort_sparse():
     y = y[:, 0]
 
     for est, sparse_matrix in product(ests, sparse_matrices):
-        yield check_presort_sparse, est, sparse_matrix(X), y
+        check_presort_sparse(est, sparse_matrix(X), y)
 
 
-def test_invalid_presort():
-    classes = (DecisionTreeRegressor, DecisionTreeClassifier)
+@pytest.mark.parametrize('cls',
+                         (DecisionTreeRegressor, DecisionTreeClassifier))
+def test_invalid_presort(cls):
     allowed_presort = ('auto', True, False)
     invalid_presort = 'invalid'
     msg = ("'presort' should be in {}. "
            "Got {!r} instead.".format(allowed_presort, invalid_presort))
-    for cls in classes:
-        est = cls(presort=invalid_presort)
-        assert_raise_message(ValueError, msg,
-                             est.fit, X, y)
+    est = cls(presort=invalid_presort)
+    assert_raise_message(ValueError, msg, est.fit, X, y)
 
 
 def test_decision_path_hardcoded():
@@ -1674,9 +1675,9 @@ def check_decision_path(name):
     assert_less_equal(est.tree_.max_depth, max_depth)
 
 
-def test_decision_path():
-    for name in ALL_TREES:
-        yield (check_decision_path, name)
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_decision_path(name):
+    check_decision_path(name)
 
 
 def check_no_sparse_y_support(name):
@@ -1685,10 +1686,10 @@ def check_no_sparse_y_support(name):
     assert_raises(TypeError, TreeEstimator(random_state=0).fit, X, y)
 
 
-def test_no_sparse_y_support():
+@pytest.mark.parametrize("name", ALL_TREES)
+def test_no_sparse_y_support(name):
     # Currently we don't support sparse y
-    for name in ALL_TREES:
-        yield (check_no_sparse_y_support, name)
+    check_no_sparse_y_support(name)
 
 
 def test_mae():
diff --git a/sklearn/tree/tree.py b/sklearn/tree/tree.py
index dc52eee06814..af216f1906eb 100644
--- a/sklearn/tree/tree.py
+++ b/sklearn/tree/tree.py
@@ -672,7 +672,10 @@ class DecisionTreeClassifier(BaseDecisionTree, ClassifierMixin):
         The number of outputs when ``fit`` is performed.
 
     tree_ : Tree object
-        The underlying Tree object.
+        The underlying Tree object. Please refer to
+        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and
+        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`
+        for basic usage of these attributes.
 
     Notes
     -----
@@ -1008,7 +1011,10 @@ class DecisionTreeRegressor(BaseDecisionTree, RegressorMixin):
         The number of outputs when ``fit`` is performed.
 
     tree_ : Tree object
-        The underlying Tree object.
+        The underlying Tree object. Please refer to
+        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and
+        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`
+        for basic usage of these attributes.
 
     Notes
     -----
@@ -1260,7 +1266,8 @@ class ExtraTreeClassifier(DecisionTreeClassifier):
 
     See also
     --------
-    ExtraTreeRegressor, ExtraTreesClassifier, ExtraTreesRegressor
+    ExtraTreeRegressor, sklearn.ensemble.ExtraTreesClassifier,
+    sklearn.ensemble.ExtraTreesRegressor
 
     Notes
     -----
@@ -1423,7 +1430,8 @@ class ExtraTreeRegressor(DecisionTreeRegressor):
 
     See also
     --------
-    ExtraTreeClassifier, ExtraTreesClassifier, ExtraTreesRegressor
+    ExtraTreeClassifier, sklearn.ensemble.ExtraTreesClassifier,
+    sklearn.ensemble.ExtraTreesRegressor
 
     Notes
     -----
diff --git a/sklearn/utils/__init__.py b/sklearn/utils/__init__.py
index e3d1e7faaabd..bb1f383505fe 100644
--- a/sklearn/utils/__init__.py
+++ b/sklearn/utils/__init__.py
@@ -2,6 +2,7 @@
 The :mod:`sklearn.utils` module includes various utilities.
 """
 from collections import Sequence
+import numbers
 
 import numpy as np
 from scipy.sparse import issparse
@@ -553,3 +554,38 @@ def get_chunk_n_rows(row_bytes, max_n_rows=None,
                       (working_memory, np.ceil(row_bytes * 2 ** -20)))
         chunk_n_rows = 1
     return chunk_n_rows
+
+
+def is_scalar_nan(x):
+    """Tests if x is NaN
+
+    This function is meant to overcome the issue that np.isnan does not allow
+    non-numerical types as input, and that np.nan is not np.float('nan').
+
+    Parameters
+    ----------
+    x : any type
+
+    Returns
+    -------
+    boolean
+
+    Examples
+    --------
+    >>> is_scalar_nan(np.nan)
+    True
+    >>> is_scalar_nan(float("nan"))
+    True
+    >>> is_scalar_nan(None)
+    False
+    >>> is_scalar_nan("")
+    False
+    >>> is_scalar_nan([np.nan])
+    False
+    """
+
+    # convert from numpy.bool_ to python bool to ensure that testing
+    # is_scalar_nan(x) is True does not fail.
+    # Redondant np.floating is needed because numbers can't match np.float32
+    # in python 2.
+    return bool(isinstance(x, (numbers.Real, np.floating)) and np.isnan(x))
diff --git a/sklearn/utils/deprecation.py b/sklearn/utils/deprecation.py
index 5621f436d9ba..fc06f9bc84d3 100644
--- a/sklearn/utils/deprecation.py
+++ b/sklearn/utils/deprecation.py
@@ -78,6 +78,9 @@ def wrapped(*args, **kwargs):
             return fun(*args, **kwargs)
 
         wrapped.__doc__ = self._update_doc(wrapped.__doc__)
+        # Add a reference to the wrapped function so that we can introspect
+        # on function arguments in Python 2 (already works in Python 3)
+        wrapped.__wrapped__ = fun
 
         return wrapped
 
diff --git a/sklearn/utils/estimator_checks.py b/sklearn/utils/estimator_checks.py
index 4021ede05736..8d16b5853c09 100644
--- a/sklearn/utils/estimator_checks.py
+++ b/sklearn/utils/estimator_checks.py
@@ -36,6 +36,7 @@
 from sklearn.utils.testing import ignore_warnings
 from sklearn.utils.testing import assert_dict_equal
 from sklearn.utils.testing import create_memmap_backed_data
+from sklearn.utils import is_scalar_nan
 from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
 
 
@@ -76,8 +77,9 @@
                 'RANSACRegressor', 'RadiusNeighborsRegressor',
                 'RandomForestRegressor', 'Ridge', 'RidgeCV']
 
-ALLOW_NAN = ['Imputer', 'SimpleImputer', 'MICEImputer',
-             'MinMaxScaler', 'QuantileTransformer']
+ALLOW_NAN = ['Imputer', 'SimpleImputer', 'ChainedImputer',
+             'MinMaxScaler', 'StandardScaler', 'PowerTransformer',
+             'QuantileTransformer']
 
 
 def _yield_non_meta_checks(name, estimator):
@@ -301,10 +303,10 @@ def check_estimator(Estimator):
     for check in _yield_all_checks(name, estimator):
         try:
             check(name, estimator)
-        except SkipTest as message:
+        except SkipTest as exception:
             # the only SkipTest thrown currently results from not
             # being able to import pandas.
-            warnings.warn(message, SkipTestWarning)
+            warnings.warn(str(exception), SkipTestWarning)
 
 
 def _boston_subset(n_samples=200):
@@ -327,7 +329,6 @@ def set_checking_parameters(estimator):
             and not isinstance(estimator, BaseSGD)):
         estimator.set_params(n_iter=5)
     if "max_iter" in params:
-        warnings.simplefilter("ignore", ConvergenceWarning)
         if estimator.max_iter is not None:
             estimator.set_params(max_iter=min(5, estimator.max_iter))
         # LinearSVR, LinearSVC
@@ -1608,6 +1609,7 @@ def check_classifiers_predictions(X, y, name, classifier_orig):
 def choose_check_classifiers_labels(name, y, y_names):
     return y if name in ["LabelPropagation", "LabelSpreading"] else y_names
 
+
 def check_classifiers_classes(name, classifier_orig):
     X_multiclass, y_multiclass = make_blobs(n_samples=30, random_state=0,
                                             cluster_std=0.1)
@@ -2003,11 +2005,13 @@ def param_filter(p):
 
             init_params = [p for p in signature(init).parameters.values()
                            if param_filter(p)]
+
         except (TypeError, ValueError):
             # init is not a python function.
             # true for mixins
             return
         params = estimator.get_params()
+
         if name in META_ESTIMATORS:
             # they can need a non-default argument
             init_params = init_params[1:]
@@ -2033,7 +2037,11 @@ def param_filter(p):
             if isinstance(param_value, np.ndarray):
                 assert_array_equal(param_value, init_param.default)
             else:
-                assert_equal(param_value, init_param.default, init_param.name)
+                if is_scalar_nan(param_value):
+                    # Allows to set default parameters to np.nan
+                    assert param_value is init_param.default, init_param.name
+                else:
+                    assert param_value == init_param.default, init_param.name
 
 
 def multioutput_estimator_convert_y_2d(estimator, y):
diff --git a/sklearn/utils/extmath.py b/sklearn/utils/extmath.py
index c6c13c4f933a..f049430d23a6 100644
--- a/sklearn/utils/extmath.py
+++ b/sklearn/utils/extmath.py
@@ -15,8 +15,7 @@
 import warnings
 
 import numpy as np
-from scipy import linalg
-from scipy.sparse import issparse, csr_matrix
+from scipy import linalg, sparse
 
 from . import check_random_state, deprecated
 from .fixes import np_version
@@ -60,9 +59,9 @@ def row_norms(X, squared=False):
 
     Performs no input validation.
     """
-    if issparse(X):
-        if not isinstance(X, csr_matrix):
-            X = csr_matrix(X)
+    if sparse.issparse(X):
+        if not isinstance(X, sparse.csr_matrix):
+            X = sparse.csr_matrix(X)
         norms = csr_row_norms(X)
     else:
         norms = np.einsum('ij,ij->i', X, X)
@@ -131,7 +130,7 @@ def safe_sparse_dot(a, b, dense_output=False):
     dot_product : array or sparse matrix
         sparse if ``a`` or ``b`` is sparse and ``dense_output=False``.
     """
-    if issparse(a) or issparse(b):
+    if sparse.issparse(a) or sparse.issparse(b):
         ret = a * b
         if dense_output and hasattr(ret, "toarray"):
             ret = ret.toarray()
@@ -162,7 +161,7 @@ def randomized_range_finder(A, size, n_iter,
         (the fastest but numerically unstable when `n_iter` is large, e.g.
         typically 5 or larger), or 'LU' factorization (numerically stable
         but can lose slightly in accuracy). The 'auto' mode applies no
-        normalization if `n_iter`<=2 and switches to LU otherwise.
+        normalization if `n_iter` <= 2 and switches to LU otherwise.
 
         .. versionadded:: 0.18
 
@@ -259,7 +258,7 @@ def randomized_svd(M, n_components, n_oversamples=10, n_iter='auto',
         (the fastest but numerically unstable when `n_iter` is large, e.g.
         typically 5 or larger), or 'LU' factorization (numerically stable
         but can lose slightly in accuracy). The 'auto' mode applies no
-        normalization if `n_iter`<=2 and switches to LU otherwise.
+        normalization if `n_iter` <= 2 and switches to LU otherwise.
 
         .. versionadded:: 0.18
 
@@ -307,6 +306,12 @@ def randomized_svd(M, n_components, n_oversamples=10, n_iter='auto',
       analysis
       A. Szlam et al. 2014
     """
+    if isinstance(M, (sparse.lil_matrix, sparse.dok_matrix)):
+        warnings.warn("Calculating SVD of a {} is expensive. "
+                      "csr_matrix is more efficient.".format(
+                          type(M).__name__),
+                      sparse.SparseEfficiencyWarning)
+
     random_state = check_random_state(random_state)
     n_random = n_components + n_oversamples
     n_samples, n_features = M.shape
@@ -593,7 +598,7 @@ def softmax(X, copy=True):
 
     Parameters
     ----------
-    X : array-like, shape (M, N)
+    X : array-like of floats, shape (M, N)
         Argument to the logistic function
 
     copy : bool, optional
@@ -620,7 +625,7 @@ def safe_min(X):
     Adapated from http://stackoverflow.com/q/13426580
 
     """
-    if issparse(X):
+    if sparse.issparse(X):
         if len(X.data) == 0:
             return 0
         m = X.data.min()
@@ -633,7 +638,7 @@ def make_nonnegative(X, min_value=0):
     """Ensure `X.min()` >= `min_value`."""
     min_ = safe_min(X)
     if min_ < min_value:
-        if issparse(X):
+        if sparse.issparse(X):
             raise ValueError("Cannot make the data matrix"
                              " nonnegative because it is sparse."
                              " Adding a value to every entry would"
@@ -642,8 +647,7 @@ def make_nonnegative(X, min_value=0):
     return X
 
 
-def _incremental_mean_and_var(X, last_mean=.0, last_variance=None,
-                              last_sample_count=0):
+def _incremental_mean_and_var(X, last_mean, last_variance, last_sample_count):
     """Calculate mean update and a Youngs and Cramer variance update.
 
     last_mean and last_variance are statistics computed at the last step by the
@@ -664,7 +668,7 @@ def _incremental_mean_and_var(X, last_mean=.0, last_variance=None,
 
     last_variance : array-like, shape: (n_features,)
 
-    last_sample_count : int
+    last_sample_count : array-like, shape (n_features,)
 
     Returns
     -------
@@ -673,7 +677,11 @@ def _incremental_mean_and_var(X, last_mean=.0, last_variance=None,
     updated_variance : array, shape (n_features,)
         If None, only mean is computed
 
-    updated_sample_count : int
+    updated_sample_count : array, shape (n_features,)
+
+    Notes
+    -----
+    NaNs are ignored during the algorithm.
 
     References
     ----------
@@ -689,9 +697,9 @@ def _incremental_mean_and_var(X, last_mean=.0, last_variance=None,
     # new = the current increment
     # updated = the aggregated stats
     last_sum = last_mean * last_sample_count
-    new_sum = X.sum(axis=0)
+    new_sum = np.nansum(X, axis=0)
 
-    new_sample_count = X.shape[0]
+    new_sample_count = np.sum(~np.isnan(X), axis=0)
     updated_sample_count = last_sample_count + new_sample_count
 
     updated_mean = (last_sum + new_sum) / updated_sample_count
@@ -699,17 +707,18 @@ def _incremental_mean_and_var(X, last_mean=.0, last_variance=None,
     if last_variance is None:
         updated_variance = None
     else:
-        new_unnormalized_variance = X.var(axis=0) * new_sample_count
-        if last_sample_count == 0:  # Avoid division by 0
-            updated_unnormalized_variance = new_unnormalized_variance
-        else:
+        new_unnormalized_variance = np.nanvar(X, axis=0) * new_sample_count
+        last_unnormalized_variance = last_variance * last_sample_count
+
+        with np.errstate(divide='ignore'):
             last_over_new_count = last_sample_count / new_sample_count
-            last_unnormalized_variance = last_variance * last_sample_count
             updated_unnormalized_variance = (
-                last_unnormalized_variance +
-                new_unnormalized_variance +
+                last_unnormalized_variance + new_unnormalized_variance +
                 last_over_new_count / updated_sample_count *
                 (last_sum / last_over_new_count - new_sum) ** 2)
+
+        zeros = last_sample_count == 0
+        updated_unnormalized_variance[zeros] = new_unnormalized_variance[zeros]
         updated_variance = updated_unnormalized_variance / updated_sample_count
 
     return updated_mean, updated_variance, updated_sample_count
diff --git a/sklearn/utils/fixes.py b/sklearn/utils/fixes.py
index f7d9d6a29f9f..011777008417 100644
--- a/sklearn/utils/fixes.py
+++ b/sklearn/utils/fixes.py
@@ -10,7 +10,6 @@
 #
 # License: BSD 3 clause
 
-import warnings
 import os
 import errno
 
@@ -71,70 +70,15 @@ def divide(x1, x2, out=None, dtype=None):
         return out
 
 
-try:
-    with warnings.catch_warnings(record=True):
-        # Don't raise the numpy deprecation warnings that appear in
-        # 1.9, but avoid Python bug due to simplefilter('ignore')
-        warnings.simplefilter('always')
-        sp.csr_matrix([1.0, 2.0, 3.0]).max(axis=0)
-except (TypeError, AttributeError):
-    # in scipy < 0.14.0, sparse matrix min/max doesn't accept `axis` argument
-    # the following code is taken from the scipy 0.14 codebase
-
-    def _minor_reduce(X, ufunc):
-        major_index = np.flatnonzero(np.diff(X.indptr))
-        value = ufunc.reduceat(X.data, X.indptr[major_index])
-        return major_index, value
-
-    def _min_or_max_axis(X, axis, min_or_max):
-        N = X.shape[axis]
-        if N == 0:
-            raise ValueError("zero-size array to reduction operation")
-        M = X.shape[1 - axis]
-        mat = X.tocsc() if axis == 0 else X.tocsr()
-        mat.sum_duplicates()
-        major_index, value = _minor_reduce(mat, min_or_max)
-        not_full = np.diff(mat.indptr)[major_index] < N
-        value[not_full] = min_or_max(value[not_full], 0)
-        mask = value != 0
-        major_index = np.compress(mask, major_index)
-        value = np.compress(mask, value)
-
-        from scipy.sparse import coo_matrix
-        if axis == 0:
-            res = coo_matrix((value, (np.zeros(len(value)), major_index)),
-                             dtype=X.dtype, shape=(1, M))
-        else:
-            res = coo_matrix((value, (major_index, np.zeros(len(value)))),
-                             dtype=X.dtype, shape=(M, 1))
-        return res.A.ravel()
-
-    def _sparse_min_or_max(X, axis, min_or_max):
-        if axis is None:
-            if 0 in X.shape:
-                raise ValueError("zero-size array to reduction operation")
-            zero = X.dtype.type(0)
-            if X.nnz == 0:
-                return zero
-            m = min_or_max.reduce(X.data.ravel())
-            if X.nnz != np.product(X.shape):
-                m = min_or_max(zero, m)
-            return m
-        if axis < 0:
-            axis += 2
-        if (axis == 0) or (axis == 1):
-            return _min_or_max_axis(X, axis, min_or_max)
-        else:
-            raise ValueError("invalid axis, use 0 for rows, or 1 for columns")
-
-    def sparse_min_max(X, axis):
-        return (_sparse_min_or_max(X, axis, np.minimum),
-                _sparse_min_or_max(X, axis, np.maximum))
+# boxcox ignore NaN in scipy.special.boxcox after 0.14
+if sp_version < (0, 14):
+    from scipy import stats
 
+    def boxcox(x, lmbda):
+        with np.errstate(invalid='ignore'):
+            return stats.boxcox(x, lmbda)
 else:
-    def sparse_min_max(X, axis):
-        return (X.min(axis=axis).toarray().ravel(),
-                X.max(axis=axis).toarray().ravel())
+    from scipy.special import boxcox  # noqa
 
 
 if sp_version < (0, 15):
@@ -334,3 +278,20 @@ def nanpercentile(a, q):
             return np.array([np.nan] * size_q)
 else:
     from numpy import nanpercentile  # noqa
+
+
+# Fix for behavior inconsistency on numpy.equal for object dtypes.
+# For numpy versions < 1.13, numpy.equal tests element-wise identity of objects
+# instead of equality. This fix returns the mask of NaNs in an array of
+# numerical or object values for all nupy versions.
+
+_nan_object_array = np.array([np.nan], dtype=object)
+_nan_object_mask = _nan_object_array != _nan_object_array
+
+if np.array_equal(_nan_object_mask, np.array([True])):
+    def _object_dtype_isnan(X):
+        return X != X
+
+else:
+    def _object_dtype_isnan(X):
+        return np.frompyfunc(lambda x: x != x, 1, 1)(X).astype(bool)
diff --git a/sklearn/utils/sparsefuncs.py b/sklearn/utils/sparsefuncs.py
index 9f85a0ad6cfc..ccaa6eeb28e6 100644
--- a/sklearn/utils/sparsefuncs.py
+++ b/sklearn/utils/sparsefuncs.py
@@ -6,7 +6,6 @@
 import scipy.sparse as sp
 import numpy as np
 
-from .fixes import sparse_min_max
 from .sparsefuncs_fast import (
     csr_mean_variance_axis0 as _csr_mean_var_axis0,
     csc_mean_variance_axis0 as _csc_mean_var_axis0,
@@ -122,7 +121,7 @@ def incr_mean_variance_axis(X, axis, last_mean, last_var, last_n):
     last_var : float array with shape (n_features,)
         Array of feature-wise var to update with the new data X.
 
-    last_n : int
+    last_n : int with shape (n_features,)
         Number of samples seen so far, excluded X.
 
     Returns
@@ -134,9 +133,13 @@ def incr_mean_variance_axis(X, axis, last_mean, last_var, last_n):
     variances : float array with shape (n_features,)
         Updated feature-wise variances.
 
-    n : int
+    n : int with shape (n_features,)
         Updated number of seen samples.
 
+    Notes
+    -----
+    NaNs are ignored in the algorithm.
+
     """
     _raise_error_wrong_axis(axis)
 
@@ -336,8 +339,67 @@ def inplace_swap_column(X, m, n):
         _raise_typeerror(X)
 
 
-def min_max_axis(X, axis):
-    """Compute minimum and maximum along an axis on a CSR or CSC matrix
+def _minor_reduce(X, ufunc):
+    major_index = np.flatnonzero(np.diff(X.indptr))
+    value = ufunc.reduceat(X.data, X.indptr[major_index])
+    return major_index, value
+
+
+def _min_or_max_axis(X, axis, min_or_max):
+    N = X.shape[axis]
+    if N == 0:
+        raise ValueError("zero-size array to reduction operation")
+    M = X.shape[1 - axis]
+    mat = X.tocsc() if axis == 0 else X.tocsr()
+    mat.sum_duplicates()
+    major_index, value = _minor_reduce(mat, min_or_max)
+    not_full = np.diff(mat.indptr)[major_index] < N
+    value[not_full] = min_or_max(value[not_full], 0)
+    mask = value != 0
+    major_index = np.compress(mask, major_index)
+    value = np.compress(mask, value)
+
+    if axis == 0:
+        res = sp.coo_matrix((value, (np.zeros(len(value)), major_index)),
+                            dtype=X.dtype, shape=(1, M))
+    else:
+        res = sp.coo_matrix((value, (major_index, np.zeros(len(value)))),
+                            dtype=X.dtype, shape=(M, 1))
+    return res.A.ravel()
+
+
+def _sparse_min_or_max(X, axis, min_or_max):
+    if axis is None:
+        if 0 in X.shape:
+            raise ValueError("zero-size array to reduction operation")
+        zero = X.dtype.type(0)
+        if X.nnz == 0:
+            return zero
+        m = min_or_max.reduce(X.data.ravel())
+        if X.nnz != np.product(X.shape):
+            m = min_or_max(zero, m)
+        return m
+    if axis < 0:
+        axis += 2
+    if (axis == 0) or (axis == 1):
+        return _min_or_max_axis(X, axis, min_or_max)
+    else:
+        raise ValueError("invalid axis, use 0 for rows, or 1 for columns")
+
+
+def _sparse_min_max(X, axis):
+        return (_sparse_min_or_max(X, axis, np.minimum),
+                _sparse_min_or_max(X, axis, np.maximum))
+
+
+def _sparse_nan_min_max(X, axis):
+    return(_sparse_min_or_max(X, axis, np.fmin),
+           _sparse_min_or_max(X, axis, np.fmax))
+
+
+def min_max_axis(X, axis, ignore_nan=False):
+    """Compute minimum and maximum along an axis on a CSR or CSC matrix and
+    optionally ignore NaN values.
 
     Parameters
     ----------
@@ -347,6 +409,11 @@ def min_max_axis(X, axis):
     axis : int (either 0 or 1)
         Axis along which the axis should be computed.
 
+    ignore_nan : bool, default is False
+        Ignore or passing through NaN values.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
 
@@ -357,7 +424,10 @@ def min_max_axis(X, axis):
         Feature-wise maxima
     """
     if isinstance(X, sp.csr_matrix) or isinstance(X, sp.csc_matrix):
-        return sparse_min_max(X, axis=axis)
+        if ignore_nan:
+            return _sparse_nan_min_max(X, axis=axis)
+        else:
+            return _sparse_min_max(X, axis=axis)
     else:
         _raise_typeerror(X)
 
diff --git a/sklearn/utils/sparsefuncs_fast.pyx b/sklearn/utils/sparsefuncs_fast.pyx
index efad40a2ea28..7de906cdaa14 100644
--- a/sklearn/utils/sparsefuncs_fast.pyx
+++ b/sklearn/utils/sparsefuncs_fast.pyx
@@ -15,6 +15,7 @@ import numpy as np
 import scipy.sparse as sp
 cimport cython
 from cython cimport floating
+from numpy.math cimport isnan
 
 np.import_array()
 
@@ -64,7 +65,6 @@ def csr_mean_variance_axis0(X):
 
     Returns
     -------
-
     means : float array with shape (n_features,)
         Feature-wise means
 
@@ -74,26 +74,26 @@ def csr_mean_variance_axis0(X):
     """
     if X.dtype != np.float32:
         X = X.astype(np.float64)
-    return _csr_mean_variance_axis0(X.data, X.shape, X.indices)
+    means, variances, _ =  _csr_mean_variance_axis0(X.data, X.shape[0],
+                                                    X.shape[1], X.indices)
+    return means, variances
 
 
 def _csr_mean_variance_axis0(np.ndarray[floating, ndim=1, mode="c"] X_data,
-                             shape,
-                             np.ndarray[int, ndim=1] X_indices):
+                             unsigned long long n_samples,
+                             unsigned long long n_features,
+                             np.ndarray[integral, ndim=1] X_indices):
     # Implement the function here since variables using fused types
     # cannot be declared directly and can only be passed as function arguments
-    cdef unsigned int n_samples = shape[0]
-    cdef unsigned int n_features = shape[1]
-
-    cdef unsigned int i
-    cdef unsigned int non_zero = X_indices.shape[0]
-    cdef unsigned int col_ind
-    cdef floating diff
-
-    # means[j] contains the mean of feature j
-    cdef np.ndarray[floating, ndim=1] means
-    # variances[j] contains the variance of feature j
-    cdef np.ndarray[floating, ndim=1] variances
+    cdef:
+        np.npy_intp i
+        unsigned long long non_zero = X_indices.shape[0]
+        np.npy_intp col_ind
+        floating diff
+        # means[j] contains the mean of feature j
+        np.ndarray[floating, ndim=1] means
+        # variances[j] contains the variance of feature j
+        np.ndarray[floating, ndim=1] variances
 
     if floating is float:
         dtype = np.float32
@@ -103,27 +103,36 @@ def _csr_mean_variance_axis0(np.ndarray[floating, ndim=1, mode="c"] X_data,
     means = np.zeros(n_features, dtype=dtype)
     variances = np.zeros_like(means, dtype=dtype)
 
-    # counts[j] contains the number of samples where feature j is non-zero
-    cdef np.ndarray[int, ndim=1] counts = np.zeros(n_features,
-                                                   dtype=np.int32)
+    cdef:
+        # counts[j] contains the number of samples where feature j is non-zero
+        np.ndarray[np.int64_t, ndim=1] counts = np.zeros(n_features,
+                                                         dtype=np.int64)
+        # counts_nan[j] contains the number of NaNs for feature j
+        np.ndarray[np.int64_t, ndim=1] counts_nan = np.zeros(n_features,
+                                                             dtype=np.int64)
 
     for i in xrange(non_zero):
         col_ind = X_indices[i]
-        means[col_ind] += X_data[i]
+        if not isnan(X_data[i]):
+            means[col_ind] += X_data[i]
+        else:
+            counts_nan[col_ind] += 1
 
-    means /= n_samples
+    for i in xrange(n_features):
+        means[i] /= (n_samples - counts_nan[i])
 
     for i in xrange(non_zero):
         col_ind = X_indices[i]
-        diff = X_data[i] - means[col_ind]
-        variances[col_ind] += diff * diff
-        counts[col_ind] += 1
+        if not isnan(X_data[i]):
+            diff = X_data[i] - means[col_ind]
+            variances[col_ind] += diff * diff
+            counts[col_ind] += 1
 
     for i in xrange(n_features):
-        variances[i] += (n_samples - counts[i]) * means[i] ** 2
-        variances[i] /= n_samples
+        variances[i] += (n_samples - counts_nan[i] - counts[i]) * means[i]**2
+        variances[i] /= (n_samples - counts_nan[i])
 
-    return means, variances
+    return means, variances, counts_nan
 
 
 def csc_mean_variance_axis0(X):
@@ -136,7 +145,6 @@ def csc_mean_variance_axis0(X):
 
     Returns
     -------
-
     means : float array with shape (n_features,)
         Feature-wise means
 
@@ -146,29 +154,30 @@ def csc_mean_variance_axis0(X):
     """
     if X.dtype != np.float32:
         X = X.astype(np.float64)
-    return _csc_mean_variance_axis0(X.data, X.shape, X.indices, X.indptr)
+    means, variances, _ = _csc_mean_variance_axis0(X.data, X.shape[0],
+                                                   X.shape[1], X.indices,
+                                                  X.indptr)
+    return means, variances
 
 
 def _csc_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
-                             shape,
-                             np.ndarray[int, ndim=1] X_indices,
-                             np.ndarray[int, ndim=1] X_indptr):
+                             unsigned long long n_samples,
+                             unsigned long long n_features,
+                             np.ndarray[integral, ndim=1] X_indices,
+                             np.ndarray[integral, ndim=1] X_indptr):
     # Implement the function here since variables using fused types
     # cannot be declared directly and can only be passed as function arguments
-    cdef unsigned int n_samples = shape[0]
-    cdef unsigned int n_features = shape[1]
-
-    cdef unsigned int i
-    cdef unsigned int j
-    cdef unsigned int counts
-    cdef unsigned int startptr
-    cdef unsigned int endptr
-    cdef floating diff
-
-    # means[j] contains the mean of feature j
-    cdef np.ndarray[floating, ndim=1] means
-    # variances[j] contains the variance of feature j
-    cdef np.ndarray[floating, ndim=1] variances
+    cdef:
+        np.npy_intp i, j
+        unsigned long long counts
+        unsigned long long startptr
+        unsigned long long endptr
+        floating diff
+        # means[j] contains the mean of feature j
+        np.ndarray[floating, ndim=1] means
+        # variances[j] contains the variance of feature j
+        np.ndarray[floating, ndim=1] variances
+
     if floating is float:
         dtype = np.float32
     else:
@@ -177,6 +186,9 @@ def _csc_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
     means = np.zeros(n_features, dtype=dtype)
     variances = np.zeros_like(means, dtype=dtype)
 
+    cdef np.ndarray[np.int64_t, ndim=1] counts_nan = np.zeros(n_features,
+                                                              dtype=np.int64)
+
     for i in xrange(n_features):
 
         startptr = X_indptr[i]
@@ -184,20 +196,25 @@ def _csc_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
         counts = endptr - startptr
 
         for j in xrange(startptr, endptr):
-            means[i] += X_data[j]
-        means[i] /= n_samples
+            if not isnan(X_data[j]):
+                means[i] += X_data[j]
+            else:
+                counts_nan[i] += 1
+        counts -= counts_nan[i]
+        means[i] /= (n_samples - counts_nan[i])
 
         for j in xrange(startptr, endptr):
-            diff = X_data[j] - means[i]
-            variances[i] += diff * diff
+            if not isnan(X_data[j]):
+                diff = X_data[j] - means[i]
+                variances[i] += diff * diff
 
-        variances[i] += (n_samples - counts) * means[i] * means[i]
-        variances[i] /= n_samples
+        variances[i] += (n_samples - counts_nan[i] - counts) * means[i]**2
+        variances[i] /= (n_samples - counts_nan[i])
 
-    return means, variances
+    return means, variances, counts_nan
 
 
-def incr_mean_variance_axis0(X, last_mean, last_var, unsigned long last_n):
+def incr_mean_variance_axis0(X, last_mean, last_var, last_n):
     """Compute mean and variance along axis 0 on a CSR or CSC matrix.
 
     last_mean, last_var are the statistics computed at the last step by this
@@ -215,24 +232,26 @@ def incr_mean_variance_axis0(X, last_mean, last_var, unsigned long last_n):
     last_var : float array with shape (n_features,)
       Array of feature-wise var to update with the new data X.
 
-    last_n : int
+    last_n : int array with shape (n_features,)
       Number of samples seen so far, before X.
 
     Returns
     -------
-
     updated_mean : float array with shape (n_features,)
       Feature-wise means
 
     updated_variance : float array with shape (n_features,)
       Feature-wise variances
 
-    updated_n : int
+    updated_n : int array with shape (n_features,)
       Updated number of samples seen
 
+    Notes
+    -----
+    NaNs are ignored during the computation.
+
     References
     ----------
-
     T. Chan, G. Golub, R. LeVeque. Algorithms for computing the sample
       variance: recommendations, The American Statistician, Vol. 37, No. 3,
       pp. 242-247
@@ -243,32 +262,35 @@ def incr_mean_variance_axis0(X, last_mean, last_var, unsigned long last_n):
     """
     if X.dtype != np.float32:
         X = X.astype(np.float64)
-    return _incr_mean_variance_axis0(X.data, X.shape, X.indices, X.indptr,
-                                     X.format, last_mean, last_var, last_n)
+    return _incr_mean_variance_axis0(X.data, X.shape[0], X.shape[1], X.indices,
+                                     X.indptr, X.format, last_mean, last_var,
+                                     last_n)
 
 
 def _incr_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
-                              shape,
-                              np.ndarray[int, ndim=1] X_indices,
-                              np.ndarray[int, ndim=1] X_indptr,
-                              X_format,
-                              last_mean,
-                              last_var,
-                              unsigned long last_n):
+                              unsigned long long n_samples,
+                              unsigned long long n_features,
+                              np.ndarray[integral, ndim=1] X_indices,
+                              np.ndarray[integral, ndim=1] X_indptr,
+                              str X_format,
+                              np.ndarray[floating, ndim=1] last_mean,
+                              np.ndarray[floating, ndim=1] last_var,
+                              np.ndarray[np.int64_t, ndim=1] last_n):
     # Implement the function here since variables using fused types
     # cannot be declared directly and can only be passed as function arguments
-    cdef unsigned long n_samples = shape[0]
-    cdef unsigned int n_features = shape[1]
-    cdef unsigned int i
+    cdef:
+        np.npy_intp i
 
     # last = stats until now
     # new = the current increment
     # updated = the aggregated stats
     # when arrays, they are indexed by i per-feature
-    cdef np.ndarray[floating, ndim=1] new_mean
-    cdef np.ndarray[floating, ndim=1] new_var
-    cdef np.ndarray[floating, ndim=1] updated_mean
-    cdef np.ndarray[floating, ndim=1] updated_var
+    cdef:
+        np.ndarray[floating, ndim=1] new_mean
+        np.ndarray[floating, ndim=1] new_var
+        np.ndarray[floating, ndim=1] updated_mean
+        np.ndarray[floating, ndim=1] updated_var
+
     if floating is float:
         dtype = np.float32
     else:
@@ -279,40 +301,57 @@ def _incr_mean_variance_axis0(np.ndarray[floating, ndim=1] X_data,
     updated_mean = np.zeros_like(new_mean, dtype=dtype)
     updated_var = np.zeros_like(new_mean, dtype=dtype)
 
-    cdef unsigned long new_n
-    cdef unsigned long updated_n
-    cdef floating last_over_new_n
+    cdef:
+        np.ndarray[np.int64_t, ndim=1] new_n
+        np.ndarray[np.int64_t, ndim=1] updated_n
+        np.ndarray[floating, ndim=1] last_over_new_n
+        np.ndarray[np.int64_t, ndim=1] counts_nan
 
     # Obtain new stats first
-    new_n = n_samples
+    new_n = np.ones(n_features, dtype=np.int64) * n_samples
+    updated_n = np.zeros_like(new_n, dtype=np.int64)
+    last_over_new_n = np.zeros_like(new_n, dtype=dtype)
 
     if X_format == 'csr':
         # X is a CSR matrix
-        new_mean, new_var = _csr_mean_variance_axis0(X_data, shape, X_indices)
+        new_mean, new_var, counts_nan = _csr_mean_variance_axis0(
+            X_data, n_samples, n_features, X_indices)
     else:
         # X is a CSC matrix
-        new_mean, new_var = _csc_mean_variance_axis0(X_data, shape, X_indices,
-                                                     X_indptr)
+        new_mean, new_var, counts_nan = _csc_mean_variance_axis0(
+            X_data, n_samples, n_features, X_indices, X_indptr)
+
+    for i in xrange(n_features):
+        new_n[i] -= counts_nan[i]
 
     # First pass
-    if last_n == 0:
+    cdef bint is_first_pass = True
+    for i in xrange(n_features):
+        if last_n[i] > 0:
+            is_first_pass = False
+            break
+    if is_first_pass:
         return new_mean, new_var, new_n
 
     # Next passes
-    updated_n = last_n + new_n
-    last_over_new_n = last_n / new_n
+    for i in xrange(n_features):
+        updated_n[i] = last_n[i] + new_n[i]
+        last_over_new_n[i] = last_n[i] / new_n[i]
 
     # Unnormalized stats
-    last_mean *= last_n
-    last_var *= last_n
-    new_mean *= new_n
-    new_var *= new_n
+    for i in xrange(n_features):
+        last_mean[i] *= last_n[i]
+        last_var[i] *= last_n[i]
+        new_mean[i] *= new_n[i]
+        new_var[i] *= new_n[i]
 
     # Update stats
-    updated_var = (last_var + new_var + last_over_new_n / updated_n *
-                   (last_mean / last_over_new_n - new_mean) ** 2)
-    updated_mean = (last_mean + new_mean) / updated_n
-    updated_var /= updated_n
+    for i in xrange(n_features):
+        updated_var[i] = (last_var[i] + new_var[i] +
+                          last_over_new_n[i] / updated_n[i] *
+                          (last_mean[i] / last_over_new_n[i] - new_mean[i])**2)
+        updated_mean[i] = (last_mean[i] + new_mean[i]) / updated_n[i]
+        updated_var[i] /= updated_n[i]
 
     return updated_mean, updated_var, updated_n
 
diff --git a/sklearn/utils/testing.py b/sklearn/utils/testing.py
index bb67443f97fc..c67a314e2fc5 100644
--- a/sklearn/utils/testing.py
+++ b/sklearn/utils/testing.py
@@ -137,7 +137,6 @@ def assert_warns(warning_class, func, *args, **kw):
     result : the return value of `func`
 
     """
-    # very important to avoid uncontrolled state propagation
     clean_warning_registry()
     with warnings.catch_warnings(record=True) as w:
         # Cause all warnings to always be triggered.
@@ -321,7 +320,6 @@ def __call__(self, fn):
         """Decorator to catch and hide warnings without visual nesting."""
         @wraps(fn)
         def wrapper(*args, **kwargs):
-            # very important to avoid uncontrolled state propagation
             clean_warning_registry()
             with warnings.catch_warnings():
                 warnings.simplefilter("ignore", self.category)
@@ -339,14 +337,14 @@ def __repr__(self):
         return "%s(%s)" % (name, ", ".join(args))
 
     def __enter__(self):
-        clean_warning_registry()  # be safe and not propagate state + chaos
-        warnings.simplefilter("ignore", self.category)
         if self._entered:
             raise RuntimeError("Cannot enter %r twice" % self)
         self._entered = True
         self._filters = self._module.filters
         self._module.filters = self._filters[:]
         self._showwarning = self._module.showwarning
+        clean_warning_registry()
+        warnings.simplefilter("ignore", self.category)
 
     def __exit__(self, *exc_info):
         if not self._entered:
@@ -354,7 +352,7 @@ def __exit__(self, *exc_info):
         self._module.filters = self._filters
         self._module.showwarning = self._showwarning
         self.log[:] = []
-        clean_warning_registry()  # be safe and not propagate state + chaos
+        clean_warning_registry()
 
 
 assert_less = _dummy.assertLess
@@ -551,7 +549,7 @@ def uninstall_mldata_mock():
              'LabelBinarizer', 'LabelEncoder',
              'MultiLabelBinarizer', 'TfidfTransformer',
              'TfidfVectorizer', 'IsotonicRegression',
-             'OneHotEncoder', 'RandomTreesEmbedding', 'CategoricalEncoder',
+             'OneHotEncoder', 'RandomTreesEmbedding', 'OrdinalEncoder',
              'FeatureHasher', 'DummyClassifier', 'DummyRegressor',
              'TruncatedSVD', 'PolynomialFeatures',
              'GaussianRandomProjectionHash', 'HashingVectorizer',
@@ -724,8 +722,13 @@ def run_test(*args, **kwargs):
 
 
 def clean_warning_registry():
-    """Safe way to reset warnings."""
-    warnings.resetwarnings()
+    """Clean Python warning registry for easier testing of warning messages.
+
+    We may not need to do this any more when getting rid of Python 2, not
+    entirely sure. See https://bugs.python.org/issue4180 and
+    https://bugs.python.org/issue21724 for more details.
+
+    """
     reg = "__warningregistry__"
     for mod_name, mod in list(sys.modules.items()):
         if 'six.moves' in mod_name:
diff --git a/sklearn/utils/tests/test_estimator_checks.py b/sklearn/utils/tests/test_estimator_checks.py
index 53a67693843d..049dff4baa92 100644
--- a/sklearn/utils/tests/test_estimator_checks.py
+++ b/sklearn/utils/tests/test_estimator_checks.py
@@ -9,12 +9,14 @@
 from sklearn.externals import joblib
 
 from sklearn.base import BaseEstimator, ClassifierMixin
+from sklearn.utils import deprecated
 from sklearn.utils.testing import (assert_raises_regex, assert_true,
                                    assert_equal, ignore_warnings)
 from sklearn.utils.estimator_checks import check_estimator
 from sklearn.utils.estimator_checks import set_random_state
 from sklearn.utils.estimator_checks import set_checking_parameters
 from sklearn.utils.estimator_checks import check_estimators_unfitted
+from sklearn.utils.estimator_checks import check_fit_score_takes_y
 from sklearn.utils.estimator_checks import check_no_attributes_set_in_init
 from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
 from sklearn.linear_model import LinearRegression, SGDClassifier
@@ -176,6 +178,19 @@ def transform(self, X):
         return sp.csr_matrix(X)
 
 
+def test_check_fit_score_takes_y_works_on_deprecated_fit():
+    # Tests that check_fit_score_takes_y works on a class with
+    # a deprecated fit method
+
+    class TestEstimatorWithDeprecatedFitMethod(BaseEstimator):
+        @deprecated("Deprecated for the purpose of testing "
+                    "check_fit_score_takes_y")
+        def fit(self, X, y):
+            return self
+
+    check_fit_score_takes_y("test", TestEstimatorWithDeprecatedFitMethod())
+
+
 def test_check_estimator():
     # tests that the estimator actually fails on "bad" estimators.
     # not a complete test of all checks, which are very extensive.
diff --git a/sklearn/utils/tests/test_extmath.py b/sklearn/utils/tests/test_extmath.py
index f53b814c7008..ee08e016abe6 100644
--- a/sklearn/utils/tests/test_extmath.py
+++ b/sklearn/utils/tests/test_extmath.py
@@ -9,8 +9,11 @@
 from scipy import linalg
 from scipy import stats
 
+import pytest
+
 from sklearn.utils.testing import assert_equal
 from sklearn.utils.testing import assert_almost_equal
+from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_true
@@ -170,9 +173,10 @@ def check_randomized_svd_low_rank(dtype):
         assert_almost_equal(s[:rank], sa[:rank], decimal=decimal)
 
 
-def test_randomized_svd_low_rank_all_dtypes():
-    for dtype in (np.int32, np.int64, np.float32, np.float64):
-        yield check_randomized_svd_low_rank, dtype
+@pytest.mark.parametrize('dtype',
+                         (np.int32, np.int64, np.float32, np.float64))
+def test_randomized_svd_low_rank_all_dtypes(dtype):
+    check_randomized_svd_low_rank(dtype)
 
 
 @ignore_warnings  # extmath.norm is deprecated to be removed in 0.21
@@ -191,34 +195,35 @@ def test_norm_squared_norm():
                     squared_norm, X.astype(int))
 
 
-def test_row_norms():
+@pytest.mark.parametrize('dtype',
+                         (np.float32, np.float64))
+def test_row_norms(dtype):
     X = np.random.RandomState(42).randn(100, 100)
-    for dtype in (np.float32, np.float64):
-        if dtype is np.float32:
-            precision = 4
-        else:
-            precision = 5
-
-        X = X.astype(dtype)
-        sq_norm = (X ** 2).sum(axis=1)
-
-        assert_array_almost_equal(sq_norm, row_norms(X, squared=True),
+    if dtype is np.float32:
+        precision = 4
+    else:
+        precision = 5
+
+    X = X.astype(dtype)
+    sq_norm = (X ** 2).sum(axis=1)
+
+    assert_array_almost_equal(sq_norm, row_norms(X, squared=True),
+                              precision)
+    assert_array_almost_equal(np.sqrt(sq_norm), row_norms(X), precision)
+
+    for csr_index_dtype in [np.int32, np.int64]:
+        Xcsr = sparse.csr_matrix(X, dtype=dtype)
+        # csr_matrix will use int32 indices by default,
+        # up-casting those to int64 when necessary
+        if csr_index_dtype is np.int64:
+            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype)
+            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype)
+        assert Xcsr.indices.dtype == csr_index_dtype
+        assert Xcsr.indptr.dtype == csr_index_dtype
+        assert_array_almost_equal(sq_norm, row_norms(Xcsr, squared=True),
+                                  precision)
+        assert_array_almost_equal(np.sqrt(sq_norm), row_norms(Xcsr),
                                   precision)
-        assert_array_almost_equal(np.sqrt(sq_norm), row_norms(X), precision)
-
-        for csr_index_dtype in [np.int32, np.int64]:
-            Xcsr = sparse.csr_matrix(X, dtype=dtype)
-            # csr_matrix will use int32 indices by default,
-            # up-casting those to int64 when necessary
-            if csr_index_dtype is np.int64:
-                Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype)
-                Xcsr.indices = Xcsr.indices.astype(csr_index_dtype)
-            assert Xcsr.indices.dtype == csr_index_dtype
-            assert Xcsr.indptr.dtype == csr_index_dtype
-            assert_array_almost_equal(sq_norm, row_norms(Xcsr, squared=True),
-                                      precision)
-            assert_array_almost_equal(np.sqrt(sq_norm), row_norms(Xcsr),
-                                      precision)
 
 
 def test_randomized_svd_low_rank_with_noise():
@@ -361,6 +366,21 @@ def test_randomized_svd_power_iteration_normalizer():
             assert_greater(15, np.abs(error_2 - error))
 
 
+def test_randomized_svd_sparse_warnings():
+    # randomized_svd throws a warning for lil and dok matrix
+    rng = np.random.RandomState(42)
+    X = make_low_rank_matrix(50, 20, effective_rank=10, random_state=rng)
+    n_components = 5
+    for cls in (sparse.lil_matrix, sparse.dok_matrix):
+        X = cls(X)
+        assert_warns_message(
+            sparse.SparseEfficiencyWarning,
+            "Calculating SVD of a {} is expensive. "
+            "csr_matrix is more efficient.".format(cls.__name__),
+            randomized_svd, X, n_components, n_iter=1,
+            power_iteration_normalizer='none')
+
+
 def test_svd_flip():
     # Check that svd_flip works in both situations, and reconstructs input.
     rs = np.random.RandomState(1999)
@@ -480,7 +500,7 @@ def test_incremental_variance_update_formulas():
 
     old_means = X1.mean(axis=0)
     old_variances = X1.var(axis=0)
-    old_sample_count = X1.shape[0]
+    old_sample_count = np.ones(X1.shape[1], dtype=np.int32) * X1.shape[0]
     final_means, final_variances, final_count = \
         _incremental_mean_and_var(X2, old_means, old_variances,
                                   old_sample_count)
@@ -489,6 +509,30 @@ def test_incremental_variance_update_formulas():
     assert_almost_equal(final_count, A.shape[0])
 
 
+def test_incremental_mean_and_variance_ignore_nan():
+    old_means = np.array([535., 535., 535., 535.])
+    old_variances = np.array([4225., 4225., 4225., 4225.])
+    old_sample_count = np.array([2, 2, 2, 2], dtype=np.int32)
+
+    X = np.array([[170, 170, 170, 170],
+                  [430, 430, 430, 430],
+                  [300, 300, 300, 300]])
+
+    X_nan = np.array([[170, np.nan, 170, 170],
+                      [np.nan, 170, 430, 430],
+                      [430, 430, np.nan, 300],
+                      [300, 300, 300, np.nan]])
+
+    X_means, X_variances, X_count = _incremental_mean_and_var(
+        X, old_means, old_variances, old_sample_count)
+    X_nan_means, X_nan_variances, X_nan_count = _incremental_mean_and_var(
+        X_nan, old_means, old_variances, old_sample_count)
+
+    assert_allclose(X_nan_means, X_means)
+    assert_allclose(X_nan_variances, X_variances)
+    assert_allclose(X_nan_count, X_count)
+
+
 @skip_if_32bit
 def test_incremental_variance_numerical_stability():
     # Test Youngs and Cramer incremental variance formulas.
@@ -558,12 +602,13 @@ def naive_mean_variance_update(x, last_mean, last_variance,
     assert_greater(np.abs(stable_var(A) - var).max(), tol)
 
     # Robust implementation: <tol (177)
-    mean, var, n = A0[0, :], np.zeros(n_features), n_samples // 2
+    mean, var = A0[0, :], np.zeros(n_features)
+    n = np.ones(n_features, dtype=np.int32) * (n_samples // 2)
     for i in range(A1.shape[0]):
         mean, var, n = \
             _incremental_mean_and_var(A1[i, :].reshape((1, A1.shape[1])),
                                       mean, var, n)
-    assert_equal(n, A.shape[0])
+    assert_array_equal(n, A.shape[0])
     assert_array_almost_equal(A.mean(axis=0), mean)
     assert_greater(tol, np.abs(stable_var(A) - var).max())
 
@@ -585,7 +630,8 @@ def test_incremental_variance_ddof():
                 incremental_variances = batch.var(axis=0)
                 # Assign this twice so that the test logic is consistent
                 incremental_count = batch.shape[0]
-                sample_count = batch.shape[0]
+                sample_count = (np.ones(batch.shape[1], dtype=np.int32) *
+                                batch.shape[0])
             else:
                 result = _incremental_mean_and_var(
                     batch, incremental_means, incremental_variances,
@@ -599,7 +645,7 @@ def test_incremental_variance_ddof():
             assert_almost_equal(incremental_means, calculated_means, 6)
             assert_almost_equal(incremental_variances,
                                 calculated_variances, 6)
-            assert_equal(incremental_count, sample_count)
+            assert_array_equal(incremental_count, sample_count)
 
 
 def test_vector_sign_flip():
diff --git a/sklearn/utils/tests/test_sparsefuncs.py b/sklearn/utils/tests/test_sparsefuncs.py
index f2b35e745983..838435a0deab 100644
--- a/sklearn/utils/tests/test_sparsefuncs.py
+++ b/sklearn/utils/tests/test_sparsefuncs.py
@@ -1,3 +1,4 @@
+import pytest
 import numpy as np
 import scipy.sparse as sp
 
@@ -19,6 +20,7 @@
                                             inplace_csr_row_normalize_l1,
                                             inplace_csr_row_normalize_l2)
 from sklearn.utils.testing import assert_raises
+from sklearn.utils.testing import assert_allclose
 
 
 def test_mean_variance_axis0():
@@ -94,7 +96,7 @@ def test_incr_mean_variance_axis():
         # default params for incr_mean_variance
         last_mean = np.zeros(n_features)
         last_var = np.zeros_like(last_mean)
-        last_n = 0
+        last_n = np.zeros_like(last_mean, dtype=np.int64)
 
         # Test errors
         X = np.array(data_chunks[0])
@@ -136,6 +138,8 @@ def test_incr_mean_variance_axis():
         for input_dtype, output_dtype in expected_dtypes:
             for X_sparse in (X_csr, X_csc):
                 X_sparse = X_sparse.astype(input_dtype)
+                last_mean = last_mean.astype(output_dtype)
+                last_var = last_var.astype(output_dtype)
                 X_means, X_vars = mean_variance_axis(X_sparse, axis)
                 X_means_incr, X_vars_incr, n_incr = \
                     incr_mean_variance_axis(X_sparse, axis, last_mean,
@@ -147,6 +151,43 @@ def test_incr_mean_variance_axis():
                 assert_equal(X.shape[axis], n_incr)
 
 
+@pytest.mark.parametrize("axis", [0, 1])
+@pytest.mark.parametrize("sparse_constructor", [sp.csc_matrix, sp.csr_matrix])
+def test_incr_mean_variance_axis_ignore_nan(axis, sparse_constructor):
+    old_means = np.array([535., 535., 535., 535.])
+    old_variances = np.array([4225., 4225., 4225., 4225.])
+    old_sample_count = np.array([2, 2, 2, 2], dtype=np.int64)
+
+    X = sparse_constructor(
+        np.array([[170, 170, 170, 170],
+                  [430, 430, 430, 430],
+                  [300, 300, 300, 300]]))
+
+    X_nan = sparse_constructor(
+        np.array([[170, np.nan, 170, 170],
+                  [np.nan, 170, 430, 430],
+                  [430, 430, np.nan, 300],
+                  [300, 300, 300, np.nan]]))
+
+    # we avoid creating specific data for axis 0 and 1: translating the data is
+    # enough.
+    if axis:
+        X = X.T
+        X_nan = X_nan.T
+
+    # take a copy of the old statistics since they are modified in place.
+    X_means, X_vars, X_sample_count = incr_mean_variance_axis(
+        X, axis, old_means.copy(), old_variances.copy(),
+        old_sample_count.copy())
+    X_nan_means, X_nan_vars, X_nan_sample_count = incr_mean_variance_axis(
+        X_nan, axis, old_means.copy(), old_variances.copy(),
+        old_sample_count.copy())
+
+    assert_allclose(X_nan_means, X_means)
+    assert_allclose(X_nan_vars, X_vars)
+    assert_allclose(X_nan_sample_count, X_sample_count)
+
+
 def test_mean_variance_illegal_axis():
     X, _ = make_classification(5, 4, random_state=0)
     # Sparsify the array a little bit
@@ -344,60 +385,27 @@ def test_inplace_swap_column():
     assert_raises(TypeError, inplace_swap_column, X_csr.tolil())
 
 
-def test_min_max_axis0():
+@pytest.mark.parametrize("dtype", [np.float32, np.float64])
+@pytest.mark.parametrize("axis", [0, 1, None])
+@pytest.mark.parametrize("sparse_format", [sp.csr_matrix, sp.csc_matrix])
+@pytest.mark.parametrize(
+    "missing_values, min_func, max_func, ignore_nan",
+    [(0, np.min, np.max, False),
+     (np.nan, np.nanmin, np.nanmax, True)]
+)
+def test_min_max(dtype, axis, sparse_format, missing_values, min_func,
+                 max_func, ignore_nan):
     X = np.array([[0, 3, 0],
-                  [2, -1, 0],
+                  [2, -1, missing_values],
                   [0, 0, 0],
-                  [9, 8, 7],
-                  [4, 0, 5]], dtype=np.float64)
-    X_csr = sp.csr_matrix(X)
-    X_csc = sp.csc_matrix(X)
-
-    mins_csr, maxs_csr = min_max_axis(X_csr, axis=0)
-    assert_array_equal(mins_csr, X.min(axis=0))
-    assert_array_equal(maxs_csr, X.max(axis=0))
-
-    mins_csc, maxs_csc = min_max_axis(X_csc, axis=0)
-    assert_array_equal(mins_csc, X.min(axis=0))
-    assert_array_equal(maxs_csc, X.max(axis=0))
-
-    X = X.astype(np.float32)
-    X_csr = sp.csr_matrix(X)
-    X_csc = sp.csc_matrix(X)
-    mins_csr, maxs_csr = min_max_axis(X_csr, axis=0)
-    assert_array_equal(mins_csr, X.min(axis=0))
-    assert_array_equal(maxs_csr, X.max(axis=0))
-    mins_csc, maxs_csc = min_max_axis(X_csc, axis=0)
-    assert_array_equal(mins_csc, X.min(axis=0))
-    assert_array_equal(maxs_csc, X.max(axis=0))
-
-
-def test_min_max_axis1():
-    X = np.array([[0, 3, 0],
-                  [2, -1, 0],
-                  [0, 0, 0],
-                  [9, 8, 7],
-                  [4, 0, 5]], dtype=np.float64)
-    X_csr = sp.csr_matrix(X)
-    X_csc = sp.csc_matrix(X)
-
-    mins_csr, maxs_csr = min_max_axis(X_csr, axis=1)
-    assert_array_equal(mins_csr, X.min(axis=1))
-    assert_array_equal(maxs_csr, X.max(axis=1))
-
-    mins_csc, maxs_csc = min_max_axis(X_csc, axis=1)
-    assert_array_equal(mins_csc, X.min(axis=1))
-    assert_array_equal(maxs_csc, X.max(axis=1))
-
-    X = X.astype(np.float32)
-    X_csr = sp.csr_matrix(X)
-    X_csc = sp.csc_matrix(X)
-    mins_csr, maxs_csr = min_max_axis(X_csr, axis=1)
-    assert_array_equal(mins_csr, X.min(axis=1))
-    assert_array_equal(maxs_csr, X.max(axis=1))
-    mins_csc, maxs_csc = min_max_axis(X_csc, axis=1)
-    assert_array_equal(mins_csc, X.min(axis=1))
-    assert_array_equal(maxs_csc, X.max(axis=1))
+                  [9, missing_values, 7],
+                  [4, 0, 5]], dtype=dtype)
+    X_sparse = sparse_format(X)
+
+    mins_sparse, maxs_sparse = min_max_axis(X_sparse, axis=axis,
+                                            ignore_nan=ignore_nan)
+    assert_array_equal(mins_sparse, min_func(X, axis=axis))
+    assert_array_equal(maxs_sparse, max_func(X, axis=axis))
 
 
 def test_min_max_axis_errors():
diff --git a/sklearn/utils/tests/test_stats.py b/sklearn/utils/tests/test_stats.py
index fbd05031c87b..36e3bf72b609 100644
--- a/sklearn/utils/tests/test_stats.py
+++ b/sklearn/utils/tests/test_stats.py
@@ -1,3 +1,4 @@
+import pytest
 from sklearn.utils.testing import assert_array_equal, ignore_warnings
 
 from sklearn.utils.stats import rankdata
@@ -13,12 +14,10 @@
 )
 
 
-@ignore_warnings  # Test deprecated backport to be removed in 0.21
-def test_cases():
+@pytest.mark.parametrize("values, method, expected", _cases)
+def test_cases_rankdata(values, method, expected):
 
-    def check_case(values, method, expected):
+    # Test deprecated backport to be removed in 0.21
+    with ignore_warnings():
         r = rankdata(values, method=method)
         assert_array_equal(r, expected)
-
-    for values, method, expected in _cases:
-        yield check_case, values, method, expected
diff --git a/sklearn/utils/tests/test_testing.py b/sklearn/utils/tests/test_testing.py
index 6b55431d21d7..eb9512f177ed 100644
--- a/sklearn/utils/tests/test_testing.py
+++ b/sklearn/utils/tests/test_testing.py
@@ -211,26 +211,19 @@ def context_manager_no_user_multiple_warning():
     assert_warns(DeprecationWarning, context_manager_no_user_multiple_warning)
 
 
-# This class is inspired from numpy 1.7 with an alteration to check
-# the reset warning filters after calls to assert_warns.
-# This assert_warns behavior is specific to scikit-learn because
-# `clean_warning_registry()` is called internally by assert_warns
-# and clears all previous filters.
 class TestWarns(unittest.TestCase):
     def test_warn(self):
         def f():
             warnings.warn("yo")
             return 3
 
-        # Test that assert_warns is not impacted by externally set
-        # filters and is reset internally.
-        # This is because `clean_warning_registry()` is called internally by
-        # assert_warns and clears all previous filters.
-        warnings.simplefilter("ignore", UserWarning)
-        assert_equal(assert_warns(UserWarning, f), 3)
-
-        # Test that the warning registry is empty after assert_warns
-        assert_equal(sys.modules['warnings'].filters, [])
+        with warnings.catch_warnings():
+            warnings.simplefilter("ignore", UserWarning)
+            filters_orig = warnings.filters[:]
+            assert_equal(assert_warns(UserWarning, f), 3)
+            # test that assert_warns doesn't have side effects on warnings
+            # filters
+            assert_equal(warnings.filters, filters_orig)
 
         assert_raises(AssertionError, assert_no_warnings, f)
         assert_equal(assert_no_warnings(lambda x: x, 1), 1)
diff --git a/sklearn/utils/tests/test_utils.py b/sklearn/utils/tests/test_utils.py
index 1f1efed825c8..c2474c58c13f 100644
--- a/sklearn/utils/tests/test_utils.py
+++ b/sklearn/utils/tests/test_utils.py
@@ -21,6 +21,7 @@
 from sklearn.utils import shuffle
 from sklearn.utils import gen_even_slices
 from sklearn.utils import get_chunk_n_rows
+from sklearn.utils import is_scalar_nan
 from sklearn.utils.extmath import pinvh
 from sklearn.utils.arpack import eigsh
 from sklearn.utils.mocking import MockDataFrame
@@ -314,3 +315,18 @@ def check_warning(*args, **kw):
                                max_n_rows=max_n_rows)
         assert actual == expected
         assert type(actual) is type(expected)
+
+
+@pytest.mark.parametrize("value, result", [(float("nan"), True),
+                                           (np.nan, True),
+                                           (np.float("nan"), True),
+                                           (np.float32("nan"), True),
+                                           (np.float64("nan"), True),
+                                           (0, False),
+                                           (0., False),
+                                           (None, False),
+                                           ("", False),
+                                           ("nan", False),
+                                           ([np.nan], False)])
+def test_is_scalar_nan(value, result):
+    assert is_scalar_nan(value) is result
diff --git a/sklearn/utils/tests/test_validation.py b/sklearn/utils/tests/test_validation.py
index 076e6d88440f..5af26ac5b978 100644
--- a/sklearn/utils/tests/test_validation.py
+++ b/sklearn/utils/tests/test_validation.py
@@ -22,6 +22,7 @@
 from sklearn.utils.testing import assert_allclose_dense_sparse
 from sklearn.utils import as_float_array, check_array, check_symmetric
 from sklearn.utils import check_X_y
+from sklearn.utils import deprecated
 from sklearn.utils.mocking import MockDataFrame
 from sklearn.utils.estimator_checks import NotAnArray
 from sklearn.random_projection import sparse_random_matrix
@@ -563,6 +564,15 @@ def test_has_fit_parameter():
     assert_true(has_fit_parameter(SVR, "sample_weight"))
     assert_true(has_fit_parameter(SVR(), "sample_weight"))
 
+    class TestClassWithDeprecatedFitMethod:
+        @deprecated("Deprecated for the purpose of testing has_fit_parameter")
+        def fit(self, X, y, sample_weight=None):
+            pass
+
+    assert has_fit_parameter(TestClassWithDeprecatedFitMethod,
+                             "sample_weight"), \
+        "has_fit_parameter fails for class with deprecated fit method."
+
 
 def test_check_symmetric():
     arr_sym = np.array([[0, 1], [1, 2]])
