Using worker: worker-linux-docker-1c3e8ce5.prod.travis-ci.org:travis-linux-8

travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: python
[34m[1mBuild image provisioning date and time[0m
Thu Feb  5 15:09:33 UTC 2015
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 12.04.5 LTS
Release:	12.04
Codename:	precise
[34m[1mLinux Version[0m
3.13.0-29-generic
[34m[1mCookbooks Version[0m
a68419e https://github.com/travis-ci/travis-cookbooks/tree/a68419e
[34m[1mGCC version[0m
gcc (Ubuntu/Linaro 4.6.3-1ubuntu5) 4.6.3
Copyright (C) 2011 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mLLVM version[0m
clang version 3.4 (tags/RELEASE_34/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
[34m[1mPre-installed Ruby versions[0m
ruby-1.9.3-p551
[34m[1mPre-installed Node.js versions[0m
v0.10.36
[34m[1mPre-installed Go versions[0m
1.4.1
[34m[1mRedis version[0m
redis-server 2.8.19
[34m[1mriak version[0m
2.0.2
[34m[1mMongoDB version[0m
MongoDB 2.4.12
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mNeo4j version[0m
1.9.4
[34m[1mRabbitMQ Version[0m
3.4.3
[34m[1mElasticSearch version[0m
1.4.0
[34m[1mInstalled Sphinx versions[0m
2.0.10
2.1.9
2.2.6
[34m[1mDefault Sphinx version[0m
2.2.6
[34m[1mInstalled Firefox version[0m
firefox 31.0esr
[34m[1mPhantomJS version[0m
1.9.8
[34m[1mant -version[0m
Apache Ant(TM) version 1.8.2 compiled on December 3 2011
[34m[1mmvn -version[0m
Apache Maven 3.2.5 (12a6b3acb947671f09b81f49094c53f426d8cea1; 2014-12-14T17:29:23+00:00)
Maven home: /usr/local/maven
Java version: 1.7.0_76, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-7-oracle/jre
Default locale: en_US, platform encoding: ANSI_X3.4-1968
OS name: "linux", version: "3.13.0-29-generic", arch: "amd64", family: "unix"
travis_fold:end:system_info[0K
travis_fold:start:git.checkout[0Ktravis_time:start:1109f2d4[0K$ git clone --depth=50 --branch=staging https://github.com/Cal-CS-61A-Staff/ok.git Cal-CS-61A-Staff/ok
Cloning into 'Cal-CS-61A-Staff/ok'...
remote: Counting objects: 1439, done.[K
remote: Compressing objects:   0% (1/620)   [Kremote: Compressing objects:   1% (7/620)   [Kremote: Compressing objects:   2% (13/620)   [Kremote: Compressing objects:   3% (19/620)   [Kremote: Compressing objects:   4% (25/620)   [Kremote: Compressing objects:   5% (31/620)   [Kremote: Compressing objects:   6% (38/620)   [Kremote: Compressing objects:   7% (44/620)   [Kremote: Compressing objects:   8% (50/620)   [Kremote: Compressing objects:   9% (56/620)   [Kremote: Compressing objects:  10% (62/620)   [Kremote: Compressing objects:  11% (69/620)   [Kremote: Compressing objects:  12% (75/620)   [Kremote: Compressing objects:  13% (81/620)   [Kremote: Compressing objects:  14% (87/620)   [Kremote: Compressing objects:  15% (93/620)   [Kremote: Compressing objects:  16% (100/620)   [Kremote: Compressing objects:  17% (106/620)   [Kremote: Compressing objects:  18% (112/620)   [Kremote: Compressing objects:  19% (118/620)   [Kremote: Compressing objects:  20% (124/620)   [Kremote: Compressing objects:  21% (131/620)   [Kremote: Compressing objects:  22% (137/620)   [Kremote: Compressing objects:  23% (143/620)   [Kremote: Compressing objects:  24% (149/620)   [Kremote: Compressing objects:  25% (155/620)   [Kremote: Compressing objects:  26% (162/620)   [Kremote: Compressing objects:  27% (168/620)   [Kremote: Compressing objects:  28% (174/620)   [Kremote: Compressing objects:  29% (180/620)   [Kremote: Compressing objects:  30% (186/620)   [Kremote: Compressing objects:  31% (193/620)   [Kremote: Compressing objects:  32% (199/620)   [Kremote: Compressing objects:  33% (205/620)   [Kremote: Compressing objects:  34% (211/620)   [Kremote: Compressing objects:  35% (217/620)   [Kremote: Compressing objects:  36% (224/620)   [Kremote: Compressing objects:  37% (230/620)   [Kremote: Compressing objects:  38% (236/620)   [Kremote: Compressing objects:  39% (242/620)   [Kremote: Compressing objects:  40% (248/620)   [Kremote: Compressing objects:  41% (255/620)   [Kremote: Compressing objects:  42% (261/620)   [Kremote: Compressing objects:  43% (267/620)   [Kremote: Compressing objects:  44% (273/620)   [Kremote: Compressing objects:  45% (279/620)   [Kremote: Compressing objects:  46% (286/620)   [Kremote: Compressing objects:  47% (292/620)   [Kremote: Compressing objects:  48% (298/620)   [Kremote: Compressing objects:  49% (304/620)   [Kremote: Compressing objects:  50% (310/620)   [Kremote: Compressing objects:  51% (317/620)   [Kremote: Compressing objects:  52% (323/620)   [Kremote: Compressing objects:  53% (329/620)   [Kremote: Compressing objects:  54% (335/620)   [Kremote: Compressing objects:  55% (341/620)   [Kremote: Compressing objects:  56% (348/620)   [Kremote: Compressing objects:  57% (354/620)   [Kremote: Compressing objects:  58% (360/620)   [Kremote: Compressing objects:  59% (366/620)   [Kremote: Compressing objects:  60% (372/620)   [Kremote: Compressing objects:  61% (379/620)   [Kremote: Compressing objects:  62% (385/620)   [Kremote: Compressing objects:  63% (391/620)   [Kremote: Compressing objects:  64% (397/620)   [Kremote: Compressing objects:  65% (403/620)   [Kremote: Compressing objects:  66% (410/620)   [Kremote: Compressing objects:  67% (416/620)   [Kremote: Compressing objects:  68% (422/620)   [Kremote: Compressing objects:  69% (428/620)   [Kremote: Compressing objects:  70% (434/620)   [Kremote: Compressing objects:  71% (441/620)   [Kremote: Compressing objects:  72% (447/620)   [Kremote: Compressing objects:  73% (453/620)   [Kremote: Compressing objects:  74% (459/620)   [Kremote: Compressing objects:  75% (465/620)   [Kremote: Compressing objects:  76% (472/620)   [Kremote: Compressing objects:  77% (478/620)   [Kremote: Compressing objects:  78% (484/620)   [Kremote: Compressing objects:  79% (490/620)   [Kremote: Compressing objects:  80% (496/620)   [Kremote: Compressing objects:  81% (503/620)   [Kremote: Compressing objects:  82% (509/620)   [Kremote: Compressing objects:  83% (515/620)   [Kremote: Compressing objects:  84% (521/620)   [Kremote: Compressing objects:  85% (527/620)   [Kremote: Compressing objects:  86% (534/620)   [Kremote: Compressing objects:  87% (540/620)   [Kremote: Compressing objects:  88% (546/620)   [Kremote: Compressing objects:  89% (552/620)   [Kremote: Compressing objects:  90% (558/620)   [Kremote: Compressing objects:  91% (565/620)   [Kremote: Compressing objects:  92% (571/620)   [Kremote: Compressing objects:  93% (577/620)   [Kremote: Compressing objects:  94% (583/620)   [Kremote: Compressing objects:  95% (589/620)   [Kremote: Compressing objects:  96% (596/620)   [Kremote: Compressing objects:  97% (602/620)   [Kremote: Compressing objects:  98% (608/620)   [Kremote: Compressing objects:  99% (614/620)   [Kremote: Compressing objects: 100% (620/620)   [Kremote: Compressing objects: 100% (620/620), done.[K
Receiving objects:   0% (1/1439)   Receiving objects:   1% (15/1439)   Receiving objects:   2% (29/1439)   Receiving objects:   3% (44/1439)   Receiving objects:   4% (58/1439)   Receiving objects:   5% (72/1439)   Receiving objects:   6% (87/1439)   Receiving objects:   7% (101/1439)   Receiving objects:   8% (116/1439)   Receiving objects:   9% (130/1439)   Receiving objects:  10% (144/1439)   Receiving objects:  11% (159/1439)   Receiving objects:  12% (173/1439)   Receiving objects:  13% (188/1439)   Receiving objects:  14% (202/1439)   Receiving objects:  15% (216/1439)   Receiving objects:  16% (231/1439)   Receiving objects:  17% (245/1439)   Receiving objects:  18% (260/1439)   Receiving objects:  19% (274/1439)   Receiving objects:  20% (288/1439)   Receiving objects:  21% (303/1439)   Receiving objects:  22% (317/1439)   Receiving objects:  23% (331/1439)   Receiving objects:  24% (346/1439)   Receiving objects:  25% (360/1439)   Receiving objects:  26% (375/1439)   Receiving objects:  27% (389/1439)   Receiving objects:  28% (403/1439)   Receiving objects:  29% (418/1439)   Receiving objects:  30% (432/1439)   Receiving objects:  31% (447/1439)   Receiving objects:  32% (461/1439)   Receiving objects:  33% (475/1439)   Receiving objects:  34% (490/1439)   Receiving objects:  35% (504/1439)   Receiving objects:  36% (519/1439)   Receiving objects:  37% (533/1439)   Receiving objects:  38% (547/1439)   Receiving objects:  39% (562/1439)   Receiving objects:  40% (576/1439)   Receiving objects:  41% (590/1439)   Receiving objects:  42% (605/1439)   Receiving objects:  43% (619/1439)   Receiving objects:  44% (634/1439)   Receiving objects:  45% (648/1439)   Receiving objects:  46% (662/1439)   Receiving objects:  47% (677/1439)   Receiving objects:  48% (691/1439)   Receiving objects:  49% (706/1439)   Receiving objects:  50% (720/1439)   Receiving objects:  51% (734/1439)   Receiving objects:  52% (749/1439)   Receiving objects:  53% (763/1439)   Receiving objects:  54% (778/1439)   Receiving objects:  55% (792/1439)   Receiving objects:  56% (806/1439)   Receiving objects:  57% (821/1439)   Receiving objects:  58% (835/1439)   Receiving objects:  59% (850/1439)   Receiving objects:  60% (864/1439)   Receiving objects:  61% (878/1439)   Receiving objects:  62% (893/1439)   Receiving objects:  63% (907/1439)   Receiving objects:  64% (921/1439)   Receiving objects:  65% (936/1439)   Receiving objects:  66% (950/1439)   Receiving objects:  67% (965/1439)   Receiving objects:  68% (979/1439)   Receiving objects:  69% (993/1439)   Receiving objects:  70% (1008/1439)   Receiving objects:  71% (1022/1439)   Receiving objects:  72% (1037/1439)   Receiving objects:  73% (1051/1439)   Receiving objects:  74% (1065/1439)   Receiving objects:  75% (1080/1439)   Receiving objects:  76% (1094/1439)   Receiving objects:  77% (1109/1439)   Receiving objects:  78% (1123/1439)   Receiving objects:  79% (1137/1439)   Receiving objects:  80% (1152/1439)   Receiving objects:  81% (1166/1439)   Receiving objects:  82% (1180/1439)   Receiving objects:  83% (1195/1439)   Receiving objects:  84% (1209/1439)   Receiving objects:  85% (1224/1439)   Receiving objects:  86% (1238/1439)   Receiving objects:  87% (1252/1439)   Receiving objects:  88% (1267/1439)   Receiving objects:  89% (1281/1439)   Receiving objects:  90% (1296/1439)   Receiving objects:  91% (1310/1439)   Receiving objects:  92% (1324/1439)   Receiving objects:  93% (1339/1439)   Receiving objects:  94% (1353/1439)   Receiving objects:  95% (1368/1439)   remote: Total 1439 (delta 933), reused 1203 (delta 794), pack-reused 0[K
Receiving objects:  96% (1382/1439)   Receiving objects:  97% (1396/1439)   Receiving objects:  98% (1411/1439)   Receiving objects:  99% (1425/1439)   Receiving objects: 100% (1439/1439)   Receiving objects: 100% (1439/1439), 1.40 MiB | 0 bytes/s, done.
Resolving deltas:   0% (0/933)   Resolving deltas:   1% (11/933)   Resolving deltas:  19% (183/933)   Resolving deltas:  20% (190/933)   Resolving deltas:  21% (203/933)   Resolving deltas:  22% (208/933)   Resolving deltas:  34% (326/933)   Resolving deltas:  40% (381/933)   Resolving deltas:  41% (383/933)   Resolving deltas:  42% (394/933)   Resolving deltas:  43% (404/933)   Resolving deltas:  44% (411/933)   Resolving deltas:  49% (462/933)   Resolving deltas:  50% (474/933)   Resolving deltas:  54% (509/933)   Resolving deltas:  55% (522/933)   Resolving deltas:  56% (523/933)   Resolving deltas:  57% (533/933)   Resolving deltas:  58% (543/933)   Resolving deltas:  59% (551/933)   Resolving deltas:  60% (560/933)   Resolving deltas:  62% (586/933)   Resolving deltas:  63% (588/933)   Resolving deltas:  64% (602/933)   Resolving deltas:  65% (609/933)   Resolving deltas:  66% (617/933)   Resolving deltas:  67% (633/933)   Resolving deltas:  68% (637/933)   Resolving deltas:  69% (649/933)   Resolving deltas:  70% (654/933)   Resolving deltas:  71% (664/933)   Resolving deltas:  72% (673/933)   Resolving deltas:  75% (704/933)   Resolving deltas:  76% (710/933)   Resolving deltas:  77% (719/933)   Resolving deltas:  78% (729/933)   Resolving deltas:  79% (738/933)   Resolving deltas:  80% (747/933)   Resolving deltas:  81% (756/933)   Resolving deltas:  82% (769/933)   Resolving deltas:  83% (775/933)   Resolving deltas:  86% (810/933)   Resolving deltas:  88% (827/933)   Resolving deltas:  90% (843/933)   Resolving deltas:  91% (855/933)   Resolving deltas:  93% (868/933)   Resolving deltas:  94% (882/933)   Resolving deltas:  95% (892/933)   Resolving deltas:  96% (900/933)   Resolving deltas:  97% (906/933)   Resolving deltas:  99% (925/933)   Resolving deltas: 100% (933/933)   Resolving deltas: 100% (933/933), done.
Checking connectivity... done.
travis_time:end:1109f2d4:start=1446882864106505339,finish=1446882864709422819,duration=602917480[0K$ cd Cal-CS-61A-Staff/ok
$ git checkout -qf 1ab975ffb1223ac5645d209436c9399945fe0a29
travis_fold:end:git.checkout[0K
[33;1mThis job is running on container-based infrastructure, which does not allow use of 'sudo', setuid and setguid executables.[0m
[33;1mIf you require sudo, add 'sudo: required' to your .travis.yml[0m
[33;1mSee http://docs.travis-ci.com/user/workers/container-based-infrastructure/ for details.[0m

[33;1mSetting environment variables from .travis.yml[0m
$ export CMD=server/apptest.py
$ export GAE_VERSION=1.9.23

travis_fold:start:cache.1[0KSetting up build cache
$ export CASHER_DIR=$HOME/.casher
travis_time:start:25c0f1f4[0K$ Installing caching utilities
travis_time:end:25c0f1f4:start=1446882867585062985,finish=1446882867638551569,duration=53488584[0Ktravis_time:start:061a1060[0Kattempting to download cache archive
fetching staging/cache--python-2.7.tgz
found cache
travis_time:end:061a1060:start=1446882867643272930,finish=1446882868526844925,duration=883571995[0Ktravis_time:start:17360762[0Kadding /home/travis/virtualenv/python2.7.9 to cache
travis_time:end:17360762:start=1446882868530771534,finish=1446882870433937731,duration=1903166197[0Ktravis_fold:end:cache.1[0Ktravis_time:start:003ad3be[0K$ source ~/virtualenv/python2.7/bin/activate
travis_time:end:003ad3be:start=1446882870437933641,finish=1446882870441524472,duration=3590831[0K$ python --version
Python 2.7.9
$ pip --version
pip 7.1.2 from /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (python 2.7)
travis_fold:start:install.1[0Ktravis_time:start:025724d0[0K$ pip install pip --upgrade
Collecting pip
  Downloading pip-7.1.2-py2.py3-none-any.whl (1.1MB)
[?25l[K    0% |▏                               | 4.1kB 34.2MB/s eta 0:00:01[K    0% |▎                               | 8.2kB 28.8MB/s eta 0:00:01[K    1% |▍                               | 12kB 29.2MB/s eta 0:00:01[K    1% |▌                               | 16kB 27.5MB/s eta 0:00:01[K    1% |▋                               | 20kB 28.3MB/s eta 0:00:01[K    2% |▊                               | 24kB 29.1MB/s eta 0:00:01[K    2% |▉                               | 28kB 29.6MB/s eta 0:00:01[K    2% |█                               | 32kB 28.3MB/s eta 0:00:01[K    3% |█                               | 36kB 28.5MB/s eta 0:00:01[K    3% |█▏                              | 40kB 29.1MB/s eta 0:00:01[K    4% |█▎                              | 45kB 28.8MB/s eta 0:00:01[K    4% |█▍                              | 49kB 28.8MB/s eta 0:00:01[K    4% |█▌                              | 53kB 29.1MB/s eta 0:00:01[K    5% |█▋                              | 57kB 30.4MB/s eta 0:00:01[K    5% |█▊                              | 61kB 30.5MB/s eta 0:00:01[K    5% |█▉                              | 65kB 28.8MB/s eta 0:00:01[K    6% |██                              | 69kB 28.6MB/s eta 0:00:01[K    6% |██▏                             | 73kB 30.1MB/s eta 0:00:01[K    7% |██▎                             | 77kB 30.5MB/s eta 0:00:01[K    7% |██▍                             | 81kB 28.9MB/s eta 0:00:01[K    7% |██▌                             | 86kB 28.6MB/s eta 0:00:01[K    8% |██▋                             | 90kB 29.7MB/s eta 0:00:01[K    8% |██▊                             | 94kB 29.7MB/s eta 0:00:01[K    8% |██▉                             | 98kB 24.9MB/s eta 0:00:01[K    9% |███                             | 102kB 24.8MB/s eta 0:00:01[K    9% |███                             | 106kB 26.1MB/s eta 0:00:01[K    9% |███▏                            | 110kB 26.3MB/s eta 0:00:01[K    10% |███▎                            | 114kB 25.6MB/s eta 0:00:01[K    10% |███▍                            | 118kB 25.5MB/s eta 0:00:01[K    11% |███▌                            | 122kB 26.7MB/s eta 0:00:01[K    11% |███▋                            | 126kB 27.1MB/s eta 0:00:01[K    11% |███▊                            | 131kB 26.2MB/s eta 0:00:01[K    12% |████                            | 135kB 26.2MB/s eta 0:00:01[K    12% |████                            | 139kB 31.5MB/s eta 0:00:01[K    12% |████▏                           | 143kB 31.7MB/s eta 0:00:01[K    13% |████▎                           | 147kB 30.6MB/s eta 0:00:01[K    13% |████▍                           | 151kB 30.5MB/s eta 0:00:01[K    14% |████▌                           | 155kB 31.8MB/s eta 0:00:01[K    14% |████▋                           | 159kB 31.7MB/s eta 0:00:01[K    14% |████▊                           | 163kB 30.4MB/s eta 0:00:01[K    15% |████▉                           | 167kB 30.4MB/s eta 0:00:01[K    15% |█████                           | 172kB 31.6MB/s eta 0:00:01[K    15% |█████                           | 176kB 31.6MB/s eta 0:00:01[K    16% |█████▏                          | 180kB 30.0MB/s eta 0:00:01[K    16% |█████▎                          | 184kB 29.9MB/s eta 0:00:01[K    16% |█████▍                          | 188kB 31.0MB/s eta 0:00:01[K    17% |█████▌                          | 192kB 31.0MB/s eta 0:00:01[K    17% |█████▋                          | 196kB 29.3MB/s eta 0:00:01[K    18% |█████▉                          | 200kB 29.0MB/s eta 0:00:01[K    18% |██████                          | 204kB 30.1MB/s eta 0:00:01[K    18% |██████                          | 208kB 30.1MB/s eta 0:00:01[K    19% |██████▏                         | 212kB 28.6MB/s eta 0:00:01[K    19% |██████▎                         | 217kB 28.5MB/s eta 0:00:01[K    19% |██████▍                         | 221kB 30.1MB/s eta 0:00:01[K    20% |██████▌                         | 225kB 30.1MB/s eta 0:00:01[K    20% |██████▋                         | 229kB 28.7MB/s eta 0:00:01[K    21% |██████▊                         | 233kB 28.7MB/s eta 0:00:01[K    21% |██████▉                         | 237kB 30.2MB/s eta 0:00:01[K    21% |███████                         | 241kB 30.6MB/s eta 0:00:01[K    22% |███████                         | 245kB 29.3MB/s eta 0:00:01[K    22% |███████▏                        | 249kB 29.2MB/s eta 0:00:01[K    22% |███████▎                        | 253kB 30.8MB/s eta 0:00:01[K    23% |███████▍                        | 258kB 30.9MB/s eta 0:00:01[K    23% |███████▌                        | 262kB 29.4MB/s eta 0:00:01[K    23% |███████▋                        | 266kB 29.3MB/s eta 0:00:01[K    24% |███████▉                        | 270kB 30.7MB/s eta 0:00:01[K    24% |████████                        | 274kB 30.9MB/s eta 0:00:01[K    25% |████████                        | 278kB 29.4MB/s eta 0:00:01[K    25% |████████▏                       | 282kB 29.3MB/s eta 0:00:01[K    25% |████████▎                       | 286kB 30.8MB/s eta 0:00:01[K    26% |████████▍                       | 290kB 30.8MB/s eta 0:00:01[K    26% |████████▌                       | 294kB 29.7MB/s eta 0:00:01[K    26% |████████▋                       | 299kB 29.7MB/s eta 0:00:01[K    27% |████████▊                       | 303kB 31.1MB/s eta 0:00:01[K    27% |████████▉                       | 307kB 31.4MB/s eta 0:00:01[K    28% |█████████                       | 311kB 29.8MB/s eta 0:00:01[K    28% |█████████                       | 315kB 29.7MB/s eta 0:00:01[K    28% |█████���███▏                      | 319kB 30.8MB/s eta 0:00:01[K    29% |█████████▎                      | 323kB 30.7MB/s eta 0:00:01[K    29% |█████████▍                      | 327kB 29.2MB/s eta 0:00:01[K    29% |█████████▌                      | 331kB 29.2MB/s eta 0:00:01[K    30% |█████████▊                      | 335kB 30.4MB/s eta 0:00:01[K    30% |█████████▉                      | 339kB 30.4MB/s eta 0:00:01[K    30% |██████████                      | 344kB 29.3MB/s eta 0:00:01[K    31% |██████████                      | 348kB 29.3MB/s eta 0:00:01[K    31% |██████████▏                     | 352kB 30.8MB/s eta 0:00:01[K    32% |██████████▎                     | 356kB 30.8MB/s eta 0:00:01[K    32% |██████████▍                     | 360kB 29.6MB/s eta 0:00:01[K    32% |██████████▌                     | 364kB 29.7MB/s eta 0:00:01[K    33% |██████████▋                     | 368kB 31.2MB/s eta 0:00:01[K    33% |██████████▊                     | 372kB 31.3MB/s eta 0:00:01[K    33% |██████████▉                     | 376kB 29.7MB/s eta 0:00:01[K    34% |███████████                     | 380kB 29.4MB/s eta 0:00:01[K    34% |███████████                     | 385kB 30.7MB/s eta 0:00:01[K    35% |███████████▏                    | 389kB 30.7MB/s eta 0:00:01[K    35% |███████████▎                    | 393kB 29.1MB/s eta 0:00:01[K    35% |███████████▍                    | 397kB 29.1MB/s eta 0:00:01[K    36% |███████████▋                    | 401kB 30.7MB/s eta 0:00:01[K    36% |███████████▊                    | 405kB 30.8MB/s eta 0:00:01[K    36% |███████████▉                    | 409kB 29.3MB/s eta 0:00:01[K    37% |████████████                    | 413kB 29.2MB/s eta 0:00:01[K    37% |████████████                    | 417kB 30.7MB/s eta 0:00:01[K    37% |████████████▏                   | 421kB 30.7MB/s eta 0:00:01[K    38% |████████████▎                   | 425kB 29.2MB/s eta 0:00:01[K    38% |████████████▍                   | 430kB 29.1MB/s eta 0:00:01[K    39% |████████████▌                   | 434kB 30.6MB/s eta 0:00:01[K    39% |████████████▋                   | 438kB 25.2MB/s eta 0:00:01[K    39% |████████████▊                   | 442kB 24.1MB/s eta 0:00:01[K    40% |████████████▉                   | 446kB 24.0MB/s eta 0:00:01[K    40% |█████████████                   | 450kB 25.0MB/s eta 0:00:01[K    40% |█████████████                   | 454kB 25.1MB/s eta 0:00:01[K    41% |█████████████▏                  | 458kB 24.1MB/s eta 0:00:01[K    41% |█████████████▎                  | 462kB 24.0MB/s eta 0:00:01[K    42% |█████████████▌                  | 466kB 25.1MB/s eta 0:00:01[K    42% |█████████████▋                  | 471kB 25.1MB/s eta 0:00:01[K    42% |█████████████▊                  | 475kB 24.4MB/s eta 0:00:01[K    43% |█████████████▉                  | 479kB 29.6MB/s eta 0:00:01[K    43% |██████████████                  | 483kB 31.4MB/s eta 0:00:01[K    43% |██████████████                  | 487kB 31.5MB/s eta 0:00:01[K    44% |██████████████▏                 | 491kB 29.9MB/s eta 0:00:01[K    44% |██████████████▎                 | 495kB 29.4MB/s eta 0:00:01[K    44% |██████████████▍                 | 499kB 30.9MB/s eta 0:00:01[K    45% |██████████████▌                 | 503kB 31.1MB/s eta 0:00:01[K    45% |██████████████▋                 | 507kB 30.1MB/s eta 0:00:01[K    46% |██████████████▊                 | 512kB 30.0MB/s eta 0:00:01[K    46% |██████████████▉                 | 516kB 31.1MB/s eta 0:00:01[K    46% |███████████████                 | 520kB 31.2MB/s eta 0:00:01[K    47% |███████████████                 | 524kB 29.6MB/s eta 0:00:01[K    47% |███████████████▏                | 528kB 29.5MB/s eta 0:00:01[K    47% |███████████████▎                | 532kB 31.1MB/s eta 0:00:01[K    48% |███████████████▌                | 536kB 31.6MB/s eta 0:00:01[K    48% |███████████████▋                | 540kB 30.1MB/s eta 0:00:01[K    49% |███████████████▊                | 544kB 30.0MB/s eta 0:00:01[K    49% |█████���█████████▉                | 548kB 31.1MB/s eta 0:00:01[K    49% |████████████████                | 552kB 30.3MB/s eta 0:00:01[K    50% |████████████████                | 557kB 29.1MB/s eta 0:00:01[K    50% |████████████████▏               | 561kB 29.0MB/s eta 0:00:01[K    50% |████████████████▎               | 565kB 30.4MB/s eta 0:00:01[K    51% |████████████████▍               | 569kB 30.5MB/s eta 0:00:01[K    51% |████████████████▌               | 573kB 29.0MB/s eta 0:00:01[K    51% |████████████████▋               | 577kB 28.8MB/s eta 0:00:01[K    52% |████████████████▊               | 581kB 30.3MB/s eta 0:00:01[K    52% |████████████████▉               | 585kB 30.4MB/s eta 0:00:01[K    53% |█████████████████               | 589kB 29.0MB/s eta 0:00:01[K    53% |█████████████████               | 593kB 29.6MB/s eta 0:00:01[K    53% |█████████████████▏              | 598kB 30.8MB/s eta 0:00:01[K    54% |█████████████████▍              | 602kB 30.9MB/s eta 0:00:01[K    54% |█████████████████▌              | 606kB 29.9MB/s eta 0:00:01[K    54% |█████████████████▋              | 610kB 29.8MB/s eta 0:00:01[K    55% |█████████████████▊              | 614kB 31.3MB/s eta 0:00:01[K    55% |█████████████████▉              | 618kB 31.4MB/s eta 0:00:01[K    56% |██████████████████              | 622kB 29.9MB/s eta 0:00:01[K    56% |██████████████████              | 626kB 29.6MB/s eta 0:00:01[K    56% |██████████████████▏             | 630kB 31.2MB/s eta 0:00:01[K    57% |██████████████████▎             | 634kB 31.2MB/s eta 0:00:01[K    57% |██████████████████▍             | 638kB 30.1MB/s eta 0:00:01[K    57% |██████████████████▌             | 643kB 30.0MB/s eta 0:00:01[K    58% |██████████████████▋             | 647kB 31.2MB/s eta 0:00:01[K    58% |██████████████████▊             | 651kB 31.2MB/s eta 0:00:01[K    58% |██████████████████▉             | 655kB 29.7MB/s eta 0:00:01[K    59% |███████████████████             | 659kB 29.6MB/s eta 0:00:01[K    59% |███████████████████             | 663kB 31.1MB/s eta 0:00:01[K    60% |███████████████████▎            | 667kB 31.3MB/s eta 0:00:01[K    60% |███████████████████▍            | 671kB 30.2MB/s eta 0:00:01[K    60% |███████████████████▌            | 675kB 29.8MB/s eta 0:00:01[K    61% |███████████████████▋            | 679kB 30.9MB/s eta 0:00:01[K    61% |███████████████████▊            | 684kB 30.9MB/s eta 0:00:01[K    61% |███████████████████▉            | 688kB 29.7MB/s eta 0:00:01[K    62% |████████████████████            | 692kB 29.6MB/s eta 0:00:01[K    62% |████████████████████            | 696kB 31.2MB/s eta 0:00:01[K    63% |████████████████████▏           | 700kB 31.4MB/s eta 0:00:01[K    63% |████████████████████▎           | 704kB 30.2MB/s eta 0:00:01[K    63% |████████████████████▍           | 708kB 30.2MB/s eta 0:00:01[K    64% |████████████████████▌           | 712kB 31.3MB/s eta 0:00:01[K    64% |████████████████████▋           | 716kB 31.8MB/s eta 0:00:01[K    64% |████████████████████▊           | 720kB 30.3MB/s eta 0:00:01[K    65% |████████████████████▉           | 724kB 30.1MB/s eta 0:00:01[K    65% |█████████████████████           | 729kB 31.3MB/s eta 0:00:01[K    65% |█████████████████████           | 733kB 31.5MB/s eta 0:00:01[K    66% |█████████████████████▎          | 737kB 29.9MB/s eta 0:00:01[K    66% |█████████████████████▍          | 741kB 29.8MB/s eta 0:00:01[K    67% |█████████████████████▌          | 745kB 30.9MB/s eta 0:00:01[K    67% |█████████████████████▋          | 749kB 30.3MB/s eta 0:00:01[K    67% |█████████████████████▊          | 753kB 27.7MB/s eta 0:00:01[K    68% |█████████████████████▉          | 757kB 27.5MB/s eta 0:00:01[K    68% |██████████████████████          | 761kB 28.7MB/s eta 0:00:01[K    68% |██████████████████████          | 765kB 28.8MB/s eta 0:00:01[K    69% |██████████████████████▏         | 770kB 27.5MB/s eta 0:00:01[K    69% |██████████████████████▎         | 774kB 27.4MB/s eta 0:00:01[K    70% |██████████████████████▍         | 778kB 28.7MB/s eta 0:00:01[K    70% |██████████████████████▌         | 782kB 28.7MB/s eta 0:00:01[K    70% |██████████████████████▋         | 786kB 27.4MB/s eta 0:00:01[K    71% |██████████████████████▊         | 790kB 27.5MB/s eta 0:00:01[K    71% |██████████████████████▉         | 794kB 30.0MB/s eta 0:00:01[K    71% |███████████████████████         | 798kB 30.3MB/s eta 0:00:01[K    72% |███████████████████████▏        | 802kB 29.2MB/s eta 0:00:01[K    72% |███████████████████████▎        | 806kB 29.0MB/s eta 0:00:01[K    72% |███████████████████████▍        | 811kB 30.6MB/s eta 0:00:01[K    73% |███████████████████████▌        | 815kB 30.7MB/s eta 0:00:01[K    73% |███████████████████████▋        | 819kB 29.2MB/s eta 0:00:01[K    74% |███████████████████████▊        | 823kB 29.1MB/s eta 0:00:01[K    74% |███████████████████████▉        | 827kB 30.6MB/s eta 0:00:01[K    74% |████████████████████████        | 831kB 31.1MB/s eta 0:00:01[K    75% |████████████████████████        | 835kB 29.6MB/s eta 0:00:01[K    75% |████████████████████████▏       | 839kB 29.5MB/s eta 0:00:01[K    75% |████████████████████████▎       | 843kB 30.6MB/s eta 0:00:01[K    76% |████████████████████████▍       | 847kB 30.7MB/s eta 0:00:01[K    76% |████████████████████████▌       | 851kB 29.7MB/s eta 0:00:01[K    77% |████████████████████████▋       | 856kB 29.6MB/s eta 0:00:01[K    77% |████████████████████████▊       | 860kB 31.3MB/s eta 0:00:01[K    77% |████████████████████████▉       | 864kB 31.4MB/s eta 0:00:01[K    78% |█████████████████████████       | 868kB 29.8MB/s eta 0:00:01[K    78% |█████████████████████████▏      | 872kB 29.7MB/s eta 0:00:01[K    78% |█████████████████████████▎      | 876kB 31.3MB/s eta 0:00:01[K    79% |█████████████████████████▍      | 880kB 31.4MB/s eta 0:00:01[K    79% |█████████████████████████▌      | 884kB 29.8MB/s eta 0:00:01[K    79% |█████████████████████████▋      | 888kB 29.7MB/s eta 0:00:01[K    80% |█████████████████████████▊      | 892kB 30.7MB/s eta 0:00:01[K    80% |█████████████████████████▉      | 897kB 30.7MB/s eta 0:00:01[K    81% |██████████████████████████      | 901kB 29.6MB/s eta 0:00:01[K    81% |██████████████████████████      | 905kB 29.6MB/s eta 0:00:01[K    81% |██████████████████████████▏     | 909kB 31.1MB/s eta 0:00:01[K    82% |██████████████████████████▎     | 913kB 30.8MB/s eta 0:00:01[K    82% |██████████████████████████▍     | 917kB 29.1MB/s eta 0:00:01[K    82% |██████████████████████████▌     | 921kB 29.0MB/s eta 0:00:01[K    83% |██████████████████████████▋     | 925kB 30.6MB/s eta 0:00:01[K    83% |██████████████████████████▊     | 929kB 30.7MB/s eta 0:00:01[K    84% |███████████████████████████     | 933kB 29.2MB/s eta 0:00:01[K    84% |█���█████████████████████████     | 937kB 29.1MB/s eta 0:00:01[K    84% |███████████████████████████▏    | 942kB 30.2MB/s eta 0:00:01[K    85% |███████████████████████████▎    | 946kB 30.2MB/s eta 0:00:01[K    85% |███████████████████████████▍    | 950kB 29.2MB/s eta 0:00:01[K    85% |███████████████████████████▌    | 954kB 29.5MB/s eta 0:00:01[K    86% |███████████████████████████▋    | 958kB 31.1MB/s eta 0:00:01[K    86% |███████████████████████████▊    | 962kB 31.2MB/s eta 0:00:01[K    86% |███████████████████████████▉    | 966kB 29.7MB/s eta 0:00:01[K    87% |████████████████████████████    | 970kB 29.6MB/s eta 0:00:01[K    87% |████████████████████████████    | 974kB 31.1MB/s eta 0:00:01[K    88% |████████████████████████████▏   | 978kB 31.2MB/s eta 0:00:01[K    88% |████████████████████████████▎   | 983kB 30.1MB/s eta 0:00:01[K    88% |████████████████████████████▍   | 987kB 30.0MB/s eta 0:00:01[K    89% |████████████████████████████▌   | 991kB 31.0MB/s eta 0:00:01[K    89% |████████████████████████████▋   | 995kB 31.1MB/s eta 0:00:01[K    89% |████████████████████████████▊   | 999kB 29.9MB/s eta 0:00:01[K    90% |█████████████████████████████   | 1.0MB 29.9MB/s eta 0:00:01[K    90% |█████████████████████████████   | 1.0MB 31.5MB/s eta 0:00:01[K    91% |█████████████████████████████▏  | 1.0MB 31.6MB/s eta 0:00:01[K    91% |█████████████████████████████▎  | 1.0MB 30.5MB/s eta 0:00:01[K    91% |█████████████████████████████▍  | 1.0MB 30.5MB/s eta 0:00:01[K    92% |█████████████████████████████▌  | 1.0MB 31.2MB/s eta 0:00:01[K    92% |█████████████████████████████▋  | 1.0MB 31.2MB/s eta 0:00:01[K    92% |█████████████████████████████▊  | 1.0MB 30.1MB/s eta 0:00:01[K    93% |█████████████████████████████▉  | 1.0MB 29.8MB/s eta 0:00:01[K    93% |██████████████████████████████  | 1.0MB 30.9MB/s eta 0:00:01[K    93% |██████████████████████████████  | 1.0MB 31.0MB/s eta 0:00:01[K    94% |██████████████████████████████▏ | 1.0MB 29.8MB/s eta 0:00:01[K    94% |██████████████████████████████▎ | 1.1MB 29.7MB/s eta 0:00:01[K    95% |██████████████████████████████▍ | 1.1MB 30.9MB/s eta 0:00:01[K    95% |██████████████████████████████▌ | 1.1MB 30.9MB/s eta 0:00:01[K    95% |██████████████████████████████▋ | 1.1MB 30.2MB/s eta 0:00:01[K    96% |██████████████████████████████▉ | 1.1MB 30.2MB/s eta 0:00:01[K    96% |███████████████████████████████ | 1.1MB 31.4MB/s eta 0:00:01[K    96% |███████████████████████████████ | 1.1MB 32.0MB/s eta 0:00:01[K    97% |███████████████████████████████▏| 1.1MB 30.8MB/s eta 0:00:01[K    97% |███████████████████████████████▎| 1.1MB 30.7MB/s eta 0:00:01[K    98% |███████████████████████████████▍| 1.1MB 31.8MB/s eta 0:00:01[K    98% |███████████████████████████████▌| 1.1MB 32.0MB/s eta 0:00:01[K    98% |███████████████████████████████▋| 1.1MB 30.8MB/s eta 0:00:01[K    99% |███████████████████████████████▊| 1.1MB 30.8MB/s eta 0:00:01[K    99% |███████████████████████████████▉| 1.1MB 32.0MB/s eta 0:00:01[K    99% |████████████████████████████████| 1.1MB 32.1MB/s eta 0:00:01[K    100% |████████████████████████████████| 1.1MB 521kB/s 
[?25hInstalling collected packages: pip
  Found existing installation: pip 6.0.7
    Uninstalling pip-6.0.7:
      Successfully uninstalled pip-6.0.7
Successfully installed pip-7.1.2
travis_time:end:025724d0:start=1446882870711773293,finish=1446882871965458363,duration=1253685070[0Ktravis_fold:end:install.1[0Ktravis_fold:start:install.2[0Ktravis_time:start:215e60d0[0K$ pip install -r server_requirements.txt
Requirement already satisfied (use --upgrade to upgrade): Flask==0.10.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 1))
Requirement already satisfied (use --upgrade to upgrade): Flask-Cache==0.13.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 2))
Requirement already satisfied (use --upgrade to upgrade): Jinja2==2.7.3 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 3))
Requirement already satisfied (use --upgrade to upgrade): MarkupSafe==0.23 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 4))
Requirement already satisfied (use --upgrade to upgrade): PyYAML==3.11 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 5))
Requirement already satisfied (use --upgrade to upgrade): Pygments==1.6 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 6))
Requirement already satisfied (use --upgrade to upgrade): Sphinx==1.2.2 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 7))
Requirement already satisfied (use --upgrade to upgrade): Werkzeug==0.9.6 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 8))
Requirement already satisfied (use --upgrade to upgrade): argparse==1.2.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 9))
Requirement already satisfied (use --upgrade to upgrade): astroid==1.1.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 10))
Requirement already satisfied (use --upgrade to upgrade): docutils==0.11 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 11))
Requirement already satisfied (use --upgrade to upgrade): git-pylint-commit-hook==2.0.5 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 12))
Requirement already satisfied (use --upgrade to upgrade): itsdangerous==0.24 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 13))
Obtaining linkenv-master from git+git://github.com/ze-phyr-us/linkenv.git@ae463b3211cb8dcc8868e88176a1101733c83b6d#egg=linkenv-master (from -r server_requirements.txt (line 14))
  Updating /home/travis/virtualenv/python2.7.9/src/linkenv-master clone (to ae463b3211cb8dcc8868e88176a1101733c83b6d)
[33m  Could not find a tag or branch 'ae463b3211cb8dcc8868e88176a1101733c83b6d', assuming commit.[0m
Requirement already satisfied (use --upgrade to upgrade): logilab-common==0.61.0 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 15))
Requirement already satisfied (use --upgrade to upgrade): mimerender==0.5.4 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 16))
Requirement already satisfied (use --upgrade to upgrade): nose==1.3.4 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 17))
Requirement already satisfied (use --upgrade to upgrade): pylint==1.2.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 18))
Requirement already satisfied (use --upgrade to upgrade): python-dateutil==2.2 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 19))
Requirement already satisfied (use --upgrade to upgrade): python-mimeparse==0.1.4 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 20))
Requirement already satisfied (use --upgrade to upgrade): requests==2.3.0 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 21))
Requirement already satisfied (use --upgrade to upgrade): six==1.6.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 22))
Requirement already satisfied (use --upgrade to upgrade): sphinxcontrib-httpdomain==1.2.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 23))
Requirement already satisfied (use --upgrade to upgrade): unittest2==0.5.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 24))
Requirement already satisfied (use --upgrade to upgrade): wsgiref==0.1.2 in /opt/python/2.7.9/lib/python2.7 (from -r server_requirements.txt (line 25))
Requirement already satisfied (use --upgrade to upgrade): ddt==0.8.0 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 26))
Requirement already satisfied (use --upgrade to upgrade): webargs==0.5.0 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 27))
Requirement already satisfied (use --upgrade to upgrade): webob==1.1.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 28))
Requirement already satisfied (use --upgrade to upgrade): pytz==2014.10 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 29))
Requirement already satisfied (use --upgrade to upgrade): coverage==3.7.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 30))
Requirement already satisfied (use --upgrade to upgrade): coveralls==0.5 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from -r server_requirements.txt (line 31))
Collecting mock==1.3.0 (from -r server_requirements.txt (line 32))
  Downloading mock-1.3.0-py2.py3-none-any.whl (56kB)
[?25l[K    7% |██▎                             | 4.1kB 33.6MB/s eta 0:00:01[K    14% |████▋                           | 8.2kB 28.0MB/s eta 0:00:01[K    21% |███████                         | 12kB 28.5MB/s eta 0:00:01[K    29% |█████████▎                      | 16kB 25.9MB/s eta 0:00:01[K    36% |███████████▋                    | 20kB 26.8MB/s eta 0:00:01[K    43% |██████████████                  | 24kB 27.7MB/s eta 0:00:01[K    50% |████████████████▎               | 28kB 28.3MB/s eta 0:00:01[K    58% |██████████████████▋             | 32kB 27.7MB/s eta 0:00:01[K    65% |█████████████████████           | 36kB 28.0MB/s eta 0:00:01[K    72% |███████████████████████▎        | 40kB 28.7MB/s eta 0:00:01[K    80% |█████████████████████████▋      | 45kB 28.5MB/s eta 0:00:01[K    87% |████████████████████████████    | 49kB 28.9MB/s eta 0:00:01[K    94% |██████████████████████████████▎ | 53kB 29.2MB/s eta 0:00:01[K    100% |████████████████████████████████| 57kB 7.0MB/s 
[?25hRequirement already satisfied (use --upgrade to upgrade): docopt>=0.6.1 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from coveralls==0.5->-r server_requirements.txt (line 31))
Requirement already satisfied (use --upgrade to upgrade): funcsigs in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from mock==1.3.0->-r server_requirements.txt (line 32))
Requirement already satisfied (use --upgrade to upgrade): pbr>=0.11 in /home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages (from mock==1.3.0->-r server_requirements.txt (line 32))
Installing collected packages: linkenv-master, mock
  Running setup.py develop for linkenv-master
  Found existing installation: mock 1.0.1
    Uninstalling mock-1.0.1:
      Successfully uninstalled mock-1.0.1
Successfully installed linkenv-master mock-1.3.0
travis_time:end:215e60d0:start=1446882871969390375,finish=1446882872859045124,duration=889654749[0Ktravis_fold:end:install.2[0Ktravis_fold:start:before_script.1[0Ktravis_time:start:0a4f0940[0K$ wget https://storage.googleapis.com/appengine-sdks/featured/google_appengine_$GAE_VERSION.zip -o gae_sdk.zip
travis_time:end:0a4f0940:start=1446882872862959160,finish=1446882873286406319,duration=423447159[0Ktravis_fold:end:before_script.1[0Ktravis_fold:start:before_script.2[0Ktravis_time:start:0b015904[0K$ unzip -q google_appengine_$GAE_VERSION.zip
travis_time:end:0b015904:start=1446882873290368719,finish=1446882875176516998,duration=1886148279[0Ktravis_fold:end:before_script.2[0Ktravis_fold:start:before_script.3[0Ktravis_time:start:0f4ecc3f[0K$ mv google_appengine gae_sdk
travis_time:end:0f4ecc3f:start=1446882875180877169,finish=1446882875191856721,duration=10979552[0Ktravis_fold:end:before_script.3[0Ktravis_fold:start:before_script.4[0Ktravis_time:start:15c5f66e[0K$ export GAE_SDK=$PWD/gae_sdk
travis_time:end:15c5f66e:start=1446882875196367036,finish=1446882875199639079,duration=3272043[0Ktravis_fold:end:before_script.4[0Ktravis_fold:start:before_script.5[0Ktravis_time:start:0e27b56a[0K$ export PATH=$PATH:$GAE_SDK
travis_time:end:0e27b56a:start=1446882875203865856,finish=1446882875207156369,duration=3290513[0Ktravis_fold:end:before_script.5[0Ktravis_fold:start:before_script.6[0Ktravis_time:start:23dc3630[0K$ export PYTHONPATH=$PYTHONPATH:$GAE_SDK
travis_time:end:23dc3630:start=1446882875211328627,finish=1446882875214631638,duration=3303011[0Ktravis_fold:end:before_script.6[0Ktravis_fold:start:before_script.7[0Ktravis_time:start:2f6777a0[0K$ python server/app/generate_keys.py
travis_time:end:2f6777a0:start=1446882875218824582,finish=1446882875244716968,duration=25892386[0Ktravis_fold:end:before_script.7[0Ktravis_time:start:31fd3025[0K$ FLASK_CONF=TEST coverage run $CMD --sdk_location $GAE_SDK --quiet
============================================================
Doing regression testing
============================================================
..........................................................................................
----------------------------------------------------------------------
Ran 90 tests in 0.682s

OK
============================================================
Doing permissions testing
============================================================
...............................................................................................................................................................
----------------------------------------------------------------------
Ran 159 tests in 23.214s

OK
============================================================
Doing integration testing
============================================================
..................................................................................................................................................................................................................................................................................................
----------------------------------------------------------------------
Ran 290 tests in 19.039s

OK
ALL TESTS PASSED
travis_time:end:31fd3025:start=1446882875248600939,finish=1446882920181745128,duration=44933144189[0K
[32;1mThe command "FLASK_CONF=TEST coverage run $CMD --sdk_location $GAE_SDK --quiet" exited with 0.[0m
travis_fold:start:cache.2[0Kstore build cache
travis_time:start:15c0c78c[0Kchange detected:
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock-1.0.1-py2.7.egg-info/dependency_links.txt
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock-1.0.1-py2.7.egg-info/installed-files.txt
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock-1.0.1-py2.7.egg-info/PKG-INFO
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock-1.0.1-py2.7.egg-info/SOURCES.txt
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock-1.0.1-py2.7.egg-info/top_level.txt
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock/__init__.pyc
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock/__init__.pyc
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock/mock.pyc
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock/mock.pyc
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock.py
/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/mock.pyc
/home/trav
...
changes detected, packing new archive
uploading archive
travis_time:end:15c0c78c:start=1446882920186148526,finish=1446882924856134519,duration=4669985993[0Ktravis_fold:end:cache.2[0Ktravis_fold:start:after_success.1[0Ktravis_time:start:07ba8a28[0K$ coveralls
Submitting coverage to coveralls.io...
Coverage submitted!
Job #3685.1
https://coveralls.io/jobs/9541468
travis_time:end:07ba8a28:start=1446882924860064401,finish=1446882926185969373,duration=1325904972[0Ktravis_fold:end:after_success.1[0Ktravis_fold:start:after_success.2[0Ktravis_time:start:071f6c58[0K$ coveralls debug
Missing .coveralls.yml file. Using only env variables.
Testing coveralls-python...
{"service_job_id": "89788123", "service_name": "travis-ci", "git": {"head": {"committer_email": "sumukh1@gmail.com", "author_email": "sumukh1@gmail.com", "author_name": "Sumukh Sridhara", "message": "ensure staging branch stays on staging", "committer_name": "Sumukh Sridhara", "id": "1ab975ffb1223ac5645d209436c9399945fe0a29"}, "remotes": [{"url": "https://github.com/Cal-CS-61A-Staff/ok.git", "name": "origin"}], "branch": "staging"}, "config_file": ".coveragerc", "source_files": [{"source": "import time\n\nfrom google.appengine.ext import ndb, deferred\nfrom app.analytics.mapper import Mapper\nfrom app.models import Base, User\n\n\nclass JobException(Exception):\n    \"\"\"\n    Represents an Exception that happens in a Mapper or Reducer.\n    \"\"\"\n    def __init__(self, message, job_type):\n        self.message = message\n        self.job_type = job_type\n\n\nclass JobMapper(Mapper):\n    \"\"\"\n    A wrapper class for the NDB Mapper that stores\n    map results in an NDB AnalyticsDump in addition to just mapping.\n    \"\"\"\n    def __init__(self, kind, user, job_dump, job_mapper, filters):\n        super(JobMapper, self).__init__(kind, user)\n        self.job_dump = job_dump\n        self.job_mapper = job_mapper\n        self.set_filters(filters)\n\n    def map(self, entity):\n        try:\n            map_result = self.job_mapper(entity)\n        except Exception as e:\n            raise JobException(e.message, \"map\")\n        self.job_dump.map_result.append(map_result)\n        self.job_dump.map_count += 1\n        self.job_dump.put()\n\n\nclass JobReducer(object):\n    \"\"\"\n    A class that performs a reduce job on a map result\n    and stores the result in an NDB AnalyticsDump.\n    \"\"\"\n    def __init__(self, job_dump, job_reducer):\n        self.job_dump = job_dump\n        self.job_reducer = job_reducer\n\n    def run(self, map_result):\n        try:\n            reduce_result = self.job_reducer(map_result)\n        except Exception as e:\n            raise JobException(e.message, \"reduce\")\n        self.job_dump.result = {\n            'result': reduce_result\n        }\n        self.job_dump.put()\n\n\nclass Job(object):\n    \"\"\"\n    A class that represents a map-reduce job over some sort of\n    entity in NDB. Each Job corresponds to an AnalyticsDump\n    entity in NDB that stores the intermediary and final results.\n    The user of this object needs to specify a mapper and\n    a reducer over entities.\n    \"\"\"\n    FAILURE = \"failure\"\n    SUCCESS = \"success\"\n\n    MAPPING = \"mapping\"\n    REDUCING = \"reducing\"\n\n    def __init__(self, kind, user, mapper, reducer, filters, save_output=False):\n        self.kind = kind\n        self.user = user\n        self.job_dump = AnalyticsDump(owner=user.key)\n        self.job_mapper = JobMapper(kind, user, self.job_dump, mapper, filters)\n        self.job_reducer = JobReducer(self.job_dump, reducer)\n        self.save_output = save_output\n\n    def start(self):\n        self.job_dump.initialize()\n        self.job_dump.update_status('starting')\n        result = deferred.defer(self._run)\n        return result\n\n    def wait(self, poll_time=1):\n        # Hacky polling implementation, but not sure of a better way\n        status = self.get_status()\n        while status != self.FAILURE and status != self.SUCCESS:\n            time.sleep(poll_time)\n            status = self.get_status()\n\n    def get_status(self):\n        return self.get_dump().status\n\n    def get_dump(self):\n        return self.job_dump.key.get()\n\n    def _run(self):\n        self.job_dump.update_status(self.MAPPING)\n        try:\n            self.job_mapper.run()\n            self.job_dump.update_status(self.REDUCING)\n            self.job_reducer.run(self.job_dump.map_result)\n            if not self.save_output:\n                self.clean_up()\n            self.job_dump.update_status(self.SUCCESS)\n        except JobException as e:\n            self.clean_up()\n            self.job_dump.error = '%s: %s' % (e.job_type, e.message)\n            self.job_dump.update_status(self.FAILURE)\n            raise deferred.PermanentTaskFailure()\n\n    def clean_up(self):\n        self.job_dump.map_result = None\n\n\nclass AnalyticsDump(Base):\n    \"\"\"Represents the intermediary and final results of an analytics job\"\"\"\n    map_result = ndb.JsonProperty()\n    map_count = ndb.IntegerProperty()\n    result = ndb.JsonProperty()\n    status = ndb.StringProperty()\n    error = ndb.StringProperty()\n    owner = ndb.KeyProperty(User)\n\n    def initialize(self):\n        self.map_result = []\n        self.map_count = 0\n\n    def update_status(self, status):\n        self.status = status\n        self.put()\n\n    @classmethod\n    def _can(cls, user, need, obj, query):\n        if need.action == \"index\":\n            if user.is_admin:\n                return query\n            return query.filter(AnalyticsDump.owner == user.key)\n        if need.action == \"create\":\n            return True\n        if need.action == \"get\":\n            if user.is_admin:\n                return True\n            return obj.owner == user.key\n        return False\n", "name": "server/app/analytics/job.py", "coverage": [1, null, 1, 1, 1, null, null, 1, null, null, null, 1, 1, 1, null, null, 1, null, null, null, null, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, null, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, 1, null, null, null, null, null, null, null, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null]}, {"source": "from app import models\n\nKIND = models.User\n\ndef mapper(entity):\n    return entity.email\n\ndef reducer(map_result):\n    return len(map_result)\n\n", "name": "server/app/analytics/jobs/sample_job.py", "coverage": [1, null, 1, null, 1, 1, null, 1, 1, null, null]}, {"source": "\"\"\"\nNDB Mapper, taken from http://blog.altlimit.com/2013/05/simple-mapper-class-for-ndb-on-app.html,\ninspired by http://cloud.google.com/appengine/articles/remote_api\n\"\"\"\n\nimport logging\nfrom google.appengine.ext import deferred, ndb\nfrom google.appengine.runtime import DeadlineExceededError\n\nfrom app.needs import Need\n\n\nclass Mapper(object):\n\n    def __init__(self, kind, user, use_cache=False):\n\n        ndb.get_context().set_cache_policy(use_cache)\n        if not use_cache:\n            ndb.get_context().clear_cache()\n\n        self.kind = kind\n        self.user = user\n        self.to_put = []\n        self.to_delete = []\n        self.terminate = False\n        # Data you wanna carry on in case of error\n        self.data = None\n        # Temporary Data that won't carry on in case of error\n        self.tmp_data = None\n        self.filters = []\n        self.orders = []\n        self.keys_only = False\n        self.initial_query = None\n        # implement init for different initializations\n        self.init()\n\n    def delete(self, entity):\n        self.to_delete.append(entity if isinstance(entity, ndb.Key) else entity.key)\n\n    def update(self, entity):\n        self.to_put.append(entity)\n\n    def map(self, entity):\n        \"\"\"Updates a single entity.\n\n        Implementers should return a tuple containing two iterables (to_update, to_delete).\n        \"\"\"\n        raise NotImplementedError\n\n    def init(self):\n        # initialize variables\n        pass\n\n    def deadline_error(self):\n        # on deadline error execute\n        pass\n\n    def finish(self):\n        \"\"\"Called when the mapper has finished, to allow for any final work to be done.\"\"\"\n        pass\n\n    def get_query(self):\n        \"\"\"Returns a query over the specified kind, with any appropriate filters applied.\"\"\"\n        q = self.kind.can(self.user, Need('index'), query=self.kind.query())\n        for filter in self.filters:\n            q = q.filter(ndb.query.FilterNode(*filter))\n        for order in self.orders:\n            q = q.order(order)\n        return q\n\n    def set_filters(self, filters):\n        self.filters = filters\n\n    def run(self, batch_size=100, initial_data=None):\n        if initial_data is None:\n            initial_data = self.data\n        \"\"\"Starts the mapper running.\"\"\"\n        if hasattr(self, '_pre_run_hook'):\n            getattr(self, '_pre_run_hook')()\n\n        self._continue(None, batch_size, initial_data)\n\n    def _batch_write(self):\n        \"\"\"Writes updates and deletes entities in a batch.\"\"\"\n        if self.to_put:\n            ndb.put_multi(self.to_put)\n            del self.to_put[:]\n        if self.to_delete:\n            ndb.delete_multi(self.to_delete)\n            del self.to_delete[:]\n\n    def _continue(self, cursor, batch_size, data):\n        self.data = data\n        q = self.get_query()\n        if q is None:\n            self.finish()\n            return\n        # If we're resuming, pick up where we left off last time.\n        iter = q.iter(produce_cursors=True, start_cursor=cursor, keys_only=self.keys_only)\n        try:\n            # Steps over the results, returning each entity and its index.\n            i = 0\n            while iter.has_next():\n                entity = iter.next()\n                self.map(entity)\n                # Do updates and deletes in batches.\n                if (i + 1) % batch_size == 0:\n                    # Record the last entity we processed.\n                    self._batch_write()\n                i += 1\n                if self.terminate:\n                    break\n\n            self._batch_write()\n        except DeadlineExceededError:\n            # Write any unfinished updates to the datastore.\n            self._batch_write()\n            self.deadline_error()\n            # Queue a new task to pick up where we left off.\n            deferred.defer(self._continue, iter.cursor_after(), batch_size, self.data)\n            logging.error(self.__class__.__name__ + ' DeadlineExceedError')\n            return\n        self.finish()\n", "name": "server/app/analytics/mapper.py", "coverage": [null, null, null, null, null, 1, 1, 1, null, 1, null, null, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, null, 1, 0, null, 1, 0, null, 1, null, null, null, null, null, null, 1, null, null, null, 1, null, null, null, 1, null, null, null, 1, null, 1, 1, 0, 1, 0, 1, null, 1, 1, null, 1, 1, 1, null, 1, 0, null, 1, null, 1, null, 1, 0, 0, 1, 0, 0, null, 1, 1, 1, 1, 0, 0, null, 1, 1, null, 1, 1, 1, 1, null, 1, null, 0, 1, 1, 0, null, 1, 1, null, 0, 0, null, 0, 0, 0, 1, null]}, {"source": "\"\"\"\n\nTHE PUBLIC API\n\nThis file is responsible for API endpoints. In here, all\nmethods should handle:\n\n    - web arguments\n      Parse and \"translate\" web arguments where need be,\n      so that models.py can easily generate queries or\n      perform business logic.\n\n    - file formats\n      Prepare .zip, .csv etc. files.\n\n    - errors\n      Catch and return errors, so that the front-end can\n      feed that information back to the user.\n\nOther data-related and logic functionality should go in\nmodels.py. See that file for more information\n\n\"\"\"\n\n#pylint: disable=no-member,unused-argument\n\nimport datetime\nimport logging\nimport ast\nimport requests\nimport flask\n\nfrom flask.views import View\nfrom flask.app import request, json\nfrom flask import session, make_response, redirect\nfrom webargs import Arg\nfrom webargs.flaskparser import FlaskParser\nfrom app.constants import STUDENT_ROLE, STAFF_ROLE, API_PREFIX, AUTOGRADER_URL\n\nfrom app import models, app, analytics, utils\nfrom app.needs import Need\nfrom app.utils import paginate, filter_query, create_zip, add_to_zip, start_zip, finish_zip\nfrom app.utils import scores_to_gcs, subms_to_gcs, make_zip_filename, submit_to_ag\nfrom app.utils import add_to_grading_queues, parse_date, assign_submission, assign_staff_to_queues\nfrom app.utils import merge_user, backup_group_file, add_to_file_contents\nfrom app.utils import autograde_final_subs, autograde_subms, promote_student_backups\n\nfrom app.exceptions import *\n\nfrom google.appengine.ext import ndb\nfrom google.appengine.ext import deferred\nfrom google.appengine.ext.ndb import stats\nfrom google.appengine.api import memcache\n\nimport re\nimport operator as op\n\nparser = FlaskParser()\n\n\ndef parse_json_field(field):\n    \"\"\"\n    Parses field or list, or returns appropriate boolean value.\n\n    :param field: (string)\n    :return: (string) parsed JSON\n    \"\"\"\n    if not field[0] in ['{', '[']:\n        if field == 'false':\n            return False\n        elif field == 'true':\n            return True\n        return field\n    return json.loads(field)\n\n\nparse_json_list_field = parse_json_field\n\n# Arguments to convert query strings to a python type\n\ndef DateTimeArg(**kwds):\n    \"\"\"\n    Converts a webarg to a datetime object\n\n    :param kwds: (dictionary) set of parameters\n    :return: (Arg) type of argument\n    \"\"\"\n    def parse_date(arg):\n        op = None\n        if '|' in arg:\n            op, arg = arg.split('|', 1)\n\n        date = datetime.datetime.strptime(arg,\n                                          app.config['GAE_DATETIME_FORMAT'])\n        delta = datetime.timedelta(hours=7)\n        date = (datetime.datetime.combine(date.date(), date.time()) + delta)\n        return (op, date) if op else date\n    return Arg(None, use=parse_date, **kwds)\n\nMODEL_VERSION = 'v2'\n\ndef try_int(x):\n    try:\n        return int(x)\n    except (ValueError, TypeError):\n        return x\n\ndef KeyArg(cls, **kwds):\n    \"\"\"\n    Converts a webarg to a key in Google's ndb.\n\n    :param cls: (string) class\n    :param kwds: (dictionary) -- unused --\n    :return: (Arg) type of argument\n    \"\"\"\n    def parse_key(key):\n        key = try_int(key)\n        return {'pairs': [(cls + MODEL_VERSION, key)]}\n    return Arg(ndb.Key, use=parse_key, **kwds)\n\n\ndef KeyRepeatedArg(cls, **kwds):\n    \"\"\"\n    Converts a repeated argument to a list\n\n    :param cls: (string)\n    :param kwds: (dictionary) -- unused --\n    :return: (Arg) type of argument\n    \"\"\"\n    def parse_list(key_list):\n        staff_lst = key_list\n        if not isinstance(key_list, list):\n            if ',' in key_list:\n                staff_lst = key_list.split(',')\n                staff_lst = map(try_int, staff_lst)\n            else:\n                staff_lst = [try_int(key_list)]\n        return [ndb.Key(cls + MODEL_VERSION, x) for x in staff_lst]\n    return Arg(None, use=parse_list, **kwds)\n\n\ndef BooleanArg(**kwargs):\n    \"\"\"\n    Converts a webarg to a boolean.\n\n    :param kwargs: (dictionary) -- unused --\n    :return: (Arg) type of argument\n    \"\"\"\n    def parse_bool(arg):\n        if isinstance(arg, bool):\n            return arg\n        if arg == 'false':\n            return False\n        if arg == 'true':\n            return True\n        raise BadValueError(\n            \"malformed boolean %s: either 'true' or 'false'\" % arg)\n    return Arg(None, use=parse_bool, **kwargs)\n\n\nclass APIResource(View):\n    \"\"\"\n    Base class for API Resource. Set models for each.\n    \"\"\"\n\n    model = None\n    methods = {}\n    key_type = int\n    api_version = 'v1'\n\n    @property\n    def name(self):\n        return self.model.__name__\n\n    def get_instance(self, key, user):\n        \"\"\"\n        Get instance of the object, checking against user privileges.\n\n        :param key: (int) ID of object\n        :param user: (object) user object\n        :return: (object, Exception)\n        \"\"\"\n        obj = self.model.get_by_id(key)\n        if not obj:\n            raise BadKeyError(key)\n\n        need = Need('get')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        return obj\n\n    def call_method(self, method_name, user, http_method,\n                    instance=None, is_index=False):\n        \"\"\"\n        Call method if it exists and if it's properly called.\n\n        :param method_name: (string) name of desired method\n        :param user: (object) caller\n        :param http_method: (string) get, post, put, or delete\n        :param instance: (string)\n        :param is_index: (bool) whether or not this is an index call\n        :return: result of called method\n        \"\"\"\n        if method_name not in self.methods:\n            raise BadMethodError('Unimplemented method %s' % method_name)\n        constraints = self.methods[method_name]\n        if 'methods' in constraints:\n            if http_method is None:\n                raise IncorrectHTTPMethodError('Need to specify HTTP method')\n            if http_method not in constraints['methods']:\n                raise IncorrectHTTPMethodError('Bad HTTP Method: %s'\n                                               % http_method)\n        data = {}\n        web_args = constraints.get('web_args', {})\n        data = self.parse_args(web_args, user, is_index=is_index)\n        method = getattr(self, method_name)\n        if instance is not None:\n            return method(instance, user, data)\n        return method(user, data)\n\n    def dispatch_request(self, path, *args, **kwargs):\n        \"\"\"\n        \"Does the request dispatching. Matches the URL and returns\n        the return value of the view or error handler. This does\n        not have to be a response object.\"\n        - http://flask.pocoo.org/docs/0.10/api/\n\n        :param path: (string) full URL\n        :param args: (list)\n        :param kwargs: (dictionary)\n        :return: result of an attempt to call method\n        \"\"\"\n        http_method = flask.request.method.upper()\n        user = flask.session['user']\n\n        if path is None:  # Index\n            if http_method not in ('GET', 'POST'):\n                raise IncorrectHTTPMethodError('Incorrect HTTP method: %s')\n            method_name = {'GET': 'index', 'POST': 'post'}[http_method]\n            return self.call_method(method_name, user, http_method,\n                                    is_index=(method_name == 'index'))\n\n        path = path.split('/')\n\n        if len(path) == 1:\n\n            if not getattr(self, 'contains_entities', True):\n                return self.call_method(path[0], user, http_method)\n\n            entity_id = path[0]\n            try:\n                key = self.key_type(entity_id)\n            except (ValueError, AssertionError):\n                raise BadValueError('Invalid key. Needs to be of type: %s'\n                                    % self.key_type)\n            instance = self.get_instance(key, user)\n            method_name = http_method.lower()\n            return self.call_method(method_name, user, http_method,\n                                    instance=instance)\n\n        entity_id, method_name = path\n        try:\n            key = self.key_type(entity_id)\n        except (ValueError, AssertionError):\n            raise BadValueError('Invalid key. Needs to be of type: %s'\n                                % self.key_type)\n        instance = self.get_instance(key, user)\n        return self.call_method(method_name, user, http_method,\n                                instance=instance)\n\n    def get(self, obj, user, data):\n        \"\"\"\n        GET HTTP method\n\n        :param obj: (object) target\n        :param user: -- unused --\n        :param data: -- unused --\n        :return: target object\n        \"\"\"\n        return obj\n\n    def put(self, obj, user, data):\n        \"\"\"\n        The PUT HTTP method\n        \"\"\"\n        need = Need('put')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        blank_val = object()\n        changed = False\n        for key, value in data.iteritems():\n            old_val = getattr(obj, key, blank_val)\n            if old_val == blank_val:\n                return 400, '{} is not a valid field.'.format(key)\n\n            setattr(obj, key, value)\n            changed = True\n\n        if changed:\n            obj.put()\n\n        return obj\n\n    def post(self, user, data):\n        \"\"\"\n        PUT HTTP method\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: -- unused --\n        :return: target\n        \"\"\"\n        entity = self.new_entity(data)\n\n        need = Need('create')\n        if not self.model.can(user, need, obj=entity):\n            raise need.exception()\n\n        entity.put()\n\n        return (201, 'success', {\n            'key': entity.key.id()\n        })\n\n    def new_entity(self, attributes):\n        \"\"\"\n        Creates a new entity with given attributes.\n\n        :param attributes: (dictionary)\n        :return: (entity, error_response) should be ignored if error_response\n        is a True value\n        \"\"\"\n        return self.model.from_dict(attributes)\n\n    def delete(self, obj, user, data):\n        \"\"\"\n        DELETE HTTP method\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: -- unused --\n        :return: None\n        \"\"\"\n        need = Need('delete')\n        if not self.model.can(user, need, obj=obj):\n            raise need.exception()\n\n        obj.key.delete()\n\n    def parse_args(self, web_args, user, is_index=False):\n        \"\"\"\n        Parses the arguments to this API call.\n\n        :param web_args: (string) arguments passed as querystring\n        :param user: (object) caller\n        :param is_index: (bool) whether or not this is an index call\n        :return: (dictionary) mapping keys to values in web arguments\n        \"\"\"\n        fields = parser.parse({\n            'fields': Arg(None, use=parse_json_field)\n        })\n        if fields['fields'] is None:\n            fields['fields'] = {}\n        if type(fields['fields']) != dict and type(fields['fields']) != bool:\n            raise BadValueError('fields should be dictionary or boolean')\n        request.fields = fields\n        return {k: v for k, v in parser.parse(web_args).iteritems()\n                if v is not None}\n\n    def index(self, user, data):\n        \"\"\"\n        Index HTTP method. Should be called from GET when no key is provided.\n\n        Processes cursor and num_page URL arguments for pagination support.\n\n        :param user: (object) caller\n        :param data: (dictionary)\n        :return: results for query\n        \"\"\"\n        query = self.model.query()\n        need = Need('index')\n\n        result = self.model.can(user, need, query=query)\n        if not result:\n            raise need.exception()\n\n        query = filter_query(result, data, self.model)\n        created_prop = getattr(self.model, 'created', None)\n        if not query.orders and created_prop:\n            logging.info('Adding default ordering by creation time.')\n            query = query.order(-created_prop, self.model.key)\n\n        page = int(request.args.get('page', 1))\n        # default page length is 100\n        num_page = int(request.args.get('num_page', 100))\n        query_results = paginate(query, page, num_page)\n\n        add_statistics = request.args.get('stats', False)\n        if add_statistics:\n            query_results['statistics'] = self.statistics()\n        return query_results\n\n    def statistics(self):\n        \"\"\"\n        Provide statistics for any entity.\n\n        :return: (dictionary) empty or a 'total' count\n        \"\"\"\n        stat = stats.KindStat.query(\n            stats.KindStat.kind_name == self.model.__name__).get()\n        if stat:\n            return {\n                'total': stat.count\n            }\n        return {}\n\n\nclass ParticipantAPI(APIResource):\n    \"\"\"\n    Root-level API functions\n    \"\"\"\n\n    model = models.Participant\n\n    methods = {\n        'enrollment': {\n        }\n    }\n\n    def enrollment(self):\n        user = models.User.lookup(request.args.get('email'))\n        data = []\n        if user is not None:\n            parts = CourseAPI().get_courses(None, user, {'user': user.key})\n            for part in parts:\n                course = part.course.get()\n                offering = course.offering.split('/')\n                try:\n                    term = {'fa': 'fall', 'su': 'summer', 'sp': 'spring'}[offering[2][:2]]\n                    year = '20'+offering[2][2:]\n                except (IndexError, KeyError):\n                    term = year = None\n                data.append({\n                    'url': '/#/course/'+str(course.key.id()),\n                    'display_name': course.display_name,\n                    'institution': course.institution,\n                    'term': term,\n                    'year': year,\n                    'offering': course.offering\n                })\n        return json.dumps(data)\n\n    def check(self, emails, course, role):\n        parts = []\n        for email in emails:\n            part = models.Participant.has_role(\n                models.User.lookup(email).key,\n                course,\n                role)\n            if not part:\n                raise BadValueError('Permissions check failed.')\n            parts.append(part)\n        return parts\n\n\nclass UserAPI(APIResource):\n    \"\"\"\n    The API resource for the User Object\n    \"\"\"\n    model = models.User\n    key_type = str # get_instance will convert this to an int\n\n    methods = {\n        'post': {\n            'web_args': {\n                'email': Arg(str),\n                'name': Arg(str),\n                }\n        },\n        'add_email': {\n            'methods': set(['PUT']),\n            'web_args': {\n                'email': Arg(str)\n            }\n        },\n        'delete_email': {\n            'methods': set(['PUT']),\n            'web_args': {\n                'email': Arg(str)\n            }\n        },\n        'get': {\n            'web_args': {\n                'course': KeyArg('Course')\n             }\n        },\n        'index': {\n        },\n        'invitations': {\n            'methods': set(['GET']),\n            'web_args': {\n                'assignment': KeyArg('Assignment')\n            }\n        },\n        'queues': {\n            'methods': set(['GET'])\n        },\n        'create_staff': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str, required=True),\n                'role': Arg(str, required=True),\n                }\n        },\n        'final_submission': {\n            'methods': set(['GET']),\n            'web_args': {\n                'assignment': KeyArg('Assignment', required=True)\n            }\n        },\n        'get_backups': {\n            'methods': set(['GET']),\n            'web_args': {\n                'assignment': KeyArg('Assignment', required=True),\n                'quantity': Arg(int, default=10)\n            }\n        },\n        'get_submissions': {\n            'methods': set(['GET']),\n            'web_args': {\n                'assignment': KeyArg('Assignment', required=True),\n                'quantity': Arg(int, default=10)\n            }\n        },\n        'timed_submission': {\n            'methods': set(['GET']),\n            'web_args': {\n                'assignment': KeyArg('Assignment', required=True),\n                'before': DateTimeArg()\n            }\n        },\n        'merge_user': {\n            'methods': set(['POST']),\n            'web_args': {\n                'other_email': Arg(str, required=True),\n            }\n        },\n    }\n\n    def get(self, obj, user, data):\n        \"\"\"\n        Overwrite GET request for user class in order to send more data.\n\n        :param obj: (object) target\n        :param user: -- unused --\n        :param data: -- unused --\n        :return: target object\n        \"\"\"\n        if 'course' in data:\n            return obj.get_course_info(data['course'].get())\n        return obj\n\n    def get_instance(self, key, user):\n        \"\"\"\n        Convert key from email to UserKey\n        \"\"\"\n        obj = self.model.lookup(key)\n        if not obj:\n            raise BadKeyError(key)\n\n        need = Need('get')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        return obj\n\n    def new_entity(self, attributes):\n        \"\"\"\n        Creates a new entity with given attributes.\n\n        :param attributes: (dictionary) default values\n            loaded on object instantiation\n        :return: entity with loaded attributes\n        \"\"\"\n        entity = self.model.lookup(attributes['email'])\n        if entity:\n            raise BadValueError('user already exists')\n        attributes['email'] = [attributes['email']]\n        entity = self.model.from_dict(attributes)\n        return entity\n\n    def add_email(self, obj, user, data):\n        \"\"\"\n        Adds an email for the user - modified in place.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: -- unused --\n        :return: None\n        \"\"\"\n        need = Need('get') # Anyone who can get the User object can add an email\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        obj.append_email(data['email'])\n\n    def delete_email(self, obj, user, data):\n        \"\"\"\n        Deletes an email for the user - modified in place.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) key \"email\" deleted\n        :return: None\n        \"\"\"\n        need = Need('get')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        obj.delete_email(data['email'])\n\n    def invitations(self, obj, user, data):\n        \"\"\"\n        Fetches list of all invitations for the caller.\n\n        :param obj: -- unused --\n        :param user: (object) caller\n        :param data: (dictionary) key assignment called\n        :return: None\n        \"\"\"\n        query = models.Group.query(models.Group.invited == user.key)\n        if 'assignment' in data:\n            query = query.filter(models.Group.assignment == data['assignment'])\n        return list(query)\n\n    def queues(self, obj, user, data):\n        \"\"\"\n        Retrieve all assignments given to the caller on staff\n\n        :param obj: -- unused --\n        :param user: (object) caller\n        :param data: -- unused --\n        :return: None\n        \"\"\"\n        return list(models.Queue.query().filter(\n            models.Queue.assigned_staff == user.key))\n\n    def create_staff(self, obj, user, data):\n        \"\"\"\n        Checks the caller is on staff, to then create staff.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) key email called\n        :return: None\n        \"\"\"\n        need = Need('staff')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        user = models.User.get_or_insert(data['email'].id())\n        user.role = data['role']\n        user.put()\n\n    def final_submission(self, obj, user, data):\n        \"\"\"\n        Get the final submission for grading.\n\n        :param obj: -- unused --\n        :param user: (object) caller\n        :param data: (dictionary) key assignment called\n        :return: None\n        \"\"\"\n        return obj.get_final_submission(data['assignment'])\n\n    def get_backups(self, obj, user, data):\n        \"\"\"\n        Get all backups for a user, based on group.\n\n        :param obj: -- unused --\n        :param user: (object) caller\n        :param data: (dictionary) key assignment called\n        :return: None\n        \"\"\"\n        return obj.get_backups(data['assignment'], data['quantity'])\n\n    def get_submissions(self, obj, user, data):\n        return obj.get_submissions(data['assignment'], data['quantity'])\n\n    def merge_user(self, obj, user, data):\n        \"\"\"\n        Merges this user with another user.\n        This user is the user that is \"merged\" -- no longer can login.\n        \"\"\"\n        need = Need('merge')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        other_user = models.User.lookup(data['other_email'])\n        if not other_user:\n            raise BadValueError(\"Invalid user to merge to\")\n\n        merge_user(obj, other_user)\n\n\nclass AssignmentAPI(APIResource):\n    \"\"\"\n    The API resource for the Assignment Object\n    \"\"\"\n    model = models.Assignment\n\n    methods = {\n        'post': {\n            'web_args': {\n                'name': Arg(str, required=True),\n                'display_name': Arg(str, required=True),\n                'points': Arg(float, required=True),\n                'course': KeyArg('Course', required=True),\n                'max_group_size': Arg(int, required=True),\n                'due_date': DateTimeArg(required=True),\n                'templates': Arg(str, use=lambda temps: json.dumps(temps),\n                    required=True),\n                'revision': Arg(bool),\n                'lock_date': DateTimeArg(),\n                'autograding_enabled': Arg(bool),\n                'autograding_key': Arg(str),\n                'url': Arg(str)\n            }\n        },\n        'put': {\n            'web_args': {\n                'name': Arg(str),\n                'display_name': Arg(str),\n                'points': Arg(float),\n                'course': KeyArg('Course'),\n                'max_group_size': Arg(int),\n                'due_date': DateTimeArg(),\n                'templates': Arg(str, use=lambda temps: json.dumps(temps)),\n                'revision': Arg(bool),\n                'lock_date': DateTimeArg(),\n                'autograding_enabled': Arg(bool),\n                'autograding_key': Arg(str),\n                'url': Arg(str)\n            }\n        },\n        'get': {\n        },\n        'edit': {\n            'methods': set(['POST']),\n            'web_args': {\n                'name': Arg(str),\n                'display_name': Arg(str),\n                'points': Arg(float),\n                'course': KeyArg('Course'),\n                'max_group_size': Arg(int),\n                'due_date': DateTimeArg(),\n                'templates': Arg(str, use=lambda temps: json.dumps(temps)),\n                'revision': Arg(bool),\n                'lock_date': DateTimeArg(),\n                'autograding_enabled': Arg(bool),\n                'autograding_key': Arg(str),\n                'url': Arg(str)\n            }\n        },\n        'index': {\n            'web_args': {\n                'course': KeyArg('Course'),\n                'active': BooleanArg(),\n                'name': Arg(str),\n                'points': Arg(int)\n            }\n        },\n        'invite': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str)\n            }\n        },\n        'group': {\n          'methods': set(['GET']),\n        },\n        'download_scores': {\n            'methods': set(['GET'])\n        },\n        'delete': {\n            'methods': set(['DELETE'])\n        },\n        'autograde': {\n            'methods': set(['POST']),\n            'web_args': {\n                'grade_final': Arg(bool),\n                'subm': Arg(int),\n                'testing': Arg(bool, default=False),\n                'backup_promotion': Arg(bool, default=True),\n                'token': Arg(str)\n            }\n        },\n        'queues': {\n            'methods': set(['GET']),\n        },\n        'statistics': {\n        }\n    }\n\n    def post(self, user, data):\n        \"\"\"\n        :param user:\n        :param data:\n        :return:\n        \"\"\"\n        data['creator'] = user.key\n        # check if the course actually exists\n        course = data['course'].get()\n        if not course:\n            raise BadValueError(\"Course with ID {} does not exist.\".format(\n                data['course'].id()))\n\n        # check if there is a duplicate assignment\n        assignments = list(\n            models.Assignment.query(models.Assignment.name == data['name']))\n        if len(assignments) > 0:\n            raise BadValueError(\n                'assignment with name %s exists already' % data['name'])\n        return super(AssignmentAPI, self).post(user, data)\n\n    def edit(self, obj, user, data):\n        \"\"\" Save the assignment. \"\"\"\n        return super(AssignmentAPI, self).put(obj, user, data)\n\n    def group(self, obj, user, data):\n        \"\"\"User's current group for assignment.\"\"\"\n        return models.Group.lookup(user, obj)\n\n    def invite(self, obj, user, data):\n        \"\"\"User ask invited to join his/her current group for assignment.\"\"\"\n        err = models.Group.invite_to_group(user.key, data['email'], obj.key)\n        if err:\n            raise BadValueError(err)\n\n    def download_scores(self, obj, user, data):\n        \"\"\"\n        Write all composition scores for this assignment as a GCS file.\n        Format is 'STUDENT', 'SCORE', 'MESSAGE', 'GRADER', 'TAG'.\n        \"\"\"\n        need = Need('staff')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        deferred.defer(scores_to_gcs, obj, user)\n\n    def autograde(self, obj, user, data):\n        need = Need('grade')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        if not obj.autograding_enabled:\n            raise BadValueError('Autograding is not enabled for this assignment.')\n        if not obj.autograding_key:\n            raise BadValueError('Autograding key not provided in assignment.')\n\n        if 'grade_final' in data and data['grade_final']:\n            #Collect all final submissions and run grades.\n            deferred.defer(autograde_final_subs, obj, user, data)\n\n            if 'promote_backups' in data and data['promote_backups']:\n              # Force promote backups and run autograder\n              deferred.defer(promote_student_backups, obj, True, user, data)\n\n            return {'status_url': AUTOGRADER_URL+'/rq', 'length': 'TBD'}\n        elif 'subm' in data:\n            subm = models.FinalSubmission.get_by_id(data['subm'])\n            if not subm:\n                raise BadValueError(\"Requested submission is not a final submission\")\n            subm_ids = {subm.submission.id(): subm.submission.get().backup.id()}\n            return autograde_subms(obj, user, data, subm_ids, priority=\"high\")\n        else:\n            raise BadValueError('Endpoint only supports final submission grading.')\n\n    def queues(self, obj, user, data):\n        \"\"\" Return all composition queues for this assignment \"\"\"\n        need = Need('staff')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        return models.Queue.query(models.Queue.assignment == obj.key).fetch()\n\n    def statistics(self, obj, user, data):\n        \"\"\"Returns assignment statistics\"\"\"\n        need = Need('staff')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        FSub, Sub = models.FinalSubmission, models.Submission\n        return {\n            'finalsubmissions': FSub.query(FSub.assignment==obj.key).count(),\n            'submissions': Sub.query(Sub.assignment==obj.key).count()\n        }\n\n\nclass SubmitNDBImplementation(object):\n    \"\"\"\n    Implementation of DB calls required by submission using Google NDB\n    \"\"\"\n\n    def lookup_assignments_by_name(self, name):\n        \"\"\"\n        Look up all assignments of a given name.\n\n        :param name: (string) name to search for\n        :return: (list) assignments\n        \"\"\"\n        mc_key = 'assignments_{}'.format(name)\n        assignments = memcache.get(mc_key)\n        if not assignments:\n            by_name = models.Assignment.name == name\n            assignments = list(models.Assignment.query().filter(by_name))\n            memcache.set(mc_key, assignments)\n        return assignments\n\n    def create_submission(self, user, assignment, messages, submit, submitter, revision=False):\n        \"\"\"\n        Create submission using user as parent to ensure ordering.\n\n        :param user: (object) caller\n        :param assignment: (Assignment)\n        :param messages: Data content of backup/submission\n        :param submit: Whether this backup is a submission to be graded\n        :param submitter: (object) caller or submitter\n        :return: (Backup) submission\n        \"\"\"\n        if not user.is_admin or not submitter:\n            submitter = user.key\n\n        message_date = None\n        analytics = messages.get('analytics')\n        if analytics:\n            message_date = analytics.get('time', None)\n        if message_date:\n            created = parse_date(message_date)\n        else:\n            created = datetime.datetime.now()\n\n        ms = lambda kind, message: models.Message(kind=kind, contents=message)\n        db_messages = [ms(k, m) for k, m in messages.iteritems() if m]\n\n        backup = models.Backup(submitter=submitter,\n                               assignment=assignment.key,\n                               messages=db_messages,\n                               created=created)\n        backup.put()\n        deferred.defer(assign_submission, backup.key.id(), submit, revision)\n        return backup\n\n\nclass SubmissionAPI(APIResource):\n    \"\"\"\n    The API resource for the Backup & Submission Objects\n    \"\"\"\n    model = models.Backup\n    diff_model = models.Diff\n    subm_model = models.Submission\n    db = SubmitNDBImplementation()\n\n    methods = {\n        'post': {\n            'web_args': {\n                'assignment': Arg(str, required=True),\n                'messages': Arg(None, required=True),\n                'submit': BooleanArg(),\n                'submitter': KeyArg('User')\n            }\n        },\n        'get': {\n        },\n        'index': {\n            'web_args': {\n                'assignment': KeyArg('Assignment'),\n                'submitter': KeyArg('User'),\n                'created': DateTimeArg(),\n                'messages.kind': Arg(str, use=parse_json_field),\n                }\n        },\n        'diff': {\n            'methods': set(['GET']),\n            },\n        'download': {\n            'methods': set(['GET']),\n            },\n        'add_comment': {\n            'methods': set(['POST']),\n            'web_args': {\n                'index': Arg(int, required=True),\n                'file': Arg(str, required=True),\n                'message': Arg(str, required=True)\n            }\n        },\n        'edit_comment': {\n            'methods': set(['POST']),\n            'web_args': {\n                'comment':KeyArg('Comment', required=True),\n                'message': Arg(str, required=True)\n            }\n        },\n        'delete_comment': {\n            'methods': set(['POST']),\n            'web_args': {\n                'comment': KeyArg('Comment', required=True)\n            }\n        },\n        'score': {\n            'methods': set(['POST']),\n            'web_args': {\n                'submission': KeyArg('Submission', required=True),\n                'key': Arg(str, required=True),\n                'score': Arg(float, required=True),\n                'message': Arg(str, required=True),\n            }\n        }\n    }\n\n    def graded(self, obj, user, data):\n        \"\"\"\n        Gets the user's graded submissions\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) data\n        :return:\n        \"\"\"\n\n    def data_for_zip(self, obj):\n        try:\n            user = obj.submitter.get()\n            name = user.email[0]+'-'+str(obj.created)\n        except IndexError, AttributeError:\n            name = str(obj.created)\n\n        name = name.replace('.', '-').replace(' ', '_')\n        messages = obj.get_messages()\n        if 'file_contents' not in messages:\n            raise BadValueError('Submission has no contents to download')\n        file_contents = messages['file_contents']\n\n        if 'submit' in file_contents:\n            del file_contents['submit']\n\n        json_pretty = dict(sort_keys=True, indent=4, separators=(',', ': '))\n        group_files = backup_group_file(obj, json_pretty)\n        if group_files:\n            for file in group_files:\n                add_to_file_contents(file_contents, *file)\n        add_to_file_contents(file_contents,\n                             'submission_meta.json',\n                             str(json.dumps(obj.to_json(), **json_pretty)))\n\n        return name, file_contents\n\n    def zip(self, obj, user, data):\n        \"\"\" Grab all files in submission\n        :param obj:\n        :param user:\n        :param data:\n        :return:\n        \"\"\"\n        return self.zip_files(*self.data_for_zip(obj))\n\n    def zip_files(self, name, file_contents):\n        \"\"\" Zip files\n        :param file_contents:\n        :return:\n        \"\"\"\n        zipfile = create_zip(file_contents)\n        return name, zipfile\n\n    def make_zip_response(self, name, zipfile):\n        \"\"\"\n        Makes a zip response using a zip object.\n\n        :param zip:\n        :return:\n        \"\"\"\n        response = make_response(zipfile)\n        response.headers['Content-Disposition'] = (\n            'attachment; filename=submission-%s.zip' % name)\n        response.headers['Content-Type'] = 'application/zip'\n        return response\n\n    def download(self, obj, user, data):\n        \"\"\"\n        Download submission, but check if it has content and encode all files.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) data\n        :return: file contents in utf-8\n        \"\"\"\n        return self.make_zip_response(*self.zip(obj, user, data))\n\n    def diff(self, obj, user, data):\n        \"\"\"\n        Gets the associated diff for a submission\n\n        :param obj: (object) target\n        :param user: -- unused --\n        :param data: -- unused --\n        :return: (Diff) object with differences\n        \"\"\"\n        messages = obj.get_messages()\n        if 'file_contents' not in obj.get_messages():\n            raise BadValueError('Submission has no contents to diff')\n\n        file_contents = messages['file_contents']\n\n        if 'submit' in file_contents:\n            del file_contents['submit']\n\n        for key in file_contents.keys():\n            try:\n                file_contents[key] = unicode(file_contents[key]).encode('utf-8')\n            except:  # pragma: no cover\n                pass\n\n        diff_obj = self.diff_model.get_by_id(obj.key.id())\n        if diff_obj:\n            return diff_obj\n\n        diff = {}\n        templates = obj.assignment.get().templates\n        if not templates or templates == {}:\n            raise BadValueError('no templates for assignment, \\\n                                please contact course staff')\n\n        templates = json.loads(templates)\n        if type(templates) == unicode:  # pragma: no cover\n            templates = ast.literal_eval(templates)\n\n        for filename, contents in file_contents.items():\n            if filename in templates:\n                temp = templates[filename]\n                if type(templates[filename]) == list:\n                    temp = templates[filename][0]\n            else:\n                temp = \"\"\n            diff[filename] = utils.diff(temp, contents)\n\n        diff = self.diff_model(id=obj.key.id(),\n                               diff=diff)\n        diff.put()\n        return diff\n\n    def add_comment(self, obj, user, data):\n        \"\"\"\n        Adds a comment to this diff.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) data\n        :return: result of putting comment\n        \"\"\"\n        diff_obj = self.diff_model.get_by_id(obj.key.id())\n        if not diff_obj:\n            raise BadValueError(\"Diff doesn't exist yet\")\n\n        index = data['index']\n        message = data['message']\n        filename = data['file']\n\n        if message.strip() == '':\n            raise BadValueError('Cannot make empty comment')\n\n        comment = models.Comment(\n            filename=filename,\n            message=message,\n            line=index,\n            author=user.key,\n            parent=diff_obj.key)\n        comment.put()\n        return comment\n\n    def edit_comment(self, obj, user, data):\n        \"\"\"\n            Modifies an existing comment.\n        \"\"\"\n        diff_obj = self.diff_model.get_by_id(obj.key.id())\n        if not diff_obj:\n            raise BadValueError(\"Diff doesn't exist yet\")\n\n        comment = models.Comment.get_by_id(\n            data['comment'].id(), parent=diff_obj.key)\n\n        need = Need('edit')\n        if not comment.can(user, need, comment):\n            raise need.exception()\n\n        msg = data['message']\n\n        if msg.strip() == '':\n            raise BadValueError('Cannot make empty comment. Did you mean to delete the comment?')\n\n        comment.message = msg\n        comment.put()\n\n        return comment\n\n    def delete_comment(self, obj, user, data):\n        \"\"\"\n        Deletes a comment on this diff.\n\n        :param obj: (object) target\n        :param user: (object) caller\n        :param data: (dictionary) data\n        :return: result of deleting comment\n        \"\"\"\n        diff_obj = self.diff_model.get_by_id(obj.key.id())\n        if not diff_obj:\n            raise BadValueError(\"Diff doesn't exist yet\")\n\n        comment = models.Comment.get_by_id(\n            data['comment'].id(), parent=diff_obj.key)\n        if not comment:\n            raise BadKeyError(data['comment'])\n        need = Need('delete')\n        if not comment.can(user, need, comment):\n            raise need.exception()\n        comment.key.delete()\n\n    def score(self, obj, user, data):\n        \"\"\"\n        Sets a score.\n\n        :param obj: (object) backup - ignored.\n        :param user: (object) caller\n        :param data: (dictionary) data\n        :return: (int) score\n        \"\"\"\n\n        need = Need('grade')\n        subm_q = self.subm_model.query(self.subm_model.key == data['submission'])\n        subm = subm_q.get()\n\n        # Perform check on the submission because obj is a backup\n        if not self.subm_model.can(user, need, subm, subm_q):\n            raise need.exception()\n\n        if not subm.backup == obj.key:\n          raise ValueError('Submission does not match backup')\n\n        score = models.Score(\n            tag=data['key'],\n            score=int(data['score']),\n            message=data['message'],\n            grader=user.key)\n        score.put()\n\n        subm.score = [autograde for autograde in subm.score \\\n            if autograde.tag != data['key']]\n        subm.score.append(score)\n\n        subm.put()\n        return score\n\n    def get_assignment(self, name):\n        \"\"\"\n        Look up an assignment by name\n\n        :param name: (string) name of assignment\n        :return: (object, Error) the assignment object or\n            raise a validation error\n        \"\"\"\n        assignments = self.db.lookup_assignments_by_name(name)\n        if not assignments:\n            raise BadValueError('Assignment \\'%s\\' not found' % name)\n        if len(assignments) > 1:\n            raise BadValueError('Multiple assignments named \\'%s\\'' % name)\n        return assignments[0]\n\n    def submit(self, user, assignment, messages, submit, submitter=None):\n        \"\"\"\n        Process submission messages for an assignment from a user.\n        \"\"\"\n        valid_assignment = self.get_assignment(assignment)\n\n        if submitter is None:\n            submitter = user.key\n\n        due = valid_assignment.due_date\n        late_flag = valid_assignment.lock_date and \\\n                    datetime.datetime.now() >= valid_assignment.lock_date\n        revision = valid_assignment.revision\n\n        if submit and late_flag:\n            if revision:\n                # In the revision period. Ensure that user has a previously graded submission.\n                fs = user.get_final_submission(valid_assignment)\n                if not fs:\n                    return (403, 'Late: No submission to revise', {'late': True})\n                comp_score = [s for s in fs.submission.get().score if s.tag == \"composition\"]\n                if fs is None or len(comp_score) < 1:\n                    return (403, 'Previous submission does not have a composition score', {\n                      'late': True,\n                    })\n                logging.info(\"Accepting Revision Submission\")\n            else:\n                logging.info(\"Late submission from user\")\n                # Late submission. Do not allow them to submit\n                return (403, 'Late Submission', {\n                    'late': True,\n                    })\n\n        submission = self.db.create_submission(user, valid_assignment,\n                                               messages, submit, submitter, revision)\n\n        if valid_assignment.autograding_enabled and submit and not late_flag:\n            logging.info(\"Queueing submission to AG\")\n            deferred.defer(submit_to_ag, valid_assignment, messages, user)\n\n        return (201, 'success', {\n            'key': submission.key.id(),\n            'course': valid_assignment.course.id(),\n            'email': user.email[0]\n        })\n\n    def post(self, user, data):\n        submit_flag = False\n        if data['messages'].get('file_contents'):\n            if 'submit' in data['messages']['file_contents']:\n                submit_flag = data['messages']['file_contents']['submit']\n\n        return self.submit(user, data['assignment'],\n                           data['messages'], submit_flag,\n                           data.get('submitter'))\n\n\nclass SearchAPI(APIResource):\n\n    contains_entities = False\n\n    methods = {\n        'index': {\n            'methods': {'GET'},\n            'web_args': {\n                'query': Arg(str, required=True),\n                'page': Arg(int, default=1),\n                'num_per_page': Arg(int, default=10),\n                'courseId': Arg(int, required=True)\n            }\n        },\n        'download': {\n            'methods': {'GET'},\n            'web_args': {\n                'query': Arg(str, required=True),\n                'page': Arg(int, default=1),\n                'num_per_page': Arg(int, default=10),\n                'all': Arg(str, default='True'),\n                'courseId': Arg(int, required=True),\n            }\n        }\n    }\n\n    defaults = {\n        # 'onlywcode': (op.__eq__, 'True')\n    }\n\n    operators = {\n        'eq': op.__eq__,\n        'equal': op.__eq__,\n        'lt': op.__lt__,\n        'gt': op.__gt__,\n        'before': op.__lt__,\n        'after': op.__gt__\n    }\n\n    # maps flags to processing functions (e.g., instantiate objects)\n    flags = {\n        'user': lambda op, email:\n            UserAPI.model.query(\n                op(UserAPI.model.email, email)).get(),\n        'date': lambda op, s: datetime.datetime.strptime(s, '%Y-%m-%d'),\n        'onlybackup': lambda op, boolean: boolean.lower() == 'true',\n        'onlyfinal': lambda op, boolean: boolean.lower() == 'true',\n        'onlywcode': lambda op, boolean: boolean.lower() == 'true',\n        'assignment': lambda op, name:\n            AssignmentAPI.model.query(\n                op(AssignmentAPI.model.display_name, name)).get(),\n    }\n\n    def check_permissions(self, user, data):\n        course = CourseAPI()\n        key = course.key_type(data['courseId'])\n        course = course.get_instance(key, user)\n\n        if user.key not in course.staff and not user.is_admin:\n            raise Need('get').exception()\n\n    @staticmethod\n    def results(data):\n        \"\"\" Returns results of query, limiting results accordingly \"\"\"\n        results = SearchAPI.querify(data['query']).fetch()\n        if data.get('all', 'true').lower() != 'true':\n            start, end = SearchAPI.limits(data['page'], data['num_per_page'])\n            results = results[start:end]\n        return results\n\n    def index(self, user, data):\n        \"\"\" Performs search query, with some extra information \"\"\"\n        self.check_permissions(user, data)\n\n        results = self.results(data)\n        return dict(data={\n            'results': results,\n            'more': len(results) >= data['num_per_page'],\n            'query': data['query']\n        })\n\n    def download(self, user, data):\n        \"\"\" Sets up zip write to GCS \"\"\"\n        self.check_permissions(user, data)\n\n        filename = make_zip_filename(user, datetime.datetime.now())\n        deferred.defer(subms_to_gcs, SearchAPI, SubmissionAPI(), filename, data)\n        return [filename]\n\n\n    @staticmethod\n    def tokenize(query):\n        \"\"\"\n        Parses each command for flag, op, and arg\n        Regex captures first named group \"flag\" as a string preceded\n        by a single dash, followed by a space. Optionally captures\n        second named group \"op\" as a string preceded by two dashes\n        and followed by a space. Captures final named group \"arg\"\n        with optional quotations.\n\n        If quotes are detected, the string inside is allowed spaces and\n        a second, identical quote must be found.\n        \"\"\"\n        tokenizer = re.compile(\n            r'-(?P<flag>[\\S]+)\\s+(--(?P<op>[\\S]+)\\s*)?(?P<quote>\"|\\')?(?P<arg>(?(quote)[\\S ]*?|[\\S]*))(?(quote)\\4)')\n        return tokenizer.findall(query)\n\n    @classmethod\n    def translate(cls, query):\n        \"\"\" converts operators into appropriate operators and adds defaults \"\"\"\n        tokens = cls.tokenize(query)\n        scope = {k: tuple(v) for k, v in cls.defaults.items()}\n        for token in tokens:\n            flag, dummy, opr, quote, arg = token\n            try:\n                scope[flag] = (cls.operators[opr or 'eq'], arg)\n            except KeyError:\n                raise BadValueError('No such operator \"%s\". \\\n                Only these are allowed: eq, equal, lt, gt, \\\n                before, after.' % opr)\n        return scope\n\n    @classmethod\n    def objectify(cls, query):\n        \"\"\" converts keys into objects \"\"\"\n        scope = cls.translate(query)\n        for k, v in scope.items():\n            op, arg = v\n            try:\n                scope[k] = (op, cls.flags[k](op, arg))\n            except KeyError:\n                raise BadValueError('No such flag \"%s\". Only \\\n                these are allowed: %s' % (k, str(\n                    ', '.join(cls.flags.keys()))))\n            except ValueError as e:\n                raise BadValueError(str(e))\n        return scope\n\n    @classmethod\n    def querify(cls, query):\n        \"\"\" converts mush into a query object \"\"\"\n        objects = cls.objectify(query)\n        model = cls.get_model(objects)\n        args = cls.get_args(model, objects)\n        query = model.query(*args)\n        return cls.order(model, query)\n\n    @staticmethod\n    def get_model(prime):\n        \"\"\" determine model using passed-in data \"\"\"\n        op, onlyfinal = prime.get('onlyfinal', (None, False))\n        op, onlybackup = prime.get('onlybackup', (None, False))\n        if onlybackup:\n            return models.Backup\n        if onlyfinal:\n            return models.FinalSubmission\n        else:\n            return models.Submission\n\n    @classmethod\n    def order(cls, model, query):\n        try:\n            if hasattr(model, 'server_time'):\n                return query.order(-model.server_time)\n        except TypeError:\n            pass\n        return query\n\n    @staticmethod\n    def get_args(model, prime):\n        \"\"\" Creates all Filter Nodes \"\"\"\n        args, keys = [], prime.keys()\n        if 'assignment' in keys:\n            if not prime['assignment'][1]:\n                raise BadValueError('Said assignment does not exist. Remember, \\\n                if the assignment name has spaces, wrap it in double quotations.')\n            args.append(model.assignment == prime['assignment'][1].key)\n        if 'user' in keys:\n            if not prime['user'][1]:\n                raise BadValueError('Said user does not exist.')\n            args.append(model.submitter == prime['user'][1].key)\n        if 'date' in keys:\n            opr, arg = prime['date']\n            args.append(opr(model.server_time, arg))\n        if 'onlywcode' in keys:\n            raise BadValueError('-onlywcode is not yet implemented, sorry.')\n        return args\n\n    @staticmethod\n    def limits(page, num_per_page):\n        \"\"\" returns start and ends number based on page and num_per_page \"\"\"\n        return (page-1)*num_per_page, page*num_per_page\n\n\nclass VersionAPI(APIResource):\n    model = models.Version\n\n    key_type = str\n\n    methods = {\n        'post': {\n            'web_args': {\n                'name': Arg(str, required=True),\n                'base_url': Arg(str, required=True),\n                }\n        },\n        'put': {\n            'web_args': {\n                'name': Arg(str),\n                'base_url': Arg(str),\n                }\n        },\n        'get': {\n            'web_args': {\n            }\n        },\n        'index': {\n            'web_args': {\n            }\n        },\n        'new': {\n            'methods': set(['PUT']),\n            'web_args': {\n                'version': Arg(str, required=True),\n                'current': BooleanArg()\n            }\n        },\n        'download': {\n            'methods': set(['GET']),\n            'web_args': {\n                'version': Arg(str)\n            }\n        },\n        'current': {\n            'methods': set(['GET']),\n            'web_args': {\n            }\n        },\n        'set_current': {\n            'methods': set(['POST']),\n            'web_args': {\n                'version': Arg(str, required=True)\n            }\n        },\n        }\n\n    def new(self, obj, user, data):\n        need = Need('update')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n\n        new_version = data['version']\n\n        if new_version in obj.versions:\n            raise BadValueError('Duplicate version: {}'.format(new_version))\n\n        obj.versions.append(new_version)\n        if 'current' in data and data['current']:\n            obj.current_version = data['version']\n        obj.put()\n        return obj\n\n    def current(self, obj, user, data):\n        need = Need('get')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        if not obj.current_version:\n            raise BadValueError(\n                'Invalid version resource. Contact an administrator.')\n        return obj.current_version\n\n    def download(self, obj, user, data):\n        need = Need('get')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        if 'version' not in data:\n            download_link = obj.download_link()\n        else:\n            download_link = obj.download_link(data['version'])\n        return flask.redirect(download_link)\n\n    def set_current(self, obj, user, data):\n        need = Need('update')\n        if not obj.can(user, need, obj):\n            raise need.exception()\n        current_version = data['version']\n        if current_version not in obj.versions:\n            raise BadValueError(\n                'Invalid version. Cannot update to current.')\n        obj.current_version = current_version\n        obj.put()\n\n\nclass CourseAPI(APIResource):\n    model = models.Course\n\n    methods = {\n        'post': {\n            'web_args': {\n                'display_name': Arg(str),\n                'institution': Arg(str, required=True),\n                'offering': Arg(str, required=True),\n                'active': BooleanArg(),\n            }\n        },\n        'put': {\n            'web_args': {\n                'display_name': Arg(str),\n                'institution': Arg(str),\n                'term': Arg(str),\n                'year': Arg(str),\n                'active': BooleanArg(),\n            }\n        },\n        'delete': {\n        },\n        'get': {\n        },\n        'index': {\n            'web_args': {\n                'onlyenrolled': Arg(bool, default=False)\n            }\n        },\n        'get_staff': {\n        },\n        'add_staff': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str, required=True)\n            }\n        },\n        'remove_staff': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str, required=True)\n            }\n        },\n        'add_student': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str, required=True)\n            }\n        },\n        'add_students': {\n            'methods': set(['POST']),\n            'web_args': {\n                'emails': Arg(list, required=True)\n            }\n        },\n        'remove_student': {\n            'methods': set(['POST']),\n            'web_args': {\n                'email': Arg(str, required=True)\n            }\n        },\n        'assignments': {\n            'methods': set(['GET']),\n            'web_args': {\n            }\n        },\n        'get_courses': {\n            'methods': set(['GET']),\n            'web_args': {\n                'user': KeyArg('User', required=True)\n            }\n        },\n        'get_students': {\n        }\n    }\n\n    def post(self, user, data):\n        \"\"\"\n        The POST HTTP method\n        \"\"\"\n        return super(CourseAPI, self).post(user, data)\n\n    def index(self, user, data):\n        if data['onlyenrolled']:\n            return dict(results=[result.course for result in models.Participant.query(\n                models.Participant.user == user.key)])\n        else:\n            return super(CourseAPI, self).index(user, data)\n\n    def add_staff(self, course, user, data):\n        need = Need('staff')\n        if not course.can(user, need, course):\n            raise need.exception()\n\n        user = models.User.get_or_insert(data['email'])\n        if user not in course.staff:\n          models.Participant.add_role(user, course, STAFF_ROLE)\n\n    def get_staff(self, course, user, data):\n        need = Need('staff')\n        if not course.can(user, need, course):\n            raise need.exception()\n        query = models.Participant.query(\n          models.Participant.course == course.key,\n          models.Participant.role == 'staff')\n        return list(query.fetch())\n\n    def remove_staff(self, course, user, data):\n        need = Need('staff')\n        if not course.can(user, need, course):\n            raise need.exception()\n\n        removed_user = models.User.lookup(data['email'])\n        if not removed_user:\n            raise BadValueError('No such user with email \"%s\" exists' % data['email'])\n        models.Participant.remove_role(removed_user, course, STAFF_ROLE)\n\n    def get_courses(self, course, user, data):\n        query = models.Participant.query(\n            models.Participant.user == data['user'])\n        need = Need('index')\n        query = models.Participant.can(user, need, course, query)\n        return list(query)\n\n    def get_students(self, course, user, data):\n        query = models.Participant.query(\n            models.Participant.course == course.key,\n            models.Participant.role == 'student')\n        need = Need('staff')\n        if not models.Participant.can(user, need, course, query):\n            raise need.exception()\n        return list(query.fetch())\n\n    def add_students(self, course, user, data):\n        need = Need('staff') # Only staff can call this API\n        if not course.can(user, need, course):\n            raise need.exception()\n\n        for email in set(data['emails']):  # to remove potential duplicates\n            user = models.User.get_or_insert(email)\n            models.Participant.add_role(user, course, STUDENT_ROLE)\n\n    def add_student(self, course, user, data):\n        need = Need('staff') # Only staff can call this API\n        if not course.can(user, need, course):\n            raise need.exception()\n\n        user = models.User.get_or_insert(data['email'])\n        models.Participant.add_role(user, course, STUDENT_ROLE)\n\n    def remove_student(self, course, user, data):\n        need = Need('staff')\n        if not course.can(user, need, course):\n            raise need.exception()\n\n        removed_user = models.User.lookup(data['email'])\n        if not removed_user:\n            raise BadValueError('No such user with email \"%s\" exists' % data['email'])\n        models.Participant.remove_role(removed_user, course, STUDENT_ROLE)\n\n    def assignments(self, course, user, data):\n        return course.assignments.fetch()\n\n\nclass GroupAPI(APIResource):\n    model = models.Group\n\n    methods = {\n        'get': {\n        },\n        'index': {\n            'web_args': {\n                'assignment': KeyArg('Assignment'),\n                'member': KeyArg('User')\n            }\n        },\n        'add_member': {\n            'methods': set(['PUT', 'POST']),\n            'web_args': {\n                'email': Arg(str, required=True),\n                },\n            },\n        'remove_member': {\n            'methods': set(['PUT', 'POST']),\n            'web_args': {\n                'email': Arg(str, required=True),\n                },\n            },\n        'accept': {\n            'methods': set(['PUT', 'POST']),\n            },\n        'decline': {\n            'methods': set(['PUT', 'POST']),\n            },\n        'exit': {\n            'methods': set(['PUT', 'POST']),\n            },\n        'reorder': {\n            'methods': {'PUT', 'POST'},\n            'web_args': {\n                'order': Arg(list, required=True)\n            }\n        }\n    }\n\n    def add_member(self, group, user, data):\n        need = Need('invite')\n        if not group.can(user, need, group):\n            raise need.exception()\n\n        if data['email'] in group.invited:\n            raise BadValueError('user has already been invited')\n        if data['email'] in group.member:\n            raise BadValueError('user already part of group')\n\n        error = group.invite(data['email'])\n        if error:\n            raise BadValueError(error)\n\n        audit_log_message = models.AuditLog(\n            event_type='Group.add_member',\n            user=user.key,\n            description='Added member {} to group'.format(data['email']),\n            obj=group.key\n        )\n        audit_log_message.put()\n\n    def remove_member(self, group, user, data):\n        need = Need('remove')\n        if not group.can(user, need, group):\n            raise need.exception()\n\n        to_remove = models.User.lookup(data['email'])\n        if to_remove:\n            group.exit(to_remove)\n\n            audit_log_message = models.AuditLog(\n                event_type='Group.remove_member',\n                user=user.key,\n                obj=group.key,\n                description='Removed user from group'\n            )\n            audit_log_message.put()\n\n    def invite(self, group, user, data):\n        need = Need('invite')\n        if not group.can(user, need, group):\n            return need.exception()\n\n        error = group.invite(data['email'])\n        if error:\n            raise BadValueError(error)\n\n    def accept(self, group, user, data):\n        need = Need('accept')\n        if not group.can(user, need, group):\n            raise need.exception()\n\n        group.accept(user)\n\n    def decline(self, group, user, data):\n        self.exit(group, user, data)\n\n    def exit(self, group, user, data):\n        need = Need('exit')\n        if not group.can(user, need, group):\n            raise need.exception()\n\n        error = group.exit(user)\n        if error:\n            raise BadValueError(error)\n\n    def reorder(self, group, user, data):\n        \"\"\" Saves order of partners \"\"\"\n        need = Need('reorder')\n        if not group.can(user, need, group):\n            raise need.exception()\n\n        new_order = [models.User.lookup(email).key\n                     for email in data['order']]\n\n        if len(new_order) != len(group.member):\n            raise BadValueError('Incorrect number of group members.')\n\n        for member in group.member:\n            if member not in new_order:\n                raise BadValueError('Intruding group member does not belong.')\n\n        group.member = new_order\n        group.put()\n\n\nclass QueueAPI(APIResource):\n    \"\"\"\n    The API resource for the Assignment Object\n    \"\"\"\n    model = models.Queue\n\n    methods = {\n        'post': {\n            'web_args': {\n                'assignment': KeyArg('Assignment', required=True),\n                'assigned_staff': KeyRepeatedArg('User'),\n                'submissions': KeyRepeatedArg('Submissionvtwo')\n            }\n        },\n        'get': {\n        },\n        'put': {\n            'web_args': {\n                'assigned_staff': KeyRepeatedArg('User'),\n                'submissions': KeyRepeatedArg('Submissionvtwo')\n            }\n        },\n        'index': {\n            'web_args': {\n                'assignment': KeyArg('Assignment'),\n                'assigned_staff': KeyArg('User'),\n                'owner': KeyArg('User'),\n            }\n        },\n        }\n\n    def new_entity(self, attributes):\n        \"\"\"\n        Request to define a new entity\n\n        :param attributes: entity attributes,\n            to be loaded on entity instantiation\n        :return: entity\n        \"\"\"\n        if 'owner' not in attributes:\n            attributes['owner'] = attributes['assigned_staff'][0]\n        ent = super(QueueAPI, self).new_entity(attributes)\n        ent.assigned_staff = [user.get().key for user in ent.assigned_staff]\n        return ent\n\n\nclass QueuesAPI(APIResource):\n    \"\"\" API resource for sets of queues \"\"\"\n\n    contains_entities = False\n\n    methods = {\n        'generate': {\n            'methods': set(['POST']),\n            'web_args': {\n                'course': KeyArg('Course', required=True),\n                'assignment': KeyArg('Assignment', required=True),\n                'staff': Arg(list, required=True)\n            }\n        }\n    }\n\n    def generate(self, user, data):\n        \"\"\" Splits up submissions among staff members \"\"\"\n\n        if self.check_permissions(user, data):\n            raise Need('get').exception()\n\n        course_key, assignment_key, staff_list = data['course'], data['assignment'], data['staff']\n\n        userify = lambda parts: [part.user.get() for part in parts]\n\n        # Get select staff members\n        staff = [staff for staff in\n            userify(models.Participant.query(\n            models.Participant.role == STAFF_ROLE,\n            models.Participant.course == course_key).fetch())\n            if staff_list[0] == '*' or staff.email[0] in staff_list]\n\n        if len(staff) == 0:\n            raise BadValueError('Course has no registered staff members.')\n\n        # Check permissions, raising an error if it fails.\n        ParticipantAPI().check([stf.email[0] for stf in staff], course_key.get(), STAFF_ROLE)\n\n        deferred.defer(assign_staff_to_queues, assignment_key, staff)\n\n    def check_permissions(self, user, data):\n        course = data['course'].get()\n        return user.key not in course.staff and not user.is_admin\n\n\nclass FinalSubmissionAPI(APIResource):\n    \"\"\"\n    The API resource for the Assignment Object\n    \"\"\"\n    model = models.FinalSubmission\n\n    methods = {\n        'get': {\n        },\n        'index': {\n        },\n        'post': {\n            'web_args': {\n                'submission': KeyArg('Submission', required=True)\n            }\n        }\n    }\n\n    def new_entity(self, attributes):\n        \"\"\"\n        Creates a new entity with given attributes.\n        - when POSTing directly, new_entity has its own\n        permissions checks\n\n        :param attributes: (dictionary)\n        :return: (entity, error_response) should be ignored if error_response\n        is a True value\n        \"\"\"\n        subm = attributes['submission'].get()\n\n        if not subm:\n            raise BadValueError('No such submission exists.')\n\n        if not subm.backup.get():\n            raise BadValueError('Submission backup is missing.')\n\n        subm.mark_as_final()\n        return subm.get_final()\n\n\nclass AnalyticsAPI(APIResource):\n    \"\"\"\n    The API resource for the AnalyticsDump Object\n    \"\"\"\n    model = analytics.AnalyticsDump\n\n    methods = {\n        'get': {\n        },\n        'index': {\n        },\n        'post': {\n            'web_args': {\n                'job_type': Arg(str, required=True),\n                'filters': Arg(None, use=parse_json_list_field, required=True),\n            }\n        },\n    }\n\n    def post(self, user, data):\n\n        need = Need('create')\n\n        if not self.model.can(user, need, None):\n            raise need.exception()\n\n        job_type, filters = data['job_type'], data['filters']\n\n        if not isinstance(filters, list):\n            raise BadValueError('filters must be a list of triples')\n        for filter in filters:\n            if len(filter) != 3:\n                raise BadValueError('filters must be a list of triples')\n\n        if job_type not in analytics.available_jobs:\n            raise BadValueError('job must be of the following types: %s' %\n                                ', '.join(list(analytics.available_jobs.keys())))\n\n        job = analytics.get_job(job_type, user, filters)\n        job.start()\n\n        return (201, 'success', {\n            'key': job.job_dump.key.id()\n        })\n", "name": "server/app/api.py", "coverage": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, null, null, 1, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, null, 1, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, null, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, null, null, 1, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, null, null, null, null, 1, 1, 1, 1, null, 1, null, 1, null, 1, null, null, null, null, null, null, null, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, 1, 1, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, null, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, 1, null, null, 1, 1, 1, 1, 1, null, 1, 1, null, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, null, null, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, 1, 1, null, 1, null, 1, null, null, null, 1, null, null, null, null, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, null, null, null, null, null, null, null, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, 1, null, 1, 1, null, null, 1, null, null, 1, null, null, null, null, 1, null, 1, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, null, null, null, null, null, null, 1, null, 1, 1, 1, 1, null, null, null, 1, 1, 1, 1, null, null, 1, null, null, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, null, null, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, 1, null, 1, null, null, null, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, 1, null, 1, 1, 1, null, null, null, 1, null, 1, 1, null, 1, null, 1, null, 1, null, 1, null, 1, null, 1, null, 1, 1, 1, null, 1, null, null, null, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, 0, null, 0, null, 0, null, 0, 1, 1, 1, 0, 1, 1, null, 1, null, 1, null, 1, 1, 1, null, 1, null, 1, null, 1, 1, 1, null, 1, 1, null, null, null, null, null, 1, null, null, null, null, 1, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, null, null, null, 1, 1, 1, null, null, 1, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 0, 0, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, 1, null, 1, null, null, null, null, 1, 1, null, 1, null, null, null, null, null, null, 1, 1, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, null, null, null, 1, 1, 1, null, 1, 1, 1, 1, null, null, 1, null, null, null, 1, 1, 1, 1, 1, null, 1, 1, null, 1, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, 1, 1, null, 1, 1, null, 1, null, null, null, null, null, 1, 1, null, 1, null, null, null, 1, 1, 0, null, 1, null, null, 1, 1, 1, null, 1, null, 1, 0, null, 1, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, 1, 1, 1, null, null, 1, 1, null, 1, 1, null, 1, null, null, null, null, 1, null, 1, null, 1, null, 1, 1, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, 1, null, 1, 1, null, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 0, null, null, 1, null, 1, null, 1, null, null, null, 1, null, null, 1, 0, 0, null, 1, null, null, null, null, null, 1, 1, 1, 1, 1, null, 1, null, null, null, null, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, 1, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, null, null, null, null, null, 1, null, 1, null, 1, 1, 1, null, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, 1, 1, null, 1, null, 1, null, null, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, null, null, 1, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, null, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, 1, null, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, null, 1, 1, null, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, null, null, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, null, null, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, null, null, null, 1, null, 1, 1, 1, 0, null, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, null, 1, null, null, 1, 1, null, 1, 1, 1, null, 1, 1, null, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, null, null, 1, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, 1, null, null, 1, 1, null, 1, null, 1, null, null, 1, null, null, null, null, null, 1, 1, null, null, 1, null, 1, null, 1, 1, 1, null, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, 1, null, null, null, null, null, null, null, null, null, 1, null, 1, 1, null, 1, 1, null, 1, 1, null, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, 1, null, 1, null, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, 1, null, null, 1, 1, null, 1, null, null, null]}, {"source": "\"\"\"Convert access tokens to user records.\"\"\"\n\n# pylint: disable=no-member\n\nfrom app import models\nfrom app import app\nfrom app.authenticator import AuthenticationException\n\nfrom google.appengine.api import memcache as mc\n\nimport flask\n\nfrom google.appengine.api import users\n\nMC_NAMESPACE = \"access-token\"\n\ndef authenticate():\n    \"\"\"Returns the user which made this request.\"\"\"\n    authenticator = app.config[\"AUTHENTICATOR\"]\n    user = users.get_current_user()\n    if user:\n        return models.User.get_or_insert(user.email().lower())\n\n    if 'access_token' not in flask.request.args:\n        return models.User.get_or_insert(\"<anon>\")\n    else:\n        access_token = flask.request.args['access_token']\n        user = mc.get(\"%s-%s\" % (MC_NAMESPACE, access_token))\n        if user:\n            return user\n        try:\n            email = authenticator.authenticate(access_token)\n        except AuthenticationException:\n            return models.User.get_or_insert('_anon')\n        user = models.User.get_or_insert(email)\n        mc.set(\"%s-%s\" % (MC_NAMESPACE, access_token), user)\n    return user\n", "name": "server/app/auth.py", "coverage": [null, null, null, null, 1, 1, 1, null, 1, null, 1, null, 1, null, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null]}, {"source": "import requests\n\n\nclass AuthenticationException(Exception):\n    \"\"\"\n    Exception thrown when authentication fails.\n    \"\"\"\n    pass\n\n\nclass Authenticator(object):\n    \"\"\"\n    Authenticates a user with an access token.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def authenticate(self, access_token):\n        \"\"\"\n        Returns the email this access token corresponds to.\n        \"\"\"\n        raise NotImplementedError\n\n\nclass GoogleAuthenticator(Authenticator):\n    \"\"\"\n    Authenticates a user with an access token using Google APIs.\n    \"\"\"\n\n    API_URL = \"https://www.googleapis.com/oauth2/v1/userinfo\"\n\n    def authenticate(self, access_token):\n        response = requests.get(self.API_URL, params={\n            'access_token': access_token\n        }).json()\n        if 'error' in response:\n            raise AuthenticationException(\"access token invalid\")\n        if 'email' not in response:\n            raise AuthenticationException(\"email doesn't exist\")\n        return response['email'].lower()\n\n\nclass TestingAuthenticator(Authenticator):\n    \"\"\"\n    Authenticates a user with an access token.\n    FOR TESTING ONLY.\n    \"\"\"\n    def authenticate(self, access_token):\n        return access_token\n\n\n", "name": "server/app/authenticator.py", "coverage": [1, null, null, 1, null, null, null, null, null, null, 1, null, null, null, null, 1, null, null, 1, null, null, null, null, null, null, 1, null, null, null, null, 1, null, 1, 1, null, null, 1, 1, 1, 1, 1, null, null, 1, null, null, null, null, 1, 1, null, null, null]}, {"source": "\"\"\"App constants\"\"\"\n\nAPI_PREFIX = '/api'\nSTUDENT_ROLE = 'student'\nSTAFF_ROLE = 'staff'\nVALID_ROLES = [STUDENT_ROLE, STAFF_ROLE]\nGRADES_BUCKET = 'ok_grades_bucket'\nTIMEZONE = 'America/Los_Angeles'\nAUTOGRADER_URL = 'http://autograder.cs61a.org:5000'\n\n# submission downloads\nBATCH_SIZE = 25\n", "name": "server/app/constants.py", "coverage": [null, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null]}, {"source": "class APIException(Exception):\n    code = 400\n    data = None\n\n\nclass BadValueError(APIException):\n    code = 400\n\n\nclass BadMethodError(APIException):\n    code = 405\n\n\nclass IncorrectHTTPMethodError(APIException):\n    code = 405\n\n\nclass PermissionError(APIException):\n    code = 401\n\n    def __init__(self, need):\n        self.need = need\n\n    @property\n    def message(self):\n        return self.need.get_exception_message()\n\n\nclass BadKeyError(APIException):\n    code = 404\n\n    def __init__(self, key):\n        self.key = key\n\n    @property\n    def message(self):\n        return \"Key {key} not found\".format(key=self.key)\n\n\nclass IncorrectVersionError(APIException):\n    code = 403\n\n    def __init__(self, supplied_version, correct_version):\n        self.supplied_version = supplied_version\n        self.correct_version = correct_version\n\n    @property\n    def message(self):\n        return (\"Incorrect client version. Supplied version was {}. \"\n                \"Correct version is {}.\".format(self.supplied_version,\n                                                self.correct_version.current_version))\n\n    @property\n    def data(self):\n        return {\n            'supplied': self.supplied_version,\n            'correct': self.correct_version.current_version,\n            'download_link': self.correct_version.download_link()\n        }\n\n", "name": "server/app/exceptions.py", "coverage": [1, 1, 1, null, null, 1, 1, null, null, 1, 1, null, null, 1, 1, null, null, 1, 1, null, 1, 1, null, 1, null, 1, null, null, 1, 1, null, 1, 1, null, 1, null, 1, null, null, 1, 1, null, 1, 1, 1, null, 1, null, 1, null, null, null, 1, null, 1, null, null, null, null, null, null]}, {"source": "\"\"\"\n\nDATA MODELS\n\nThis file is responsible for models and business logic. In\nhere, all methods should handle:\n\n    - permission checks\n      Check user for each operation.\n\n    - basic operations\n      Get, put, delete. All of those go in here.\n\n    - queries\n      Search queries all go in here.\n\nMethods in here should try to throw informational BadValueErrors\nupon failure.\n\nParsing web arguments and error handling go in api.py.\n\nSpecification: https://github.com/Cal-CS-61A-Staff/ok/wiki/Models\n\"\"\"\n\n#pylint: disable=no-member, unused-argument, too-many-return-statements\n\nimport datetime\nimport itertools\nimport logging\n\nfrom app import app\nfrom app.constants import STUDENT_ROLE, STAFF_ROLE, VALID_ROLES\nfrom app.exceptions import *\nfrom app import utils\nfrom flask import json\nfrom flask.json import JSONEncoder as old_json\n\nfrom google.appengine.ext import ndb\n\n\nclass JSONEncoder(old_json):\n    \"\"\"\n    Wrapper class to try calling an object's to_dict() method. This allows\n    us to JSONify objects coming from the ORM. Also handles dates & datetimes.\n    \"\"\"\n    def default(self, obj):\n        if isinstance(obj, ndb.Key):\n            got = obj.get()\n            if not got:\n                return None\n            return got.to_json()\n        elif isinstance(obj, datetime.datetime):\n            obj = convert_timezone(obj)\n            return obj.strftime(app.config[\"GAE_DATETIME_FORMAT\"])\n        if isinstance(obj, ndb.Model):\n            return obj.to_json()\n        return super(JSONEncoder, self).default(obj)\n\napp.json_encoder = JSONEncoder\n\ndef convert_timezone(utc_dt):\n    \"\"\"Convert times to Pacific time.\"\"\"\n    # This looks like a hack... is it even right? What about daylight savings?\n    # Correct approach: each course should have a timezone. All times should be\n    # stored in UTC for easy comparison. Dates should be converted to\n    # course-local time when displayed.\n    delta = datetime.timedelta(hours=-7)\n    return datetime.datetime.combine(utc_dt.date(), utc_dt.time()) + delta\n\n\nclass Base(ndb.Model):\n    \"\"\"Shared utility methods and properties.\"\"\"\n    created = ndb.DateTimeProperty(auto_now_add=True)\n\n    @classmethod\n    def from_dict(cls, values):\n        \"\"\"Creates an instance from the given values.\"\"\"\n        inst = cls()\n        inst.populate(**values)\n        return inst\n\n    @classmethod\n    def _get_kind(cls):\n        return cls.__name__ + 'v2'\n\n    def to_json(self, fields=None):\n        \"\"\"Converts this model to a json dictionary.\"\"\"\n        if fields == True:\n            return self.to_dict()\n        elif fields == False:\n            return {}\n\n        if not fields:\n            fields = {}\n        if fields:\n            result = self.to_dict(include=fields.keys())\n        else:\n            result = self.to_dict()\n\n        if self.key and (not fields or 'id' in fields):\n            result['id'] = self.key.id()\n\n        # Protect sensitive fields: autograding_key\n        # Previous sensitive fields: zip_file_url and script\n        sensitive_fields = ['autograding_key',\n            'zip_file_url', 'grading_script_file']\n        for sensitive in sensitive_fields:\n            if sensitive in result:\n                result[sensitive] = ''\n\n        for key, value in result.items():\n            if isinstance(value, ndb.Key):\n                value = value.get()\n                if value:\n                    result[key] = value.to_json(fields.get(key))\n                else:\n                    result[key] = None\n            elif isinstance(value, list) and len(value) > 0 and isinstance(value[0], ndb.Key):\n                new_list = []\n                for value in value:\n                    fields_key = fields.get(key)\n                    if fields_key and not isinstance(fields_key, dict):\n                        if fields.get(key):\n                            new_list.append(value)\n                    else:\n                        value = value.get()\n                        if value:\n                            new_list.append(value.to_json(fields.get(key)))\n                result[key] = new_list\n            else:\n                try:\n                    new_value = app.json_encoder().default(value)\n                    result[key] = new_value\n                except TypeError:\n                    pass\n        return result\n\n    @classmethod\n    def can(cls, user, need, obj=None, query=None):\n        \"\"\"Whether user satisfies the given need for this object.\n\n        The index action requires a query that gets filtered and returned.\n        \"\"\"\n        if need.action == \"index\":\n            assert query, \"No query for index\"\n        need.set_object(obj or cls)\n        return cls._can(user, need, obj, query)\n\n    @classmethod\n    def _can(cls, user, need, obj, query):\n        \"\"\"\n        The internal permissions method. Overridden by subclasses.\n        \"\"\"\n        return False\n\ndef make_num_counter(helper):\n    def wrapper(self, assignment, max_size=None):\n        count = 0\n\n        all_submissions = helper(self, assignment)\n        if max_size is not None:\n            left_to_count = max_size\n            for submission_query in all_submissions:\n                if count >= max_size:\n                    break\n                diff = submission_query.count(left_to_count)\n                left_to_count -= diff\n                count += diff\n        else:\n            for submission_query in all_submissions:\n                count += submission_query.count(max_size)\n\n\n        return count\n    return wrapper\n\nclass User(Base):\n    \"\"\"Users may have multiple email addresses. Note: the built-in user model\n    in appengine associates a different user object with each email.\n    \"\"\"\n    email = ndb.StringProperty(repeated=True)\n    is_admin = ndb.BooleanProperty(default=False)\n    # TODO add a name\n    # TODO add a student ID\n\n    @property\n    def logged_in(self):\n        return self.email != [\"_anon\"]\n\n    def append_email(self, email):\n        if email not in self.email:\n            self.email.append(email)\n\n    def delete_email(self, email):\n        if email in self.email and len(self.email) > 1:\n            self.email.remove(email)\n\n    def final_submission(self, group, assignment_key):\n        \"\"\"A query for the final submission of a group and assignment.\"\"\"\n        if isinstance(assignment_key, Assignment):\n            assignment_key = assignment_key.key\n        if group and self.key in group.member:\n            return FinalSubmission.query(\n                FinalSubmission.assignment==assignment_key,\n                FinalSubmission.group==group.key)\n        else:\n            return FinalSubmission.query(\n                FinalSubmission.assignment==assignment_key,\n                FinalSubmission.submitter==self.key)\n\n    def get_final_submission(self, assignment_key):\n        \"\"\"Get the current final submission for this user.\"\"\"\n        group = self.get_group(assignment_key)\n        return self.final_submission(group, assignment_key).get()\n\n    def _contains_files(self, backup):\n        messages = backup.get_messages()\n        if 'file_contents' in messages:\n            return messages['file_contents']\n\n    def members(self, group):\n        \"\"\"The members of a group. If group is None, then we are its only member.\"\"\"\n        if not group or self.key not in group.member:\n            return [self.key]\n        else:\n            return group.member\n\n    def backups(self, group, assignment):\n        \"\"\"A query that fetches all backups for a group and assignment.\"\"\"\n        members = self.members(group)\n        return Backup.query(\n            Backup.submitter.IN(members),\n            Backup.assignment == assignment\n        ).order(-Backup.server_time)\n\n    def get_backups(self, assignment, num_backups=10):\n        group = self.get_group(assignment)\n        return self.backups(group, assignment).fetch(num_backups)\n\n    def submissions(self, group, assignment):\n        \"\"\"A query that fetches all backups for a group and assignment.\"\"\"\n        members = self.members(group)\n        return Submission.query(\n            Submission.submitter.IN(members),\n            Submission.assignment == assignment\n        ).order(-Backup.server_time)\n\n    def get_submissions(self, assignment, num_submissions=10):\n        group = self.get_group(assignment)\n        return self.submissions(group, assignment).fetch(num_submissions)\n\n    def group(self, assignment_key):\n        \"\"\"Return a query that fetches the group for this user for an assignment.\"\"\"\n        if isinstance(assignment_key, Assignment):\n            assignment_key = assignment_key.key\n        return Group.query(ndb.OR(Group.member==self.key,\n                                  Group.invited==self.key),\n                           Group.assignment==assignment_key)\n\n    def get_group(self, assignment_key):\n        \"\"\"Return the group for this user for an assignment.\"\"\"\n        return self.group(assignment_key).get()\n\n    def get_course_info(self, course):\n        if not course:\n            raise BadValueError(\"Invalid course\")\n\n        @ndb.tasklet\n        def final_submission_info(group, assignment):\n            final_submission = yield self.final_submission(group, assignment.key).get_async()\n            if final_submission:\n                submission = yield final_submission.submission.get_async()\n                backup = yield submission.backup.get_async()\n                final_info = {\n                    'submission': submission,\n                    'backup': backup,\n                    'final_submission': final_submission\n                }\n                if final_submission.revision:\n                    revision = yield final_submission.revision.get_async()\n                    final_info['revision'] = revision\n            else:\n                final_info = {}\n            raise ndb.Return(final_info)\n\n        @ndb.tasklet\n        def assignment_info(assignment):\n            group = self.group(assignment.key).get()\n            final_info, num_backups, num_submissions = yield (\n                final_submission_info(group, assignment),\n                self.backups(group, assignment.key).count_async(1),\n                self.submissions(group, assignment.key).count_async(1))\n            raise ndb.Return({\n                'group': {\n                    'group_info': group,\n                    'invited': group and self.key in group.invited\n                },\n                'final': final_info,\n                'backups': num_backups > 0,\n                'submissions': num_submissions > 0,\n                'assignment': assignment\n            })\n\n        assignments = course.assignments.order(-Assignment.due_date).map(assignment_info)\n\n        return {\n            'assignments': assignments,\n            'user': self\n        }\n\n    def update_final_submission(self, assignment, group=None):\n        \"\"\"Update the final submission of the user and its group.\n        Call on all users after group changes.\n        \"\"\"\n        if isinstance(assignment, Assignment):\n            assignment = assignment.key\n\n        options = [FinalSubmission.submitter == self.key]\n        if not group:\n            group = self.get_group(assignment)\n        if group and self.key in group.member:\n            options.append(FinalSubmission.group == group.key)\n            options += [FinalSubmission.submitter == m for m in group.member]\n        who = options[0] if len(options) == 1 else ndb.OR(*options)\n        assigned = FinalSubmission.assignment == assignment\n        finals = FinalSubmission.query(assigned, who).fetch()\n\n        if finals:\n            # Keep the most recent and delete the rest.\n            # Note: Deleting a FinalSubmission does not delete its submission.\n            finals.sort(key=lambda final: final.submission.get().server_time)\n            old, latest = finals[:-1], finals[-1]\n            latest.group = group.key if group else None\n            latest.put()\n            for final in old:\n                final.key.delete()\n        else:\n            # Create a final submission for user from her latest submission.\n            subs = Submission.query(\n                Submission.submitter == self.key,\n                Submission.assignment == assignment)\n            latest = subs.order(-Submission.server_time).get()\n            if latest:\n                FinalSubmission(assignment=assignment,\n                                group=group.key if group else None,\n                                submission=latest.key).put()\n\n    #@ndb.transactional\n    @classmethod\n    def get_or_insert(cls, email):\n        \"\"\"Retrieve a user by email or create that user.\"\"\"\n        email = email.lower()\n        user = cls.lookup(email)\n        if user:\n            return user\n        else:\n            user = cls(email=[email])\n            user.put()\n            return user\n\n    @classmethod\n    def lookup(cls, email):\n        \"\"\"Retrieve a user by email or return None.\"\"\"\n        assert isinstance(email, (str, unicode)), \"Invalid email: \" + str(email)\n        email = email.lower()\n        users = cls.query(cls.email == email).fetch()\n        if not users:\n            return None\n        if len(users) > 1:\n            pass # TODO Decide how to handle non-unique users\n        return users[0]\n\n    @classmethod\n    def _can(cls, user, need, obj, query):\n        if not user.logged_in:\n            return False\n        if user.is_admin:\n            if need.action == \"index\":\n                return query\n            return True\n\n        if need.action == \"lookup\":\n            return True\n        elif need.action == \"merge\":\n            # TODO(soumya) figure out how to make permissions for this\n            return False\n        if need.action == \"get\":\n            if not obj or not isinstance(obj, User):\n                return False\n            elif obj.key == user.key:\n                return True\n            else:\n                for part in Participant.courses(user, STAFF_ROLE):\n                    course = part.course\n                    if Participant.has_role(obj, course, STUDENT_ROLE):\n                        return True\n                return False\n        elif need.action == \"index\":\n            # TODO Update documentation: users can only index themselves.\n            #      See Participant for listing users by course\n            return query.filter(User.key == user.key)\n        else:\n            return False\n\n    def _pre_put_hook(self):\n        \"\"\"Ensure that a user can be accessed by at least one email.\"\"\"\n        if not self.email:\n            raise BadValueError(\"No email associated with \" + str(self))\n        #utils.check_user(self.key.id())\n\n    def scores_for_assignment(self, assignment):\n        \"\"\" Returns a tuple of two elements:\n                1) Score data (list of lists) for STUDENT's final submission for ASSIGNMENT.\n                    There is an element for each score.\n                    * OBS * If the student is in a group, the list will contain an\n                    element for each combination of group member and score.\n                2) A boolean indicating whether the student had a\n                    scored final submission for ASSIGNMENT.\n            Format: [['STUDENT', 'SCORE', 'MESSAGE', 'GRADER', 'TAG']]\n        \"\"\"\n        fs = self.get_final_submission(assignment.key)\n        scores = []\n        if fs:\n            scores = fs.get_scores()\n        return (scores, True) if scores else ([[self.email[0], 0, None, None, None]], False)\n\nclass Course(Base):\n    \"\"\"Courses are expected to have a unique offering.\"\"\"\n    offering = ndb.StringProperty() # E.g., 'cal/cs61a/fa14'\n    institution = ndb.StringProperty() # E.g., 'UC Berkeley'\n    display_name = ndb.StringProperty()\n    instructor = ndb.KeyProperty(User, repeated=True)\n    active = ndb.BooleanProperty(default=True)\n\n    @property\n    def staff(self):\n        \"\"\"\n        Returns all the staff of this course.\n        \"\"\"\n        return [part.user for part in Participant.query(\n            Participant.course == self.key,\n            Participant.role == STAFF_ROLE).fetch()]\n\n    @classmethod\n    def _can(cls, user, need, course, query):\n        action = need.action\n        if action == \"get\":\n            return True\n        elif action == \"index\":\n            return query\n        elif action == \"modify\":\n            return bool(course) and user.key in course.staff\n        elif action == \"staff\":\n            if user.is_admin:\n                return True\n            return user.key in course.staff\n        elif action == \"create\":\n            return user.is_admin\n        return False\n\n    @property\n    def assignments(self):\n        \"\"\"Return a query for assignments.\"\"\"\n        return Assignment.query(Assignment.course == self.key)\n\n    def get_students(self, user):\n\n        query = Participant.query(\n            Participant.course == self.key,\n            Participant.role == 'student')\n\n        return list(query.fetch())\n\n\nclass Assignment(Base):\n    \"\"\"Assignments are particular to courses and have unique names.\"\"\"\n    name = ndb.StringProperty() # E.g., cal/cs61a/fa14/proj1\n    display_name = ndb.StringProperty()\n    url = ndb.StringProperty()\n    points = ndb.FloatProperty()\n    templates = ndb.JsonProperty()\n    creator = ndb.KeyProperty(User)\n    course = ndb.KeyProperty(Course)\n    max_group_size = ndb.IntegerProperty()\n    due_date = ndb.DateTimeProperty()\n    lock_date = ndb.DateTimeProperty() # no submissions after this date\n    active = ndb.ComputedProperty(\n        lambda a: a.due_date and datetime.datetime.now() <= a.due_date)\n    revision = ndb.BooleanProperty(default=False)\n    autograding_key = ndb.StringProperty()\n    autograding_enabled = ndb.BooleanProperty(default=False)\n\n    # TODO Add services requested\n\n    @classmethod\n    def _can(cls, user, need, obj, query):\n        if need.action == \"index\":\n            return query\n        if user.is_admin:\n            return True\n        if need.action == \"get\":\n            return True\n        elif need.action in [\"grade\", 'delete', 'create', 'put', 'staff']:\n            if obj and isinstance(obj, Assignment):\n                return Participant.has_role(user, obj.course, STAFF_ROLE)\n        return False\n\n    def __lt__(self, other):\n        \"\"\" Allows us to sort assignments - reverse order so that latest due dates come first \"\"\"\n        return self.due_date > other.due_date\n\n\nclass Participant(Base):\n    \"\"\"Tracks participation of students & staff in courses.\"\"\"\n    user = ndb.KeyProperty(User)\n    course = ndb.KeyProperty(Course)\n    role = ndb.StringProperty() # See constants.py for roles\n\n    @classmethod\n    def _can(cls, user, need, course, query):\n        action = need.action\n        if action == \"get\":\n            return True\n        elif action == \"staff\":\n            if user.is_admin:\n                return True\n            return user.key in course.staff\n        elif action == \"index\":\n            if cls.has_role(user, course, STAFF_ROLE):\n                return query.filter(cls.course == course.key)\n            else:\n                return query.filter(cls.user == user.key)\n\n    @classmethod\n    def add_role(cls, user_key, course_key, role):\n        if role not in VALID_ROLES:\n            raise BadValueError(\"Bad role: \" + str(role))\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(course_key, Course):\n            course_key = course_key.key\n\n        query = cls.query(cls.user == user_key,\n                          cls.course == course_key,\n                          cls.role == role)\n        current = query.get()\n        if not current:\n            Participant(user=user_key, course=course_key, role=role).put()\n\n    @classmethod\n    def remove_role(cls, user_key, course_key, role):\n        if role not in VALID_ROLES:\n            raise BadValueError(\"Bad role: \" + str(role))\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(course_key, Course):\n            course_key = course_key.key\n        query = cls.query(cls.user == user_key,\n                          cls.course == course_key,\n                          cls.role == role)\n        current = query.get()\n        if current:\n            current.key.delete()\n\n    @classmethod\n    def has_role(cls, user_key, course_key, role):\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(course_key, Course):\n            course_key = course_key.key\n        query = cls.query(cls.user == user_key,\n                          cls.course == course_key,\n                          cls.role == role)\n        return query.get() is not None\n\n    @classmethod\n    def courses(cls, user_key, role=None):\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        query = cls.query(cls.user == user_key)\n        if role:\n            query = query.filter(cls.role == role)\n        return query.fetch()\n\n\ndef validate_messages(_, message_str):\n    \"\"\"message_str is a JSON string encoding a map from protocols to data.\"\"\"\n    if not message_str:\n        raise BadValueError('Empty messages')\n    try:\n        messages = json.loads(message_str)\n        if not isinstance(messages, dict):\n            raise BadValueError('messages is not a JSON map')\n    except Exception as exc:\n        raise BadValueError(exc)\n\n\nclass Message(Base):\n    \"\"\"A message given to us from the client (e.g., the contents of files).\"\"\"\n    contents = ndb.JsonProperty()\n    kind = ndb.StringProperty()\n\n    @classmethod\n    def _can(cls, user, need, obj=None, query=None):\n        action = need.action\n\n        if action == \"index\":\n            return False\n\n        return Backup._can(user, need, obj, query)\n\n\ndef disjunction(query, filters):\n    \"\"\"Return a query in which at least one filter is true.\"\"\"\n    assert filters, \"No filters\"\n    if len(filters) > 1:\n        return query.filter(ndb.OR(*filters)) #pylint: disable=star-args\n    else:\n        return query.filter(filters[0])\n\n\nclass Backup(Base):\n    \"\"\"A backup is sent each time a student runs the client.\"\"\"\n    submitter = ndb.KeyProperty(User)\n    assignment = ndb.KeyProperty(Assignment)\n    client_time = ndb.DateTimeProperty()\n    server_time = ndb.DateTimeProperty(auto_now_add=True)\n    messages = ndb.StructuredProperty(Message, repeated=True)\n    tags = ndb.StringProperty(repeated=True)\n\n    def get_messages(self, fields=None):\n        \"\"\"Returns self.messages formatted as a dictionary.\n\n        fields: The selected fields of the dictionary.\n        \"\"\"\n\n        if not fields:\n            fields = {}\n\n        # TODO What does this do and why? Please add a comment.\n        message_fields = fields.get('messages', {})\n        if isinstance(message_fields, (str, unicode)):\n            message_fields = message_fields == \"true\"\n\n        messages = {m.kind: m.contents for m in self.messages}\n        def test(item):\n            if isinstance(message_fields, bool):\n                return message_fields\n\n            if not message_fields:\n                return True\n            return item in message_fields\n\n        def get_contents(kind, contents):\n            if isinstance(message_fields, bool):\n                return contents\n\n            if message_fields.get(kind) == \"presence\":\n                return True\n            return contents\n\n        return {\n            kind: get_contents(kind, contents)\n            for kind, contents in messages.iteritems()\n            if test(kind)}\n\n    @property\n    def group(self):\n        return Group.lookup(self.submitter, self.assignment)\n\n    def to_json(self, fields=None):\n        json = super(Backup, self).to_json(fields)\n        if 'messages' in json:\n            json['messages'] = self.get_messages(fields)\n        return json\n\n    @classmethod\n    def _can(cls, user, need, backup, query):\n        \"\"\"A user can access a backup as staff or through a group.\"\"\"\n        action = need.action\n        if action == \"get\":\n            if not backup or not isinstance(backup, Backup):\n                raise ValueError(\"Need Backup instance for get action.\")\n            if user.is_admin or backup.submitter == user.key:\n                return True\n            course_key = backup.assignment.get().course\n            if Participant.has_role(user, course_key, STAFF_ROLE):\n                return True\n            group = backup.group\n            return bool(group and user.key in group.member)\n        if action in (\"create\", \"put\"):\n            return user.logged_in and user.key == backup.submitter\n        if action == \"index\":\n            if not user.logged_in:\n                return False\n            filters = [Backup.submitter == user.key]\n            staff_list = Participant.courses(user, STAFF_ROLE)\n            if user.key in [part.user for part in staff_list]:\n                for participant in staff_list:\n                    course = participant.course\n                    assigns = Assignment.query(Assignment.course == course).fetch()\n                    if assigns:\n                        filters.append(\n                            Backup.assignment.IN([a.key for a in assigns]))\n            grp = backup and backup.group\n            if grp and user.key in grp.member:\n                filters.append(ndb.AND(\n                    Backup.submitter.IN(grp.member),\n                    Backup.assignment == grp.assignment))\n            return disjunction(query, filters)\n        return False\n\n\nclass Score(Base):\n    \"\"\"The score for a submission, either from a grader or autograder.\"\"\"\n    tag = ndb.TextProperty() # E.g., \"Partner 0\" or \"composition\"\n    score = ndb.IntegerProperty()\n    message = ndb.TextProperty() # Plain text\n    grader = ndb.KeyProperty(User) # For autograders, the user who authenticated\n    server_time = ndb.DateTimeProperty(auto_now_add=True)\n\n\nclass Submission(Base):\n    \"\"\"A backup that may be scored.\"\"\"\n    backup = ndb.KeyProperty(Backup)\n    score = ndb.StructuredProperty(Score, repeated=True)\n    submitter = ndb.ComputedProperty(lambda x: x.backup.get().submitter)\n    assignment = ndb.ComputedProperty(lambda x: x.backup.get().assignment)\n    server_time = ndb.DateTimeProperty(auto_now_add=True)\n    is_revision = ndb.BooleanProperty(default=False)\n\n    def get_final(self):\n        assignment = self.assignment\n        # I have no idea why this works... need it to pass tests\n        group = self.submitter.get().get_group(assignment)\n        submitter = self.submitter\n        if group:\n            final = FinalSubmission.query(\n                FinalSubmission.assignment==assignment,\n                FinalSubmission.group==group.key).get()\n        else:\n            final = FinalSubmission.query(\n                FinalSubmission.assignment==assignment,\n                FinalSubmission.submitter==submitter).get()\n        return final\n\n    def mark_as_final(self):\n        \"\"\"Create or update a final submission.\"\"\"\n        final = self.get_final()\n        assignment = self.assignment.get()\n        if final:\n            if assignment.revision:\n                # Follow resubmssion procedure\n                final.revision = self.key\n                self.is_revision = True\n                self.put()\n            elif datetime.datetime.now() > assignment.lock_date:\n                return ValueError(\"Cannot change submission after due date\")\n            elif self.server_time <= assignment.lock_date:\n                final.submitter = self.submitter\n                final.submission = self.key\n            else:\n                return ValueError(\"Cannot flag submission that is past due date\")\n            return final.put()\n        else:\n            if self.server_time < assignment.lock_date:\n                group = self.submitter.get().get_group(self.assignment)\n                final = FinalSubmission(\n                    assignment=self.assignment, submission=self.key)\n                if group:\n                    final.group = group.key\n                return final.put()\n        return ValueError(\"Cannot flag submission that is past due date\")\n\n    def resubmit(self, user_key):\n        \"\"\"\n        Resubmits this submission as being submitted by |user|.\n        \"\"\"\n        old_backup = self.backup.get()\n        new_backup = Backup(\n            submitter=user_key,\n            assignment=self.assignment,\n            client_time=old_backup.client_time,\n            server_time=old_backup.server_time,\n            messages=old_backup.messages,\n            tags=old_backup.tags)\n        new_backup_key = new_backup.put()\n        new_subm = Submission(\n            backup=new_backup_key,\n            score=self.score,\n            server_time=self.server_time)\n        new_subm_key = new_subm.put_async()\n\n        final = self.get_final()\n        if final:\n            final.submitter = user_key\n            final.submission = new_subm_key.get_result()\n            final.put()\n\n    @classmethod\n    def _can(cls, user, need, submission, query):\n        if need.action == \"grade\":\n            if not submission or not isinstance(submission, Submission):\n                raise ValueError(\"Need Submission instance for grade action\")\n            if user.is_admin:\n                return True\n            course_key = submission.assignment.get().course\n            return Participant.has_role(user, course_key, STAFF_ROLE)\n        return Backup._can(user, need, submission.backup.get() if submission else None, query)\n\n\nclass Diff(Base):\n    \"\"\"A diff between two versions of the same project, with comments.\n    A diff has three types of lines: insertions, deletions, and matches.\n    Every insertion line is associated with a diff line.\n    \"\"\"\n    before = ndb.KeyProperty(Backup) # Set to None to compare to template\n    after = ndb.KeyProperty(Backup)\n    diff = ndb.JsonProperty()\n\n    @property\n    def comments(self):\n        \"\"\"\n        Returns all the comments for this diff.\n        \"\"\"\n        return Comment.query(ancestor=self.key).order(Comment.created)\n\n    def to_json(self, fields=None):\n        data = super(Diff, self).to_json(fields)\n        comments = list(self.comments)\n        all_comments = {}\n        for comment in comments:\n            file_comments = all_comments.setdefault(comment.filename, {})\n            file_comments.setdefault(comment.line, []).append(comment)\n\n        data['comments'] = all_comments\n        return data\n\n\nclass Comment(Base):\n    \"\"\"A comment is part of a diff. The key has the diff as its parent.\"\"\"\n    author = ndb.KeyProperty(User)\n    diff = ndb.KeyProperty(Diff)\n    filename = ndb.StringProperty()\n    line = ndb.IntegerProperty()\n    # TODO Populate submission_line so that when diffs are changed, comments\n    #      don't move around.\n    submission_line = ndb.IntegerProperty()\n    message = ndb.TextProperty() # Markdown\n\n    @classmethod\n    def _can(cls, user, need, comment=None, query=None):\n        if user.is_admin:\n          return True\n        if need.action in [\"get\", \"modify\", \"delete\", \"edit\"]:\n            return comment.author == user.key\n        return False\n\n\nclass Version(Base):\n    \"\"\"A version of client-side resources. Used for auto-updating.\"\"\"\n    name = ndb.StringProperty(required=True)\n    versions = ndb.StringProperty(repeated=True)\n    current_version = ndb.StringProperty()\n    base_url = ndb.StringProperty(required=True)\n\n    def download_link(self, version=None):\n        if version is None:\n            if not self.current_version:\n                raise BadValueError(\"current version doesn't exist\")\n            return '/'.join((self.base_url, self.current_version,\n                             self.name))\n        if version not in self.versions:\n            raise BadValueError(\"specified version %s doesn't exist\" % version)\n        return '/'.join((self.base_url, version, self.name))\n\n    def to_json(self, fields=None):\n        converted = super(Version, self).to_json(fields)\n        if self.current_version:\n            converted['current_download_link'] = self.download_link()\n\n        return converted\n\n    @classmethod\n    def _can(cls, user, need, obj=None, query=None):\n        action = need.action\n\n        if action == \"delete\":\n            return False\n        if action == \"index\":\n            return query\n        if action == \"get\":\n            return True\n        return user.is_admin\n\n    @classmethod\n    def from_dict(cls, values):\n        \"\"\"Creates an instance from the given values.\"\"\"\n        if 'name' not in values:\n            raise ValueError(\"Need to specify a name\")\n        inst = cls(key=ndb.Key(cls._get_kind(), values['name']))\n        inst.populate(**values) #pylint: disable=star-args\n        return inst\n\n    @classmethod\n    def get_or_insert(cls, key, **kwargs):\n        assert not isinstance(id, int), \"Only string keys allowed for versions\"\n        kwargs['name'] = key\n        return super(cls, Version).get_or_insert(key, **kwargs)\n\n    @classmethod\n    def get_by_id(cls, key, **kwargs):\n        assert not isinstance(id, int), \"Only string keys allowed for versions\"\n        return super(cls, Version).get_by_id(key, **kwargs)\n\nclass Group(Base):\n    \"\"\"A group is a collection of users who are either members or invited.\n\n    Members of a group can view each other's submissions.\n\n    Specification:\n    https://github.com/Cal-CS-61A-Staff/ok/wiki/Group-&-Submission-Consistency\n    \"\"\"\n    member = ndb.KeyProperty(User, repeated=True)\n    invited = ndb.KeyProperty(User, repeated=True)\n    assignment = ndb.KeyProperty(Assignment, required=True)\n    order = ndb.StringProperty()\n\n    @classmethod\n    def lookup(cls, user_key, assignment_key):\n        \"\"\"Return the group for a user key.\"\"\"\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(assignment_key, Assignment):\n            assignment_key = assignment_key.key\n        return Group.query(ndb.OR(Group.member == user_key,\n                                  Group.invited == user_key),\n                           Group.assignment == assignment_key).get()\n\n    @classmethod\n    def _lookup_or_create(cls, user_key, assignment_key):\n        \"\"\"Retrieve a group for user or create a group. Group is *not* put.\"\"\"\n        group = cls.lookup(user_key, assignment_key)\n        if group:\n            return group\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(assignment_key, Assignment):\n            assignment_key = assignment_key.key\n        return Group(member=[user_key], invited=[], assignment=assignment_key)\n\n    @classmethod\n    def lookup_by_assignment(cls, assignment):\n        \"\"\" Returns all groups with the given assignment \"\"\"\n        if isinstance(assignment, Assignment):\n            assign_key = assignment.key\n        return Group.query(Group.assignment == assign_key).fetch()\n\n    #@ndb.transactional\n    def invite(self, email):\n        \"\"\"Invites a user to the group. Returns an error message or None.\"\"\"\n        if isinstance(email, ndb.Key):\n            user = email.get()\n            email = user.email[0]\n        else:\n            user = User.lookup(email)\n        if not user:\n            return \"{} is not a valid user\".format(email)\n        course = self.assignment.get().course\n        if not Participant.has_role(user, course, STUDENT_ROLE):\n            return \"{} is not enrolled in {}\".format(email, course.get().display_name)\n        if user.key in self.invited:\n            return '{} has already been invited'.format(email)\n        if user.key in self.member:\n            return \"{} is already in the group\".format(email)\n        has_user = ndb.OR(Group.member == user.key, Group.invited == user.key)\n        if Group.query(has_user, Group.assignment == self.assignment).get():\n            return \"{} is already in some other group\".format(email)\n        max_group_size = self.assignment.get().max_group_size\n        total_member = len(self.member) + len(self.invited)\n        if total_member + 1 > max_group_size:\n            return \"The group is full\"\n        self.invited.append(user.key)\n        self.put()\n        for member in self.member:\n            member.get().update_final_submission(self.assignment, self)\n\n    #@ndb.transactional\n    @classmethod\n    def invite_to_group(cls, user_key, email, assignment_key):\n        \"\"\"User invites email to join his/her group. Returns error or None.\"\"\"\n        group = cls._lookup_or_create(user_key, assignment_key)\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if isinstance(assignment_key, Assignment):\n            assignment_key = assignment_key.key\n        AuditLog(\n            event_type='Group.invite',\n            user=user_key,\n            assignment=assignment_key,\n            description='Added {} to group'.format(email),\n            obj=group.key,\n        ).put()\n        return group.invite(email)\n\n    #@ndb.transactional\n    def accept(self, user_key):\n        \"\"\"User accepts an invitation to join. Returns error or None.\"\"\"\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if user_key not in self.invited:  # Note: these will never happen, according to _can\n            return \"That user is not invited to the group\"\n        if user_key in self.member:\n            return \"That user has already accepted.\"\n        self.invited.remove(user_key)\n        self.member.append(user_key)\n        self.put()\n        for user_key in self.member:\n            user_key.get().update_final_submission(self.assignment, self)\n\n    #@ndb.transactional\n    def exit(self, user_key):\n        \"\"\"User leaves the group. Empty/singleton groups are deleted.\"\"\"\n        if isinstance(user_key, User):\n            user_key = user_key.key\n        if user_key not in self.member and user_key not in self.invited:\n            return 'That user is not in this group and has not been invited.'\n        for users in [self.member, self.invited]:\n            if user_key in users:\n                users.remove(user_key)\n\n        error = self.validate()\n        if error:\n            subms = FinalSubmission.query(\n                FinalSubmission.group==self.key\n            ).fetch()\n            for subm in subms:\n                subm.group = None\n                subm.put()\n            self.key.delete()\n        else:\n            self.put()\n\n        for user in self.member + [user_key]:\n            user.get().update_final_submission(self.assignment)\n\n    @classmethod\n    def _can(cls, user, need, group, query):\n        action = need.action\n        if not user.logged_in:\n            return False\n\n        if action == \"index\":\n            if user.is_admin:\n                return query\n            return query.filter(ndb.OR(Group.member == user.key,\n                                       Group.invited == user.key))\n\n        if user.is_admin:\n            return True\n        if not group:\n            return False\n        if action in (\"get\", \"exit\"):\n            return user.key in group.member or user.key in group.invited\n        elif action in (\"invite\", \"remove\", \"reorder\"):\n            return user.key in group.member\n        elif action in \"accept\":\n            return user.key in group.invited\n        return False\n\n    def validate(self):\n        \"\"\"Return an error string if group is invalid.\"\"\"\n        max_group_size = self.assignment.get().max_group_size\n        total_member = len(self.member) + len(self.invited)\n        if max_group_size and total_member > max_group_size:\n            sizes = (total_member, max_group_size)\n            return \"%s member found; at most %s allowed\" % sizes\n        if total_member < 2:\n            return \"No group can have %s total member\" % total_member\n        if not self.member:\n            return \"A group must have an active member\"\n\n    def _pre_put_hook(self):\n        \"\"\"Ensure that the group is well-formed before put.\"\"\"\n        error = self.validate()\n        if error:\n            raise BadValueError(error)\n\n    def scores_for_assignment(self, assignment):\n        \"\"\" Returns a list of lists containing score data\n            for the groups's final submission for ASSIGNMENT.\n            There is one element for each combination of\n            group member and score.\n            Ensures that each student only appears once in the list.\n            Format: [['STUDENT', 'SCORE', 'MESSAGE', 'GRADER', 'TAG']]\n        \"\"\"\n        content = []\n        member = self.member[0].get()\n\n        for m in self.member:\n            member = m.get()\n            if member:\n              data, success = member.scores_for_assignment(assignment)\n              content.extend(data)\n              if success:\n                  # get_scores_for_student_or_group will return scores for all group members.\n                  return content\n\n        # Handle the case where the member key no longer exists.\n        if not member:\n          return [[\"Unknown-\"+str(self.member[0]), 0, None, None, None]]\n\n        return [[member.email[0], 0, None, None, None]]\n\n\n\nclass AuditLog(Base):\n    \"\"\"Keeps track of Group changes that are happening. That way, we can stop\n    cases of cheating by temporary access. (e.g. A is C's partner for 10 min\n    so A can copy off of C).\"\"\"\n    event_type = ndb.StringProperty()\n    user = ndb.KeyProperty(User)\n    assignment = ndb.KeyProperty(Assignment)\n    description = ndb.StringProperty()\n    obj = ndb.KeyProperty()\n\n\nclass Queue(Base):\n    \"\"\"A queue of submissions to grade.\"\"\"\n    assignment = ndb.KeyProperty(Assignment)\n    course = ndb.ComputedProperty(lambda q: q.assignment.get().course)\n    assigned_staff = ndb.KeyProperty(User, repeated=True)\n    owner = ndb.KeyProperty(User)\n\n    @property\n    def submissions(self):\n        \"\"\"\n        Returns all the submissions in this queue.\n        \"\"\"\n        query = FinalSubmission.query().filter(FinalSubmission.queue == self.key)\n        return [fs for fs in query]\n\n    @property\n    def graded(self):\n        \"\"\"\n        Returns the count of graded composition submissions in this queue.\n        \"\"\"\n        num_comp = 0\n        for fs in self.submissions:\n            scores = fs.submission.get().score\n            for score in scores:\n                if score.tag == \"composition\":\n                    num_comp += 1\n        return num_comp\n\n    def to_json(self, fields=None):\n        if not fields:\n            fields = {}\n\n        final_submissions = self.submissions\n        subms = []\n        submitters = ndb.get_multi(fs.submitter for fs in final_submissions)\n        submissions = [fs.submission for fs in final_submissions]\n        submissions = ndb.get_multi(submissions)\n        groups = [fs.group for fs in final_submissions]\n        groups = ndb.get_multi(filter(None, groups))\n        groups = {v.key: v for v in groups}\n        for i, fs in enumerate(final_submissions):\n          submission = submissions[i]\n          group = groups.get(fs.group)\n          subms.append(\n            {\n             'id': fs.key.id(),\n             'submission': submission.key.id(),\n             'created': submission.created,\n             'backup': submission.backup.id(),\n             'submitter': submitters[i],\n             'group': group,\n             'score': submission.score,\n            })\n        owner_email = \"Unknown\"\n        if self.owner.get():\n          owner_email = self.owner.get().email[0]\n\n        return {\n            'submissions': subms,\n            'count': len(final_submissions),\n            'graded': self.graded,\n            'remaining': len(final_submissions) - self.graded,\n            'assignment': {'id': self.assignment},\n            'assigned_staff': [val.get() for val in self.assigned_staff],\n            'owner': owner_email,\n            'id': self.key.id()\n        }\n\n    @classmethod\n    def _can(cls, user, need, queue, query=None):\n        action = need.action\n        if not user.logged_in:\n            return False\n\n        if action == \"index\":\n            if user.is_admin:\n                return query\n            courses = [part.course for part in Participant.query(\n                Participant.user == user.key,\n                Participant.role == STAFF_ROLE).fetch()]\n            if courses:\n                return disjunction(\n                    query, [(Queue.course == course) for course in courses])\n            return False\n\n        course = queue.assignment.get().course\n        is_staff = user.is_admin or \\\n            Participant.has_role(user, course, STAFF_ROLE)\n        if is_staff:\n            return True\n\n        return False\n\n\nclass FinalSubmission(Base):\n    \"\"\"The final submission for an assignment from a group.\n\n    Specification:\n    https://github.com/Cal-CS-61A-Staff/ok/wiki/Final-Submissions-and-Grading\n    \"\"\"\n    assignment = ndb.KeyProperty(Assignment)\n    group = ndb.KeyProperty(Group)\n    submission = ndb.KeyProperty(Submission)\n    revision = ndb.KeyProperty(Submission)\n    queue = ndb.KeyProperty(Queue)\n    server_time = ndb.ComputedProperty(lambda q: q.submission.get().server_time)\n    # submitter = ndb.ComputedProperty(lambda q: q.submission.get().submitter.get())\n    submitter = ndb.KeyProperty(User)\n    published = ndb.BooleanProperty(default=False)\n\n    @property\n    def backup(self):\n        \"\"\"\n        Return the associated backup.\n        \"\"\"\n        return self.submission.get().backup.get()\n\n    @property\n    def assigned(self):\n        \"\"\"\n        Return whether or not this assignment has been assigned to a queue.\n        \"\"\"\n        return bool(self.queue)\n\n    @classmethod\n    def _can(cls, user, need, final, query):\n        action = need.action\n        if action in (\"create\", \"put\") and final:\n            group = final.submission.get().backup.get().group\n            if group:\n              return user.logged_in and user.key in group.member\n        return Submission._can(\n            user, need, final.submission.get() if final else None, query)\n\n    def _pre_put_hook(self):\n        # TODO Remove when submitter is a computed property\n        self.submitter = self.submission.get().submitter\n\n    def get_scores(self):\n        \"\"\"\n        Return a list of lists of the format [[student, score, message, grader, tag]]\n        if the submission has been scored. Otherwise an empty list.\n        If the submission is a group submission, there will be an element\n        for each combination of student and score.\n        \"\"\"\n        # TODO: get the most recent score for each tag.\n        # Question: will all scores have a grader? In particular the scores from the autograder.\n        all_scores = []\n        if self.group:\n            members = [member for member in self.group.get().member]\n        else:\n            members = [self.submitter]\n        for member in members:\n            member_row = member.get()\n            if member_row:\n              email = member_row.email[0]\n              for score in self.submission.get().score:\n                  all_scores.append([email,\n                          score.score,\n                          score.message,\n                          score.grader.get().email[0],\n                          score.tag])\n            else:\n              logging.warning(\"User key not found - \" + str(member))\n        return all_scores\n", "name": "server/app/models.py", "coverage": [null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, null, null, null, null, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, null, 1, null, 1, null, null, null, null, null, 1, 1, null, null, 1, null, 1, null, 1, null, null, 1, 1, 1, null, 1, null, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, null, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 0, 0, null, 1, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, null, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, null, null, 1, 1, null, 1, null, null, null, 1, 1, null, null, null, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, null, null, 1, null, null, null, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, null, 1, null, 1, 1, null, null, null, null, 1, 1, 1, null, 1, null, 1, 1, null, null, null, null, 1, 1, 1, null, 1, null, 1, 1, 1, null, null, null, 1, null, 1, null, 1, 0, 0, null, 0, null, 0, 0, 0, 0, 0, null, null, null, null, 0, 0, 0, null, 0, 0, null, 0, null, 0, 0, null, null, null, 0, null, null, null, null, null, null, null, null, null, null, 0, null, 0, null, null, null, null, 1, null, null, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, 1, 1, 1, null, null, null, null, 1, null, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, null, 1, null, 1, 1, null, null, 1, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, null, null, null, null, 1, null, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, null, 1, null, 1, null, null, null, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, null, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, null, 1, null, 1, null, null, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, null, 1, 1, 1, null, 1, 1, null, 1, null, null, 1, null, 1, 1, 1, null, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, null, null, null, null, null, 1, 1, null, null, 1, 1, 0, null, 1, 1, 1, 0, null, 1, 1, 0, null, 1, 1, 0, null, 1, 0, 1, null, 1, null, null, null, null, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, null, 1, 1, 1, null, null, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, null, null, null, 1, null, null, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, null, 0, 1, null, 1, 1, 1, null, 1, 1, 1, 0, null, 1, null, null, null, 1, 1, null, null, null, null, null, null, 1, 1, null, null, null, 1, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, null, null, 1, 1, 1, null, 1, null, null, null, null, 1, null, 1, 1, 1, 1, 1, 0, 0, null, 1, 1, null, null, 1, null, 1, 1, 1, 1, null, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, null, 1, null, 1, 1, null, 1, null, null, null, null, null, null, null, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, null, null, 1, null, null, 1, 1, 1, 1, 0, 1, 1, 1, null, 1, null, null, 1, 1, 1, null, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, null, 1, 1, 0, 1, 1, 1, null, null, null, null, null, null, 1, null, null, 1, null, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, null, null, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, 1, null, null, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, null, 1, null, 1, 1, 1, 0, 0, 1, 1, 1, 0, null, 1, null, 1, 1, 0, null, 1, null, null, null, null, null, null, null, 0, 0, null, 0, 0, 0, 0, 0, 0, null, 0, null, null, 0, 0, null, 0, null, null, null, 1, null, null, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, null, null, null, null, 1, 1, null, 1, null, null, null, null, 1, 1, 0, 0, 0, 0, 1, null, 1, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, null, null, null, null, null, null, null, null, null, 1, 1, 1, null, 1, null, null, null, null, null, null, null, null, null, null, 1, 1, 1, 1, 0, null, 1, 0, 0, 0, null, null, 0, 0, null, 0, null, 1, 1, null, 1, 1, null, 1, null, null, 1, null, null, null, null, null, 1, 1, 1, 1, 1, 1, null, 1, 1, null, 1, null, null, null, null, 0, null, 1, null, null, null, null, 0, null, 1, null, 1, 1, 1, 1, 0, 1, null, null, 1, null, 1, null, 1, null, null, null, null, null, null, null, null, 1, 1, 0, null, 1, 1, 1, 1, 1, 1, 1, null, null, null, null, null, 0, 1, null]}, {"source": "from app.exceptions import PermissionError\n\n\nclass Need(object):\n    \"\"\"A need represents an action taken on an object, such as getting it.\"\"\"\n\n    def __init__(self, action):\n        self.action = action\n        self.obj = None\n\n    def set_object(self, obj):\n        self.obj = obj\n        return self\n\n    def exception(self):\n        return PermissionError(self)\n\n    def get_exception_message(self):\n        class_name = \"\"\n        if isinstance(self.obj, type):\n            class_name = self.obj.__name__\n        elif self.obj:\n            class_name = type(self.obj).__name__\n        else:\n            class_name = 'unknown object'\n        return \"Don't have permission to {} {}\".format(\n            self.action, class_name)\n", "name": "server/app/needs.py", "coverage": [1, null, null, 1, null, null, 1, 1, 1, null, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, null, 1, 1, null, null]}, {"source": "# CSRF- and Session keys\n\nCSRF_SECRET_KEY = 'U1sxqdVlbkp8mx84uy88Fa4v'\nSESSION_KEY = 'DMdIyHZXRbEs3FSVTTSRF7kY'\n", "name": "server/app/secret_keys.py", "coverage": [null, null, 1, 1, null]}, {"source": "\"\"\"\nConfiguration for Flask app\n\nImportant: Place your keys in the secret_keys.py module,\n           which should be kept out of version control.\n           secret_keys.py is generated by generate_keys.py.\n\"\"\"\n\nfrom app import secret_keys\nfrom app.authenticator import GoogleAuthenticator, TestingAuthenticator\n\nGOOGLE_AUTHENTICATOR = GoogleAuthenticator()\nTESTING_AUTHENTICATOR = TestingAuthenticator()\n\n\nclass Config(object): #pylint: disable=R0903\n    \"\"\"\n    Base config\n    \"\"\"\n    # Set secret keys for CSRF protection\n    SECRET_KEY = secret_keys.CSRF_SECRET_KEY\n    CSRF_SESSION_KEY = secret_keys.SESSION_KEY\n    # Flask-Cache settings\n    CACHE_TYPE = 'gaememcached'\n    AUTHENTICATOR = GOOGLE_AUTHENTICATOR\n    GAE_DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S.%f\"\n    CLIENT_VERSION = '1.0.6'\n\n\nclass Debug(Config): #pylint: disable=R0903\n    \"\"\"\n    Development config\n    \"\"\"\n    DEBUG = True\n    TESTING = True\n    CSRF_ENABLED = True\n    AUTHENTICATOR = TESTING_AUTHENTICATOR\n\n\nclass Production(Config): #pylint: disable=R0903\n    \"\"\"\n    Prod config\n    \"\"\"\n    DEBUG = False\n    CSRF_ENABLED = True\n", "name": "server/app/settings.py", "coverage": [null, null, null, null, null, null, null, null, 1, 1, null, 1, 1, null, null, 1, null, null, null, null, 1, 1, null, 1, 1, 1, 1, null, null, 1, null, null, null, 1, 1, 1, 1, null, null, 1, null, null, null, 1, 1, null]}, {"source": "\"\"\"\nURL dispatch route mappings and error handlers\n\"\"\"\nfrom functools import wraps\nimport logging\nimport traceback\nimport collections\nimport json\n\nimport werkzeug\nfrom flask import render_template, session, request, Response, redirect, url_for\n\nfrom google.appengine.api import users\nfrom google.appengine.ext import deferred\n\nfrom app import app\nfrom app import api\nfrom app import auth\nfrom app import models\nfrom app import utils\nfrom app.constants import API_PREFIX\nfrom app.exceptions import *\n\ndef force_account_chooser(url):\n    \"\"\"Forces the user to choose a particular email account rather than assuming a default.\"\"\"\n    if 'ServiceLogin' in url:\n        return url.replace('ServiceLogin', 'AccountChooser')\n    return url\n\n@app.route(\"/\")\ndef home():\n    user = users.get_current_user()\n    params = {}\n    if user is None:\n      return redirect(url_for('landing'))\n    else:\n        logging.info(\"User is %s\", user.email())\n        params[\"user\"] = {'id': user.user_id(), 'email' : user.email()}\n        params['users_link'] = users.create_logout_url('/landing')\n        params['users_title'] = \"Log Out\"\n        params['relogin_link'] = users.create_logout_url(\n            force_account_chooser(users.create_login_url('/')))\n    params['DEBUG'] = app.config['DEBUG']\n    return render_template(\"student.html\", **params)\n\n@app.route(\"/landing\")\ndef landing():\n    user = users.get_current_user()\n    params = {}\n    if user is None:\n        params['users_link'] = force_account_chooser(\n            users.create_login_url('/'))\n        params['users_title'] = \"Sign In\"\n    else:\n        logging.info(\"User is %s\", user.email())\n        params[\"user\"] = {'id': user.user_id(), 'email' : user.email()}\n        params['users_link'] = users.create_logout_url('/landing')\n        params['users_title'] = \"Log Out\"\n        params['relogin_link'] = users.create_logout_url(\n            force_account_chooser(users.create_login_url('/')))\n    params['DEBUG'] = app.config['DEBUG']\n    return render_template(\"landing.html\", **params)\n\n@app.route(\"/sudo/su/<su_email>\")\ndef sudo(su_email):\n    user = users.get_current_user()\n    params = {}\n    if user is not None:\n        logging.info(\"Staff Login Attempt from %s, Attempting to login as %s\", user.email(), su_email)\n        userobj = models.User.lookup(user.email())\n        if userobj.is_admin:\n          logging.info(\"Sudo %s to %s granted\", user.email(), su_email)\n          substitute = models.User.lookup(su_email)\n          if substitute:\n            params[\"user\"] = {'id': substitute.key, 'email' : substitute.email[0]}\n            params[\"sudo\"] = {'su': substitute.email[0], 'admin': user.email()}\n            params['users_link'] = '/'\n            params['users_title'] = \"Exit Sudo Mode\"\n            params['relogin_link'] = '/'\n            params['DEBUG'] = app.config['DEBUG']\n            return render_template(\"sudo.html\", **params)\n          else:\n            error = {'code': 404, 'description': \"User not found\"}\n            return page_not_found(error)\n        else:\n          logging.error(\"Sudo %s to %s failure\", user.email(), su_email)\n          error = {'code': 403, 'description': \"Insufficient permission\"}\n          return page_not_found(error)\n    return redirect(url_for('login'))\n\n@app.route(\"/login\")\ndef login():\n    user = users.get_current_user()\n    params = {}\n    if user is None:\n      return redirect(users.create_login_url('/'))\n    else:\n      return redirect(url_for('home'))\n\n\n@app.route(\"/manage\")\ndef admin():\n    user = users.get_current_user()\n    params = {}\n    if user is None:\n        params['users_link'] = force_account_chooser(\n            users.create_login_url('/#/loginLanding'))\n        params['users_title'] = \"Sign In\"\n        return redirect(users.create_login_url('/manage'))\n    else:\n        logging.info(\"Staff Login Attempt from %s\", user.email())\n        userobj = models.User.lookup(user.email())\n\n        # TODO: Filter by class.\n        query = models.Participant.query(\n          models.Participant.role == 'staff')\n        all_staff = [part.user.id() for part in list(query.fetch())]\n\n        if userobj.is_admin or userobj.key.id() in all_staff:\n            logging.info(\"Staff Login Success from %s\", user.email())\n            params[\"user\"] = {'id': user.user_id(), 'keyId': userobj.key.id(), 'email' : user.email()}\n            params[\"admin\"] = {'email': user.email()}\n            params['users_link'] = users.create_logout_url('/')\n            params['users_title'] = \"Log Out\"\n            params['relogin_link'] = users.create_logout_url(\n                force_account_chooser(\n                    users.create_login_url('/#/loginLanding')))\n            return render_template(\"admin.html\", **params)\n        else:\n            logging.info(\"Staff Login Failure from %s\", user.email())\n            error = {'code': 403, 'description': \"Insufficient permission\"}\n            return page_not_found(error)\n\n## Error handlers\n# Handle 404 errors\n@app.errorhandler(404)\ndef page_not_found(e):\n    return render_template('error.html', error=e), 404\n\n# Handle 500 errors\n@app.errorhandler(500)\ndef server_error(e):\n    return render_template('error.html', error=e), 500\n\n@api.parser.error_handler\ndef args_error(e):\n    raise BadValueError(e.message)\n\ndef check_version(client):\n    latest = models.Version.query(models.Version.name == 'ok').get()\n\n    if latest is None or latest.current_version is None:\n        raise APIException('Current version of ok not found')\n\n    if client != latest.current_version:\n        raise IncorrectVersionError(client, latest)\n\ndef register_api(view, endpoint, url):\n    \"\"\"\n    Registers the given view at the endpoint, accessible by the given url.\n    \"\"\"\n    url = '/'.join((API_PREFIX, view.api_version, url))\n    view = view.as_view(endpoint)\n\n    def api_wrapper(*args, **kwds):\n        # Any client can check for the latest version\n\n        try:\n            request.fields = {}\n            message = \"success\"\n            if request.args.get('client_version'):\n                check_version(request.args['client_version'])\n\n            user = auth.authenticate()\n\n            if not isinstance(user, models.User):\n                return user\n\n            session['user'] = user\n            logging.info(\"User is %s.\", user.email)\n\n            rval = view(*args, **kwds)\n\n            if (isinstance(rval, Response) or\n                    isinstance(rval, werkzeug.wrappers.Response)):\n                pass\n            elif isinstance(rval, list):\n                rval = utils.create_api_response(200, message, rval)\n            elif (isinstance(rval, collections.Iterable)\n                  and not isinstance(rval, dict)):\n                rval = utils.create_api_response(*rval)\n            else:\n                rval = utils.create_api_response(200, message, rval)\n            return rval\n\n        except IncorrectVersionError as e:\n            logging.warn(e.message)\n            return utils.create_api_response(e.code, e.message, e.data)\n\n        except APIException as e:\n            logging.exception(e.message)\n            return utils.create_api_response(e.code, e.message, e.data)\n\n        except Exception as e: #pylint: disable=broad-except\n            logging.exception(e.message)\n            return utils.create_api_response(500, e.message, getattr(e, 'data', None))\n\n    @wraps(view)\n    def wrapper(*args, **kwargs):\n        return api_wrapper(*args, **kwargs)\n\n    app.add_url_rule(\n        '%s' % url, view_func=wrapper, defaults={'path': None},\n        methods=['GET', 'POST'])\n    app.add_url_rule(\n        '%s/<path:path>' % url, view_func=wrapper,\n        methods=['GET', 'POST', 'DELETE', 'PUT'])\n\n    return api_wrapper  # adding for testing purposes\n\n\ndef register_root_api(api):\n    api = api()\n    for method, value in api.methods.items():\n        app.add_url_rule('/%s' % method, view_func=getattr(api, method))\n\n\nregister_api(api.AssignmentAPI, 'assignment_api', 'assignment')\nregister_api(api.SubmissionAPI, 'submission_api', 'submission')\nregister_api(api.SearchAPI, 'search_api', 'search')\nregister_api(api.VersionAPI, 'version_api', 'version')\nregister_api(api.CourseAPI, 'course_api', 'course')\nregister_api(api.GroupAPI, 'group_api', 'group')\nregister_api(api.UserAPI, 'user_api', 'user')\nregister_api(api.QueueAPI, 'queue_api', 'queue')\nregister_api(api.QueuesAPI, 'queues_api', 'queues')\nregister_api(api.FinalSubmissionAPI, 'final_submission_api', 'final_submission')\nregister_api(api.AnalyticsAPI, 'analytics_api', 'analytics')\nregister_root_api(api.ParticipantAPI)\n", "name": "server/app/urls.py", "coverage": [null, null, null, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 1, 1, null, 1, null, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, null, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, 1, null, 1, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, null, 1, 1, 1, 1, null, 1, null, null, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, null, null, 1, null, 1, null, 1, 1, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, null, null, null, 1, null, 1, null, null, 1, null, 1, null, 1, null, 1, null, 1, 1, null, 1, 1, null, 1, 1, null, 1, null, null, null, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, null, 1, null, 1, null, null, 1, 1, 1, null, 1, null, 1, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, 1, null, 1, null, null, 1, null, null, null, 1, null, null, 1, 1, 1, 1, null, null, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, null]}, {"source": "\"\"\"\nUtility functions used by API and other services\n\"\"\"\n\n# pylint: disable=no-member\n\nimport collections\nimport contextlib\nimport logging\nimport datetime\nimport itertools\nfrom os import path\nfrom app import constants\nimport requests\n\ntry:\n    from cStringIO import StringIO\nexcept:\n    from StringIO import StringIO\nimport zipfile as zf\nimport csv\nfrom flask import jsonify, request, Response, json\n\nfrom google.appengine.api import memcache\nfrom google.appengine.ext import ndb\nfrom google.appengine.ext import deferred\nimport cloudstorage as gcs\n\nfrom app import app\nfrom app.constants import GRADES_BUCKET, AUTOGRADER_URL, STUDENT_ROLE\nfrom app.exceptions import BadValueError\n\n# TODO Looks like this can be removed just by relocating parse_date\n# To deal with circular imports\nclass ModelProxy(object):\n    def __getattribute__(self, key):\n        import app\n        return app.models.__getattribute__(key)\n\nModelProxy = ModelProxy()\n\ndef parse_date(date):\n    # TODO Describe what date translation is happening here. Probably needs\n    # a rewrite to handle daylight savings and work with other time zones.\n    try:\n        date = datetime.datetime.strptime(\n            date, app.config[\"GAE_DATETIME_FORMAT\"])\n    except ValueError:\n        date = datetime.datetime.strptime(\n            date, \"%Y-%m-%d %H:%M:%S\")\n\n    delta = datetime.timedelta(hours=7)\n    return datetime.datetime.combine(date.date(), date.time()) + delta\n\ndef coerce_to_json(data, fields):\n    \"\"\"\n    Coerces |data| to json, using only the allowed |fields|\n    \"\"\"\n    if hasattr(data, 'to_json'):\n        return data.to_json(fields)\n    elif isinstance(data, list):\n        return [mdl.to_json(fields) if hasattr(mdl, 'to_json')\n                else coerce_to_json(mdl, fields) for mdl in data]\n    elif isinstance(data, dict):\n        if hasattr(data, 'to_json'):\n            return {\n                k: mdl.to_json(fields.get(k, {}))\n                for k, mdl in data.iteritems()}\n        else:\n            return {k: coerce_to_json(mdl, fields.get(k, {}))\n                    for k, mdl in data.iteritems()}\n    else:\n        return data\n\n#TODO(martinis) somehow having data be an empty list doesn't make it\n# return an empty list, but an empty object.\ndef create_api_response(status, message, data=None):\n    \"\"\"Creates a JSON response that contains status code (HTTP),\n    an arbitrary message string, and a dictionary or list of data\"\"\"\n    if isinstance(data, dict) and 'results' in data:\n        data['results'] = (\n            coerce_to_json(data['results'], request.fields.get('fields', {})))\n    else:\n        data = coerce_to_json(data, request.fields.get('fields', {}))\n\n    if request.args.get('format', 'default') == 'raw':\n        response = Response(json.dumps(data))\n    else:\n        response = jsonify(**{\n            'status': status,\n            'message': message,\n            'data': data\n        })\n    response.status_code = status\n    return response\n\n\ndef create_zip(file_contents={}, dir=''):\n    return finish_zip(*start_zip(file_contents, dir))\n\n\ndef start_zip(file_contents={}, dir=''):\n    \"\"\"\n    Creates a file from the given dictionary of filenames to contents.\n    Uses specified dir to store all files.\n    \"\"\"\n    zipfile_str = StringIO()\n    zipfile = zf.ZipFile(zipfile_str, 'w')\n    zipfile = add_to_zip(zipfile, file_contents, dir)\n    return zipfile_str, zipfile\n\n\ndef finish_zip(zipfile_str, zipfile):\n    zipfile.close()\n    return zipfile_str.getvalue()\n\n\ndef add_to_zip(zipfile, files, dir=''):\n    \"\"\"\n    Adds files to a given zip file. Uses specified dir to store files.\n\n    :param zipfile: (ZipFile) zip archive to be extended\n    :param files: (dict) map from filenames (str) to file contents.\n        File contents will be encoded into a utf-8 text file.\n    :param dir: (str) directory to place files in. Both this and the filename\n        will be utf-8 encoded.\n    \"\"\"\n    for filename, contents in files.iteritems():\n        # The Python 2.7 zipfile packages encodes filenames as UTF-8, but\n        # does not encode the contents.\n        zipfile.writestr(path.join(dir, filename), unicode(contents).encode('utf-8'))\n    return zipfile\n\ndef create_csv_content(content):\n    \"\"\"\n    Return all contents in CSV file format. Content must be a list of lists.\n    \"\"\"\n    scsv = StringIO()\n    writer = csv.writer(scsv)\n    try:\n        writer.writerows(content)\n    except csv.Error as e:\n        scsv.close()\n        sys.exit('Error creating CSV: {}'.format(e))\n    contents = scsv.getvalue()\n    scsv.close()\n    return contents\n\ndef data_for_scores(assignment, user):\n    \"\"\"\n    Returns a tuple of two values a list of lists of score info for assignment.\n    Format: [['STUDENT', 'SCORE', 'MESSAGE', 'GRADER', 'TAG']]\n    \"\"\"\n    content = [['STUDENT', 'SCORE', 'MESSAGE', 'GRADER', 'TAG']]\n    course = assignment.course.get()\n    groups = ModelProxy.Group.lookup_by_assignment(assignment)\n    seen_members = set()\n\n    for group in groups:\n        members = group.member\n        seen_members |= set(members)\n        content.extend(group.scores_for_assignment(assignment))\n\n    students = [part.user.get() for part in course.get_students(user) if part.user not in seen_members]\n    for student in students:\n        content.extend(student.scores_for_assignment(assignment)[0])\n\n    return content\n\ndef create_gcs_file(gcs_filename, contents, content_type):\n    \"\"\"\n    Creates a GCS csv file with contents CONTENTS.\n    \"\"\"\n    try:\n        gcs_file = gcs.open(gcs_filename, 'w', content_type=content_type, options={'x-goog-acl': 'project-private'})\n        gcs_file.write(contents)\n        gcs_file.close()\n    except Exception as e:\n        logging.exception(\"ERROR: {}\".format(e))\n        try:\n            gcs.delete(gcs_filename)\n        except gcs.NotFoundError:\n            logging.info(\"Could not delete file \" + gcs_filename)\n    logging.info(\"Created file \" + gcs_filename)\n\n\ndef make_csv_filename(assignment, infotype):\n    \"\"\" Returns filename of format INFOTYPE_COURSE_ASSIGNMENT.csv \"\"\"\n    course_name = assignment.course.get().offering\n    assign_name = assignment.display_name\n    filename = '{}_{}_{}.csv'.format(infotype, course_name, assign_name)\n    return filename.replace('/', '_').replace(' ', '_')\n\ndef paginate(entries, page, num_per_page):\n    \"\"\"\n    Added stuff from\n    https://p.ota.to/blog/2013/4/pagination-with-cursors-\n        in-the-app-engine-datastore/\n\n    Support pagination for an NDB query.\n    Arguments:\n      |entries| - a query which returns the items to paginate over.\n      |cursor|  - a cursor of where in the pagination the user is.\n      |num_per_page| - the number of results to display per page.\n\n    The return value will be different from a regular query:\n    There will be 3 things returned:\n    - results: a list of results\n    - forward_curs: a urlsafe hash for the cursor. Use this to get\n    the next page. To retrieve the cursor object, do Cursor(urlsafe=s)\n    - more: a boolean for whether or not there is more content.\n\n    For more documentation, look at:\n    https://developers.google.com/appengine/docs/python/ndb/queryclass#Query_fetch_page\n    \"\"\"\n    if num_per_page is None:\n        return {\n            'results': entries.fetch(),\n            'page': 1,\n            'more': False\n        }\n\n    query_serialized = (\n        '_'.join(str(x) for x in (\n            entries.kind, entries.filters, entries.orders)))\n    query_serialized = query_serialized.replace(' ', '_')\n    def get_mem_key(page):\n        offset = (page - 1) * num_per_page\n        return \"cp_%s_%s\" % (query_serialized, offset)\n    this_page_key = get_mem_key(page)\n    next_page_key = get_mem_key(page + 1)\n\n    cursor = None\n    store_cache = True\n    if page > 1:\n        cursor = memcache.get(this_page_key)\n        if not cursor:\n            page = 1 # Reset to the front, since memcached failed\n            store_cache = False\n\n    pages_to_fetch = int(num_per_page)\n    if cursor is not None:\n        results, forward_cursor, more = entries.fetch_page(\n            pages_to_fetch, start_cursor=cursor)\n    else:\n        results, forward_cursor, more = entries.fetch_page(pages_to_fetch)\n\n    if store_cache:\n        memcache.set(next_page_key, forward_cursor)\n\n    return {\n        'results': results,\n        'page': page,\n        'more': more\n    }\n\n\ndef _apply_filter(query, model, arg, value, op):\n    \"\"\"\n    Applies a filter on |model| of |arg| |op| |value| to |query|.\n    \"\"\"\n    if '.' in arg:\n        arg = arg.split('.')\n    else:\n        arg = [arg]\n\n    field = model\n    while arg:\n        field = getattr(field, arg.pop(0), None)\n        if not field:\n            # Silently swallow for now\n            # TODO(martinis) cause an error\n            return query\n\n    if op == \"==\":\n        filtered = field == value\n    elif op == \"<\":\n        filtered = field < value\n    elif op == \"<=\":\n        filtered = field <= value\n    elif op == \">\":\n        filtered = field > value\n    elif op == \">=\":\n        filtered = field >= value\n    else:\n        raise ValueError(\"Invalid filtering operator {}\".format(op))\n\n    return query.filter(filtered)\n\ndef filter_query(query, args, model):\n    \"\"\"\n    Applies the filters in |args| to |query|.\n    |args| is a dictionary of key to value, to be used to filter the query.\n    |allowed| is an optional list of the allowed filters.\n\n    Returns a modified query with the appropriate filters.\n    \"\"\"\n    for arg, value in args.iteritems():\n        if (isinstance(value, collections.Iterable)\n                and not isinstance(value, str)):\n            op, value = value\n        else:\n            value, op = value, '=='\n\n        query = _apply_filter(query, model, arg, value, op)\n\n    return query\n\n\n####################\n# Deferred actions #\n####################\n\nASSIGN_BATCH_SIZE = 20\n\n# TODO: This code is used for seeding but not in the API.\ndef add_to_grading_queues(assign_key, cursor=None, num_updated=0):\n    query = ModelProxy.FinalSubmission.query().filter(\n        ModelProxy.FinalSubmission.assignment == assign_key)\n\n    queues = list(ModelProxy.Queue.query(\n        ModelProxy.Queue.assignment == assign_key))\n    if not queues:\n        logging.error(\"Tried to assign work, but no queues existed\")\n        return\n\n    kwargs = {}\n\n    if cursor:\n        kwargs['start_cursor'] = cursor\n\n    to_put = 0\n    results, cursor, _ = query.fetch_page(ASSIGN_BATCH_SIZE, **kwargs)\n    seen = set()\n    for queue in queues:\n        for subm in queue.submissions:\n            if isinstance(subm, ndb.Key):\n                seen.add(subm.get().submitter.id())\n            else:\n                seen.add(subm.submitter.id())\n\n    for subm in results:\n        user = subm.submitter.get()\n        if not user.logged_in or user.key.id() in seen:\n            continue\n        queues.sort(key=lambda x: len(x.submissions))\n\n        final_subm = user.get_final_submission(assign_key)\n        if final_subm:\n            subm = final_subm.submission.get()\n            if final_subm.backup.get_messages().get('file_contents'):\n                queues[0].submissions.append(subm)\n                seen.add(user.key.id())\n                to_put += 1\n\n    if to_put:\n        num_updated += to_put\n        ndb.put_multi(queues)\n        logging.debug(\n            'Put %d entities to Datastore for a total of %d',\n            to_put, num_updated)\n        deferred.defer(\n            add_to_grading_queues, assign_key, cursor=cursor,\n            num_updated=num_updated)\n    else:\n        logging.debug(\n            'add_to_grading_queues complete with %d updates!', num_updated)\n\ndef assign_staff_to_queues(assignment_key, staff_list):\n        subms = ModelProxy.FinalSubmission.query(\n            ModelProxy.FinalSubmission.assignment == assignment_key\n        ).fetch()\n\n        queues = []\n\n        for instr in staff_list:\n            q = ModelProxy.Queue.query(\n                ModelProxy.Queue.owner == instr.key,\n                ModelProxy.Queue.assignment == assignment_key).get()\n            if not q:\n                q = ModelProxy.Queue(\n                    owner=instr.key,\n                    assignment=assignment_key,\n                    assigned_staff=[instr.key])\n                q.put()\n            queues.append(q)\n\n        i = 0\n\n        for subm in subms:\n            subm.queue = queues[i].key\n            subm.put()\n            i = (i + 1) % len(staff_list)\n\n        logging.debug(\n            'assign_staff_to_queues complete with %d updates!', len(subms))\n\ndef assign_submission(backup_id, submit, revision=False):\n    \"\"\"\n    Create Submisson and FinalSubmission records for a submitted Backup.\n\n    :param backup_id: ID of a Backup\n    :param submit: Whether this backup is a submission to be graded\n    \"\"\"\n    backup = ModelProxy.Backup.get_by_id(backup_id)\n    if not backup.get_messages().get('file_contents'):\n        logging.info(\"Submission had no file_contents; not processing\")\n        return\n\n    if submit:\n        assign = backup.assignment.get_async()\n        subm = ModelProxy.Submission(backup=backup.key, is_revision=revision)\n        subm.put()\n\n        # Can only make a final submission before it's due, or if it's revision\n        if datetime.datetime.now() < assign.get_result().due_date:\n            subm.mark_as_final()\n        elif revision:\n            # Mark as final handles changing revision attribute.\n            subm.mark_as_final()\n\ndef sort_by_assignment(key_func, entries):\n    entries = sorted(entries, key=key_func)\n    return itertools.groupby(entries, key_func)\n\n@ndb.toplevel\ndef merge_user(user_key, dup_user_key):\n    \"\"\"\n    Merges |dup_user| into |user|.\n    \"\"\"\n    if isinstance(user_key, ModelProxy.Base):\n        user = user_key\n        user_key = user_key.key\n        get_user = lambda: user\n    else:\n        user = user_key.get_async()\n        def get_user():\n            return user.get_result()\n\n    if isinstance(dup_user_key, ModelProxy.Base):\n        dup_user = dup_user_key\n        get_dup_user = lambda: dup_user\n        dup_user_key = dup_user_key.key\n    else:\n        dup_user = dup_user_key.get_async()\n        def get_dup_user():\n            return dup_user.get_result()\n\n    # Leave all groups\n    G = ModelProxy.Group\n    groups = G.query(ndb.OR(\n        G.member == dup_user_key,\n        G.invited == dup_user_key)).fetch()\n    for group in groups:\n        group.exit(dup_user_key)\n\n    # Deactivate all enrollments\n    E = ModelProxy.Participant\n    enrolls = E.query(E.user == dup_user_key).fetch()\n    for enroll in enrolls:\n        # enroll.status = 'inactive'\n        enroll.put_async()\n\n    # Re-submit submissions\n    S = ModelProxy.Submission\n    subms = S.query(S.submitter == dup_user_key).fetch()\n    for subm in subms:\n        subm.resubmit(user_key)\n\n    dup_user = get_dup_user()\n    # Change email\n\n    user = get_user()\n    lowered_emails = [email.lower() for email in user.email]\n    for email in dup_user.email:\n        if email.lower() not in lowered_emails:\n            user.email.append(email.lower())\n\n    # Invalidate emails\n    dup_user.email = ['#'+email for email in dup_user.email]\n    # dup_user.status = 'inactive'\n    dup_user.put_async()\n    user.put_async()\n\n    log = ModelProxy.AuditLog()\n    log.event_type = \"Merge user\"\n    log.user = user_key\n    log.description = \"Merged user {} with {}. Merged emails {}\".format(\n        dup_user_key.id(), user_key.id(), dup_user.email)\n    log.obj = dup_user_key\n    log.put_async()\n\ndef unique_email_address(user):\n    U = ModelProxy.User\n\n    dups = []\n    for email in user.email:\n        users = U.query(U.email == email).fetch()\n        for found_user in users:\n            if found_user.key != user.key:\n                dups.append((user, found_user))\n\n    for usera, userb in dups:\n        if usera.email[0].lower() != usera.email[0]:\n            user, dup_user = usera, userb\n        else:\n            user, dup_user = userb, usera\n\n        merge_user(user, dup_user)\n\ndef unique_final_submission(user):\n    FS = ModelProxy.FinalSubmission\n\n    key_func = lambda subm: subm.assignment\n    submissions = FS.query(FS.submitter == user.key).fetch()\n    for lst in sort_by_assignment(key_func, submissions):\n        if len(lst) > 1:\n            lst = sorted(lst, key=lambda subm: subm.server_time)[1:]\n            for subm in lst:\n                subm.key.delete()\n\ndef unique_group(user):\n    G = ModelProxy.Group\n    key_func = lambda group: group.assignment\n    groups = G.query(G.member == user.key).fetch()\n    for lst in sort_by_assignment(key_func, groups):\n        if len(lst) > 1:\n            # TODO(martinis, denero) figure out what to do\n            pass\n\ndef deferred_check_user(user_id):\n    user = ModelProxy.User.get_by_id(user_id)\n    if not user:\n        raise deferred.PermanentTaskFailure(\"User id {} is invalid.\".format(user_id))\n\n    unique_email_address(user)\n    unique_final_submission(user)\n    unique_group(user)\n\n\ndef check_user(user_key):\n    if isinstance(user_key, ModelProxy.User):\n        user_key = user_key.key.id()\n\n    if isinstance(user_key, ndb.Key):\n        user_key = user_key.id()\n\n    deferred.defer(deferred_check_user, user_key)\n\n\ndef scores_to_gcs(assignment, user):\n    \"\"\" Writes all final submission scores\n    for the given assignment to GCS csv file. \"\"\"\n    content = data_for_scores(assignment, user)\n    csv_contents = create_csv_content(content)\n    assign_name = assignment.name\n    # Not sure what this line was doing here.\n    # create_gcs_file(assignment, csv_contents, 'scores')\n    csv_filename = '/{}/{}'.format(GRADES_BUCKET, make_csv_filename(assignment, 'scores'))\n    create_gcs_file(csv_filename, csv_contents, 'text/csv')\n\n\ndef add_subm_to_zip(subm, zipfile, submission):\n    \"\"\" Adds submission contents to a zipfile in-place, returns zipfile \"\"\"\n    try:\n        if isinstance(submission, ModelProxy.FinalSubmission):\n            # Get the actual submission\n            submission = submission.submission.get()\n        backup = submission.backup.get()\n        name, file_contents = subm.data_for_zip(backup)\n        return add_to_zip(zipfile, file_contents, name)\n    except BadValueError as e:\n        if str(e) != 'Submission has no contents to download':\n            raise e\n\n\ndef add_to_file_contents(file_contents, file_name, file_content):\n    \"\"\" add a file to file_contents \"\"\"\n    file_contents[file_name] = file_content\n\n# TODO(Alvin): generalize, cleanup everything about zip\ndef backup_group_file(backup, json_pretty={}):\n    \"\"\" Returns group information: group_[group ID], group JSON \"\"\"\n    G = ModelProxy.Group\n    group = G.lookup(backup.submitter, backup.assignment)\n    if group:\n        json_data = group.to_json()\n        # use chr(97+i) to convert numbers to letters\n        # 97+i converts 0, 1, 2, 3 to ascii codes corresponding to a, b, c...\n        # chr converts ascii code to an ascii char\n        order = {i: u['email'][0]\n                 for i, u in enumerate(json_data['member'])}\n        return (\n            ('group_members_%s.json' % group.key.id(),\n             str(json.dumps(order, **json_pretty))),\n            ('group_meta_%s.json' % group.key.id(),\n             str(json.dumps(json_data, **json_pretty)))\n        )\n\n\ndef make_zip_filename(user, now):\n    \"\"\" Makes zip filename: query_USER EMAIL_DATETIME.zip \"\"\"\n    outlawed = [' ', '.', ':', '/', '@']\n    filename = '%s_%s_%s' % (\n        'query',\n        user.email[0],\n        str(now))\n    for outlaw in outlawed:\n        filename = filename.replace(outlaw, '-')\n    filename = '/{}/{}'.format(\n        GRADES_BUCKET,\n        filename)\n    return filename+'.zip'\n\n\ndef subms_to_gcs(SearchAPI, subm, filename, data):\n    \"\"\"Writes all submissions for a given search query to a GCS zip file.\"\"\"\n    query = SearchAPI.querify(data['query'])\n    gcs_file = gcs.open(filename, 'w',\n        content_type='application/zip',\n        options={'x-goog-acl': 'project-private'})\n    with contextlib.closing(gcs_file) as f:\n        with zf.ZipFile(f, 'w') as zipfile:\n            for result in query:\n                add_subm_to_zip(subm, zipfile, result)\n    logging.info(\"Exported submissions to \" + filename)\n\ndef submit_to_ag(assignment, messages, submitter):\n    if 'file_contents' not in messages:\n        return\n    email = submitter.email[0]\n    data = {\n        'assignment': assignment.autograding_key,\n        'file_contents': messages['file_contents'],\n        'submitter': email\n    }\n    # Ensure user is enrolled.\n    enrollment = ModelProxy.Participant.query(\n        ModelProxy.Participant.course == assignment.course,\n        ModelProxy.Participant.user == submitter.key).get()\n\n    if not enrollment:\n        raise BadValueError('User is not enrolled and cannot be autograded.')\n    logging.info(\"Starting send to AG\")\n    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n    r = requests.post(AUTOGRADER_URL+'/api/file/grade/continous',\n        data=json.dumps(data), headers=headers)\n    if r.status_code == requests.codes.ok:\n        logging.info(\"Sent to Autograder\")\n        return {'status': \"pending\"}\n    else:\n        raise BadValueError('The autograder the rejected your request')\n\ndef autograde_subms(assignment, user, data, subm_ids, priority=\"default\"):\n    ag_data = {\n        'subm_ids': subm_ids,\n        'assignment': assignment.autograding_key,\n        'access_token': data['token'],\n        'priority': priority,\n        'testing': 'testing' in data and data['testing']\n    }\n\n    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n    r = requests.post(AUTOGRADER_URL+'/api/ok/grade/batch',\n        data=json.dumps(ag_data), headers=headers)\n    if r.status_code == requests.codes.ok:\n        # TODO: Contact staff (via email)\n      return {'status_url': AUTOGRADER_URL+'/rq', 'length': str(len(subm_ids))}\n    else:\n      raise BadValueError('The autograder the rejected your request')\n\ndef autograde_final_subs(assignment, user, data):\n    subm_ids = {}\n    fsubs = list(ModelProxy.FinalSubmission.query(\n                    ModelProxy.FinalSubmission.assignment == assignment.key))\n    for fsub in fsubs:\n      subm_ids[fsub.submission.id()] = fsub.submission.get().backup.id()\n    return autograde_subms(assignment, user, data, subm_ids)\n\ndef promote_student_backups(assignment, autograde=False, user=None, data=None):\n    \"\"\"\n    Find all students with no final submissions and make their latest backup into\n    a submission.\n\n    :param assignment - an assignment object\n    \"\"\"\n    enrollment = ModelProxy.Participant.query(\n        ModelProxy.Participant.course == assignment.course,\n        ModelProxy.Participant.role == STUDENT_ROLE).get()\n\n    newly_created_fs = []\n\n    for student in enrollment:\n        fs = student.get_final_submission(assignment)\n        if not fs:\n            recent_bck = student.get_backups(assignment.key, 1)\n            new_sub = force_promote_backup(recent_bck)\n            newly_created_fs.append(new_sub.id())\n\n    if autograde:\n        return autograde_subms(assignment, user, data, newly_created_fs)\n\n\ndef force_promote_backup(backup_id):\n    \"\"\"\n    Create Submisson and FinalSubmission records for a submitted Backup.\n    This ignores deadlines.\n\n    :param backup_id: ID of a Backup\n    \"\"\"\n    backup = ModelProxy.Backup.get_by_id(backup_id)\n    if not backup.get_messages().get('file_contents'):\n        logging.info(\"Submission had no file_contents; not processing\")\n        return\n\n    assign = backup.assignment.get_async()\n    subm = ModelProxy.Submission(backup=backup.key)\n    subm.put()\n    return subm.mark_as_final()\n\n\n\nimport difflib\n\ndiffer = difflib.Differ()\n\n\ndef diff(s1, s2):\n    lines1 = s1.split('\\n')\n    lines2 = s2.split('\\n')\n    return list(differ.compare(lines1, lines2))\n", "name": "server/app/utils.py", "coverage": [null, null, null, null, null, null, 1, 1, 1, 1, 1, 1, 1, 1, null, 1, 1, 0, 0, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, null, null, 1, 1, 1, 1, null, 1, null, 1, null, null, 1, 1, null, 1, 1, null, null, 1, 1, null, 1, null, null, null, 1, 1, 1, 1, null, 1, 1, 0, null, null, null, 1, null, null, 1, null, null, null, 1, null, null, 1, 1, null, null, 1, null, 1, 0, null, 1, null, null, null, null, 1, 1, null, null, 1, 1, null, null, 1, null, null, null, null, 1, 1, 1, 1, null, null, 1, 1, 1, null, null, 1, null, null, null, null, null, null, null, null, null, 1, null, null, 1, 1, null, 1, null, null, null, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, null, 1, null, null, null, null, 0, 0, 0, 0, null, 0, 0, 0, 0, null, 0, 0, 0, null, 0, null, 1, null, null, null, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, null, null, 1, null, 0, 0, 0, 0, null, 1, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 1, 0, null, null, null, null, null, 1, null, null, 1, 1, 1, 1, 1, 1, null, 1, 1, 1, 1, 1, 0, 0, null, 1, 1, 1, null, null, 1, null, 1, 1, null, 1, null, null, null, null, null, null, 1, null, null, null, 1, 0, null, 1, null, 1, 1, 1, 1, null, null, 1, null, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, null, 0, null, 1, null, 1, null, null, null, null, null, null, null, 1, 1, null, 1, null, 1, null, 1, null, 1, null, null, null, null, null, null, 1, null, null, 1, 0, null, null, 0, null, 0, 0, 0, null, 0, null, 0, 0, null, 0, 0, 0, 0, 0, 0, 0, null, 0, null, 0, 0, 0, 0, 0, null, 0, 0, 0, 0, 0, 0, 0, null, 0, 0, 0, 0, null, null, 0, null, null, null, 0, null, null, 1, 0, null, null, null, 0, null, 0, 0, null, null, 0, 0, null, null, null, 0, 0, null, 0, null, 0, 0, 0, 0, null, 0, null, null, 1, null, null, null, null, null, null, 1, 1, 0, 0, null, 1, 1, 1, 1, null, null, 1, 1, 1, null, 0, null, 1, 1, 1, null, 1, null, null, null, null, 1, 1, 1, 1, null, 1, 1, 1, null, 1, 1, 1, 1, null, 1, 1, 1, null, null, 1, 1, null, null, 1, 1, null, null, 1, 1, 1, null, 0, null, null, 1, 1, 1, 1, null, 1, null, null, 1, 1, 1, 1, 1, null, null, 1, null, 1, 1, null, 1, 1, 1, 1, null, 1, 1, null, 1, 1, null, 1, 1, 1, 1, 1, 0, null, 1, 0, 0, null, 0, null, 0, null, 1, 1, null, 1, 1, 1, 0, 0, 0, 0, null, 1, 1, 1, 1, 1, 0, null, null, null, 1, 1, 1, 0, null, 1, 1, 1, null, null, 1, 0, 0, null, 0, 0, null, 0, null, null, 1, null, null, 0, 0, 0, null, null, 0, 0, null, null, 1, null, 1, 1, null, 0, 1, 1, 0, 1, 1, 0, null, null, 1, null, 1, null, null, 1, null, 1, 1, 1, 0, null, null, null, 0, null, 0, null, null, null, null, null, null, null, 1, null, 1, 1, null, null, null, 1, 1, 1, null, null, 1, null, null, 1, null, 0, 0, null, null, 0, 0, 0, 0, 0, null, 1, 0, 0, 0, 0, null, null, null, null, null, 0, null, null, null, 0, 0, 0, 0, 0, null, 0, 0, 0, null, 0, null, 1, 1, null, null, null, null, null, null, null, 1, 1, null, 1, null, 1, null, 1, null, 1, 1, 1, null, 1, 1, 1, null, 1, null, null, null, null, null, null, 0, null, null, null, 0, null, 0, 0, 0, 0, 0, 0, null, 0, 0, null, null, 1, null, null, null, null, null, null, 0, 0, 0, 0, null, 0, 0, 0, 0, null, null, null, 1, null, 1, null, null, 1, 1, 1, 1, null]}]}
==
Reporting 14 files
==

server/app/analytics/job.py - 100/148
server/app/analytics/jobs/sample_job.py - 6/11
server/app/analytics/mapper.py - 58/124
server/app/api.py - 810/2095
server/app/auth.py - 25/38
server/app/authenticator.py - 17/53
server/app/constants.py - 8/13
server/app/exceptions.py - 30/61
server/app/models.py - 716/1293
server/app/needs.py - 18/28
server/app/secret_keys.py - 2/5
server/app/settings.py - 19/46
server/app/urls.py - 160/240
server/app/utils.py - 237/732
travis_time:end:071f6c58:start=1446882926189930166,finish=1446882926835643667,duration=645713501[0Ktravis_fold:end:after_success.2[0K
Done. Your build exited with 0.
