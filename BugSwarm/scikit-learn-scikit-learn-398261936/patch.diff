diff --git a/.travis.yml b/.travis.yml
index ae33461500..92363f82ad 100755
--- a/.travis.yml
+++ b/.travis.yml
@@ -57,7 +57,7 @@ matrix:
     # interpreter provided by travis.
     -  python: 3.6
        env: DISTRIB="scipy-dev"
-       if: type = cron OR commit_message ~ /\[scipy-dev\]/
+       if: type = cron OR commit_message =~ /\[scipy-dev\]/
 
 install: source build_tools/travis/install.sh
 script: bash build_tools/travis/test_script.sh
diff --git a/appveyor.yml b/appveyor.yml
index e0989fda8b..1a44e2d79d 100755
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -17,20 +17,20 @@ environment:
     SKLEARN_SKIP_NETWORK_TESTS: 1
 
   matrix:
-    - PYTHON: "C:\\Python27"
-      PYTHON_VERSION: "2.7.8"
+    - PYTHON: "C:\\Python37"
+      PYTHON_VERSION: "3.7.0"
       PYTHON_ARCH: "32"
 
-    - PYTHON: "C:\\Python27-x64"
-      PYTHON_VERSION: "2.7.8"
+    - PYTHON: "C:\\Python37-x64"
+      PYTHON_VERSION: "3.7.0"
       PYTHON_ARCH: "64"
 
-    - PYTHON: "C:\\Python36"
-      PYTHON_VERSION: "3.6.1"
+    - PYTHON: "C:\\Python27"
+      PYTHON_VERSION: "2.7.8"
       PYTHON_ARCH: "32"
 
-    - PYTHON: "C:\\Python36-x64"
-      PYTHON_VERSION: "3.6.1"
+    - PYTHON: "C:\\Python27-x64"
+      PYTHON_VERSION: "2.7.8"
       PYTHON_ARCH: "64"
 
 
@@ -90,9 +90,7 @@ artifacts:
 
 on_success:
   # Upload the generated wheel package to Rackspace
-  # On Windows, Apache Libcloud cannot find a standard CA cert bundle so we
-  # disable the ssl checks.
-  - "python -m wheelhouse_uploader upload --no-ssl-check --local-folder=dist sklearn-windows-wheels"
+  - "python -m wheelhouse_uploader upload --local-folder=dist sklearn-windows-wheels"
 
 notifications:
   - provider: Webhook
diff --git a/build_tools/appveyor/requirements.txt b/build_tools/appveyor/requirements.txt
index 35c772b52d..6cd6f13928 100755
--- a/build_tools/appveyor/requirements.txt
+++ b/build_tools/appveyor/requirements.txt
@@ -1,15 +1,7 @@
-# Fetch numpy and scipy wheels from the sklearn rackspace wheelhouse.
-# Those wheels were collected from https://www.lfd.uci.edu/~gohlke/pythonlibs/
-# This is a temporary solution. As soon as numpy and scipy provide official
-# wheel for windows we ca delete this --find-links line.
---find-links http://28daf2247a33ed269873-7b1aad3fab3cc330e1fd9d109892382a.r6.cf2.rackcdn.com/
-
-# fix the versions of numpy to force the use of numpy and scipy to use the whl
-# of the rackspace folder instead of trying to install from more recent
-# source tarball published on PyPI
-numpy==1.13.0
-scipy==0.19.0
-cython
+numpy
+scipy
+# Pin Cython to avoid bug with 0.28.x on Python 3.7 
+cython==0.27.3
 pytest
 wheel
 wheelhouse_uploader
diff --git a/build_tools/circle/build_doc.sh b/build_tools/circle/build_doc.sh
index 86231f8de4..e290b8ca93 100755
--- a/build_tools/circle/build_doc.sh
+++ b/build_tools/circle/build_doc.sh
@@ -92,6 +92,8 @@ else
     make_args=html
 fi
 
+make_args="SPHINXOPTS=-T $make_args"  # show full traceback on exception
+
 # Installing required system packages to support the rendering of math
 # notation in the HTML documentation
 sudo -E apt-get -yq update
diff --git a/build_tools/travis/install.sh b/build_tools/travis/install.sh
index 6083132ddf..2b03f4a980 100755
--- a/build_tools/travis/install.sh
+++ b/build_tools/travis/install.sh
@@ -89,6 +89,9 @@ elif [[ "$DISTRIB" == "scipy-dev" ]]; then
     echo "Installing numpy and scipy master wheels"
     dev_url=https://7933911d6844c6c53a7d-47bd50c35cd79bd838daf386af554a83.ssl.cf2.rackcdn.com
     pip install --pre --upgrade --timeout=60 -f $dev_url numpy scipy pandas cython
+    echo "Installing joblib master"
+    pip install https://github.com/joblib/joblib/archive/master.zip
+    export SKLEARN_SITE_JOBLIB=1
     pip install pytest pytest-cov
 fi
 
diff --git a/doc/datasets/index.rst b/doc/datasets/index.rst
index 73ab66fece..d8eabfaabd 100755
--- a/doc/datasets/index.rst
+++ b/doc/datasets/index.rst
@@ -9,49 +9,60 @@ Dataset loading utilities
 The ``sklearn.datasets`` package embeds some small toy datasets
 as introduced in the :ref:`Getting Started <loading_example_dataset>` section.
 
+This package also features helpers to fetch larger datasets commonly
+used by the machine learning community to benchmark algorithms on data
+that comes from the 'real world'.
+
 To evaluate the impact of the scale of the dataset (``n_samples`` and
 ``n_features``) while controlling the statistical properties of the data
 (typically the correlation and informativeness of the features), it is
 also possible to generate synthetic data.
 
-This package also features helpers to fetch larger datasets commonly
-used by the machine learning community to benchmark algorithm on data
-that comes from the 'real world'.
-
 General dataset API
 ===================
 
-There are three distinct kinds of dataset interfaces for different types
-of datasets.
-The simplest one is the interface for sample images, which is described
-below in the :ref:`sample_images` section.
+There are three main kinds of dataset interfaces that can be used to get 
+datasets depending on the desired type of dataset.
+  
+**The dataset loaders.** They can be used to load small standard datasets, 
+described in the :ref:`toy_datasets` section.  
+
+**The dataset fetchers.** They can be used to download and load larger datasets,
+described in the :ref:`real_world_datasets` section.
 
-The dataset generation functions and the svmlight loader share a simplistic
-interface, returning a tuple ``(X, y)`` consisting of a ``n_samples`` *
+Both loaders and fetchers functions return a dictionary-like object holding 
+at least two items: an array of shape ``n_samples`` * ``n_features`` with 
+key ``data`` (except for 20newsgroups) and a numpy array of 
+length ``n_samples``, containing the target values, with key ``target``.
+
+It's also possible for almost all of these function to constrain the output
+to be a tuple containing only the data and the target, by setting the 
+``return_X_y`` parameter to ``True``.
+
+The datasets also contain a full description in their ``DESCR`` attribute and 
+some contain ``feature_names`` and ``target_names``. See the dataset 
+descriptions below for details.  
+
+**The dataset generation functions.** They can be used to generate controlled 
+synthetic datasets, described in the :ref:`generated_datasets` section.
+
+These functions return a tuple ``(X, y)`` consisting of a ``n_samples`` *
 ``n_features`` numpy array ``X`` and an array of length ``n_samples``
 containing the targets ``y``.
 
-The toy datasets as well as the 'real world' datasets and the datasets
-fetched from mldata.org have more sophisticated structure.
-These functions return a dictionary-like object holding at least two items:
-an array of shape ``n_samples`` * ``n_features`` with key ``data``
-(except for 20newsgroups)
-and a numpy array of length ``n_samples``, containing the target values,
-with key ``target``.
-
-The datasets also contain a description in ``DESCR`` and some contain
-``feature_names`` and ``target_names``.
-See the dataset descriptions below for details.
+In addition, there are also miscellanous tools to load datasets of other 
+formats or from other locations, described in the :ref:`loading_other_datasets`
+section. 
 
 .. _toy_datasets:
 
 Toy datasets
 ============
 
-scikit-learn comes with a few small standard datasets that do not
-require to download any file from some external website. 
+scikit-learn comes with a few small standard datasets that do not require to 
+download any file from some external website. 
 
-*desc*
+They can be loaded using the following functions:
 
 .. autosummary::
 
@@ -101,7 +112,10 @@ small to be representative of real world machine learning tasks.
 Real world datasets
 ===================
 
-*Add desc*
+scikit-learn provides tools to load larger datasets, downloading them if
+necessary.
+
+They can be loaded using the following functions:
 
 .. autosummary::
 
@@ -117,7 +131,6 @@ Real world datasets
    fetch_rcv1
    fetch_kddcup99
 
-
 .. toctree::
     :maxdepth: 2
     :hidden:
diff --git a/doc/developers/contributing.rst b/doc/developers/contributing.rst
index 8012b6eecb..9c20363485 100755
--- a/doc/developers/contributing.rst
+++ b/doc/developers/contributing.rst
@@ -916,41 +916,41 @@ multiple interfaces):
 
     The base object, implements a ``fit`` method to learn from data, either::
 
-      estimator = obj.fit(data, targets)
+      estimator = estimator.fit(data, targets)
 
     or::
 
-      estimator = obj.fit(data)
+      estimator = estimator.fit(data)
 
 :Predictor:
 
     For supervised learning, or some unsupervised problems, implements::
 
-      prediction = obj.predict(data)
+      prediction = predictor.predict(data)
 
     Classification algorithms usually also offer a way to quantify certainty
     of a prediction, either using ``decision_function`` or ``predict_proba``::
 
-      probability = obj.predict_proba(data)
+      probability = predictor.predict_proba(data)
 
 :Transformer:
 
     For filtering or modifying the data, in a supervised or unsupervised
     way, implements::
 
-      new_data = obj.transform(data)
+      new_data = transformer.transform(data)
 
     When fitting and transforming can be performed much more efficiently
     together than separately, implements::
 
-      new_data = obj.fit_transform(data)
+      new_data = transformer.fit_transform(data)
 
 :Model:
 
     A model that can give a `goodness of fit <https://en.wikipedia.org/wiki/Goodness_of_fit>`_
     measure or a likelihood of unseen data, implements (higher is better)::
 
-      score = obj.score(data)
+      score = model.score(data)
 
 Estimators
 ----------
diff --git a/doc/developers/tips.rst b/doc/developers/tips.rst
index 2334bd7697..1388edd441 100755
--- a/doc/developers/tips.rst
+++ b/doc/developers/tips.rst
@@ -79,7 +79,7 @@ to select tests based on their name. For instance,::
 
 will run all :term:`common tests` for the ``LogisticRegression`` estimator.
 
-When a unit tests fail, the following tricks can make debugging easier:
+When a unit test fails, the following tricks can make debugging easier:
 
   1. The command line argument ``pytest -l`` instructs pytest to print the local
      variables when a failure occurs.
diff --git a/doc/glossary.rst b/doc/glossary.rst
index f2f1767133..cea07ed1a5 100755
--- a/doc/glossary.rst
+++ b/doc/glossary.rst
@@ -202,7 +202,7 @@ General Concepts
         We use deprecation to slowly violate our :term:`backwards
         compatibility` assurances, usually to to:
 
-        * change the the default value of a parameter; or
+        * change the default value of a parameter; or
         * remove a parameter, attribute, method, class, etc.
 
         We will ordinarily issue a warning when a deprecated element is used,
@@ -289,6 +289,13 @@ General Concepts
           support for some feature, we use :term:`estimator tags` instead of
           duck typing.
 
+    early stopping
+        This consists in stopping an iterative optimization method before the
+        convergence of the training loss, to avoid over-fitting. This is
+        generally done by monitoring the generalization score on a validation
+        set. When available, it is activated through the parameter
+        ``early_stopping`` or by setting a postive :term:`n_iter_no_change`.
+
     estimator instance
         We sometimes use this terminology to distinguish an :term:`estimator`
         class from a constructed instance. For example, in the following,
@@ -457,7 +464,8 @@ General Concepts
         A Python library (http://joblib.readthedocs.io) used in Scikit-learn to
         facilite simple parallelism and caching.  Joblib is oriented towards
         efficiently working with numpy arrays, such as through use of
-        :term:`memory mapping`.
+        :term:`memory mapping`. See :ref:`parallelism` for more
+        information.
 
     label indicator matrix
     multilabel indicator matrix
@@ -1453,6 +1461,12 @@ functions or non-estimator constructors.
         input into. See :term:`components_` for the special case of affine
         projection.
 
+    ``n_iter_no_change``
+        Number of iterations with no improvement to wait before stopping the
+        iterative procedure. This is also known as a *patience* parameter. It
+        is typically used with :term:`early stopping` to avoid stopping too
+        early.
+
     ``n_jobs``
         This is used to specify how many concurrent processes/threads should be
         used for parallelized routines.  Scikit-learn uses one processor for
diff --git a/doc/modules/computational_performance.rst b/doc/modules/computing.rst
similarity index 63%
rename from doc/modules/computational_performance.rst
rename to doc/modules/computing.rst
index ca128c515f..6c28bd3385 100755
--- a/doc/modules/computational_performance.rst
+++ b/doc/modules/computing.rst
@@ -1,6 +1,145 @@
+============================
+Computing with scikit-learn
+============================
+
+.. _scaling_strategies:
+
+Strategies to scale computationally: bigger data
+=================================================
+
+For some applications the amount of examples, features (or both) and/or the
+speed at which they need to be processed are challenging for traditional
+approaches. In these cases scikit-learn has a number of options you can
+consider to make your system scale.
+
+Scaling with instances using out-of-core learning
+--------------------------------------------------
+
+Out-of-core (or "external memory") learning is a technique used to learn from
+data that cannot fit in a computer's main memory (RAM).
+
+Here is a sketch of a system designed to achieve this goal:
+
+  1. a way to stream instances
+  2. a way to extract features from instances
+  3. an incremental algorithm
+
+Streaming instances
+....................
+
+Basically, 1. may be a reader that yields instances from files on a
+hard drive, a database, from a network stream etc. However,
+details on how to achieve this are beyond the scope of this documentation.
+
+Extracting features
+...................
+
+\2. could be any relevant way to extract features among the
+different :ref:`feature extraction <feature_extraction>` methods supported by
+scikit-learn. However, when working with data that needs vectorization and
+where the set of features or values is not known in advance one should take
+explicit care. A good example is text classification where unknown terms are
+likely to be found during training. It is possible to use a stateful
+vectorizer if making multiple passes over the data is reasonable from an
+application point of view. Otherwise, one can turn up the difficulty by using
+a stateless feature extractor. Currently the preferred way to do this is to
+use the so-called :ref:`hashing trick<feature_hashing>` as implemented by
+:class:`sklearn.feature_extraction.FeatureHasher` for datasets with categorical
+variables represented as list of Python dicts or
+:class:`sklearn.feature_extraction.text.HashingVectorizer` for text documents.
+
+Incremental learning
+.....................
+
+Finally, for 3. we have a number of options inside scikit-learn. Although not
+all algorithms can learn incrementally (i.e. without seeing all the instances
+at once), all estimators implementing the ``partial_fit`` API are candidates.
+Actually, the ability to learn incrementally from a mini-batch of instances
+(sometimes called "online learning") is key to out-of-core learning as it
+guarantees that at any given time there will be only a small amount of
+instances in the main memory. Choosing a good size for the mini-batch that
+balances relevancy and memory footprint could involve some tuning [1]_.
+
+Here is a list of incremental estimators for different tasks:
+
+  - Classification
+      + :class:`sklearn.naive_bayes.MultinomialNB`
+      + :class:`sklearn.naive_bayes.BernoulliNB`
+      + :class:`sklearn.linear_model.Perceptron`
+      + :class:`sklearn.linear_model.SGDClassifier`
+      + :class:`sklearn.linear_model.PassiveAggressiveClassifier`
+      + :class:`sklearn.neural_network.MLPClassifier`
+  - Regression
+      + :class:`sklearn.linear_model.SGDRegressor`
+      + :class:`sklearn.linear_model.PassiveAggressiveRegressor`
+      + :class:`sklearn.neural_network.MLPRegressor`
+  - Clustering
+      + :class:`sklearn.cluster.MiniBatchKMeans`
+      + :class:`sklearn.cluster.Birch`
+  - Decomposition / feature Extraction
+      + :class:`sklearn.decomposition.MiniBatchDictionaryLearning`
+      + :class:`sklearn.decomposition.IncrementalPCA`
+      + :class:`sklearn.decomposition.LatentDirichletAllocation`
+  - Preprocessing
+      + :class:`sklearn.preprocessing.StandardScaler`
+      + :class:`sklearn.preprocessing.MinMaxScaler`
+      + :class:`sklearn.preprocessing.MaxAbsScaler`
+
+For classification, a somewhat important thing to note is that although a
+stateless feature extraction routine may be able to cope with new/unseen
+attributes, the incremental learner itself may be unable to cope with
+new/unseen targets classes. In this case you have to pass all the possible
+classes to the first ``partial_fit`` call using the ``classes=`` parameter.
+
+Another aspect to consider when choosing a proper algorithm is that not all of
+them put the same importance on each example over time. Namely, the
+``Perceptron`` is still sensitive to badly labeled examples even after many
+examples whereas the ``SGD*`` and ``PassiveAggressive*`` families are more
+robust to this kind of artifacts. Conversely, the latter also tend to give less
+importance to remarkably different, yet properly labeled examples when they
+come late in the stream as their learning rate decreases over time.
+
+Examples
+..........
+
+Finally, we have a full-fledged example of
+:ref:`sphx_glr_auto_examples_applications_plot_out_of_core_classification.py`. It is aimed at
+providing a starting point for people wanting to build out-of-core learning
+systems and demonstrates most of the notions discussed above.
+
+Furthermore, it also shows the evolution of the performance of different
+algorithms with the number of processed examples.
+
+.. |accuracy_over_time| image::  ../auto_examples/applications/images/sphx_glr_plot_out_of_core_classification_001.png
+    :target: ../auto_examples/applications/plot_out_of_core_classification.html
+    :scale: 80
+
+.. centered:: |accuracy_over_time|
+
+Now looking at the computation time of the different parts, we see that the
+vectorization is much more expensive than learning itself. From the different
+algorithms, ``MultinomialNB`` is the most expensive, but its overhead can be
+mitigated by increasing the size of the mini-batches (exercise: change
+``minibatch_size`` to 100 and 10000 in the program and compare).
+
+.. |computation_time| image::  ../auto_examples/applications/images/sphx_glr_plot_out_of_core_classification_003.png
+    :target: ../auto_examples/applications/plot_out_of_core_classification.html
+    :scale: 80
+
+.. centered:: |computation_time|
+
+
+Notes
+......
+
+.. [1] Depending on the algorithm the mini-batch size can influence results or
+       not. SGD*, PassiveAggressive*, and discrete NaiveBayes are truly online
+       and are not affected by batch size. Conversely, MiniBatchKMeans
+       convergence rate is affected by the batch size. Also, its memory
+       footprint can vary dramatically with batch size.
+
 .. _computational_performance:
 
-=========================
 Computational Performance
 =========================
 
@@ -27,7 +166,7 @@ non-linear, or with fewer parameters) often run faster but are not always able
 to take into account the same exact properties of the data as more complex ones.
 
 Prediction Latency
-==================
+------------------
 
 One of the most straight-forward concerns one may have when using/choosing a
 machine learning toolkit is the latency at which predictions can be made in a
@@ -43,7 +182,7 @@ A last major parameter is also the possibility to do predictions in bulk or
 one-at-a-time mode.
 
 Bulk versus Atomic mode
------------------------
+........................
 
 In general doing predictions in bulk (many instances at the same time) is
 more efficient for a number of reasons (branching predictability, CPU cache,
@@ -68,27 +207,28 @@ To benchmark different estimators for your case you can simply change the
 :ref:`sphx_glr_auto_examples_applications_plot_prediction_latency.py`. This should give
 you an estimate of the order of magnitude of the prediction latency.
 
-.. topic:: Configuring Scikit-learn for reduced validation overhead
+Configuring Scikit-learn for reduced validation overhead
+.........................................................
 
-    Scikit-learn does some validation on data that increases the overhead per
-    call to ``predict`` and similar functions. In particular, checking that
-    features are finite (not NaN or infinite) involves a full pass over the
-    data. If you ensure that your data is acceptable, you may suppress
-    checking for finiteness by setting the environment variable
-    ``SKLEARN_ASSUME_FINITE`` to a non-empty string before importing
-    scikit-learn, or configure it in Python with :func:`sklearn.set_config`.
-    For more control than these global settings, a :func:`config_context`
-    allows you to set this configuration within a specified context::
+Scikit-learn does some validation on data that increases the overhead per
+call to ``predict`` and similar functions. In particular, checking that
+features are finite (not NaN or infinite) involves a full pass over the
+data. If you ensure that your data is acceptable, you may suppress
+checking for finiteness by setting the environment variable
+``SKLEARN_ASSUME_FINITE`` to a non-empty string before importing
+scikit-learn, or configure it in Python with :func:`sklearn.set_config`.
+For more control than these global settings, a :func:`config_context`
+allows you to set this configuration within a specified context::
 
-      >>> import sklearn
-      >>> with sklearn.config_context(assume_finite=True):
-      ...    pass  # do learning/prediction here with reduced validation
+  >>> import sklearn
+  >>> with sklearn.config_context(assume_finite=True):
+  ...    pass  # do learning/prediction here with reduced validation
 
-    Note that this will affect all uses of
-    :func:`sklearn.utils.assert_all_finite` within the context.
+Note that this will affect all uses of
+:func:`sklearn.utils.assert_all_finite` within the context.
 
 Influence of the Number of Features
------------------------------------
+....................................
 
 Obviously when the number of features increases so does the memory
 consumption of each example. Indeed, for a matrix of :math:`M` instances
@@ -109,7 +249,7 @@ the number of features (non-linear cases can happen depending on the global
 memory footprint and estimator).
 
 Influence of the Input Data Representation
-------------------------------------------
+...........................................
 
 Scipy provides sparse matrix data structures which are optimized for storing
 sparse data. The main feature of sparse formats is that you don't store zeros
@@ -142,7 +282,7 @@ for more information on how to build (or convert your data to) sparse matrix
 formats. Most of the time the ``CSR`` and ``CSC`` formats work best.
 
 Influence of the Model Complexity
----------------------------------
+..................................
 
 Generally speaking, when model complexity increases, predictive power and
 latency are supposed to increase. Increasing predictive power is usually
@@ -152,7 +292,7 @@ families of supervised models.
 
 For :mod:`sklearn.linear_model` (e.g. Lasso, ElasticNet,
 SGDClassifier/Regressor, Ridge & RidgeClassifier,
-PassiveAgressiveClassifier/Regressor, LinearSVC, LogisticRegression...) the
+PassiveAggressiveClassifier/Regressor, LinearSVC, LogisticRegression...) the
 decision function that is applied at prediction time is the same (a dot product)
 , so latency should be equivalent.
 
@@ -206,7 +346,7 @@ with a speedy linear model but prediction power will very likely suffer in
 the process.
 
 Feature Extraction Latency
---------------------------
+..........................
 
 Most scikit-learn models are usually pretty fast as they are implemented
 either with compiled Cython extensions or optimized computing libraries.
@@ -229,7 +369,7 @@ feature extraction code as it may be a good place to start optimizing when
 your overall latency is too slow for your application.
 
 Prediction Throughput
-=====================
+----------------------
 
 Another important metric to care about when sizing production systems is the
 throughput i.e. the number of predictions you can make in a given amount of
@@ -252,10 +392,10 @@ explanation on how to achieve this is beyond the scope of this documentation
 though.
 
 Tips and Tricks
-===============
+----------------
 
 Linear algebra libraries
-------------------------
+.........................
 
 As scikit-learn relies heavily on Numpy/Scipy and linear algebra in general it
 makes sense to take explicit care of the versions of these libraries.
@@ -311,7 +451,7 @@ Debian / Ubuntu.
 .. _working_memory:
 
 Limiting Working Memory
------------------------
+........................
 
 Some calculations when implemented using standard numpy vectorized operations
 involve using a large amount of temporary memory.  This may potentially exhaust
@@ -330,7 +470,7 @@ An example of a chunked operation adhering to this setting is
 row-wise reductions of a pairwise distance matrix.
 
 Model Compression
------------------
+..................
 
 Model compression in scikit-learn only concerns linear models for the moment.
 In this context it means that we want to control the model sparsity (i.e. the
@@ -357,7 +497,7 @@ Furthermore, sparsifying can be very useful to reduce the memory usage of
 predictive models deployed on production servers.
 
 Model Reshaping
----------------
+................
 
 Model reshaping consists in selecting only a portion of the available features
 to fit a model. In other words, if a model discards features during the
@@ -376,7 +516,77 @@ In the case of sparse input (particularly in ``CSR`` format), it is generally
 sufficient to not generate the relevant features, leaving their columns empty.
 
 Links
------
+......
 
   - `scikit-learn developer performance documentation <../developers/performance.html>`_
   - `Scipy sparse matrix formats documentation <http://docs.scipy.org/doc/scipy/reference/sparse.html>`_
+
+Parallelism, resource management, and configuration
+=====================================================
+
+.. _parallelism:
+
+Parallel and distributed computing
+-----------------------------------
+
+Scikit-learn uses the `joblib <https://joblib.readthedocs.io/en/latest/>`__
+library to enable parallel computing inside its estimators. See the
+joblib documentation for the switches to control parallel computing.
+
+Note that, by default, scikit-learn uses its embedded (vendored) version
+of joblib. A configuration switch (documented below) controls this
+behavior.
+
+Configuration switches
+-----------------------
+
+Python runtime
+..............
+
+:func:`sklearn.set_config` controls the following behaviors:
+
+:assume_finite:
+
+    used to skip validation, which enables faster computations but may
+    lead to segmentation faults if the data contains NaNs.
+
+:working_memory:
+
+    the optimal size of temporary arrays used by some algoritms.
+
+.. _environment_variable:
+
+Environment variables
+......................
+
+These environment variables should be set before importing scikit-learn.
+
+:SKLEARN_SITE_JOBLIB:
+
+    When this environment variable is set to a non zero value,
+    scikit-learn uses the site joblib rather than its vendored version.
+    Consequently, joblib must be installed for scikit-learn to run.
+    Note that using the site joblib is at your own risks: the versions of
+    scikt-learn and joblib need to be compatible. In addition, dumps from
+    joblib.Memory might be incompatible, and you might loose some caches
+    and have to redownload some datasets.
+
+:SKLEARN_ASSUME_FINITE:
+
+    Sets the default value for the `assume_finite` argument of
+    :func:`sklearn.set_config`.
+
+:SKLEARN_WORKING_MEMORY:
+
+    Sets the default value for the `working_memory` argument of
+    :func:`sklearn.set_config`.
+
+:SKLEARN_SEED:
+
+    Sets the seed of the global random generator when running the tests,
+    for reproducibility.
+
+:SKLEARN_SKIP_NETWORK_TESTS:
+
+    When this environment variable is set to a non zero value, the tests
+    that need network access are skipped.
diff --git a/doc/modules/kernel_approximation.rst b/doc/modules/kernel_approximation.rst
index fe920db116..00d1569839 100755
--- a/doc/modules/kernel_approximation.rst
+++ b/doc/modules/kernel_approximation.rst
@@ -59,13 +59,15 @@ a linear algorithm, for example a linear SVM::
     >>> y = [0, 0, 1, 1]
     >>> rbf_feature = RBFSampler(gamma=1, random_state=1)
     >>> X_features = rbf_feature.fit_transform(X)
-    >>> clf = SGDClassifier(max_iter=5)   # doctest: +NORMALIZE_WHITESPACE
-    >>> clf.fit(X_features, y)
-    SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
-           eta0=0.0, fit_intercept=True, l1_ratio=0.15,
-           learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,
-           n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
-           shuffle=True, tol=None, verbose=0, warm_start=False)
+    >>> clf = SGDClassifier(max_iter=5)
+    >>> clf.fit(X_features, y)   # doctest: +NORMALIZE_WHITESPACE
+    SGDClassifier(alpha=0.0001, average=False, class_weight=None,
+           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
+           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,
+           n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',
+           power_t=0.5, random_state=None, shuffle=True, tol=None,
+           validation_fraction=0.1, verbose=0, warm_start=False)
+
     >>> clf.score(X_features, y)
     1.0
 
diff --git a/doc/modules/model_evaluation.rst b/doc/modules/model_evaluation.rst
index eeb058e144..e55dc1cc14 100755
--- a/doc/modules/model_evaluation.rst
+++ b/doc/modules/model_evaluation.rst
@@ -176,7 +176,7 @@ Here is an example of building custom scorers, and of using the
     >>> import numpy as np
     >>> def my_custom_loss_func(y_true, y_pred):
     ...     diff = np.abs(y_true - y_pred).max()
-    ...     return np.log(1 + diff)
+    ...     return np.log1p(diff)
     ...
     >>> # score will negate the return value of my_custom_loss_func,
     >>> # which will be np.log(2), 0.693, given the values for X
diff --git a/doc/modules/scaling_strategies.rst b/doc/modules/scaling_strategies.rst
deleted file mode 100755
index 1b3b35fed6..0000000000
--- a/doc/modules/scaling_strategies.rst
+++ /dev/null
@@ -1,132 +0,0 @@
-.. _scaling_strategies:
-
-=================================================
-Strategies to scale computationally: bigger data
-=================================================
-
-For some applications the amount of examples, features (or both) and/or the
-speed at which they need to be processed are challenging for traditional
-approaches. In these cases scikit-learn has a number of options you can
-consider to make your system scale.
-
-Scaling with instances using out-of-core learning
-=================================================
-
-Out-of-core (or "external memory") learning is a technique used to learn from
-data that cannot fit in a computer's main memory (RAM).
-
-Here is sketch of a system designed to achieve this goal:
-
-  1. a way to stream instances
-  2. a way to extract features from instances
-  3. an incremental algorithm
-
-Streaming instances
--------------------
-Basically, 1. may be a reader that yields instances from files on a
-hard drive, a database, from a network stream etc. However,
-details on how to achieve this are beyond the scope of this documentation.
-
-Extracting features
--------------------
-\2. could be any relevant way to extract features among the
-different :ref:`feature extraction <feature_extraction>` methods supported by
-scikit-learn. However, when working with data that needs vectorization and
-where the set of features or values is not known in advance one should take
-explicit care. A good example is text classification where unknown terms are
-likely to be found during training. It is possible to use a stateful
-vectorizer if making multiple passes over the data is reasonable from an
-application point of view. Otherwise, one can turn up the difficulty by using
-a stateless feature extractor. Currently the preferred way to do this is to
-use the so-called :ref:`hashing trick<feature_hashing>` as implemented by
-:class:`sklearn.feature_extraction.FeatureHasher` for datasets with categorical
-variables represented as list of Python dicts or
-:class:`sklearn.feature_extraction.text.HashingVectorizer` for text documents.
-
-Incremental learning
---------------------
-Finally, for 3. we have a number of options inside scikit-learn. Although not
-all algorithms can learn incrementally (i.e. without seeing all the instances
-at once), all estimators implementing the ``partial_fit`` API are candidates.
-Actually, the ability to learn incrementally from a mini-batch of instances
-(sometimes called "online learning") is key to out-of-core learning as it
-guarantees that at any given time there will be only a small amount of
-instances in the main memory. Choosing a good size for the mini-batch that
-balances relevancy and memory footprint could involve some tuning [1]_.
-
-Here is a list of incremental estimators for different tasks:
-
-  - Classification
-      + :class:`sklearn.naive_bayes.MultinomialNB`
-      + :class:`sklearn.naive_bayes.BernoulliNB`
-      + :class:`sklearn.linear_model.Perceptron`
-      + :class:`sklearn.linear_model.SGDClassifier`
-      + :class:`sklearn.linear_model.PassiveAggressiveClassifier`
-      + :class:`sklearn.neural_network.MLPClassifier`
-  - Regression
-      + :class:`sklearn.linear_model.SGDRegressor`
-      + :class:`sklearn.linear_model.PassiveAggressiveRegressor`
-      + :class:`sklearn.neural_network.MLPRegressor`
-  - Clustering
-      + :class:`sklearn.cluster.MiniBatchKMeans`
-      + :class:`sklearn.cluster.Birch`
-  - Decomposition / feature Extraction
-      + :class:`sklearn.decomposition.MiniBatchDictionaryLearning`
-      + :class:`sklearn.decomposition.IncrementalPCA`
-      + :class:`sklearn.decomposition.LatentDirichletAllocation`
-  - Preprocessing
-      + :class:`sklearn.preprocessing.StandardScaler`
-      + :class:`sklearn.preprocessing.MinMaxScaler`
-      + :class:`sklearn.preprocessing.MaxAbsScaler`
-
-For classification, a somewhat important thing to note is that although a
-stateless feature extraction routine may be able to cope with new/unseen
-attributes, the incremental learner itself may be unable to cope with
-new/unseen targets classes. In this case you have to pass all the possible
-classes to the first ``partial_fit`` call using the ``classes=`` parameter.
-
-Another aspect to consider when choosing a proper algorithm is that not all of
-them put the same importance on each example over time. Namely, the
-``Perceptron`` is still sensitive to badly labeled examples even after many
-examples whereas the ``SGD*`` and ``PassiveAggressive*`` families are more
-robust to this kind of artifacts. Conversely, the latter also tend to give less
-importance to remarkably different, yet properly labeled examples when they
-come late in the stream as their learning rate decreases over time.
-
-Examples
---------
-Finally, we have a full-fledged example of
-:ref:`sphx_glr_auto_examples_applications_plot_out_of_core_classification.py`. It is aimed at
-providing a starting point for people wanting to build out-of-core learning
-systems and demonstrates most of the notions discussed above.
-
-Furthermore, it also shows the evolution of the performance of different
-algorithms with the number of processed examples.
-
-.. |accuracy_over_time| image::  ../auto_examples/applications/images/sphx_glr_plot_out_of_core_classification_001.png
-    :target: ../auto_examples/applications/plot_out_of_core_classification.html
-    :scale: 80
-
-.. centered:: |accuracy_over_time|
-
-Now looking at the computation time of the different parts, we see that the
-vectorization is much more expensive than learning itself. From the different
-algorithms, ``MultinomialNB`` is the most expensive, but its overhead can be
-mitigated by increasing the size of the mini-batches (exercise: change
-``minibatch_size`` to 100 and 10000 in the program and compare).
-
-.. |computation_time| image::  ../auto_examples/applications/images/sphx_glr_plot_out_of_core_classification_003.png
-    :target: ../auto_examples/applications/plot_out_of_core_classification.html
-    :scale: 80
-
-.. centered:: |computation_time|
-
-
-Notes
------
-
-.. [1] Depending on the algorithm the mini-batch size can influence results or
-       not. SGD*, PassiveAggressive*, and discrete NaiveBayes are truly online
-       and are not affected by batch size. Conversely, MiniBatchKMeans
-       convergence rate is affected by the batch size. Also, its memory
-       footprint can vary dramatically with batch size.
diff --git a/doc/modules/sgd.rst b/doc/modules/sgd.rst
index 64eea91a9f..55c25b9bb1 100755
--- a/doc/modules/sgd.rst
+++ b/doc/modules/sgd.rst
@@ -60,12 +60,13 @@ for the training samples::
     >>> X = [[0., 0.], [1., 1.]]
     >>> y = [0, 1]
     >>> clf = SGDClassifier(loss="hinge", penalty="l2", max_iter=5)
-    >>> clf.fit(X, y)
-    SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
-           eta0=0.0, fit_intercept=True, l1_ratio=0.15,
-           learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,
-           n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
-           shuffle=True, tol=None, verbose=0, warm_start=False)
+    >>> clf.fit(X, y)   # doctest: +NORMALIZE_WHITESPACE
+    SGDClassifier(alpha=0.0001, average=False, class_weight=None,
+               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
+               l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,
+               n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',
+               power_t=0.5, random_state=None, shuffle=True, tol=None,
+               validation_fraction=0.1, verbose=0, warm_start=False)
 
 
 After being fitted, the model can then be used to predict new values::
@@ -232,6 +233,27 @@ non-zero attributes per sample.
 Recent theoretical results, however, show that the runtime to get some
 desired optimization accuracy does not increase as the training set size increases.
 
+Stopping criterion
+==================
+
+The classes :class:`SGDClassifier` and :class:`SGDRegressor` provide two
+criteria to stop the algorithm when a given level of convergence is reached:
+
+  * With ``early_stopping=True``, the input data is split into a training set
+    and a validation set. The model is then fitted on the training set, and the
+    stopping criterion is based on the prediction score computed on the
+    validation set. The size of the validation set can be changed with the
+    parameter ``validation_fraction``.
+  * With ``early_stopping=False``, the model is fitted on the entire input data
+    and the stopping criterion is based on the objective function computed on
+    the input data.
+
+In both cases, the criterion is evaluated once by epoch, and the algorithm stops
+when the criterion does not improve ``n_iter_no_change`` times in a row. The
+improvement is evaluated with a tolerance ``tol``, and the algorithm stops in
+any case after a maximum number of iteration ``max_iter``.
+
+
 Tips on Practical Use
 =====================
 
@@ -257,7 +279,7 @@ Tips on Practical Use
 
   * Empirically, we found that SGD converges after observing
     approx. 10^6 training samples. Thus, a reasonable first guess
-    for the number of iterations is ``n_iter = np.ceil(10**6 / n)``,
+    for the number of iterations is ``max_iter = np.ceil(10**6 / n)``,
     where ``n`` is the size of the training set.
 
   * If you apply SGD to features extracted using PCA we found that
@@ -373,6 +395,11 @@ user via ``eta0`` and ``power_t``, resp.
 For a constant learning rate use ``learning_rate='constant'`` and use ``eta0``
 to specify the learning rate.
 
+For an adaptively decreasing learning rate, use ``learning_rate='adaptive'``
+and use ``eta0`` to specify the starting learning rate. When the stopping
+criterion is reached, the learning rate is divided by 5, and the algorithm
+does not stop. The algorithm stops when the learning rate goes below 1e-6.
+
 The model parameters can be accessed through the members ``coef_`` and
 ``intercept_``:
 
diff --git a/doc/user_guide.rst b/doc/user_guide.rst
index 214c0a4f7d..aae88134cd 100755
--- a/doc/user_guide.rst
+++ b/doc/user_guide.rst
@@ -20,5 +20,4 @@ User Guide
    model_selection.rst
    data_transforms.rst
    Dataset loading utilities <datasets/index.rst>
-   modules/scaling_strategies.rst
-   modules/computational_performance.rst
+   modules/computing.rst
diff --git a/doc/whats_new/v0.16.rst b/doc/whats_new/v0.16.rst
index 33d8cc47e9..931c7e0fbb 100755
--- a/doc/whats_new/v0.16.rst
+++ b/doc/whats_new/v0.16.rst
@@ -499,8 +499,8 @@ API changes summary
 
 - The ``shuffle`` option of :class:`.linear_model.SGDClassifier`,
   :class:`linear_model.SGDRegressor`, :class:`linear_model.Perceptron`,
-  :class:`linear_model.PassiveAgressiveClassifier` and
-  :class:`linear_model.PassiveAgressiveRegressor` now defaults to ``True``.
+  :class:`linear_model.PassiveAggressiveClassifier` and
+  :class:`linear_model.PassiveAggressiveRegressor` now defaults to ``True``.
 
 - :class:`cluster.DBSCAN` now uses a deterministic initialization. The
   `random_state` parameter is deprecated. By :user:`Erich Schubert <kno10>`.
diff --git a/doc/whats_new/v0.17.rst b/doc/whats_new/v0.17.rst
index 35e895e5d4..08aba83ebb 100755
--- a/doc/whats_new/v0.17.rst
+++ b/doc/whats_new/v0.17.rst
@@ -152,7 +152,7 @@ Enhancements
   By `Hanna Wallach`_ and `Andreas Müller`_.
 
 - Add ``class_weight`` parameter to automatically weight samples by class
-  frequency for :class:`linear_model.PassiveAgressiveClassifier`. By
+  frequency for :class:`linear_model.PassiveAggressiveClassifier`. By
   `Trevor Stephens`_.
 
 - Added backlinks from the API reference pages to the user guide. By
diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst
index e74d46cb45..dbfaba6115 100755
--- a/doc/whats_new/v0.20.rst
+++ b/doc/whats_new/v0.20.rst
@@ -65,6 +65,11 @@ random sampling procedures.
 - :class:`neural_network.MLPRegressor` (bug fix)
 - :class:`neural_network.MLPClassifier` (bug fix)
 - :class:`neural_network.BaseMultilayerPerceptron` (bug fix)
+- :class:`linear_model.SGDClassifier` (bug fix)
+- :class:`linear_model.SGDRegressor` (bug fix)
+- :class:`linear_model.PassiveAggressiveClassifier` (bug fix)
+- :class:`linear_model.PassiveAggressiveRegressor` (bug fix)
+- :class:`linear_model.Perceptron` (bug fix)
 - :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)
 - The v0.19.0 release notes failed to mention a backwards incompatibility with
   :class:`model_selection.StratifiedKFold` when ``shuffle=True`` due to
@@ -75,6 +80,12 @@ Details are listed in the changelog below.
 (While we are trying to better inform users by providing this information, we
 cannot assure that this list is complete.)
 
+**Other backward incompatible change** The vendored version of the joblib
+module is now found at `sklearn.externals._joblib` (:issue:`11166`). The
+main API of joblib is still exposed in `sklearn.externals.joblib`, but
+code doing imports of subpackages of `sklearn.externals.joblib` will
+break.
+
 Changelog
 ---------
 
@@ -142,8 +153,15 @@ Preprocessing
   other features in a round-robin fashion. :issue:`8478` by
   :user:`Sergey Feldman <sergeyf>`.
 
-- Updated :class:`preprocessing.MinMaxScaler` to pass through NaN values. :issue:`10404`
-  by :user:`Lucija Gregov <LucijaGregov>`.
+- :class:`linear_model.SGDClassifier`, :class:`linear_model.SGDRegressor`,
+  :class:`linear_model.PassiveAggressiveClassifier`,
+  :class:`linear_model.PassiveAggressiveRegressor` and
+  :class:`linear_model.Perceptron` now expose ``early_stopping``,
+  ``validation_fraction`` and ``n_iter_no_change`` parameters, to stop
+  optimization monitoring the score on a validation set. A new learning rate
+  ``"adaptive"`` strategy divides the learning rate by 5 each time
+  ``n_iter_no_change`` consecutive epochs fail to improve the model.
+  :issue:`9043` by `Tom Dupre la Tour`_.
 
 Model evaluation
 
@@ -185,6 +203,10 @@ Misc
   :func:`metrics.pairwise_distances_chunked`.  See :ref:`working_memory`.
   :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.
 
+- An environment variable to use the site joblib instead of the vendored
+  one was added (:ref:`environment_variable`).
+  :issue:`11166`by `Gael Varoquaux`_
+
 Enhancements
 ............
 
@@ -276,27 +298,28 @@ Preprocessing
   classes found which are ignored.
   :issue:`10913` by :user:`Rodrigo Agundez <rragundez>`.
 
-- :class:`preprocessing.QuantileTransformer` handles and ignores NaN values.
-  :issue:`10404` by :user:`Guillaume Lemaitre <glemaitre>`.
-
-- Updated :class:`preprocessing.MinMaxScaler` and
-  :func:`preprocessing.minmax_scale` to pass through NaN values.
-  :issue:`10404` and :issue:`11243` by :user:`Lucija Gregov <LucijaGregov>` and
+- NaN values are ignored and handled in the following preprocessing methods:
+  :class:`preprocessing.MaxAbsScaler`,
+  :class:`preprocessing.MinMaxScaler`,
+  :class:`preprocessing.RobustScaler`,
+  :class:`preprocessing.StandardScaler`,
+  :class:`preprocessing.PowerTransformer`,
+  :class:`preprocessing.QuantileTransformer` classes and
+  :func:`preprocessing.maxabs_scale`,
+  :func:`preprocessing.minmax_scale`,
+  :func:`preprocessing.robust_scale`,
+  :func:`preprocessing.scale`,
+  :func:`preprocessing.power_transform`,
+  :func:`preprocessing.quantile_transform` functions respectively addressed in
+  issues :issue:`11011`, :issue:`11005`, :issue:`11308`, :issue:`11206`,
+  :issue:`11306`, and :issue:`10437`.
+  By :user:`Lucija Gregov <LucijaGregov>` and
   :user:`Guillaume Lemaitre <glemaitre>`.
 
-- :class:`preprocessing.StandardScaler` and :func:`preprocessing.scale`
-  ignore and pass-through NaN values.
-  :issue:`11206` by :user:`Guillaume Lemaitre <glemaitre>`.
-
-- :class:`preprocessing.MaxAbsScaler` and :func:`preprocessing.maxabs_scale`
-  handles and ignores NaN values.
-  :issue:`11011` by `Lucija Gregov <LucihaGregov>` and
-  :user:`Guillaume Lemaitre <glemaitre>`
-
-- :class:`preprocessing.PowerTransformer` and
-  :func:`preprocessing.power_transform` ignore and pass-through NaN values.
-  :issue:`11306` by :user:`Guillaume Lemaitre <glemaitre>`.
-
+- :class:`preprocessing.RobustScaler` and :func:`preprocessing.robust_scale`
+  can be fitted using sparse matrices.
+  :issue:`11308` by :user:`Guillaume Lemaitre <glemaitre>`.
+  
 Model evaluation and meta-estimators
 
 - A scorer based on :func:`metrics.brier_score_loss` is also available.
@@ -333,6 +356,9 @@ Decomposition and manifold learning
   :class:`manifold.TSNE`. :issue:`10593` and :issue:`10610` by
   `Tom Dupre la Tour`_.
 
+- Support sparse input in :meth:`manifold.Isomap.fit`. :issue:`8554` by
+  :user:`Leland McInnes <lmcinnes>`.
+
 Metrics
 
 - :func:`metrics.roc_auc_score` now supports binary ``y_true`` other than
@@ -459,8 +485,8 @@ Classifiers and regressors
 - Fixed a bug in :class:`sklearn.linear_model.Lasso`
   where the coefficient had wrong shape when ``fit_intercept=False``.
   :issue:`10687` by :user:`Martin Hahn <martin-hahn>`.
-  
-- Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the 
+
+- Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the
   multi_class='multinomial' with binary output with warm_start = True
   :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`.
 
@@ -471,6 +497,15 @@ Classifiers and regressors
   and :class:`linear_model.ElasticNet` when working with sparse matrices.
   :issue:`10992` by `Alexandre Gramfort`_.
 
+- Fixed a bug in :class:`linear_model.SGDClassifier`,
+  :class:`linear_model.SGDRegressor`,
+  :class:`linear_model.PassiveAggressiveClassifier`,
+  :class:`linear_model.PassiveAggressiveRegressor` and
+  :class:`linear_model.Perceptron`, where the stopping criterion was stopping
+  the algorithm before convergence. A parameter `n_iter_no_change` was added
+  and set by default to 5. Previous behavior is equivalent to setting the
+  parameter to 1. :issue:`9043` by `Tom Dupre la Tour`_.
+
 - Fixed a bug where liblinear and libsvm-based estimators would segfault if
   passed a scipy.sparse matrix with 64-bit indices. They now raise a
   ValueError.
@@ -542,6 +577,11 @@ Decomposition, manifold learning and clustering
   by :user:`Vighnesh Birodkar <vighneshbirodkar>` and
   :user:`Olivier Grisel <ogrisel>`.
 
+- Fixed a bug in :func:`cluster.k_means_elkan` where the returned `iteration`
+  was 1 less than the correct value. Also added the missing `n_iter_` attribute
+  in the docstring of :class:`cluster.KMeans`. :issue:`11353` by
+  :user:`Jeremie du Boisberranger <jeremiedbb>`.
+
 Metrics
 
 - Fixed a bug in :func:`metrics.precision_recall_fscore_support`
@@ -588,13 +628,13 @@ Feature Extraction
   (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`
   and `Roman Yurchak`_.
 
-- Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which 
+- Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which
   was ignoring the parameter ``dtype``. In addition,
   :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``
   for floating and raise a warning if ``dtype`` requested is integer.
   :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and
   :user:`Guillaume Lemaitre <glemaitre>`.
-  
+
 Utils
 
 - :func:`utils.check_array` yield a ``FutureWarning`` indicating
@@ -694,6 +734,11 @@ Decomposition, manifold learning and clustering
   pairwise distances or squared distances. :issue:`9775` by
   :user:`William de Vazelhes <wdevazelhes>`.
 
+- Added function :func:`fit_predict` to :class:`mixture.GaussianMixture` and
+  :class:`mixture.GaussianMixture`, which is essentially equivalent to calling
+  :func:`fit` and :func:`predict`. :issue:`10336` by
+  :user:`Shu Haoran <haoranShu>` and :user:`Andrew Peng <Andrew-peng>`.
+
 Metrics
 
 - Deprecate ``reorder`` parameter in :func:`metrics.auc` as it's no longer required
diff --git a/examples/classification/plot_lda_qda.py b/examples/classification/plot_lda_qda.py
index a7da854974..e10d0a3560 100755
--- a/examples/classification/plot_lda_qda.py
+++ b/examples/classification/plot_lda_qda.py
@@ -142,7 +142,7 @@ def plot_qda_cov(qda, splot):
     plt.axis('tight')
 
     # Quadratic Discriminant Analysis
-    qda = QuadraticDiscriminantAnalysis(store_covariances=True)
+    qda = QuadraticDiscriminantAnalysis(store_covariance=True)
     y_pred = qda.fit(X, y).predict(X)
     splot = plot_data(qda, X, y, y_pred, fig_index=2 * i + 2)
     plot_qda_cov(qda, splot)
diff --git a/examples/linear_model/plot_sgd_early_stopping.py b/examples/linear_model/plot_sgd_early_stopping.py
new file mode 100755
index 0000000000..31ce61f39d
--- /dev/null
+++ b/examples/linear_model/plot_sgd_early_stopping.py
@@ -0,0 +1,149 @@
+"""
+=============================================
+Early stopping of Stochastic Gradient Descent
+=============================================
+
+Stochastic Gradient Descent is an optimization technique which minimizes a loss
+function in a stochastic fashion, performing a gradient descent step sample by
+sample. In particular, it is a very efficient method to fit linear models.
+
+As a stochastic method, the loss function is not necessarily decreasing at each
+iteration, and convergence is only guaranteed in expectation. For this reason,
+monitoring the convergence on the loss function can be difficult.
+
+Another approach is to monitor convergence on a validation score. In this case,
+the input data is split into a training set and a validation set. The model is
+then fitted on the training set and the stopping criterion is based on the
+prediction score computed on the validation set. This enables us to find the
+least number of iterations which is sufficient to build a model that
+generalizes well to unseen data and reduces the chance of over-fitting the
+training data.
+
+This early stopping strategy is activated if ``early_stopping=True``; otherwise
+the stopping criterion only uses the training loss on the entire input data. To
+better control the early stopping strategy, we can specify a parameter
+``validation_fraction`` which set the fraction of the input dataset that we
+keep aside to compute the validation score. The optimization will continue
+until the validation score did not improve by at least ``tol`` during the last
+``n_iter_no_change`` iterations. The actual number of iterations is available
+at the attribute ``n_iter_``.
+
+This example illustrates how the early stopping can used in the
+:class:`sklearn.linear_model.SGDClassifier` model to achieve almost the same
+accuracy as compared to a model built without early stopping. This can
+significantly reduce training time. Note that scores differ between the
+stopping criteria even from early iterations because some of the training data
+is held out with the validation stopping criterion.
+"""
+# Authors: Tom Dupre la Tour
+#
+# License: BSD 3 clause
+from __future__ import print_function
+import time
+import sys
+
+import pandas as pd
+import numpy as np
+import matplotlib.pyplot as plt
+
+from sklearn import linear_model
+from sklearn.datasets import fetch_mldata
+from sklearn.model_selection import train_test_split
+from sklearn.utils.testing import ignore_warnings
+from sklearn.exceptions import ConvergenceWarning
+from sklearn.utils import shuffle
+
+print(__doc__)
+
+
+def load_mnist(n_samples=None, class_0=0, class_1=8):
+    """Load MNIST, select two classes, shuffle and return only n_samples."""
+    mnist = fetch_mldata('MNIST original')
+
+    # take only two classes for binary classification
+    mask = np.logical_or(mnist.target == class_0, mnist.target == class_1)
+
+    X, y = shuffle(mnist.data[mask], mnist.target[mask], random_state=42)
+    if n_samples is not None:
+        X, y = X[:n_samples], y[:n_samples]
+    return X, y
+
+
+@ignore_warnings(category=ConvergenceWarning)
+def fit_and_score(estimator, max_iter, X_train, X_test, y_train, y_test):
+    """Fit the estimator on the train set and score it on both sets"""
+    estimator.set_params(max_iter=max_iter)
+    estimator.set_params(random_state=0)
+
+    start = time.time()
+    estimator.fit(X_train, y_train)
+
+    fit_time = time.time() - start
+    n_iter = estimator.n_iter_
+    train_score = estimator.score(X_train, y_train)
+    test_score = estimator.score(X_test, y_test)
+
+    return fit_time, n_iter, train_score, test_score
+
+
+# Define the estimators to compare
+estimator_dict = {
+    'No stopping criterion':
+    linear_model.SGDClassifier(tol=None, n_iter_no_change=3),
+    'Training loss':
+    linear_model.SGDClassifier(early_stopping=False, n_iter_no_change=3,
+                               tol=0.1),
+    'Validation score':
+    linear_model.SGDClassifier(early_stopping=True, n_iter_no_change=3,
+                               tol=0.0001, validation_fraction=0.2)
+}
+
+# Load the dataset
+X, y = load_mnist(n_samples=10000)
+X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,
+                                                    random_state=0)
+
+results = []
+for estimator_name, estimator in estimator_dict.items():
+    print(estimator_name + ': ', end='')
+    for max_iter in range(1, 50):
+        print('.', end='')
+        sys.stdout.flush()
+
+        fit_time, n_iter, train_score, test_score = fit_and_score(
+            estimator, max_iter, X_train, X_test, y_train, y_test)
+
+        results.append((estimator_name, max_iter, fit_time, n_iter,
+                        train_score, test_score))
+    print('')
+
+# Transform the results in a pandas dataframe for easy plotting
+columns = [
+    'Stopping criterion', 'max_iter', 'Fit time (sec)', 'n_iter_',
+    'Train score', 'Test score'
+]
+results_df = pd.DataFrame(results, columns=columns)
+
+# Define what to plot (x_axis, y_axis)
+lines = 'Stopping criterion'
+plot_list = [
+    ('max_iter', 'Train score'),
+    ('max_iter', 'Test score'),
+    ('max_iter', 'n_iter_'),
+    ('max_iter', 'Fit time (sec)'),
+]
+
+nrows = 2
+ncols = int(np.ceil(len(plot_list) / 2.))
+fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(6 * ncols,
+                                                            4 * nrows))
+axes[0, 0].get_shared_y_axes().join(axes[0, 0], axes[0, 1])
+
+for ax, (x_axis, y_axis) in zip(axes.ravel(), plot_list):
+    for criterion, group_df in results_df.groupby(lines):
+        group_df.plot(x=x_axis, y=y_axis, label=criterion, ax=ax)
+    ax.set_title(y_axis)
+    ax.legend(title=lines)
+
+fig.tight_layout()
+plt.show()
diff --git a/sklearn/__init__.py b/sklearn/__init__.py
index 36fb3afdc5..4de0df5ed1 100755
--- a/sklearn/__init__.py
+++ b/sklearn/__init__.py
@@ -49,7 +49,7 @@
 
 try:
     # This variable is injected in the __builtins__ by the build
-    # process. It used to enable importing subpackages of sklearn when
+    # process. It is used to enable importing subpackages of sklearn when
     # the binaries are not built
     __SKLEARN_SETUP__
 except NameError:
diff --git a/sklearn/cluster/_k_means_elkan.pyx b/sklearn/cluster/_k_means_elkan.pyx
index 5dad5f0c24..a0734a624f 100755
--- a/sklearn/cluster/_k_means_elkan.pyx
+++ b/sklearn/cluster/_k_means_elkan.pyx
@@ -258,4 +258,4 @@ def k_means_elkan(np.ndarray[floating, ndim=2, mode='c'] X_,
         update_labels_distances_inplace(X_p, centers_p, center_half_distances,
                                         labels, lower_bounds, upper_bounds,
                                         n_samples, n_features, n_clusters)
-    return centers_, labels_, iteration
+    return centers_, labels_, iteration + 1
diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py
index e2ee291473..42ca6402df 100755
--- a/sklearn/cluster/k_means_.py
+++ b/sklearn/cluster/k_means_.py
@@ -859,6 +859,9 @@ class KMeans(BaseEstimator, ClusterMixin, TransformerMixin):
     inertia_ : float
         Sum of squared distances of samples to their closest cluster center.
 
+    n_iter_ : int
+        Number of iterations run.
+
     Examples
     --------
 
diff --git a/sklearn/cluster/tests/test_k_means.py b/sklearn/cluster/tests/test_k_means.py
index 526c33058f..485b120b54 100755
--- a/sklearn/cluster/tests/test_k_means.py
+++ b/sklearn/cluster/tests/test_k_means.py
@@ -979,3 +979,11 @@ def test_check_sample_weight():
     assert_equal(_num_samples(X), _num_samples(checked_sample_weight))
     assert_almost_equal(checked_sample_weight.sum(), _num_samples(X))
     assert_equal(X.dtype, checked_sample_weight.dtype)
+
+
+def test_iter_attribute():
+    # Regression test on bad n_iter_ value. Previous bug n_iter_ was one off
+    # it's right value (#11340).
+    estimator = KMeans(algorithm="elkan", max_iter=1)
+    estimator.fit(np.random.rand(10, 10))
+    assert estimator.n_iter_ == 1
diff --git a/sklearn/covariance/elliptic_envelope.py b/sklearn/covariance/elliptic_envelope.py
index 0f9075abfb..1e00192289 100755
--- a/sklearn/covariance/elliptic_envelope.py
+++ b/sklearn/covariance/elliptic_envelope.py
@@ -122,9 +122,9 @@ def decision_function(self, X, raw_values=None):
             decision function. Must be False (default) for compatibility
             with the others outlier detection tools.
 
-        .. deprecated:: 0.20
-            ``raw_values`` has been deprecated in 0.20 and will be removed
-            in 0.22.
+            .. deprecated:: 0.20
+                ``raw_values`` has been deprecated in 0.20 and will be removed
+                in 0.22.
 
         Returns
         -------
diff --git a/sklearn/covariance/graph_lasso_.py b/sklearn/covariance/graph_lasso_.py
index 92fb0c9a60..b9d5821fc8 100755
--- a/sklearn/covariance/graph_lasso_.py
+++ b/sklearn/covariance/graph_lasso_.py
@@ -383,6 +383,9 @@ def graphical_lasso_path(X, alphas, cov_init=None, X_test=None, mode='cd',
     alphas : list of positive floats
         The list of regularization parameters, decreasing order.
 
+    cov_init : 2D array (n_features, n_features), optional
+        The initial guess for the covariance.
+
     X_test : 2D array, shape (n_test_samples, n_features), optional
         Optional test matrix to measure generalisation error.
 
diff --git a/sklearn/covariance/robust_covariance.py b/sklearn/covariance/robust_covariance.py
index a613906f36..8b21142514 100755
--- a/sklearn/covariance/robust_covariance.py
+++ b/sklearn/covariance/robust_covariance.py
@@ -55,16 +55,16 @@ def c_step(X, n_support, remaining_iterations=30, initial_estimates=None,
     verbose : boolean, optional
         Verbose mode.
 
+    cov_computation_method : callable, default empirical_covariance
+        The function which will be used to compute the covariance.
+        Must return shape (n_features, n_features)
+
     random_state : int, RandomState instance or None, optional (default=None)
         If int, random_state is the seed used by the random number generator;
         If RandomState instance, random_state is the random number generator;
         If None, the random number generator is the RandomState instance used
         by `np.random`.
 
-    cov_computation_method : callable, default empirical_covariance
-        The function which will be used to compute the covariance.
-        Must return shape (n_features, n_features)
-
     Returns
     -------
     location : array-like, shape (n_features,)
@@ -200,9 +200,6 @@ def select_candidates(X, n_support, n_trials, select=1, n_iter=30,
     n_support : int, [(n + p + 1)/2] < n_support < n
         The number of samples the pure data set must contain.
 
-    select : int, int > 0
-        Number of best candidates results to return.
-
     n_trials : int, nb_trials > 0 or 2-tuple
         Number of different initial sets of observations from which to
         run the algorithm.
@@ -214,22 +211,25 @@ def select_candidates(X, n_support, n_trials, select=1, n_iter=30,
         - n_trials[1]: array-like, shape (n_trials, n_features, n_features)
           is the list of `n_trials` initial covariances estimates
 
+    select : int, int > 0
+        Number of best candidates results to return.
+
     n_iter : int, nb_iter > 0
         Maximum number of iterations for the c_step procedure.
         (2 is enough to be close to the final solution. "Never" exceeds 20).
 
-    random_state : int, RandomState instance or None, optional (default=None)
-        If int, random_state is the seed used by the random number generator;
-        If RandomState instance, random_state is the random number generator;
-        If None, the random number generator is the RandomState instance used
-        by `np.random`.
+    verbose : boolean, default False
+        Control the output verbosity.
 
     cov_computation_method : callable, default empirical_covariance
         The function which will be used to compute the covariance.
         Must return shape (n_features, n_features)
 
-    verbose : boolean, default False
-        Control the output verbosity.
+    random_state : int, RandomState instance or None, optional (default=None)
+        If int, random_state is the seed used by the random number generator;
+        If RandomState instance, random_state is the random number generator;
+        If None, the random number generator is the RandomState instance used
+        by `np.random`.
 
     See Also
     ---------
diff --git a/sklearn/decomposition/nmf.py b/sklearn/decomposition/nmf.py
index 5eee44a739..fac0c43d52 100755
--- a/sklearn/decomposition/nmf.py
+++ b/sklearn/decomposition/nmf.py
@@ -34,12 +34,25 @@ def norm(x):
     """Dot product-based Euclidean norm implementation
 
     See: http://fseoane.net/blog/2011/computing-the-vector-norm/
+
+    Parameters
+    ----------
+    x : array-like
+        Vector for which to compute the norm
     """
     return sqrt(squared_norm(x))
 
 
 def trace_dot(X, Y):
-    """Trace of np.dot(X, Y.T)."""
+    """Trace of np.dot(X, Y.T).
+
+    Parameters
+    ----------
+    X : array-like
+        First matrix
+    Y : array-like
+        Second matrix
+    """
     return np.dot(X.ravel(), Y.ravel())
 
 
diff --git a/sklearn/discriminant_analysis.py b/sklearn/discriminant_analysis.py
index edb17294fa..96f3421456 100755
--- a/sklearn/discriminant_analysis.py
+++ b/sklearn/discriminant_analysis.py
@@ -567,6 +567,9 @@ class QuadraticDiscriminantAnalysis(BaseEstimator, ClassifierMixin):
 
         .. versionadded:: 0.17
 
+    store_covariances : boolean
+        Deprecated, use `store_covariance`.
+
     Attributes
     ----------
     covariance_ : list of array-like, shape = [n_features, n_features]
diff --git a/sklearn/externals/README b/sklearn/externals/README
index eef7ba7dd6..38859bb488 100755
--- a/sklearn/externals/README
+++ b/sklearn/externals/README
@@ -1,6 +1,9 @@
 This directory contains bundled external dependencies that are updated
 every once in a while.
 
+Note to developers and advanced users: setting the SKLEARN_SITE_JOBLIB to
+a non null value will force scikit-learn to use the site joblib.
+
 Note for distribution packagers: if you want to remove the duplicated
 code and depend on a packaged version, we suggest that you simply do a
 symbolic link in this directory.
diff --git a/sklearn/externals/joblib/__init__.py b/sklearn/externals/_joblib/__init__.py
similarity index 100%
rename from sklearn/externals/joblib/__init__.py
rename to sklearn/externals/_joblib/__init__.py
diff --git a/sklearn/externals/joblib/_compat.py b/sklearn/externals/_joblib/_compat.py
similarity index 100%
rename from sklearn/externals/joblib/_compat.py
rename to sklearn/externals/_joblib/_compat.py
diff --git a/sklearn/externals/joblib/_memory_helpers.py b/sklearn/externals/_joblib/_memory_helpers.py
similarity index 100%
rename from sklearn/externals/joblib/_memory_helpers.py
rename to sklearn/externals/_joblib/_memory_helpers.py
diff --git a/sklearn/externals/joblib/_multiprocessing_helpers.py b/sklearn/externals/_joblib/_multiprocessing_helpers.py
similarity index 100%
rename from sklearn/externals/joblib/_multiprocessing_helpers.py
rename to sklearn/externals/_joblib/_multiprocessing_helpers.py
diff --git a/sklearn/externals/joblib/_parallel_backends.py b/sklearn/externals/_joblib/_parallel_backends.py
similarity index 100%
rename from sklearn/externals/joblib/_parallel_backends.py
rename to sklearn/externals/_joblib/_parallel_backends.py
diff --git a/sklearn/externals/joblib/backports.py b/sklearn/externals/_joblib/backports.py
similarity index 100%
rename from sklearn/externals/joblib/backports.py
rename to sklearn/externals/_joblib/backports.py
diff --git a/sklearn/externals/joblib/disk.py b/sklearn/externals/_joblib/disk.py
similarity index 100%
rename from sklearn/externals/joblib/disk.py
rename to sklearn/externals/_joblib/disk.py
diff --git a/sklearn/externals/joblib/format_stack.py b/sklearn/externals/_joblib/format_stack.py
similarity index 100%
rename from sklearn/externals/joblib/format_stack.py
rename to sklearn/externals/_joblib/format_stack.py
diff --git a/sklearn/externals/joblib/func_inspect.py b/sklearn/externals/_joblib/func_inspect.py
similarity index 100%
rename from sklearn/externals/joblib/func_inspect.py
rename to sklearn/externals/_joblib/func_inspect.py
diff --git a/sklearn/externals/joblib/hashing.py b/sklearn/externals/_joblib/hashing.py
similarity index 100%
rename from sklearn/externals/joblib/hashing.py
rename to sklearn/externals/_joblib/hashing.py
diff --git a/sklearn/externals/joblib/logger.py b/sklearn/externals/_joblib/logger.py
similarity index 100%
rename from sklearn/externals/joblib/logger.py
rename to sklearn/externals/_joblib/logger.py
diff --git a/sklearn/externals/joblib/memory.py b/sklearn/externals/_joblib/memory.py
similarity index 100%
rename from sklearn/externals/joblib/memory.py
rename to sklearn/externals/_joblib/memory.py
diff --git a/sklearn/externals/joblib/my_exceptions.py b/sklearn/externals/_joblib/my_exceptions.py
similarity index 100%
rename from sklearn/externals/joblib/my_exceptions.py
rename to sklearn/externals/_joblib/my_exceptions.py
diff --git a/sklearn/externals/joblib/numpy_pickle.py b/sklearn/externals/_joblib/numpy_pickle.py
similarity index 100%
rename from sklearn/externals/joblib/numpy_pickle.py
rename to sklearn/externals/_joblib/numpy_pickle.py
diff --git a/sklearn/externals/joblib/numpy_pickle_compat.py b/sklearn/externals/_joblib/numpy_pickle_compat.py
similarity index 100%
rename from sklearn/externals/joblib/numpy_pickle_compat.py
rename to sklearn/externals/_joblib/numpy_pickle_compat.py
diff --git a/sklearn/externals/joblib/numpy_pickle_utils.py b/sklearn/externals/_joblib/numpy_pickle_utils.py
similarity index 100%
rename from sklearn/externals/joblib/numpy_pickle_utils.py
rename to sklearn/externals/_joblib/numpy_pickle_utils.py
diff --git a/sklearn/externals/joblib/parallel.py b/sklearn/externals/_joblib/parallel.py
similarity index 100%
rename from sklearn/externals/joblib/parallel.py
rename to sklearn/externals/_joblib/parallel.py
diff --git a/sklearn/externals/joblib/pool.py b/sklearn/externals/_joblib/pool.py
similarity index 100%
rename from sklearn/externals/joblib/pool.py
rename to sklearn/externals/_joblib/pool.py
diff --git a/sklearn/externals/copy_joblib.sh b/sklearn/externals/copy_joblib.sh
index 398b567b81..8db0da232c 100755
--- a/sklearn/externals/copy_joblib.sh
+++ b/sklearn/externals/copy_joblib.sh
@@ -12,14 +12,14 @@ else
 fi
 
 pip install $JOBLIB --target $INSTALL_FOLDER
-cp -r $INSTALL_FOLDER/joblib .
+cp -r $INSTALL_FOLDER/joblib _joblib
 rm -rf $INSTALL_FOLDER
 
 # Needed to rewrite the doctests
 # Note: BSD sed -i needs an argument unders OSX
 # so first renaming to .bak and then deleting backup files
-find joblib -name "*.py" | xargs sed -i.bak "s/from joblib/from sklearn.externals.joblib/"
-find joblib -name "*.bak" | xargs rm
+find _joblib -name "*.py" | xargs sed -i.bak "s/from joblib/from sklearn.externals.joblib/"
+find _joblib -name "*.bak" | xargs rm
 
 # Remove the tests folders to speed-up test time for scikit-learn.
 # joblib is already tested on its own CI infrastructure upstream.
diff --git a/sklearn/externals/joblib.py b/sklearn/externals/joblib.py
new file mode 100755
index 0000000000..3bd6ae73b8
--- /dev/null
+++ b/sklearn/externals/joblib.py
@@ -0,0 +1,15 @@
+# We need the absolute_import to avoid the local joblib to override the
+# site one
+from __future__ import absolute_import
+import os as _os
+
+# An environment variable to use the site joblib
+if _os.environ.get('SKLEARN_SITE_JOBLIB', False):
+    from joblib import *
+    from joblib import __version__
+    from joblib import logger
+else:
+    from ._joblib import *
+    from ._joblib import __version__
+    from ._joblib import logger
+
diff --git a/sklearn/externals/setup.py b/sklearn/externals/setup.py
index 936f032722..d3869f3ed7 100755
--- a/sklearn/externals/setup.py
+++ b/sklearn/externals/setup.py
@@ -4,6 +4,6 @@
 def configuration(parent_package='', top_path=None):
     from numpy.distutils.misc_util import Configuration
     config = Configuration('externals', parent_package, top_path)
-    config.add_subpackage('joblib')
+    config.add_subpackage('_joblib')
 
     return config
diff --git a/sklearn/feature_extraction/image.py b/sklearn/feature_extraction/image.py
index 8c4f5b2689..1fe28d6739 100755
--- a/sklearn/feature_extraction/image.py
+++ b/sklearn/feature_extraction/image.py
@@ -472,6 +472,11 @@ def fit(self, X, y=None):
 
         This method is just there to implement the usual API and hence
         work in pipelines.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            Training data.
         """
         return self
 
diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py
index e96693599d..10a3d6f76c 100755
--- a/sklearn/feature_extraction/text.py
+++ b/sklearn/feature_extraction/text.py
@@ -49,6 +49,11 @@ def strip_accents_unicode(s):
     implementation 20 times slower than the strip_accents_ascii basic
     normalization.
 
+    Parameters
+    ----------
+    s : string
+        The string to strip
+
     See also
     --------
     strip_accents_ascii
@@ -68,6 +73,11 @@ def strip_accents_ascii(s):
     Warning: this solution is only suited for languages that have a direct
     transliteration to ASCII symbols.
 
+    Parameters
+    ----------
+    s : string
+        The string to strip
+
     See also
     --------
     strip_accents_unicode
@@ -82,6 +92,11 @@ def strip_tags(s):
 
     For serious HTML/XML preprocessing you should rather use an external
     library such as lxml or BeautifulSoup.
+
+    Parameters
+    ----------
+    s : string
+        The string to strip
     """
     return re.compile(r"<([^>]+)>", flags=re.UNICODE).sub(" ", s)
 
@@ -106,6 +121,11 @@ def decode(self, doc):
         """Decode the input into a string of unicode symbols
 
         The decoding strategy depends on the vectorizer parameters.
+
+        Parameters
+        ----------
+        doc : string
+            The string to decode
         """
         if self.input == 'filename':
             with open(doc, 'rb') as fh:
@@ -391,13 +411,8 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
         Both 'ascii' and 'unicode' use NFKD normalization from
         :func:`unicodedata.normalize`.
 
-    analyzer : string, {'word', 'char', 'char_wb'} or callable
-        Whether the feature should be made of word or character n-grams.
-        Option 'char_wb' creates character n-grams only from text inside
-        word boundaries; n-grams at the edges of words are padded with space.
-
-        If a callable is passed it is used to extract the sequence of features
-        out of the raw, unprocessed input.
+    lowercase : boolean, default=True
+        Convert all characters to lowercase before tokenizing.
 
     preprocessor : callable or None (default)
         Override the preprocessing (string transformation) stage while
@@ -408,11 +423,6 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
         preprocessing and n-grams generation steps.
         Only applies if ``analyzer == 'word'``.
 
-    ngram_range : tuple (min_n, max_n), default=(1, 1)
-        The lower and upper boundary of the range of n-values for different
-        n-grams to be extracted. All values of n such that min_n <= n <= max_n
-        will be used.
-
     stop_words : string {'english'}, list, or None (default)
         If 'english', a built-in stop word list for English is used.
 
@@ -420,30 +430,37 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
         will be removed from the resulting tokens.
         Only applies if ``analyzer == 'word'``.
 
-    lowercase : boolean, default=True
-        Convert all characters to lowercase before tokenizing.
-
     token_pattern : string
         Regular expression denoting what constitutes a "token", only used
         if ``analyzer == 'word'``. The default regexp selects tokens of 2
         or more alphanumeric characters (punctuation is completely ignored
         and always treated as a token separator).
 
+    ngram_range : tuple (min_n, max_n), default=(1, 1)
+        The lower and upper boundary of the range of n-values for different
+        n-grams to be extracted. All values of n such that min_n <= n <= max_n
+        will be used.
+
+    analyzer : string, {'word', 'char', 'char_wb'} or callable
+        Whether the feature should be made of word or character n-grams.
+        Option 'char_wb' creates character n-grams only from text inside
+        word boundaries; n-grams at the edges of words are padded with space.
+
+        If a callable is passed it is used to extract the sequence of features
+        out of the raw, unprocessed input.
+
     n_features : integer, default=(2 ** 20)
         The number of features (columns) in the output matrices. Small numbers
         of features are likely to cause hash collisions, but large numbers
         will cause larger coefficient dimensions in linear learners.
 
-    norm : 'l1', 'l2' or None, optional
-        Norm used to normalize term vectors. None for no normalization.
-
     binary : boolean, default=False.
         If True, all non zero counts are set to 1. This is useful for discrete
         probabilistic models that model binary events rather than integer
         counts.
 
-    dtype : type, optional
-        Type of the matrix returned by fit_transform() or transform().
+    norm : 'l1', 'l2' or None, optional
+        Norm used to normalize term vectors. None for no normalization.
 
     alternate_sign : boolean, optional, default True
         When True, an alternating sign is added to the features as to
@@ -459,6 +476,9 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
 
         .. deprecated:: 0.19
             This option will be removed in 0.21.
+    dtype : type, optional
+        Type of the matrix returned by fit_transform() or transform().
+
 
     See also
     --------
@@ -496,11 +516,21 @@ def partial_fit(self, X, y=None):
         This method is just there to mark the fact that this transformer
         can work in a streaming setup.
 
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            Training data.
         """
         return self
 
     def fit(self, X, y=None):
-        """Does nothing: this transformer is stateless."""
+        """Does nothing: this transformer is stateless.
+
+        Parameters
+        ----------
+        X : array-like, shape [n_samples, n_features]
+            Training data.
+        """
         # triggers a parameter validation
         if isinstance(X, six.string_types):
             raise ValueError(
@@ -623,13 +653,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):
         Both 'ascii' and 'unicode' use NFKD normalization from
         :func:`unicodedata.normalize`.
 
-    analyzer : string, {'word', 'char', 'char_wb'} or callable
-        Whether the feature should be made of word or character n-grams.
-        Option 'char_wb' creates character n-grams only from text inside
-        word boundaries; n-grams at the edges of words are padded with space.
-
-        If a callable is passed it is used to extract the sequence of features
-        out of the raw, unprocessed input.
+    lowercase : boolean, True by default
+        Convert all characters to lowercase before tokenizing.
 
     preprocessor : callable or None (default)
         Override the preprocessing (string transformation) stage while
@@ -640,11 +665,6 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):
         preprocessing and n-grams generation steps.
         Only applies if ``analyzer == 'word'``.
 
-    ngram_range : tuple (min_n, max_n)
-        The lower and upper boundary of the range of n-values for different
-        n-grams to be extracted. All values of n such that min_n <= n <= max_n
-        will be used.
-
     stop_words : string {'english'}, list, or None (default)
         If 'english', a built-in stop word list for English is used.
 
@@ -656,15 +676,25 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):
         in the range [0.7, 1.0) to automatically detect and filter stop
         words based on intra corpus document frequency of terms.
 
-    lowercase : boolean, True by default
-        Convert all characters to lowercase before tokenizing.
-
     token_pattern : string
         Regular expression denoting what constitutes a "token", only used
         if ``analyzer == 'word'``. The default regexp select tokens of 2
         or more alphanumeric characters (punctuation is completely ignored
         and always treated as a token separator).
 
+    ngram_range : tuple (min_n, max_n)
+        The lower and upper boundary of the range of n-values for different
+        n-grams to be extracted. All values of n such that min_n <= n <= max_n
+        will be used.
+
+    analyzer : string, {'word', 'char', 'char_wb'} or callable
+        Whether the feature should be made of word or character n-grams.
+        Option 'char_wb' creates character n-grams only from text inside
+        word boundaries; n-grams at the edges of words are padded with space.
+
+        If a callable is passed it is used to extract the sequence of features
+        out of the raw, unprocessed input.
+
     max_df : float in range [0.0, 1.0] or int, default=1.0
         When building the vocabulary ignore terms that have a document
         frequency strictly higher than the given threshold (corpus-specific
@@ -1238,11 +1268,8 @@ class TfidfVectorizer(CountVectorizer):
         Both 'ascii' and 'unicode' use NFKD normalization from
         :func:`unicodedata.normalize`.
 
-    analyzer : string, {'word', 'char'} or callable
-        Whether the feature should be made of word or character n-grams.
-
-        If a callable is passed it is used to extract the sequence of features
-        out of the raw, unprocessed input.
+    lowercase : boolean, default True
+        Convert all characters to lowercase before tokenizing.
 
     preprocessor : callable or None (default)
         Override the preprocessing (string transformation) stage while
@@ -1253,10 +1280,11 @@ class TfidfVectorizer(CountVectorizer):
         preprocessing and n-grams generation steps.
         Only applies if ``analyzer == 'word'``.
 
-    ngram_range : tuple (min_n, max_n)
-        The lower and upper boundary of the range of n-values for different
-        n-grams to be extracted. All values of n such that min_n <= n <= max_n
-        will be used.
+    analyzer : string, {'word', 'char'} or callable
+        Whether the feature should be made of word or character n-grams.
+
+        If a callable is passed it is used to extract the sequence of features
+        out of the raw, unprocessed input.
 
     stop_words : string {'english'}, list, or None (default)
         If a string, it is passed to _check_stop_list and the appropriate stop
@@ -1271,15 +1299,17 @@ class TfidfVectorizer(CountVectorizer):
         in the range [0.7, 1.0) to automatically detect and filter stop
         words based on intra corpus document frequency of terms.
 
-    lowercase : boolean, default True
-        Convert all characters to lowercase before tokenizing.
-
     token_pattern : string
         Regular expression denoting what constitutes a "token", only used
         if ``analyzer == 'word'``. The default regexp selects tokens of 2
         or more alphanumeric characters (punctuation is completely ignored
         and always treated as a token separator).
 
+    ngram_range : tuple (min_n, max_n)
+        The lower and upper boundary of the range of n-values for different
+        n-grams to be extracted. All values of n such that min_n <= n <= max_n
+        will be used.
+
     max_df : float in range [0.0, 1.0] or int, default=1.0
         When building the vocabulary ignore terms that have a document
         frequency strictly higher than the given threshold (corpus-specific
diff --git a/sklearn/impute.py b/sklearn/impute.py
index 1f3a6e131a..4b3eb7a514 100755
--- a/sklearn/impute.py
+++ b/sklearn/impute.py
@@ -46,10 +46,10 @@ def _check_inputs_dtype(X, missing_values):
     missing_values."""
     if (X.dtype.kind in ("f", "i", "u") and
             not isinstance(missing_values, numbers.Real)):
-        raise TypeError("The data type of 'missing_values' and 'X' are "
-                        "not compatible. 'missing_values' data type is "
-                        "{} and 'X' is {}."
-                        .format(type(missing_values), X.dtype))
+        raise ValueError("The data type of 'missing_values' and 'X' are "
+                         "not compatible. 'missing_values' data type is "
+                         "{} and 'X' is {}."
+                         .format(type(missing_values), X.dtype))
 
 
 def _get_mask(X, value_to_mask):
@@ -1030,7 +1030,7 @@ class MissingIndicator(BaseEstimator, TransformerMixin):
     >>> indicator = MissingIndicator()
     >>> indicator.fit(X1)
     MissingIndicator(error_on_new=True, features='missing-only',
-             missing_values='NaN', sparse='auto')
+             missing_values=nan, sparse='auto')
     >>> X2_tr = indicator.transform(X2)
     >>> X2_tr
     array([[False,  True],
diff --git a/sklearn/linear_model/passive_aggressive.py b/sklearn/linear_model/passive_aggressive.py
index e803840279..dc48b7362b 100755
--- a/sklearn/linear_model/passive_aggressive.py
+++ b/sklearn/linear_model/passive_aggressive.py
@@ -36,6 +36,27 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.19
 
+    early_stopping : bool, default=False
+        Whether to use early stopping to terminate training when validation.
+        score is not improving. If set to True, it will automatically set aside
+        a fraction of training data as validation and terminate training when
+        validation score is not improving by at least tol for
+        n_iter_no_change consecutive epochs.
+
+        .. versionadded:: 0.20
+
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
+    validation_fraction : float, default=0.1
+        The proportion of training data to set aside as validation set for
+        early stopping. Must be between 0 and 1.
+        Only used if early_stopping is True.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
@@ -119,9 +140,10 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
     >>> clf = PassiveAggressiveClassifier(random_state=0)
     >>> clf.fit(X, y)
     PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,
-                  fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,
-                  n_jobs=1, random_state=0, shuffle=True, tol=None, verbose=0,
-                  warm_start=False)
+                  early_stopping=False, fit_intercept=True, loss='hinge',
+                  max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=1,
+                  random_state=0, shuffle=True, tol=None,
+                  validation_fraction=0.1, verbose=0, warm_start=False)
     >>> print(clf.coef_)
     [[0.49324685 1.0552176  1.49519589 1.33798314]]
     >>> print(clf.intercept_)
@@ -143,14 +165,18 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
     """
     def __init__(self, C=1.0, fit_intercept=True, max_iter=None, tol=None,
-                 shuffle=True, verbose=0, loss="hinge", n_jobs=1,
-                 random_state=None, warm_start=False, class_weight=None,
-                 average=False, n_iter=None):
+                 early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, shuffle=True, verbose=0, loss="hinge",
+                 n_jobs=1, random_state=None, warm_start=False,
+                 class_weight=None, average=False, n_iter=None):
         super(PassiveAggressiveClassifier, self).__init__(
             penalty=None,
             fit_intercept=fit_intercept,
             max_iter=max_iter,
             tol=tol,
+            early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change,
             shuffle=shuffle,
             verbose=verbose,
             random_state=random_state,
@@ -187,6 +213,7 @@ def partial_fit(self, X, y, classes=None):
         -------
         self : returns an instance of self.
         """
+        self._validate_params(for_partial_fit=True)
         if self.class_weight == 'balanced':
             raise ValueError("class_weight 'balanced' is not supported for "
                              "partial_fit. For 'balanced' weights, use "
@@ -224,6 +251,7 @@ def fit(self, X, y, coef_init=None, intercept_init=None):
         -------
         self : returns an instance of self.
         """
+        self._validate_params()
         lr = "pa1" if self.loss == "hinge" else "pa2"
         return self._fit(X, y, alpha=1.0, C=self.C,
                          loss="hinge", learning_rate=lr,
@@ -260,6 +288,27 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.19
 
+    early_stopping : bool, default=False
+        Whether to use early stopping to terminate training when validation.
+        score is not improving. If set to True, it will automatically set aside
+        a fraction of training data as validation and terminate training when
+        validation score is not improving by at least tol for
+        n_iter_no_change consecutive epochs.
+
+        .. versionadded:: 0.20
+
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
+    validation_fraction : float, default=0.1
+        The proportion of training data to set aside as validation set for
+        early stopping. Must be between 0 and 1.
+        Only used if early_stopping is True.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
@@ -328,10 +377,11 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
     >>> X, y = make_regression(n_features=4, random_state=0)
     >>> regr = PassiveAggressiveRegressor(random_state=0)
     >>> regr.fit(X, y)
-    PassiveAggressiveRegressor(C=1.0, average=False, epsilon=0.1,
-                  fit_intercept=True, loss='epsilon_insensitive',
-                  max_iter=None, n_iter=None, random_state=0, shuffle=True,
-                  tol=None, verbose=0, warm_start=False)
+    PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
+                  epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',
+                  max_iter=None, n_iter=None, n_iter_no_change=5,
+                  random_state=0, shuffle=True, tol=None,
+                  validation_fraction=0.1, verbose=0, warm_start=False)
     >>> print(regr.coef_)
     [20.48736655 34.18818427 67.59122734 87.94731329]
     >>> print(regr.intercept_)
@@ -352,8 +402,10 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
     """
     def __init__(self, C=1.0, fit_intercept=True, max_iter=None, tol=None,
-                 shuffle=True, verbose=0, loss="epsilon_insensitive",
-                 epsilon=DEFAULT_EPSILON, random_state=None, warm_start=False,
+                 early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, shuffle=True, verbose=0,
+                 loss="epsilon_insensitive", epsilon=DEFAULT_EPSILON,
+                 random_state=None, warm_start=False,
                  average=False, n_iter=None):
         super(PassiveAggressiveRegressor, self).__init__(
             penalty=None,
@@ -363,6 +415,9 @@ def __init__(self, C=1.0, fit_intercept=True, max_iter=None, tol=None,
             fit_intercept=fit_intercept,
             max_iter=max_iter,
             tol=tol,
+            early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change,
             shuffle=shuffle,
             verbose=verbose,
             random_state=random_state,
@@ -387,7 +442,7 @@ def partial_fit(self, X, y):
         -------
         self : returns an instance of self.
         """
-        self._validate_params()
+        self._validate_params(for_partial_fit=True)
         lr = "pa1" if self.loss == "epsilon_insensitive" else "pa2"
         return self._partial_fit(X, y, alpha=1.0, C=self.C,
                                  loss="epsilon_insensitive",
@@ -416,6 +471,7 @@ def fit(self, X, y, coef_init=None, intercept_init=None):
         -------
         self : returns an instance of self.
         """
+        self._validate_params()
         lr = "pa1" if self.loss == "epsilon_insensitive" else "pa2"
         return self._fit(X, y, alpha=1.0, C=self.C,
                          loss="epsilon_insensitive",
diff --git a/sklearn/linear_model/perceptron.py b/sklearn/linear_model/perceptron.py
index a09663e487..64cbecef7e 100755
--- a/sklearn/linear_model/perceptron.py
+++ b/sklearn/linear_model/perceptron.py
@@ -59,6 +59,27 @@ class Perceptron(BaseSGDClassifier):
         generator; If None, the random number generator is the RandomState
         instance used by `np.random`.
 
+    early_stopping : bool, default=False
+        Whether to use early stopping to terminate training when validation.
+        score is not improving. If set to True, it will automatically set aside
+        a fraction of training data as validation and terminate training when
+        validation score is not improving by at least tol for
+        n_iter_no_change consecutive epochs.
+
+        .. versionadded:: 0.20
+
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
+    validation_fraction : float, default=0.1
+        The proportion of training data to set aside as validation set for
+        early stopping. Must be between 0 and 1.
+        Only used if early_stopping is True.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
@@ -114,21 +135,15 @@ class Perceptron(BaseSGDClassifier):
     """
     def __init__(self, penalty=None, alpha=0.0001, fit_intercept=True,
                  max_iter=None, tol=None, shuffle=True, verbose=0, eta0=1.0,
-                 n_jobs=1, random_state=0, class_weight=None,
-                 warm_start=False, n_iter=None):
-        super(Perceptron, self).__init__(loss="perceptron",
-                                         penalty=penalty,
-                                         alpha=alpha, l1_ratio=0,
-                                         fit_intercept=fit_intercept,
-                                         max_iter=max_iter,
-                                         tol=tol,
-                                         shuffle=shuffle,
-                                         verbose=verbose,
-                                         random_state=random_state,
-                                         learning_rate="constant",
-                                         eta0=eta0,
-                                         power_t=0.5,
-                                         warm_start=warm_start,
-                                         class_weight=class_weight,
-                                         n_jobs=n_jobs,
-                                         n_iter=n_iter)
+                 n_jobs=1, random_state=0, early_stopping=False,
+                 validation_fraction=0.1, n_iter_no_change=5,
+                 class_weight=None, warm_start=False, n_iter=None):
+        super(Perceptron, self).__init__(
+            loss="perceptron", penalty=penalty, alpha=alpha, l1_ratio=0,
+            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,
+            shuffle=shuffle, verbose=verbose, random_state=random_state,
+            learning_rate="constant", eta0=eta0, early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change, power_t=0.5,
+            warm_start=warm_start, class_weight=class_weight, n_jobs=n_jobs,
+            n_iter=n_iter)
diff --git a/sklearn/linear_model/sgd_fast.pyx b/sklearn/linear_model/sgd_fast.pyx
index 384ad25673..7724e6e305 100755
--- a/sklearn/linear_model/sgd_fast.pyx
+++ b/sklearn/linear_model/sgd_fast.pyx
@@ -36,8 +36,10 @@ DEF ELASTICNET = 3
 DEF CONSTANT = 1
 DEF OPTIMAL = 2
 DEF INVSCALING = 3
-DEF PA1 = 4
-DEF PA2 = 5
+DEF ADAPTIVE = 4
+DEF PA1 = 5
+DEF PA2 = 6
+
 
 
 # ----------------------------------------
@@ -337,6 +339,9 @@ def plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
               double alpha, double C,
               double l1_ratio,
               SequentialDataset dataset,
+              np.ndarray[unsigned char, ndim=1, mode='c'] validation_mask,
+              bint early_stopping, estimator,
+              int n_iter_no_change,
               int max_iter, double tol, int fit_intercept,
               int verbose, bint shuffle, np.uint32_t seed,
               double weight_pos, double weight_neg,
@@ -365,10 +370,19 @@ def plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
         l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.
     dataset : SequentialDataset
         A concrete ``SequentialDataset`` object.
+    validation_mask : ndarray[unsigned char, ndim=1]
+        Equal to True on the validation set.
+    early_stopping : boolean
+        Whether to use a stopping criterion based on the validation set.
+    estimator : BaseSGD
+        A concrete object inheriting from ``BaseSGD``.
+        Used only if early_stopping is True.
+    n_iter_no_change : int
+        Number of iteration with no improvement to wait before stopping.
     max_iter : int
         The maximum number of iterations (epochs).
     tol: double
-        The tolerance for the stopping criterion
+        The tolerance for the stopping criterion.
     fit_intercept : int
         Whether or not to fit the intercept (1 or 0).
     verbose : int
@@ -386,8 +400,9 @@ def plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
         (1) constant, eta = eta0
         (2) optimal, eta = 1.0/(alpha * t).
         (3) inverse scaling, eta = eta0 / pow(t, power_t)
-        (4) Passive Aggressive-I, eta = min(alpha, loss/norm(x))
-        (5) Passive Aggressive-II, eta = 1.0 / (norm(x) + 0.5*alpha)
+        (4) adaptive decrease
+        (5) Passive Aggressive-I, eta = min(alpha, loss/norm(x))
+        (6) Passive Aggressive-II, eta = 1.0 / (norm(x) + 0.5*alpha)
     eta0 : double
         The initial learning rate.
     power_t : double
@@ -418,6 +433,10 @@ def plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                                    alpha, C,
                                    l1_ratio,
                                    dataset,
+                                   validation_mask,
+                                   early_stopping,
+                                   estimator,
+                                   n_iter_no_change,
                                    max_iter, tol, fit_intercept,
                                    verbose, shuffle, seed,
                                    weight_pos, weight_neg,
@@ -438,6 +457,9 @@ def average_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                 double alpha, double C,
                 double l1_ratio,
                 SequentialDataset dataset,
+                np.ndarray[unsigned char, ndim=1, mode='c'] validation_mask,
+                bint early_stopping, estimator,
+                int n_iter_no_change,
                 int max_iter, double tol, int fit_intercept,
                 int verbose, bint shuffle, np.uint32_t seed,
                 double weight_pos, double weight_neg,
@@ -471,6 +493,15 @@ def average_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
         l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.
     dataset : SequentialDataset
         A concrete ``SequentialDataset`` object.
+    validation_mask : ndarray[unsigned char, ndim=1]
+        Equal to True on the validation set.
+    early_stopping : boolean
+        Whether to use a stopping criterion based on the validation set.
+    estimator : BaseSGD
+        A concrete object inheriting from ``BaseSGD``.
+        Used only if early_stopping is True.
+    n_iter_no_change : int
+        Number of iteration with no improvement to wait before stopping.
     max_iter : int
         The maximum number of iterations (epochs).
     tol: double
@@ -492,8 +523,9 @@ def average_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
         (1) constant, eta = eta0
         (2) optimal, eta = 1.0/(alpha * t).
         (3) inverse scaling, eta = eta0 / pow(t, power_t)
-        (4) Passive Aggressive-I, eta = min(alpha, loss/norm(x))
-        (5) Passive Aggressive-II, eta = 1.0 / (norm(x) + 0.5*alpha)
+        (4) adaptive decrease
+        (5) Passive Aggressive-I, eta = min(alpha, loss/norm(x))
+        (6) Passive Aggressive-II, eta = 1.0 / (norm(x) + 0.5*alpha)
     eta0 : double
         The initial learning rate.
     power_t : double
@@ -528,6 +560,10 @@ def average_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                       alpha, C,
                       l1_ratio,
                       dataset,
+                      validation_mask,
+                      early_stopping,
+                      estimator,
+                      n_iter_no_change,
                       max_iter, tol, fit_intercept,
                       verbose, shuffle, seed,
                       weight_pos, weight_neg,
@@ -547,6 +583,9 @@ def _plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                double alpha, double C,
                double l1_ratio,
                SequentialDataset dataset,
+               np.ndarray[unsigned char, ndim=1, mode='c'] validation_mask,
+               bint early_stopping, estimator,
+               int n_iter_no_change,
                int max_iter, double tol, int fit_intercept,
                int verbose, bint shuffle, np.uint32_t seed,
                double weight_pos, double weight_neg,
@@ -567,13 +606,16 @@ def _plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
     cdef double* ps_ptr = NULL
 
     # helper variables
+    cdef int no_improvement_count = 0
     cdef bint infinity = False
     cdef int xnnz
     cdef double eta = 0.0
     cdef double p = 0.0
     cdef double update = 0.0
     cdef double sumloss = 0.0
-    cdef double previous_loss = np.inf
+    cdef double score = 0.0
+    cdef double best_loss = INFINITY
+    cdef double best_score = -INFINITY
     cdef double y = 0.0
     cdef double sample_weight
     cdef double class_weight = 1.0
@@ -587,6 +629,9 @@ def _plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
     cdef double max_change = 0.0
     cdef double max_weight = 0.0
 
+    cdef long long sample_index
+    cdef unsigned char [:] validation_mask_view = validation_mask
+
     # q vector is only used for L1 regularization
     cdef np.ndarray[double, ndim = 1, mode = "c"] q = None
     cdef double * q_data_ptr = NULL
@@ -622,13 +667,19 @@ def _plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                 dataset.next(&x_data_ptr, &x_ind_ptr, &xnnz,
                              &y, &sample_weight)
 
+                sample_index = dataset.index_data_ptr[dataset.current_index]
+                if validation_mask_view[sample_index]:
+                    # do not learn on the validation set
+                    continue
+
                 p = w.dot(x_data_ptr, x_ind_ptr, xnnz) + intercept
                 if learning_rate == OPTIMAL:
                     eta = 1.0 / (alpha * (optimal_init + t - 1))
                 elif learning_rate == INVSCALING:
                     eta = eta0 / pow(t, power_t)
 
-                sumloss += loss.loss(p, y)
+                if verbose or not early_stopping:
+                    sumloss += loss.loss(p, y)
 
                 if y > 0.0:
                     class_weight = weight_pos
@@ -705,13 +756,36 @@ def _plain_sgd(np.ndarray[double, ndim=1, mode='c'] weights,
                 infinity = True
                 break
 
-            if tol > -INFINITY and sumloss > previous_loss - tol * n_samples:
-                if verbose:
-                    with gil:
-                        print("Convergence after %d epochs took %.2f seconds"
-                              % (epoch + 1, time() - t_start))
-                break
-            previous_loss = sumloss
+            # evaluate the score on the validation set
+            if early_stopping:
+                with gil:
+                    score = estimator._validation_score(weights, intercept)
+                if tol > -INFINITY and score < best_score + tol:
+                    no_improvement_count += 1
+                else:
+                    no_improvement_count = 0
+                if score > best_score:
+                    best_score = score
+            # or evaluate the loss on the training set
+            else:
+                if tol > -INFINITY and sumloss > best_loss - tol * n_samples:
+                    no_improvement_count += 1
+                else:
+                    no_improvement_count = 0
+                if sumloss < best_loss:
+                    best_loss = sumloss
+
+            # if there is no improvement several times in a row
+            if no_improvement_count >= n_iter_no_change:
+                if learning_rate == ADAPTIVE and eta > 1e-6:
+                    eta = eta / 5
+                    no_improvement_count = 0
+                else:
+                    if verbose:
+                        with gil:
+                            print("Convergence after %d epochs took %.2f "
+                                  "seconds" % (epoch + 1, time() - t_start))
+                    break
 
     if infinity:
         raise ValueError(("Floating-point under-/overflow occurred at epoch"
diff --git a/sklearn/linear_model/stochastic_gradient.py b/sklearn/linear_model/stochastic_gradient.py
index 35551dfc39..e5bc20e837 100755
--- a/sklearn/linear_model/stochastic_gradient.py
+++ b/sklearn/linear_model/stochastic_gradient.py
@@ -20,6 +20,7 @@
 from ..utils.validation import check_is_fitted
 from ..exceptions import ConvergenceWarning
 from ..externals import six
+from ..model_selection import train_test_split
 
 from .sgd_fast import plain_sgd, average_sgd
 from ..utils import compute_class_weight
@@ -33,9 +34,8 @@
 from .sgd_fast import EpsilonInsensitive
 from .sgd_fast import SquaredEpsilonInsensitive
 
-
 LEARNING_RATE_TYPES = {"constant": 1, "optimal": 2, "invscaling": 3,
-                       "pa1": 4, "pa2": 5}
+                       "adaptive": 4, "pa1": 5, "pa2": 6}
 
 PENALTY_TYPES = {"none": 0, "l2": 2, "l1": 1, "elasticnet": 3}
 
@@ -50,7 +50,9 @@ def __init__(self, loss, penalty='l2', alpha=0.0001, C=1.0,
                  l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,
                  shuffle=True, verbose=0, epsilon=0.1, random_state=None,
                  learning_rate="optimal", eta0=0.0, power_t=0.5,
-                 warm_start=False, average=False, n_iter=None):
+                 early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, warm_start=False, average=False,
+                 n_iter=None):
         self.loss = loss
         self.penalty = penalty
         self.learning_rate = learning_rate
@@ -64,6 +66,9 @@ def __init__(self, loss, penalty='l2', alpha=0.0001, C=1.0,
         self.verbose = verbose
         self.eta0 = eta0
         self.power_t = power_t
+        self.early_stopping = early_stopping
+        self.validation_fraction = validation_fraction
+        self.n_iter_no_change = n_iter_no_change
         self.warm_start = warm_start
         self.average = average
         self.n_iter = n_iter
@@ -86,13 +91,21 @@ def _validate_params(self, set_max_iter=True, for_partial_fit=False):
         """Validate input params. """
         if not isinstance(self.shuffle, bool):
             raise ValueError("shuffle must be either True or False")
+        if not isinstance(self.early_stopping, bool):
+            raise ValueError("early_stopping must be either True or False")
+        if self.early_stopping and for_partial_fit:
+            raise ValueError("early_stopping should be False with partial_fit")
         if self.max_iter is not None and self.max_iter <= 0:
             raise ValueError("max_iter must be > zero. Got %f" % self.max_iter)
         if not (0.0 <= self.l1_ratio <= 1.0):
             raise ValueError("l1_ratio must be in [0, 1]")
         if self.alpha < 0.0:
             raise ValueError("alpha must be >= 0")
-        if self.learning_rate in ("constant", "invscaling"):
+        if self.n_iter_no_change < 1:
+            raise ValueError("n_iter_no_change must be >= 1")
+        if not (0.0 < self.validation_fraction < 1.0):
+            raise ValueError("validation_fraction must be in ]0, 1[")
+        if self.learning_rate in ("constant", "invscaling", "adaptive"):
             if self.eta0 <= 0.0:
                 raise ValueError("eta0 must be > 0")
         if self.learning_rate == "optimal" and self.alpha == 0:
@@ -235,6 +248,72 @@ def _allocate_parameter_mem(self, n_classes, n_features, coef_init=None,
                                                dtype=np.float64,
                                                order="C")
 
+    def _make_validation_split(self, X, y, sample_weight):
+        """Split the dataset between training set and validation set.
+
+        Parameters
+        ----------
+        X : {array, sparse matrix}, shape (n_samples, n_features)
+            Training data.
+
+        y : array, shape (n_samples, )
+            Target values.
+
+        sample_weight : array, shape (n_samples, )
+            Weights applied to individual samples.
+
+        Returns
+        -------
+        validation_mask : array, shape (n_samples, )
+            Equal to 1 on the validation set, 0 on the training set.
+        """
+        n_samples = X.shape[0]
+        validation_mask = np.zeros(n_samples, dtype=np.uint8)
+        if not self.early_stopping:
+            # use the full set for training, with an empty validation set
+            return validation_mask
+
+        tmp = train_test_split(X, y, np.arange(n_samples), sample_weight,
+                               test_size=self.validation_fraction,
+                               random_state=self.random_state)
+        X_train, X_val, y_train, y_val = tmp[:4]
+        idx_train, idx_val, sample_weight_train, sample_weight_val = tmp[4:8]
+        if X_train.shape[0] == 0 or X_val.shape[0] == 0:
+            raise ValueError(
+                "Splitting %d samples into a train set and a validation set "
+                "with validation_fraction=%r led to an empty set (%d and %d "
+                "samples). Please either change validation_fraction, increase "
+                "number of samples, or disable early_stopping."
+                % (n_samples, self.validation_fraction, X_train.shape[0],
+                   X_val.shape[0]))
+
+        self._X_val = X_val
+        self._y_val = y_val
+        self._sample_weight_val = sample_weight_val
+        validation_mask[idx_val] = 1
+        return validation_mask
+
+    def _delete_validation_split(self):
+        if self.early_stopping:
+            del self._X_val
+            del self._y_val
+            del self._sample_weight_val
+
+    def _validation_score(self, coef, intercept):
+        """Compute the score on the validation set. Used for early stopping."""
+        # store attributes
+        old_coefs, old_intercept = self.coef_, self.intercept_
+
+        # replace them with current coefficients for scoring
+        self.coef_ = coef.reshape(1, -1)
+        self.intercept_ = np.atleast_1d(intercept)
+        score = self.score(self._X_val, self._y_val, self._sample_weight_val)
+
+        # restore old attributes
+        self.coef_, self.intercept_ = old_coefs, old_intercept
+
+        return score
+
 
 def _prepare_fit_binary(est, y, i):
     """Initialization for fit_binary.
@@ -284,6 +363,8 @@ def fit_binary(est, i, X, y, alpha, C, learning_rate, max_iter,
     penalty_type = est._get_penalty_type(est.penalty)
     learning_rate_type = est._get_learning_rate_type(learning_rate)
 
+    validation_mask = est._make_validation_split(X, y, sample_weight)
+
     # XXX should have random_state_!
     random_state = check_random_state(est.random_state)
     # numpy mtrand expects a C long which is a signed 32 bit integer under
@@ -293,20 +374,24 @@ def fit_binary(est, i, X, y, alpha, C, learning_rate, max_iter,
     tol = est.tol if est.tol is not None else -np.inf
 
     if not est.average:
-        return plain_sgd(coef, intercept, est.loss_function_,
-                         penalty_type, alpha, C, est.l1_ratio,
-                         dataset, max_iter, tol, int(est.fit_intercept),
-                         int(est.verbose), int(est.shuffle), seed,
-                         pos_weight, neg_weight,
-                         learning_rate_type, est.eta0,
-                         est.power_t, est.t_, intercept_decay)
+        result = plain_sgd(coef, intercept, est.loss_function_,
+                           penalty_type, alpha, C, est.l1_ratio,
+                           dataset, validation_mask, est.early_stopping, est,
+                           int(est.n_iter_no_change),
+                           max_iter, tol, int(est.fit_intercept),
+                           int(est.verbose), int(est.shuffle), seed,
+                           pos_weight, neg_weight,
+                           learning_rate_type, est.eta0,
+                           est.power_t, est.t_, intercept_decay)
 
     else:
         standard_coef, standard_intercept, average_coef, average_intercept, \
             n_iter_ = average_sgd(coef, intercept, average_coef,
                                   average_intercept, est.loss_function_,
                                   penalty_type, alpha, C, est.l1_ratio,
-                                  dataset, max_iter, tol,
+                                  dataset, validation_mask, est.early_stopping,
+                                  est, int(est.n_iter_no_change),
+                                  max_iter, tol,
                                   int(est.fit_intercept), int(est.verbose),
                                   int(est.shuffle), seed, pos_weight,
                                   neg_weight, learning_rate_type, est.eta0,
@@ -318,7 +403,10 @@ def fit_binary(est, i, X, y, alpha, C, learning_rate, max_iter,
         else:
             est.average_intercept_[i] = average_intercept
 
-        return standard_coef, standard_intercept, n_iter_
+        result = standard_coef, standard_intercept, n_iter_
+
+    est._delete_validation_split()
+    return result
 
 
 class BaseSGDClassifier(six.with_metaclass(ABCMeta, BaseSGD,
@@ -342,22 +430,20 @@ def __init__(self, loss="hinge", penalty='l2', alpha=0.0001,
                  l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,
                  shuffle=True, verbose=0, epsilon=DEFAULT_EPSILON, n_jobs=1,
                  random_state=None, learning_rate="optimal", eta0=0.0,
-                 power_t=0.5, class_weight=None, warm_start=False,
-                 average=False, n_iter=None):
+                 power_t=0.5, early_stopping=False,
+                 validation_fraction=0.1, n_iter_no_change=5,
+                 class_weight=None, warm_start=False, average=False,
+                 n_iter=None):
 
-        super(BaseSGDClassifier, self).__init__(loss=loss, penalty=penalty,
-                                                alpha=alpha, l1_ratio=l1_ratio,
-                                                fit_intercept=fit_intercept,
-                                                max_iter=max_iter, tol=tol,
-                                                shuffle=shuffle,
-                                                verbose=verbose,
-                                                epsilon=epsilon,
-                                                random_state=random_state,
-                                                learning_rate=learning_rate,
-                                                eta0=eta0, power_t=power_t,
-                                                warm_start=warm_start,
-                                                average=average,
-                                                n_iter=n_iter)
+        super(BaseSGDClassifier, self).__init__(
+            loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,
+            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,
+            shuffle=shuffle, verbose=verbose, epsilon=epsilon,
+            random_state=random_state, learning_rate=learning_rate, eta0=eta0,
+            power_t=power_t, early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change, warm_start=warm_start,
+            average=average, n_iter=n_iter)
         self.class_weight = class_weight
         self.n_jobs = int(n_jobs)
 
@@ -699,20 +785,48 @@ class SGDClassifier(BaseSGDClassifier):
     learning_rate : string, optional
         The learning rate schedule:
 
-        - 'constant': eta = eta0
-        - 'optimal': eta = 1.0 / (alpha * (t + t0)) [default]
-        - 'invscaling': eta = eta0 / pow(t, power_t)
-
-        where t0 is chosen by a heuristic proposed by Leon Bottou.
+        'constant':
+            eta = eta0
+        'optimal': [default]
+            eta = 1.0 / (alpha * (t + t0))
+            where t0 is chosen by a heuristic proposed by Leon Bottou.
+        'invscaling':
+            eta = eta0 / pow(t, power_t)
+        'adaptive':
+            eta = eta0, as long as the training keeps decreasing.
+            Each time n_iter_no_change consecutive epochs fail to decrease the
+            training loss by tol or fail to increase validation score by tol if
+            early_stopping is True, the current learning rate is divided by 5.
 
     eta0 : double
-        The initial learning rate for the 'constant' or 'invscaling'
-        schedules. The default value is 0.0 as eta0 is not used by the
-        default schedule 'optimal'.
+        The initial learning rate for the 'constant', 'invscaling' or
+        'adaptive' schedules. The default value is 0.0 as eta0 is not used by
+        the default schedule 'optimal'.
 
     power_t : double
         The exponent for inverse scaling learning rate [default 0.5].
 
+    early_stopping : bool, default=False
+        Whether to use early stopping to terminate training when validation.
+        score is not improving. If set to True, it will automatically set aside
+        a fraction of training data as validation and terminate training when
+        validation score is not improving by at least tol for
+        n_iter_no_change consecutive epochs.
+
+        .. versionadded:: 0.20
+
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
+    validation_fraction : float, default=0.1
+        The proportion of training data to set aside as validation set for
+        early stopping. Must be between 0 and 1.
+        Only used if early_stopping is True.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
@@ -774,11 +888,12 @@ class SGDClassifier(BaseSGDClassifier):
     >>> clf = linear_model.SGDClassifier()
     >>> clf.fit(X, Y)
     ... #doctest: +NORMALIZE_WHITESPACE
-    SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,
-           eta0=0.0, fit_intercept=True, l1_ratio=0.15,
-           learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,
-           n_jobs=1, penalty='l2', power_t=0.5, random_state=None,
-           shuffle=True, tol=None, verbose=0, warm_start=False)
+    SGDClassifier(alpha=0.0001, average=False, class_weight=None,
+           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
+           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,
+           n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',
+           power_t=0.5, random_state=None, shuffle=True, tol=None,
+           validation_fraction=0.1, verbose=0, warm_start=False)
 
     >>> print(clf.predict([[-0.8, -1]]))
     [1]
@@ -793,15 +908,18 @@ def __init__(self, loss="hinge", penalty='l2', alpha=0.0001, l1_ratio=0.15,
                  fit_intercept=True, max_iter=None, tol=None, shuffle=True,
                  verbose=0, epsilon=DEFAULT_EPSILON, n_jobs=1,
                  random_state=None, learning_rate="optimal", eta0=0.0,
-                 power_t=0.5, class_weight=None, warm_start=False,
+                 power_t=0.5, early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, class_weight=None, warm_start=False,
                  average=False, n_iter=None):
         super(SGDClassifier, self).__init__(
             loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,
             fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,
             shuffle=shuffle, verbose=verbose, epsilon=epsilon, n_jobs=n_jobs,
             random_state=random_state, learning_rate=learning_rate, eta0=eta0,
-            power_t=power_t, class_weight=class_weight, warm_start=warm_start,
-            average=average, n_iter=n_iter)
+            power_t=power_t, early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change, class_weight=class_weight,
+            warm_start=warm_start, average=average, n_iter=n_iter)
 
     def _check_proba(self):
         if self.loss not in ("log", "modified_huber"):
@@ -934,20 +1052,18 @@ def __init__(self, loss="squared_loss", penalty="l2", alpha=0.0001,
                  l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,
                  shuffle=True, verbose=0, epsilon=DEFAULT_EPSILON,
                  random_state=None, learning_rate="invscaling", eta0=0.01,
-                 power_t=0.25, warm_start=False, average=False, n_iter=None):
-        super(BaseSGDRegressor, self).__init__(loss=loss, penalty=penalty,
-                                               alpha=alpha, l1_ratio=l1_ratio,
-                                               fit_intercept=fit_intercept,
-                                               max_iter=max_iter, tol=tol,
-                                               shuffle=shuffle,
-                                               verbose=verbose,
-                                               epsilon=epsilon,
-                                               random_state=random_state,
-                                               learning_rate=learning_rate,
-                                               eta0=eta0, power_t=power_t,
-                                               warm_start=warm_start,
-                                               average=average,
-                                               n_iter=n_iter)
+                 power_t=0.25, early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, warm_start=False, average=False,
+                 n_iter=None):
+        super(BaseSGDRegressor, self).__init__(
+            loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,
+            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,
+            shuffle=shuffle, verbose=verbose, epsilon=epsilon,
+            random_state=random_state, learning_rate=learning_rate, eta0=eta0,
+            power_t=power_t, early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change, warm_start=warm_start,
+            average=average, n_iter=n_iter)
 
     def _partial_fit(self, X, y, alpha, C, loss, learning_rate,
                      max_iter, sample_weight, coef_init, intercept_init):
@@ -1115,6 +1231,8 @@ def _fit_regressor(self, X, y, alpha, C, loss, learning_rate,
         if not hasattr(self, "t_"):
             self.t_ = 1.0
 
+        validation_mask = self._make_validation_split(X, y, sample_weight)
+
         random_state = check_random_state(self.random_state)
         # numpy mtrand expects a C long which is a signed 32 bit integer under
         # Windows
@@ -1134,6 +1252,8 @@ def _fit_regressor(self, X, y, alpha, C, loss, learning_rate,
                             alpha, C,
                             self.l1_ratio,
                             dataset,
+                            validation_mask, self.early_stopping, self,
+                            int(self.n_iter_no_change),
                             max_iter, tol,
                             int(self.fit_intercept),
                             int(self.verbose),
@@ -1164,6 +1284,8 @@ def _fit_regressor(self, X, y, alpha, C, loss, learning_rate,
                           alpha, C,
                           self.l1_ratio,
                           dataset,
+                          validation_mask, self.early_stopping, self,
+                          int(self.n_iter_no_change),
                           max_iter, tol,
                           int(self.fit_intercept),
                           int(self.verbose),
@@ -1177,6 +1299,8 @@ def _fit_regressor(self, X, y, alpha, C, loss, learning_rate,
             self.t_ += self.n_iter_ * X.shape[0]
             self.intercept_ = np.atleast_1d(self.intercept_)
 
+        self._delete_validation_split()
+
 
 class SGDRegressor(BaseSGDRegressor):
     """Linear model fitted by minimizing a regularized empirical loss with SGD
@@ -1270,17 +1394,47 @@ class SGDRegressor(BaseSGDRegressor):
     learning_rate : string, optional
         The learning rate schedule:
 
-        - 'constant': eta = eta0
-        - 'optimal': eta = 1.0 / (alpha * (t + t0))
-        - 'invscaling': eta = eta0 / pow(t, power_t) [default]
+        'constant':
+            eta = eta0
+        'optimal':
+            eta = 1.0 / (alpha * (t + t0))
+            where t0 is chosen by a heuristic proposed by Leon Bottou.
+        'invscaling': [default]
+            eta = eta0 / pow(t, power_t)
+        'adaptive':
+            eta = eta0, as long as the training keeps decreasing.
+            Each time n_iter_no_change consecutive epochs fail to decrease the
+            training loss by tol or fail to increase validation score by tol if
+            early_stopping is True, the current learning rate is divided by 5.
 
-        where t0 is chosen by a heuristic proposed by Leon Bottou.
+    eta0 : double
+        The initial learning rate for the 'constant', 'invscaling' or
+        'adaptive' schedules. The default value is 0.0 as eta0 is not used by
+        the default schedule 'optimal'.
+
+    power_t : double
+        The exponent for inverse scaling learning rate [default 0.5].
+
+    early_stopping : bool, default=False
+        Whether to use early stopping to terminate training when validation.
+        score is not improving. If set to True, it will automatically set aside
+        a fraction of training data as validation and terminate training when
+        validation score is not improving by at least tol for
+        n_iter_no_change consecutive epochs.
+
+        .. versionadded:: 0.20
+
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
 
-    eta0 : double, optional
-        The initial learning rate [default 0.01].
+        .. versionadded:: 0.20
 
-    power_t : double, optional
-        The exponent for inverse scaling learning rate [default 0.25].
+    validation_fraction : float, default=0.1
+        The proportion of training data to set aside as validation set for
+        early stopping. Must be between 0 and 1.
+        Only used if early_stopping is True.
+
+        .. versionadded:: 0.20
 
     warm_start : bool, optional
         When set to True, reuse the solution of the previous call to fit as
@@ -1337,13 +1491,13 @@ class SGDRegressor(BaseSGDRegressor):
     >>> clf = linear_model.SGDRegressor()
     >>> clf.fit(X, y)
     ... #doctest: +NORMALIZE_WHITESPACE
-    SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,
-           fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',
-           loss='squared_loss', max_iter=None, n_iter=None, penalty='l2',
-           power_t=0.25, random_state=None, shuffle=True, tol=None,
+    SGDRegressor(alpha=0.0001, average=False, early_stopping=False,
+           epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
+           learning_rate='invscaling', loss='squared_loss', max_iter=None,
+           n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,
+           random_state=None, shuffle=True, tol=None, validation_fraction=0.1,
            verbose=0, warm_start=False)
 
-
     See also
     --------
     Ridge, ElasticNet, Lasso, sklearn.svm.SVR
@@ -1353,16 +1507,15 @@ def __init__(self, loss="squared_loss", penalty="l2", alpha=0.0001,
                  l1_ratio=0.15, fit_intercept=True, max_iter=None, tol=None,
                  shuffle=True, verbose=0, epsilon=DEFAULT_EPSILON,
                  random_state=None, learning_rate="invscaling", eta0=0.01,
-                 power_t=0.25, warm_start=False, average=False, n_iter=None):
-        super(SGDRegressor, self).__init__(loss=loss, penalty=penalty,
-                                           alpha=alpha, l1_ratio=l1_ratio,
-                                           fit_intercept=fit_intercept,
-                                           max_iter=max_iter, tol=tol,
-                                           shuffle=shuffle,
-                                           verbose=verbose,
-                                           epsilon=epsilon,
-                                           random_state=random_state,
-                                           learning_rate=learning_rate,
-                                           eta0=eta0, power_t=power_t,
-                                           warm_start=warm_start,
-                                           average=average, n_iter=n_iter)
+                 power_t=0.25, early_stopping=False, validation_fraction=0.1,
+                 n_iter_no_change=5, warm_start=False, average=False,
+                 n_iter=None):
+        super(SGDRegressor, self).__init__(
+            loss=loss, penalty=penalty, alpha=alpha, l1_ratio=l1_ratio,
+            fit_intercept=fit_intercept, max_iter=max_iter, tol=tol,
+            shuffle=shuffle, verbose=verbose, epsilon=epsilon,
+            random_state=random_state, learning_rate=learning_rate, eta0=eta0,
+            power_t=power_t, early_stopping=early_stopping,
+            validation_fraction=validation_fraction,
+            n_iter_no_change=n_iter_no_change, warm_start=warm_start,
+            average=average, n_iter=n_iter)
diff --git a/sklearn/linear_model/tests/test_sgd.py b/sklearn/linear_model/tests/test_sgd.py
index 18bc073139..ee1c473707 100755
--- a/sklearn/linear_model/tests/test_sgd.py
+++ b/sklearn/linear_model/tests/test_sgd.py
@@ -1,3 +1,4 @@
+
 import pickle
 import unittest
 import pytest
@@ -25,7 +26,7 @@
 from sklearn.preprocessing import LabelEncoder, scale, MinMaxScaler
 from sklearn.preprocessing import StandardScaler
 from sklearn.exceptions import ConvergenceWarning
-
+from sklearn.model_selection import train_test_split
 from sklearn.linear_model import sgd_fast
 
 
@@ -101,7 +102,8 @@ def decision_function(self, X, *args, **kw):
 true_result5 = [0, 1, 1]
 
 
-# Classification Test Case
+###############################################################################
+# Tests common to classification and regression
 
 class CommonTest(object):
 
@@ -187,6 +189,9 @@ def test_warm_start_invscaling(self):
     def test_warm_start_optimal(self):
         self._test_warm_start(X, Y, "optimal")
 
+    def test_warm_start_adaptive(self):
+        self._test_warm_start(X, Y, "adaptive")
+
     def test_input_format(self):
         # Input format tests.
         clf = self.factory(alpha=0.01, shuffle=False)
@@ -272,6 +277,68 @@ def test_sgd_bad_alpha_for_optimal_learning_rate(self):
         assert_raises(ValueError, self.factory,
                       alpha=0, learning_rate="optimal")
 
+    def test_early_stopping(self):
+        for early_stopping in [True, False]:
+            max_iter = 1000
+            clf = self.factory(early_stopping=early_stopping, tol=1e-3,
+                               max_iter=max_iter).fit(X, Y)
+            assert clf.n_iter_ < max_iter
+            assert not hasattr(clf, '_X_val')
+            assert not hasattr(clf, '_y_val')
+            assert not hasattr(clf, '_sample_weight_val')
+
+    def test_adaptive_longer_than_constant(self):
+        clf1 = self.factory(learning_rate="adaptive", eta0=0.01, tol=1e-3,
+                            max_iter=100)
+        clf1.fit(iris.data, iris.target)
+        clf2 = self.factory(learning_rate="constant", eta0=0.01, tol=1e-3,
+                            max_iter=100)
+        clf2.fit(iris.data, iris.target)
+        assert clf1.n_iter_ > clf2.n_iter_
+
+    def test_validation_set_not_used_for_training(self):
+        X, Y = iris.data, iris.target
+        validation_fraction = 0.4
+        random_state = 42
+        shuffle = False
+        clf1 = self.factory(early_stopping=True, random_state=random_state,
+                            validation_fraction=validation_fraction,
+                            learning_rate='constant', eta0=0.01,
+                            tol=None, max_iter=1000, shuffle=shuffle)
+        clf1.fit(X, Y)
+
+        idx_train, idx_val = train_test_split(
+            np.arange(X.shape[0]), test_size=validation_fraction,
+            random_state=random_state)
+        clf2 = self.factory(early_stopping=False,
+                            random_state=random_state,
+                            learning_rate='constant', eta0=0.01,
+                            tol=None, max_iter=1000, shuffle=shuffle)
+        idx_train = np.sort(idx_train)  # remove shuffling
+        clf2.fit(X[idx_train], np.array(Y)[idx_train])
+
+        assert_array_equal(clf1.coef_, clf2.coef_)
+
+    @ignore_warnings(ConvergenceWarning)
+    def test_n_iter_no_change(self):
+        # test that n_iter_ increases monotonically with n_iter_no_change
+        for early_stopping in [True, False]:
+            n_iter_list = [self.factory(early_stopping=early_stopping,
+                                        n_iter_no_change=n_iter_no_change,
+                                        tol=1e-4, max_iter=1000
+                                        ).fit(X, Y).n_iter_
+                           for n_iter_no_change in [2, 3, 10]]
+            assert_array_equal(n_iter_list, sorted(n_iter_list))
+
+    def test_not_enough_sample_for_early_stopping(self):
+        # test an error is raised if the training or validation set is empty
+        clf = self.factory(early_stopping=True, validation_fraction=0.99)
+        with pytest.raises(ValueError):
+            clf.fit(X3, Y3)
+
+
+###############################################################################
+# Classification Test Case
 
 class DenseSGDClassifierTestCase(unittest.TestCase, CommonTest):
     """Test suite for the dense representation variant of SGD"""
@@ -321,6 +388,18 @@ def test_sgd_shuffle_param(self):
         # Test parameter validity check
         assert_raises(ValueError, self.factory, shuffle="false")
 
+    def test_sgd_early_stopping_param(self):
+        # Test parameter validity check
+        assert_raises(ValueError, self.factory, early_stopping="false")
+
+    def test_sgd_validation_fraction(self):
+        # Test parameter validity check
+        assert_raises(ValueError, self.factory, validation_fraction=-.1)
+
+    def test_sgd_n_iter_no_change(self):
+        # Test parameter validity check
+        assert_raises(ValueError, self.factory, n_iter_no_change=0)
+
     def test_argument_coef(self):
         # Checks coef_init not allowed as model argument (only fit)
         # Provided coef_ does not match dataset
@@ -338,6 +417,11 @@ def test_set_intercept(self):
         assert_raises(ValueError, self.factory().fit,
                       X, Y, intercept_init=np.zeros((3,)))
 
+    def test_sgd_early_stopping_with_partial_fit(self):
+        # Test parameter validity check
+        assert_raises(ValueError,
+                      self.factory(early_stopping=True).partial_fit, X, Y)
+
     def test_set_intercept_binary(self):
         # Checks intercept_ shape for the warm starts in binary case
         self.factory().fit(X5, Y5, intercept_init=0)
@@ -809,6 +893,9 @@ def test_partial_fit_equal_fit_optimal(self):
     def test_partial_fit_equal_fit_invscaling(self):
         self._test_partial_fit_equal_fit("invscaling")
 
+    def test_partial_fit_equal_fit_adaptive(self):
+        self._test_partial_fit_equal_fit("adaptive")
+
     def test_regression_losses(self):
         clf = self.factory(alpha=0.01, learning_rate="constant",
                            eta0=0.1, loss="epsilon_insensitive")
@@ -1093,6 +1180,9 @@ def test_partial_fit_equal_fit_optimal(self):
     def test_partial_fit_equal_fit_invscaling(self):
         self._test_partial_fit_equal_fit("invscaling")
 
+    def test_partial_fit_equal_fit_adaptive(self):
+        self._test_partial_fit_equal_fit("adaptive")
+
     def test_loss_function_epsilon(self):
         clf = self.factory(epsilon=0.9)
         clf.set_params(epsilon=0.1)
diff --git a/sklearn/manifold/isomap.py b/sklearn/manifold/isomap.py
index f649237448..5d6ae04ce4 100755
--- a/sklearn/manifold/isomap.py
+++ b/sklearn/manifold/isomap.py
@@ -100,7 +100,7 @@ def __init__(self, n_neighbors=5, n_components=2, eigen_solver='auto',
         self.n_jobs = n_jobs
 
     def _fit_transform(self, X):
-        X = check_array(X)
+        X = check_array(X, accept_sparse='csr')
         self.nbrs_ = NearestNeighbors(n_neighbors=self.n_neighbors,
                                       algorithm=self.neighbors_algorithm,
                                       n_jobs=self.n_jobs)
@@ -157,7 +157,7 @@ def fit(self, X, y=None):
             numpy array, precomputed tree, or NearestNeighbors
             object.
 
-        y: Ignored
+        y : Ignored
 
         Returns
         -------
@@ -175,7 +175,7 @@ def fit_transform(self, X, y=None):
             Training vector, where n_samples in the number of samples
             and n_features is the number of features.
 
-        y: Ignored
+        y : Ignored
 
         Returns
         -------
diff --git a/sklearn/manifold/locally_linear.py b/sklearn/manifold/locally_linear.py
index 2d3257bf54..570b0402cd 100755
--- a/sklearn/manifold/locally_linear.py
+++ b/sklearn/manifold/locally_linear.py
@@ -69,10 +69,9 @@ def barycenter_kneighbors_graph(X, n_neighbors, reg=1e-3, n_jobs=1):
 
     Parameters
     ----------
-    X : {array-like, sparse matrix, BallTree, KDTree, NearestNeighbors}
+    X : {array-like, NearestNeighbors}
         Sample data, shape = (n_samples, n_features), in the form of a
-        numpy array, sparse array, precomputed tree, or NearestNeighbors
-        object.
+        numpy array or a NearestNeighbors object.
 
     n_neighbors : int
         Number of neighbors for each sample.
@@ -194,10 +193,9 @@ def locally_linear_embedding(
 
     Parameters
     ----------
-    X : {array-like, sparse matrix, BallTree, KDTree, NearestNeighbors}
+    X : {array-like, NearestNeighbors}
         Sample data, shape = (n_samples, n_features), in the form of a
-        numpy array, sparse array, precomputed tree, or NearestNeighbors
-        object.
+        numpy array or a NearestNeighbors object.
 
     n_neighbors : integer
         number of neighbors to consider for each point.
@@ -657,7 +655,7 @@ def fit(self, X, y=None):
         X : array-like of shape [n_samples, n_features]
             training set.
 
-        y: Ignored
+        y : Ignored
 
         Returns
         -------
@@ -674,7 +672,7 @@ def fit_transform(self, X, y=None):
         X : array-like of shape [n_samples, n_features]
             training set.
 
-        y: Ignored
+        y : Ignored
 
         Returns
         -------
diff --git a/sklearn/manifold/mds.py b/sklearn/manifold/mds.py
index 3890c4e40b..5aa032b89f 100755
--- a/sklearn/manifold/mds.py
+++ b/sklearn/manifold/mds.py
@@ -379,7 +379,7 @@ def fit(self, X, y=None, init=None):
             Input data. If ``dissimilarity=='precomputed'``, the input should
             be the dissimilarity matrix.
 
-        y: Ignored
+        y : Ignored
 
         init : ndarray, shape (n_samples,), optional, default: None
             Starting configuration of the embedding to initialize the SMACOF
@@ -399,7 +399,7 @@ def fit_transform(self, X, y=None, init=None):
             Input data. If ``dissimilarity=='precomputed'``, the input should
             be the dissimilarity matrix.
 
-        y: Ignored
+        y : Ignored
 
         init : ndarray, shape (n_samples,), optional, default: None
             Starting configuration of the embedding to initialize the SMACOF
diff --git a/sklearn/manifold/spectral_embedding_.py b/sklearn/manifold/spectral_embedding_.py
index bc367b4e5a..3dca967a54 100755
--- a/sklearn/manifold/spectral_embedding_.py
+++ b/sklearn/manifold/spectral_embedding_.py
@@ -487,8 +487,6 @@ def fit(self, X, y=None):
             Interpret X as precomputed adjacency graph computed from
             samples.
 
-        Y: Ignored
-
         Returns
         -------
         self : object
@@ -529,8 +527,6 @@ def fit_transform(self, X, y=None):
             Interpret X as precomputed adjacency graph computed from
             samples.
 
-        Y: Ignored
-
         Returns
         -------
         X_new : array-like, shape (n_samples, n_components)
diff --git a/sklearn/manifold/tests/test_isomap.py b/sklearn/manifold/tests/test_isomap.py
index 8006872b78..d1a68164ee 100755
--- a/sklearn/manifold/tests/test_isomap.py
+++ b/sklearn/manifold/tests/test_isomap.py
@@ -10,6 +10,8 @@
 from sklearn import preprocessing
 from sklearn.utils.testing import assert_less
 
+from scipy.sparse import rand as sparse_rand
+
 eigen_solvers = ['auto', 'dense', 'arpack']
 path_methods = ['auto', 'FW', 'D']
 
@@ -122,3 +124,15 @@ def test_isomap_clone_bug():
         model.fit(np.random.rand(50, 2))
         assert_equal(model.nbrs_.n_neighbors,
                      n_neighbors)
+
+
+def test_sparse_input():
+    X = sparse_rand(100, 3, density=0.1, format='csr')
+
+    # Should not error
+    for eigen_solver in eigen_solvers:
+        for path_method in path_methods:
+            clf = manifold.Isomap(n_components=2,
+                                  eigen_solver=eigen_solver,
+                                  path_method=path_method)
+            clf.fit(X)
diff --git a/sklearn/metrics/classification.py b/sklearn/metrics/classification.py
index f372461873..4e2d0ff399 100755
--- a/sklearn/metrics/classification.py
+++ b/sklearn/metrics/classification.py
@@ -1454,7 +1454,7 @@ def classification_report(y_true, y_pred, labels=None, target_names=None,
     digits : int
         Number of digits for formatting output floating point values
 
-    output_dict: bool (default = False)
+    output_dict : bool (default = False)
         If True, return output as dict
 
     Returns
diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py
index db73380faf..381f51777b 100755
--- a/sklearn/metrics/cluster/supervised.py
+++ b/sklearn/metrics/cluster/supervised.py
@@ -25,14 +25,23 @@
 from ...utils.fixes import comb
 
 
-def comb2(n):
+def _comb2(n):
     # the exact version is faster for k == 2: use it by default globally in
     # this module instead of the float approximate variant
     return comb(n, 2, exact=1)
 
 
 def check_clusterings(labels_true, labels_pred):
-    """Check that the two clusterings matching 1D integer arrays."""
+    """Check that the labels arrays are 1D and of same dimension.
+
+    Parameters
+    ----------
+    labels_true : int array, shape = [n_samples]
+        The true labels
+
+    labels_pred : int array, shape = [n_samples]
+        The predicted labels
+    """
     labels_true = np.asarray(labels_true)
     labels_pred = np.asarray(labels_pred)
 
@@ -205,11 +214,11 @@ def adjusted_rand_score(labels_true, labels_pred):
 
     # Compute the ARI using the contingency data
     contingency = contingency_matrix(labels_true, labels_pred, sparse=True)
-    sum_comb_c = sum(comb2(n_c) for n_c in np.ravel(contingency.sum(axis=1)))
-    sum_comb_k = sum(comb2(n_k) for n_k in np.ravel(contingency.sum(axis=0)))
-    sum_comb = sum(comb2(n_ij) for n_ij in contingency.data)
+    sum_comb_c = sum(_comb2(n_c) for n_c in np.ravel(contingency.sum(axis=1)))
+    sum_comb_k = sum(_comb2(n_k) for n_k in np.ravel(contingency.sum(axis=0)))
+    sum_comb = sum(_comb2(n_ij) for n_ij in contingency.data)
 
-    prod_comb = (sum_comb_c * sum_comb_k) / comb2(n_samples)
+    prod_comb = (sum_comb_c * sum_comb_k) / _comb2(n_samples)
     mean_comb = (sum_comb_k + sum_comb_c) / 2.
     return (sum_comb - prod_comb) / (mean_comb - prod_comb)
 
@@ -861,7 +870,13 @@ def fowlkes_mallows_score(labels_true, labels_pred, sparse=False):
 
 
 def entropy(labels):
-    """Calculates the entropy for a labeling."""
+    """Calculates the entropy for a labeling.
+
+    Parameters
+    ----------
+    labels : int array, shape = [n_samples]
+        The labels
+    """
     if len(labels) == 0:
         return 1.0
     label_idx = np.unique(labels, return_inverse=True)[1]
diff --git a/sklearn/metrics/cluster/unsupervised.py b/sklearn/metrics/cluster/unsupervised.py
index 7c954acea5..4e34cd6cab 100755
--- a/sklearn/metrics/cluster/unsupervised.py
+++ b/sklearn/metrics/cluster/unsupervised.py
@@ -20,6 +20,16 @@
 
 
 def check_number_of_labels(n_labels, n_samples):
+    """Check that number of labels are valid.
+
+    Parameters
+    ----------
+    n_labels : int
+        Number of labels
+
+    n_samples : int
+        Number of samples
+    """
     if not 1 < n_labels < n_samples:
         raise ValueError("Number of labels is %d. Valid values are 2 "
                          "to n_samples - 1 (inclusive)" % n_labels)
diff --git a/sklearn/metrics/regression.py b/sklearn/metrics/regression.py
index 4bc88561a7..e9084a4276 100755
--- a/sklearn/metrics/regression.py
+++ b/sklearn/metrics/regression.py
@@ -314,7 +314,7 @@ def mean_squared_log_error(y_true, y_pred,
         raise ValueError("Mean Squared Logarithmic Error cannot be used when "
                          "targets contain negative values.")
 
-    return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),
+    return mean_squared_error(np.log1p(y_true), np.log1p(y_pred),
                               sample_weight, multioutput)
 
 
diff --git a/sklearn/metrics/tests/test_classification.py b/sklearn/metrics/tests/test_classification.py
index 539d889082..be4545eb0d 100755
--- a/sklearn/metrics/tests/test_classification.py
+++ b/sklearn/metrics/tests/test_classification.py
@@ -667,50 +667,6 @@ def test_zero_precision_recall():
         np.seterr(**old_error_settings)
 
 
-def test_confusion_matrix_multiclass():
-    # Test confusion matrix - multi-class case
-    y_true, y_pred, _ = make_prediction(binary=False)
-
-    def test(y_true, y_pred, string_type=False):
-        # compute confusion matrix with default labels introspection
-        cm = confusion_matrix(y_true, y_pred)
-        assert_array_equal(cm, [[19, 4, 1],
-                                [4, 3, 24],
-                                [0, 2, 18]])
-
-        # compute confusion matrix with explicit label ordering
-        labels = ['0', '2', '1'] if string_type else [0, 2, 1]
-        cm = confusion_matrix(y_true,
-                              y_pred,
-                              labels=labels)
-        assert_array_equal(cm, [[19, 1, 4],
-                                [0, 18, 2],
-                                [4, 24, 3]])
-
-    test(y_true, y_pred)
-    test(list(str(y) for y in y_true),
-         list(str(y) for y in y_pred),
-         string_type=True)
-
-
-def test_confusion_matrix_sample_weight():
-    """Test confusion matrix - case with sample_weight"""
-    y_true, y_pred, _ = make_prediction(binary=False)
-
-    weights = [.1] * 25 + [.2] * 25 + [.3] * 25
-
-    cm = confusion_matrix(y_true, y_pred, sample_weight=weights)
-
-    true_cm = (.1 * confusion_matrix(y_true[:25], y_pred[:25]) +
-               .2 * confusion_matrix(y_true[25:50], y_pred[25:50]) +
-               .3 * confusion_matrix(y_true[50:], y_pred[50:]))
-
-    assert_array_almost_equal(cm, true_cm)
-    assert_raises(
-        ValueError, confusion_matrix, y_true, y_pred,
-        sample_weight=weights[:-1])
-
-
 def test_confusion_matrix_multiclass_subset_labels():
     # Test confusion matrix - multi-class case with subset of labels
     y_true, y_pred, _ = make_prediction(binary=False)
diff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py
index f835fdd507..b858868a74 100755
--- a/sklearn/metrics/tests/test_common.py
+++ b/sklearn/metrics/tests/test_common.py
@@ -16,20 +16,17 @@
 from sklearn.utils.validation import check_random_state
 from sklearn.utils import shuffle
 
-from sklearn.utils.testing import assert_almost_equal
-from sklearn.utils.testing import assert_array_almost_equal
+from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_array_equal
+from sklearn.utils.testing import assert_array_less
 from sklearn.utils.testing import assert_equal
-from sklearn.utils.testing import assert_greater
-from sklearn.utils.testing import assert_not_equal
-from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import assert_raise_message
-from sklearn.utils.testing import assert_true
+from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import ignore_warnings
 
 from sklearn.metrics import accuracy_score
-from sklearn.metrics import balanced_accuracy_score
 from sklearn.metrics import average_precision_score
+from sklearn.metrics import balanced_accuracy_score
 from sklearn.metrics import brier_score_loss
 from sklearn.metrics import cohen_kappa_score
 from sklearn.metrics import confusion_matrix
@@ -47,17 +44,14 @@
 from sklearn.metrics import mean_absolute_error
 from sklearn.metrics import mean_squared_error
 from sklearn.metrics import median_absolute_error
+from sklearn.metrics import precision_recall_curve
 from sklearn.metrics import precision_score
 from sklearn.metrics import r2_score
 from sklearn.metrics import recall_score
 from sklearn.metrics import roc_auc_score
+from sklearn.metrics import roc_curve
 from sklearn.metrics import zero_one_loss
 
-# TODO Curve are currently not covered by invariance test
-# from sklearn.metrics import precision_recall_curve
-# from sklearn.metrics import roc_curve
-
-
 from sklearn.metrics.base import _average_binary_score
 
 
@@ -106,7 +100,17 @@
     "accuracy_score": accuracy_score,
     "balanced_accuracy_score": balanced_accuracy_score,
     "unnormalized_accuracy_score": partial(accuracy_score, normalize=False),
-    "confusion_matrix": confusion_matrix,
+
+    # `confusion_matrix` returns absolute values and hence behaves unnormalized
+    # . Naming it with an unnormalized_ prefix is neccessary for this module to
+    # skip sample_weight scaling checks which will fail for unnormalized
+    # metrics.
+    "unnormalized_confusion_matrix": confusion_matrix,
+    "normalized_confusion_matrix": lambda *args, **kwargs: (
+        confusion_matrix(*args, **kwargs).astype('float') / confusion_matrix(
+            *args, **kwargs).sum(axis=1)[:, np.newaxis]
+    ),
+
     "hamming_loss": hamming_loss,
 
     "jaccard_similarity_score": jaccard_similarity_score,
@@ -151,6 +155,39 @@
     "cohen_kappa_score": cohen_kappa_score,
 }
 
+
+def precision_recall_curve_padded_thresholds(*args, **kwargs):
+    """
+    The dimensions of precision-recall pairs and the threshold array as
+    returned by the precision_recall_curve do not match. See
+    func:`sklearn.metrics.precision_recall_curve`
+
+    This prevents implicit conversion of return value triple to an higher
+    dimensional np.array of dtype('float64') (it will be of dtype('object)
+    instead). This again is needed for assert_array_equal to work correctly.
+
+    As a workaround we pad the threshold array with NaN values to match
+    the dimension of precision and recall arrays respectively.
+    """
+    precision, recall, thresholds = precision_recall_curve(*args, **kwargs)
+
+    pad_threshholds = len(precision) - len(thresholds)
+
+    return np.array([
+        precision,
+        recall,
+        np.pad(thresholds,
+               pad_width=(0, pad_threshholds),
+               mode='constant',
+               constant_values=[np.nan])
+    ])
+
+
+CURVE_METRICS = {
+    "roc_curve": roc_curve,
+    "precision_recall_curve": precision_recall_curve_padded_thresholds,
+}
+
 THRESHOLDED_METRICS = {
     "coverage_error": coverage_error,
     "label_ranking_loss": label_ranking_loss,
@@ -185,6 +222,7 @@
 ALL_METRICS.update(THRESHOLDED_METRICS)
 ALL_METRICS.update(CLASSIFICATION_METRICS)
 ALL_METRICS.update(REGRESSION_METRICS)
+ALL_METRICS.update(CURVE_METRICS)
 
 # Lists of metrics with common properties
 # ---------------------------------------
@@ -232,6 +270,10 @@
     "f1_score",
     "f2_score",
     "f0.5_score",
+
+    # curves
+    "roc_curve",
+    "precision_recall_curve",
 }
 
 # Metric undefined with "binary" or "multiclass" input
@@ -251,6 +293,7 @@
 # Metrics with a "pos_label" argument
 METRICS_WITH_POS_LABEL = {
     "roc_curve",
+    "precision_recall_curve",
 
     "brier_score_loss",
 
@@ -271,7 +314,10 @@
 # TODO: Handle multi_class metrics that has a labels argument as well as a
 # decision function argument. e.g hinge_loss
 METRICS_WITH_LABELS = {
-    "confusion_matrix",
+    "unnormalized_confusion_matrix",
+    "normalized_confusion_matrix",
+    "roc_curve",
+    "precision_recall_curve",
 
     "hamming_loss",
 
@@ -364,7 +410,10 @@
     "balanced_accuracy_score",
     "explained_variance_score",
     "r2_score",
-    "confusion_matrix",
+    "unnormalized_confusion_matrix",
+    "normalized_confusion_matrix",
+    "roc_curve",
+    "precision_recall_curve",
 
     "precision_score", "recall_score", "f2_score", "f0.5_score",
 
@@ -378,11 +427,6 @@
 
 # No Sample weight support
 METRICS_WITHOUT_SAMPLE_WEIGHT = {
-    "confusion_matrix", # Left this one here because the tests in this file do
-                        # not work for confusion_matrix, as its output is a
-                        # matrix instead of a number. Testing of
-                        # confusion_matrix with sample_weight is in
-                        # test_classification.py
     "median_absolute_error",
 }
 
@@ -407,15 +451,17 @@ def test_symmetry():
     # Symmetric metric
     for name in SYMMETRIC_METRICS:
         metric = ALL_METRICS[name]
-        assert_almost_equal(metric(y_true, y_pred),
-                            metric(y_pred, y_true),
-                            err_msg="%s is not symmetric" % name)
+        assert_allclose(metric(y_true, y_pred), metric(y_pred, y_true),
+                        err_msg="%s is not symmetric" % name)
 
     # Not symmetric metrics
     for name in NOT_SYMMETRIC_METRICS:
         metric = ALL_METRICS[name]
-        assert_true(np.any(metric(y_true, y_pred) != metric(y_pred, y_true)),
-                    msg="%s seems to be symmetric" % name)
+
+        # use context manager to supply custom error message
+        with assert_raises(AssertionError) as cm:
+            assert_array_equal(metric(y_true, y_pred), metric(y_pred, y_true))
+            cm.msg = ("%s seems to be symmetric" % name)
 
 
 @pytest.mark.parametrize(
@@ -429,10 +475,9 @@ def test_sample_order_invariance(name):
 
     with ignore_warnings():
         metric = ALL_METRICS[name]
-        assert_almost_equal(metric(y_true, y_pred),
-                            metric(y_true_shuffle, y_pred_shuffle),
-                            err_msg="%s is not sample order invariant"
-                                    % name)
+        assert_allclose(metric(y_true, y_pred),
+                        metric(y_true_shuffle, y_pred_shuffle),
+                        err_msg="%s is not sample order invariant" % name)
 
 
 @ignore_warnings
@@ -451,28 +496,24 @@ def test_sample_order_invariance_multilabel_and_multioutput():
 
     for name in MULTILABELS_METRICS:
         metric = ALL_METRICS[name]
-        assert_almost_equal(metric(y_true, y_pred),
-                            metric(y_true_shuffle, y_pred_shuffle),
-                            err_msg="%s is not sample order invariant"
-                                    % name)
+        assert_allclose(metric(y_true, y_pred),
+                        metric(y_true_shuffle, y_pred_shuffle),
+                        err_msg="%s is not sample order invariant" % name)
 
     for name in THRESHOLDED_MULTILABEL_METRICS:
         metric = ALL_METRICS[name]
-        assert_almost_equal(metric(y_true, y_score),
-                            metric(y_true_shuffle, y_score_shuffle),
-                            err_msg="%s is not sample order invariant"
-                                    % name)
+        assert_allclose(metric(y_true, y_score),
+                        metric(y_true_shuffle, y_score_shuffle),
+                        err_msg="%s is not sample order invariant" % name)
 
     for name in MULTIOUTPUT_METRICS:
         metric = ALL_METRICS[name]
-        assert_almost_equal(metric(y_true, y_score),
-                            metric(y_true_shuffle, y_score_shuffle),
-                            err_msg="%s is not sample order invariant"
-                                    % name)
-        assert_almost_equal(metric(y_true, y_pred),
-                            metric(y_true_shuffle, y_pred_shuffle),
-                            err_msg="%s is not sample order invariant"
-                                    % name)
+        assert_allclose(metric(y_true, y_score),
+                        metric(y_true_shuffle, y_score_shuffle),
+                        err_msg="%s is not sample order invariant" % name)
+        assert_allclose(metric(y_true, y_pred),
+                        metric(y_true_shuffle, y_pred_shuffle),
+                        err_msg="%s is not sample order invariant" % name)
 
 
 @pytest.mark.parametrize(
@@ -487,8 +528,8 @@ def test_format_invariance_with_1d_vectors(name):
     y2_list = list(y2)
 
     y1_1d, y2_1d = np.array(y1), np.array(y2)
-    assert_equal(y1_1d.ndim, 1)
-    assert_equal(y2_1d.ndim, 1)
+    assert_array_equal(y1_1d.ndim, 1)
+    assert_array_equal(y2_1d.ndim, 1)
     y1_column = np.reshape(y1_1d, (-1, 1))
     y2_column = np.reshape(y2_1d, (-1, 1))
     y1_row = np.reshape(y1_1d, (1, -1))
@@ -499,46 +540,42 @@ def test_format_invariance_with_1d_vectors(name):
 
         measure = metric(y1, y2)
 
-        assert_almost_equal(metric(y1_list, y2_list), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with list" % name)
+        assert_allclose(metric(y1_list, y2_list), measure,
+                        err_msg="%s is not representation invariant with list"
+                                "" % name)
 
-        assert_almost_equal(metric(y1_1d, y2_1d), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with np-array-1d" % name)
+        assert_allclose(metric(y1_1d, y2_1d), measure,
+                        err_msg="%s is not representation invariant with "
+                                "np-array-1d" % name)
 
-        assert_almost_equal(metric(y1_column, y2_column), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with np-array-column" % name)
+        assert_allclose(metric(y1_column, y2_column), measure,
+                        err_msg="%s is not representation invariant with "
+                                "np-array-column" % name)
 
         # Mix format support
-        assert_almost_equal(metric(y1_1d, y2_list), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix np-array-1d and list" % name)
-
-        assert_almost_equal(metric(y1_list, y2_1d), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix np-array-1d and list" % name)
-
-        assert_almost_equal(metric(y1_1d, y2_column), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix np-array-1d and np-array-column"
-                                    % name)
-
-        assert_almost_equal(metric(y1_column, y2_1d), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix np-array-1d and np-array-column"
-                                    % name)
-
-        assert_almost_equal(metric(y1_list, y2_column), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix list and np-array-column"
-                                    % name)
-
-        assert_almost_equal(metric(y1_column, y2_list), measure,
-                            err_msg="%s is not representation invariant "
-                                    "with mix list and np-array-column"
-                                    % name)
+        assert_allclose(metric(y1_1d, y2_list), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "np-array-1d and list" % name)
+
+        assert_allclose(metric(y1_list, y2_1d), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "np-array-1d and list" % name)
+
+        assert_allclose(metric(y1_1d, y2_column), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "np-array-1d and np-array-column" % name)
+
+        assert_allclose(metric(y1_column, y2_1d), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "np-array-1d and np-array-column" % name)
+
+        assert_allclose(metric(y1_list, y2_column), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "list and np-array-column" % name)
+
+        assert_allclose(metric(y1_column, y2_list), measure,
+                        err_msg="%s is not representation invariant with mix "
+                                "list and np-array-column" % name)
 
         # These mix representations aren't allowed
         assert_raises(ValueError, metric, y1_1d, y2_row)
@@ -723,10 +760,10 @@ def test_multioutput_regression_invariance_to_dimension_shuffling(name):
 
     for _ in range(3):
         perm = random_state.permutation(y_true.shape[1])
-        assert_almost_equal(metric(y_true[:, perm], y_pred[:, perm]),
-                            error,
-                            err_msg="%s is not dimension shuffling "
-                                    "invariant" % name)
+        assert_allclose(metric(y_true[:, perm], y_pred[:, perm]),
+                        error,
+                        err_msg="%s is not dimension shuffling invariant" % (
+                            name))
 
 
 @ignore_warnings
@@ -760,12 +797,10 @@ def test_multilabel_representation_invariance():
         measure = metric(y1, y2)
 
         # Check representation invariance
-        assert_almost_equal(metric(y1_sparse_indicator,
-                                   y2_sparse_indicator),
-                            measure,
-                            err_msg="%s failed representation invariance  "
-                                    "between dense and sparse indicator "
-                                    "formats." % name)
+        assert_allclose(metric(y1_sparse_indicator, y2_sparse_indicator),
+                        measure,
+                        err_msg="%s failed representation invariance between "
+                                "dense and sparse indicator formats." % name)
 
 
 @pytest.mark.parametrize('name', MULTILABELS_METRICS)
@@ -794,10 +829,11 @@ def test_normalize_option_binary_classification(name):
 
     metrics = ALL_METRICS[name]
     measure = metrics(y_true, y_pred, normalize=True)
-    assert_greater(measure, 0,
-                   msg="We failed to test correctly the normalize option")
-    assert_almost_equal(metrics(y_true, y_pred, normalize=False)
-                        / n_samples, measure)
+    assert_array_less(-1.0 * measure, 0,
+                      err_msg="We failed to test correctly the normalize "
+                              "option")
+    assert_allclose(metrics(y_true, y_pred, normalize=False) / n_samples,
+                    measure)
 
 
 @pytest.mark.parametrize('name', METRICS_WITH_NORMALIZE_OPTION)
@@ -810,10 +846,11 @@ def test_normalize_option_multiclass_classification(name):
 
     metrics = ALL_METRICS[name]
     measure = metrics(y_true, y_pred, normalize=True)
-    assert_greater(measure, 0,
-                   msg="We failed to test correctly the normalize option")
-    assert_almost_equal(metrics(y_true, y_pred, normalize=False)
-                        / n_samples, measure)
+    assert_array_less(-1.0 * measure, 0,
+                      err_msg="We failed to test correctly the normalize "
+                              "option")
+    assert_allclose(metrics(y_true, y_pred, normalize=False) / n_samples,
+                    measure)
 
 
 def test_normalize_option_multilabel_classification():
@@ -841,11 +878,11 @@ def test_normalize_option_multilabel_classification():
     for name in METRICS_WITH_NORMALIZE_OPTION:
         metrics = ALL_METRICS[name]
         measure = metrics(y_true, y_pred, normalize=True)
-        assert_greater(measure, 0,
-                       msg="We failed to test correctly the normalize option")
-        assert_almost_equal(metrics(y_true, y_pred, normalize=False)
-                            / n_samples, measure,
-                            err_msg="Failed with %s" % name)
+        assert_array_less(-1.0 * measure, 0,
+                          err_msg="We failed to test correctly the normalize "
+                                  "option")
+        assert_allclose(metrics(y_true, y_pred, normalize=False) / n_samples,
+                        measure, err_msg="Failed with %s" % name)
 
 
 @ignore_warnings
@@ -855,38 +892,36 @@ def _check_averaging(metric, y_true, y_pred, y_true_binarize, y_pred_binarize,
 
     # No averaging
     label_measure = metric(y_true, y_pred, average=None)
-    assert_array_almost_equal(label_measure,
-                              [metric(y_true_binarize[:, i],
-                                      y_pred_binarize[:, i])
-                               for i in range(n_classes)])
+    assert_allclose(label_measure,
+                    [metric(y_true_binarize[:, i], y_pred_binarize[:, i])
+                     for i in range(n_classes)])
 
     # Micro measure
     micro_measure = metric(y_true, y_pred, average="micro")
-    assert_almost_equal(micro_measure, metric(y_true_binarize.ravel(),
-                                              y_pred_binarize.ravel()))
+    assert_allclose(micro_measure,
+                    metric(y_true_binarize.ravel(), y_pred_binarize.ravel()))
 
     # Macro measure
     macro_measure = metric(y_true, y_pred, average="macro")
-    assert_almost_equal(macro_measure, np.mean(label_measure))
+    assert_allclose(macro_measure, np.mean(label_measure))
 
     # Weighted measure
     weights = np.sum(y_true_binarize, axis=0, dtype=int)
 
     if np.sum(weights) != 0:
         weighted_measure = metric(y_true, y_pred, average="weighted")
-        assert_almost_equal(weighted_measure, np.average(label_measure,
-                                                         weights=weights))
+        assert_allclose(weighted_measure,
+                        np.average(label_measure, weights=weights))
     else:
         weighted_measure = metric(y_true, y_pred, average="weighted")
-        assert_almost_equal(weighted_measure, 0)
+        assert_allclose(weighted_measure, 0)
 
     # Sample measure
     if is_multilabel:
         sample_measure = metric(y_true, y_pred, average="samples")
-        assert_almost_equal(sample_measure,
-                            np.mean([metric(y_true_binarize[i],
-                                            y_pred_binarize[i])
-                                     for i in range(n_samples)]))
+        assert_allclose(sample_measure,
+                        np.mean([metric(y_true_binarize[i], y_pred_binarize[i])
+                                 for i in range(n_samples)]))
 
     assert_raises(ValueError, metric, y_true, y_pred, average="unknown")
     assert_raises(ValueError, metric, y_true, y_pred, average="garbage")
@@ -985,7 +1020,8 @@ def check_sample_weight_invariance(name, metric, y1, y2):
 
     # check that unit weights gives the same score as no weight
     unweighted_score = metric(y1, y2, sample_weight=None)
-    assert_almost_equal(
+
+    assert_allclose(
         unweighted_score,
         metric(y1, y2, sample_weight=np.ones(shape=len(y1))),
         err_msg="For %s sample_weight=None is not equivalent to "
@@ -993,25 +1029,28 @@ def check_sample_weight_invariance(name, metric, y1, y2):
 
     # check that the weighted and unweighted scores are unequal
     weighted_score = metric(y1, y2, sample_weight=sample_weight)
-    assert_not_equal(
-        unweighted_score, weighted_score,
-        msg="Unweighted and weighted scores are unexpectedly "
-            "equal (%f) for %s" % (weighted_score, name))
+
+    # use context manager to supply custom error message
+    with assert_raises(AssertionError) as cm:
+        assert_allclose(unweighted_score, weighted_score)
+        cm.msg = ("Unweighted and weighted scores are unexpectedly almost "
+                  "equal (%s) and (%s) for %s" % (unweighted_score,
+                                                  weighted_score, name))
 
     # check that sample_weight can be a list
     weighted_score_list = metric(y1, y2,
                                  sample_weight=sample_weight.tolist())
-    assert_almost_equal(
+    assert_allclose(
         weighted_score, weighted_score_list,
         err_msg=("Weighted scores for array and list "
-                 "sample_weight input are not equal (%f != %f) for %s") % (
+                 "sample_weight input are not equal (%s != %s) for %s") % (
                      weighted_score, weighted_score_list, name))
 
     # check that integer weights is the same as repeated samples
     repeat_weighted_score = metric(
         np.repeat(y1, sample_weight, axis=0),
         np.repeat(y2, sample_weight, axis=0), sample_weight=None)
-    assert_almost_equal(
+    assert_allclose(
         weighted_score, repeat_weighted_score,
         err_msg="Weighting %s is not equal to repeating samples" % name)
 
@@ -1026,17 +1065,17 @@ def check_sample_weight_invariance(name, metric, y1, y2):
                                    sample_weight=sample_weight_subset)
     weighted_score_zeroed = metric(y1, y2,
                                    sample_weight=sample_weight_zeroed)
-    assert_almost_equal(
+    assert_allclose(
         weighted_score_subset, weighted_score_zeroed,
         err_msg=("Zeroing weights does not give the same result as "
-                 "removing the corresponding samples (%f != %f) for %s" %
+                 "removing the corresponding samples (%s != %s) for %s" %
                  (weighted_score_zeroed, weighted_score_subset, name)))
 
     if not name.startswith('unnormalized'):
         # check that the score is invariant under scaling of the weights by a
         # common factor
         for scaling in [2, 0.3]:
-            assert_almost_equal(
+            assert_allclose(
                 weighted_score,
                 metric(y1, y2, sample_weight=sample_weight * scaling),
                 err_msg="%s sample_weight is not invariant "
diff --git a/sklearn/metrics/tests/test_ranking.py b/sklearn/metrics/tests/test_ranking.py
index 28b79e9b84..5e9a8a0c84 100755
--- a/sklearn/metrics/tests/test_ranking.py
+++ b/sklearn/metrics/tests/test_ranking.py
@@ -539,21 +539,6 @@ def test_precision_recall_curve():
     assert_equal(p.size, t.size + 1)
 
 
-def test_precision_recall_curve_pos_label():
-    y_true, _, probas_pred = make_prediction(binary=False)
-    pos_label = 2
-    p, r, thresholds = precision_recall_curve(y_true,
-                                              probas_pred[:, pos_label],
-                                              pos_label=pos_label)
-    p2, r2, thresholds2 = precision_recall_curve(y_true == pos_label,
-                                                 probas_pred[:, pos_label])
-    assert_array_almost_equal(p, p2)
-    assert_array_almost_equal(r, r2)
-    assert_array_almost_equal(thresholds, thresholds2)
-    assert_equal(p.size, r.size)
-    assert_equal(p.size, thresholds.size + 1)
-
-
 def _test_precision_recall_curve(y_true, probas_pred):
     # Test Precision-Recall and aread under PR curve
     p, r, thresholds = precision_recall_curve(y_true, probas_pred)
diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py
index a9f66740f2..1cf8a0fb93 100755
--- a/sklearn/mixture/base.py
+++ b/sklearn/mixture/base.py
@@ -172,7 +172,7 @@ def _initialize(self, X, resp):
     def fit(self, X, y=None):
         """Estimate model parameters with the EM algorithm.
 
-        The method fit the model `n_init` times and set the parameters with
+        The method fits the model `n_init` times and set the parameters with
         which the model has the largest likelihood or lower bound. Within each
         trial, the method iterates between E-step and M-step for `max_iter`
         times until the change of likelihood or lower bound is less than
@@ -188,6 +188,32 @@ def fit(self, X, y=None):
         -------
         self
         """
+        self.fit_predict(X, y)
+        return self
+
+    def fit_predict(self, X, y=None):
+        """Estimate model parameters using X and predict the labels for X.
+
+        The method fits the model n_init times and sets the parameters with
+        which the model has the largest likelihood or lower bound. Within each
+        trial, the method iterates between E-step and M-step for `max_iter`
+        times until the change of likelihood or lower bound is less than
+        `tol`, otherwise, a `ConvergenceWarning` is raised. After fitting, it
+        predicts the most probable label for the input data points.
+
+        .. versionadded:: 0.20
+
+        Parameters
+        ----------
+        X : array-like, shape (n_samples, n_features)
+            List of n_features-dimensional data points. Each row
+            corresponds to a single data point.
+
+        Returns
+        -------
+        labels : array, shape (n_samples,)
+            Component labels.
+        """
         X = _check_X(X, self.n_components, ensure_min_samples=2)
         self._check_initial_parameters(X)
 
@@ -240,7 +266,7 @@ def fit(self, X, y=None):
         self._set_parameters(best_params)
         self.n_iter_ = best_n_iter
 
-        return self
+        return log_resp.argmax(axis=1)
 
     def _e_step(self, X):
         """E step.
diff --git a/sklearn/mixture/tests/test_bayesian_mixture.py b/sklearn/mixture/tests/test_bayesian_mixture.py
index e678c07d92..540b6265ca 100755
--- a/sklearn/mixture/tests/test_bayesian_mixture.py
+++ b/sklearn/mixture/tests/test_bayesian_mixture.py
@@ -1,12 +1,16 @@
 # Author: Wei Xue <xuewei4d@gmail.com>
 #         Thierry Guillemot <thierry.guillemot.work@gmail.com>
 # License: BSD 3 clause
+import copy
 
 import numpy as np
 from scipy.special import gammaln
 
 from sklearn.utils.testing import assert_raise_message
 from sklearn.utils.testing import assert_almost_equal
+from sklearn.utils.testing import assert_array_equal
+
+from sklearn.metrics.cluster import adjusted_rand_score
 
 from sklearn.mixture.bayesian_mixture import _log_dirichlet_norm
 from sklearn.mixture.bayesian_mixture import _log_wishart_norm
@@ -14,7 +18,7 @@
 from sklearn.mixture import BayesianGaussianMixture
 
 from sklearn.mixture.tests.test_gaussian_mixture import RandomData
-from sklearn.exceptions import ConvergenceWarning
+from sklearn.exceptions import ConvergenceWarning, NotFittedError
 from sklearn.utils.testing import assert_greater_equal, ignore_warnings
 
 
@@ -419,3 +423,49 @@ def test_invariant_translation():
             assert_almost_equal(bgmm1.means_, bgmm2.means_ - 100)
             assert_almost_equal(bgmm1.weights_, bgmm2.weights_)
             assert_almost_equal(bgmm1.covariances_, bgmm2.covariances_)
+
+
+def test_bayesian_mixture_fit_predict():
+    rng = np.random.RandomState(0)
+    rand_data = RandomData(rng, scale=7)
+    n_components = 2 * rand_data.n_components
+
+    for covar_type in COVARIANCE_TYPE:
+        bgmm1 = BayesianGaussianMixture(n_components=n_components,
+                                        max_iter=100, random_state=rng,
+                                        tol=1e-3, reg_covar=0)
+        bgmm1.covariance_type = covar_type
+        bgmm2 = copy.deepcopy(bgmm1)
+        X = rand_data.X[covar_type]
+
+        Y_pred1 = bgmm1.fit(X).predict(X)
+        Y_pred2 = bgmm2.fit_predict(X)
+        assert_array_equal(Y_pred1, Y_pred2)
+
+
+def test_bayesian_mixture_predict_predict_proba():
+    # this is the same test as test_gaussian_mixture_predict_predict_proba()
+    rng = np.random.RandomState(0)
+    rand_data = RandomData(rng)
+    for prior_type in PRIOR_TYPE:
+        for covar_type in COVARIANCE_TYPE:
+            X = rand_data.X[covar_type]
+            Y = rand_data.Y
+            bgmm = BayesianGaussianMixture(
+                n_components=rand_data.n_components,
+                random_state=rng,
+                weight_concentration_prior_type=prior_type,
+                covariance_type=covar_type)
+
+            # Check a warning message arrive if we don't do fit
+            assert_raise_message(NotFittedError,
+                                 "This BayesianGaussianMixture instance"
+                                 " is not fitted yet. Call 'fit' with "
+                                 "appropriate arguments before using "
+                                 "this method.", bgmm.predict, X)
+
+            bgmm.fit(X)
+            Y_pred = bgmm.predict(X)
+            Y_pred_proba = bgmm.predict_proba(X).argmax(axis=1)
+            assert_array_equal(Y_pred, Y_pred_proba)
+            assert_greater_equal(adjusted_rand_score(Y, Y_pred), .95)
diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py
index 08a083abf7..3b17bf17bf 100755
--- a/sklearn/mixture/tests/test_gaussian_mixture.py
+++ b/sklearn/mixture/tests/test_gaussian_mixture.py
@@ -3,6 +3,7 @@
 # License: BSD 3 clause
 
 import sys
+import copy
 import warnings
 
 import numpy as np
@@ -569,6 +570,26 @@ def test_gaussian_mixture_predict_predict_proba():
         assert_greater(adjusted_rand_score(Y, Y_pred), .95)
 
 
+def test_gaussian_mixture_fit_predict():
+    rng = np.random.RandomState(0)
+    rand_data = RandomData(rng)
+    for covar_type in COVARIANCE_TYPE:
+        X = rand_data.X[covar_type]
+        Y = rand_data.Y
+        g = GaussianMixture(n_components=rand_data.n_components,
+                            random_state=rng, weights_init=rand_data.weights,
+                            means_init=rand_data.means,
+                            precisions_init=rand_data.precisions[covar_type],
+                            covariance_type=covar_type)
+
+        # check if fit_predict(X) is equivalent to fit(X).predict(X)
+        f = copy.deepcopy(g)
+        Y_pred1 = f.fit(X).predict(X)
+        Y_pred2 = g.fit_predict(X)
+        assert_array_equal(Y_pred1, Y_pred2)
+        assert_greater(adjusted_rand_score(Y, Y_pred2), .95)
+
+
 def test_gaussian_mixture_fit():
     # recover the ground truth
     rng = np.random.RandomState(0)
diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
index 7ec71ac273..d80e39f9f0 100755
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -3,7 +3,6 @@
 from collections import Iterable, Sized
 from sklearn.externals.six.moves import cStringIO as StringIO
 from sklearn.externals.six.moves import xrange
-from sklearn.externals.joblib._compat import PY3_OR_LATER
 from itertools import chain, product
 import pickle
 import sys
@@ -15,6 +14,7 @@
 import pytest
 
 from sklearn.utils.fixes import sp_version
+from sklearn.utils.fixes import PY3_OR_LATER
 from sklearn.utils.testing import assert_equal
 from sklearn.utils.testing import assert_not_equal
 from sklearn.utils.testing import assert_raises
diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
index eee30948e8..7516b2af9e 100755
--- a/sklearn/preprocessing/_encoders.py
+++ b/sklearn/preprocessing/_encoders.py
@@ -16,7 +16,7 @@
 from ..utils import deprecated
 from ..utils.fixes import _argmax
 from ..utils.validation import check_is_fitted, FLOAT_DTYPES
-from .label import LabelEncoder
+from .label import _encode, _encode_check_unknown
 
 
 range = six.moves.range
@@ -104,32 +104,30 @@ def _fit(self, X, handle_unknown='error'):
         n_samples, n_features = X.shape
 
         if self._categories != 'auto':
-            for cats in self._categories:
-                if not np.all(np.sort(cats) == np.array(cats)):
-                    raise ValueError("Unsorted categories are not yet "
-                                     "supported")
+            if X.dtype != object:
+                for cats in self._categories:
+                    if not np.all(np.sort(cats) == np.array(cats)):
+                        raise ValueError("Unsorted categories are not "
+                                         "supported for numerical categories")
             if len(self._categories) != n_features:
                 raise ValueError("Shape mismatch: if n_values is an array,"
                                  " it has to be of shape (n_features,).")
 
-        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]
+        self.categories_ = []
 
         for i in range(n_features):
-            le = self._label_encoders_[i]
             Xi = X[:, i]
             if self._categories == 'auto':
-                le.fit(Xi)
+                cats = _encode(Xi)
             else:
-                if handle_unknown == 'error':
-                    valid_mask = np.in1d(Xi, self._categories[i])
-                    if not np.all(valid_mask):
-                        diff = np.unique(Xi[~valid_mask])
+                cats = np.array(self._categories[i], dtype=X.dtype)
+                if self.handle_unknown == 'error':
+                    diff = _encode_check_unknown(Xi, cats)
+                    if diff:
                         msg = ("Found unknown categories {0} in column {1}"
                                " during fit".format(diff, i))
                         raise ValueError(msg)
-                le.classes_ = np.array(self._categories[i], dtype=X.dtype)
-
-        self.categories_ = [le.classes_ for le in self._label_encoders_]
+            self.categories_.append(cats)
 
     def _transform(self, X, handle_unknown='error'):
 
@@ -145,11 +143,11 @@ def _transform(self, X, handle_unknown='error'):
 
         for i in range(n_features):
             Xi = X[:, i]
-            valid_mask = np.in1d(Xi, self.categories_[i])
+            diff, valid_mask = _encode_check_unknown(Xi, self.categories_[i],
+                                                     return_mask=True)
 
             if not np.all(valid_mask):
                 if handle_unknown == 'error':
-                    diff = np.unique(X[~valid_mask, i])
                     msg = ("Found unknown categories {0} in column {1}"
                            " during transform".format(diff, i))
                     raise ValueError(msg)
@@ -160,7 +158,8 @@ def _transform(self, X, handle_unknown='error'):
                     X_mask[:, i] = valid_mask
                     Xi = Xi.copy()
                     Xi[~valid_mask] = self.categories_[i][0]
-            X_int[:, i] = self._label_encoders_[i].transform(Xi)
+            _, encoded = _encode(Xi, self.categories_[i], encode=True)
+            X_int[:, i] = encoded
 
         return X_int, X_mask
 
@@ -195,8 +194,9 @@ class OneHotEncoder(_BaseEncoder):
 
         - 'auto' : Determine categories automatically from the training data.
         - list : ``categories[i]`` holds the categories expected in the ith
-          column. The passed categories must be sorted and should not mix
-          strings and numeric values.
+          column. The passed categories should not mix strings and numeric
+          values within a single feature, and should be sorted in case of
+          numeric values.
 
         The used categories can be found in the ``categories_`` attribute.
 
@@ -713,8 +713,8 @@ class OrdinalEncoder(_BaseEncoder):
 
         - 'auto' : Determine categories automatically from the training data.
         - list : ``categories[i]`` holds the categories expected in the ith
-          column. The passed categories must be sorted and should not mix
-          strings and numeric values.
+          column. The passed categories should not mix strings and numeric
+          values, and should be sorted in case of numeric values.
 
         The used categories can be found in the ``categories_`` attribute.
 
diff --git a/sklearn/preprocessing/data.py b/sklearn/preprocessing/data.py
index 7c014a0748..e3c72d6884 100755
--- a/sklearn/preprocessing/data.py
+++ b/sklearn/preprocessing/data.py
@@ -24,7 +24,7 @@
 from ..utils import check_array
 from ..utils.extmath import row_norms
 from ..utils.extmath import _incremental_mean_and_var
-from ..utils.fixes import boxcox, nanpercentile
+from ..utils.fixes import boxcox, nanpercentile, nanmedian
 from ..utils.sparsefuncs_fast import (inplace_csr_row_normalize_l1,
                                       inplace_csr_row_normalize_l2)
 from ..utils.sparsefuncs import (inplace_column_scale,
@@ -1092,18 +1092,6 @@ def __init__(self, with_centering=True, with_scaling=True,
         self.quantile_range = quantile_range
         self.copy = copy
 
-    def _check_array(self, X, copy):
-        """Makes sure centering is not enabled for sparse matrices."""
-        X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,
-                        estimator=self, dtype=FLOAT_DTYPES)
-
-        if sparse.issparse(X):
-            if self.with_centering:
-                raise ValueError(
-                    "Cannot center sparse matrices: use `with_centering=False`"
-                    " instead. See docstring for motivation and alternatives.")
-        return X
-
     def fit(self, X, y=None):
         """Compute the median and quantiles to be used for scaling.
 
@@ -1113,39 +1101,60 @@ def fit(self, X, y=None):
             The data used to compute the median and quantiles
             used for later scaling along the features axis.
         """
-        if sparse.issparse(X):
-            raise TypeError("RobustScaler cannot be fitted on sparse inputs")
-        X = self._check_array(X, self.copy)
+        # at fit, convert sparse matrices to csc for optimized computation of
+        # the quantiles
+        X = check_array(X, accept_sparse='csc', copy=self.copy, estimator=self,
+                        dtype=FLOAT_DTYPES, force_all_finite='allow-nan')
+
+        q_min, q_max = self.quantile_range
+        if not 0 <= q_min <= q_max <= 100:
+            raise ValueError("Invalid quantile range: %s" %
+                             str(self.quantile_range))
+
         if self.with_centering:
-            self.center_ = np.median(X, axis=0)
+            if sparse.issparse(X):
+                raise ValueError(
+                    "Cannot center sparse matrices: use `with_centering=False`"
+                    " instead. See docstring for motivation and alternatives.")
+            self.center_ = nanmedian(X, axis=0)
+        else:
+            self.center_ = None
 
         if self.with_scaling:
-            q_min, q_max = self.quantile_range
-            if not 0 <= q_min <= q_max <= 100:
-                raise ValueError("Invalid quantile range: %s" %
-                                 str(self.quantile_range))
+            quantiles = []
+            for feature_idx in range(X.shape[1]):
+                if sparse.issparse(X):
+                    column_nnz_data = X.data[X.indptr[feature_idx]:
+                                             X.indptr[feature_idx + 1]]
+                    column_data = np.zeros(shape=X.shape[0], dtype=X.dtype)
+                    column_data[:len(column_nnz_data)] = column_nnz_data
+                else:
+                    column_data = X[:, feature_idx]
 
-            q = np.percentile(X, self.quantile_range, axis=0)
-            self.scale_ = (q[1] - q[0])
+                quantiles.append(nanpercentile(column_data,
+                                               self.quantile_range))
+
+            quantiles = np.transpose(quantiles)
+
+            self.scale_ = quantiles[1] - quantiles[0]
             self.scale_ = _handle_zeros_in_scale(self.scale_, copy=False)
+        else:
+            self.scale_ = None
+
         return self
 
     def transform(self, X):
         """Center and scale the data.
 
-        Can be called on sparse input, provided that ``RobustScaler`` has been
-        fitted to dense input and ``with_centering=False``.
-
         Parameters
         ----------
         X : {array-like, sparse matrix}
             The data used to scale along the specified axis.
         """
-        if self.with_centering:
-            check_is_fitted(self, 'center_')
-        if self.with_scaling:
-            check_is_fitted(self, 'scale_')
-        X = self._check_array(X, self.copy)
+        check_is_fitted(self, 'center_', 'scale_')
+        X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,
+                        estimator=self, dtype=FLOAT_DTYPES,
+                        force_all_finite='allow-nan')
 
         if sparse.issparse(X):
             if self.with_scaling:
@@ -1165,11 +1174,10 @@ def inverse_transform(self, X):
         X : array-like
             The data used to scale along the specified axis.
         """
-        if self.with_centering:
-            check_is_fitted(self, 'center_')
-        if self.with_scaling:
-            check_is_fitted(self, 'scale_')
-        X = self._check_array(X, self.copy)
+        check_is_fitted(self, 'center_', 'scale_')
+        X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,
+                        estimator=self, dtype=FLOAT_DTYPES,
+                        force_all_finite='allow-nan')
 
         if sparse.issparse(X):
             if self.with_scaling:
@@ -1242,7 +1250,8 @@ def robust_scale(X, axis=0, with_centering=True, with_scaling=True,
         (e.g. as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).
     """
     X = check_array(X, accept_sparse=('csr', 'csc'), copy=False,
-                    ensure_2d=False, dtype=FLOAT_DTYPES)
+                    ensure_2d=False, dtype=FLOAT_DTYPES,
+                    force_all_finite='allow-nan')
     original_ndim = X.ndim
 
     if original_ndim == 1:
diff --git a/sklearn/preprocessing/label.py b/sklearn/preprocessing/label.py
index 043067fa37..51faccf1a3 100755
--- a/sklearn/preprocessing/label.py
+++ b/sklearn/preprocessing/label.py
@@ -37,6 +37,129 @@
 ]
 
 
+def _encode_numpy(values, uniques=None, encode=False):
+    # only used in _encode below, see docstring there for details
+    if uniques is None:
+        if encode:
+            uniques, encoded = np.unique(values, return_inverse=True)
+            return uniques, encoded
+        else:
+            # unique sorts
+            return np.unique(values)
+    if encode:
+        diff = _encode_check_unknown(values, uniques)
+        if diff:
+            raise ValueError("y contains previously unseen labels: %s"
+                             % str(diff))
+        encoded = np.searchsorted(uniques, values)
+        return uniques, encoded
+    else:
+        return uniques
+
+
+def _encode_python(values, uniques=None, encode=False):
+    # only used in _encode below, see docstring there for details
+    if uniques is None:
+        uniques = sorted(set(values))
+        uniques = np.array(uniques, dtype=values.dtype)
+    if encode:
+        table = {val: i for i, val in enumerate(uniques)}
+        try:
+            encoded = np.array([table[v] for v in values])
+        except KeyError as e:
+            raise ValueError("y contains previously unseen labels: %s"
+                             % str(e))
+        return uniques, encoded
+    else:
+        return uniques
+
+
+def _encode(values, uniques=None, encode=False):
+    """Helper function to factorize (find uniques) and encode values.
+
+    Uses pure python method for object dtype, and numpy method for
+    all other dtypes.
+    The numpy method has the limitation that the `uniques` need to
+    be sorted. Importantly, this is not checked but assumed to already be
+    the case. The calling method needs to ensure this for all non-object
+    values.
+
+    Parameters
+    ----------
+    values : array
+        Values to factorize or encode.
+    uniques : array, optional
+        If passed, uniques are not determined from passed values (this
+        can be because the user specified categories, or because they
+        already have been determined in fit).
+    encode : bool, default False
+        If True, also encode the values into integer codes based on `uniques`.
+
+    Returns
+    -------
+    uniques
+        If ``encode=False``. The unique values are sorted if the `uniques`
+        parameter was None (and thus inferred from the data).
+    (uniques, encoded)
+        If ``encode=True``.
+
+    """
+    if values.dtype == object:
+        return _encode_python(values, uniques, encode)
+    else:
+        return _encode_numpy(values, uniques, encode)
+
+
+def _encode_check_unknown(values, uniques, return_mask=False):
+    """
+    Helper function to check for unknowns in values to be encoded.
+
+    Uses pure python method for object dtype, and numpy method for
+    all other dtypes.
+
+    Parameters
+    ----------
+    values : array
+        Values to check for unknowns.
+    uniques : array
+        Allowed uniques values.
+    return_mask : bool, default False
+        If True, return a mask of the same shape as `values` indicating
+        the valid values.
+
+    Returns
+    -------
+    diff : list
+        The unique values present in `values` and not in `uniques` (the
+        unknown values).
+    valid_mask : boolean array
+        Additionally returned if ``return_mask=True``.
+
+    """
+    if values.dtype == object:
+        uniques_set = set(uniques)
+        diff = list(set(values) - uniques_set)
+        if return_mask:
+            if diff:
+                valid_mask = np.array([val in uniques_set for val in values])
+            else:
+                valid_mask = np.ones(len(values), dtype=bool)
+            return diff, valid_mask
+        else:
+            return diff
+    else:
+        unique_values = np.unique(values)
+        diff = list(np.setdiff1d(unique_values, uniques, assume_unique=True))
+        if return_mask:
+            if diff:
+                valid_mask = np.in1d(values, uniques)
+            else:
+                valid_mask = np.ones(len(values), dtype=bool)
+            return diff, valid_mask
+        else:
+            return diff
+
+
 class LabelEncoder(BaseEstimator, TransformerMixin):
     """Encode labels with value between 0 and n_classes-1.
 
@@ -94,7 +217,7 @@ def fit(self, y):
         self : returns an instance of self.
         """
         y = column_or_1d(y, warn=True)
-        self.classes_ = np.unique(y)
+        self.classes_ = _encode(y)
         return self
 
     def fit_transform(self, y):
@@ -110,7 +233,7 @@ def fit_transform(self, y):
         y : array-like of shape [n_samples]
         """
         y = column_or_1d(y, warn=True)
-        self.classes_, y = np.unique(y, return_inverse=True)
+        self.classes_, y = _encode(y, encode=True)
         return y
 
     def transform(self, y):
@@ -131,12 +254,8 @@ def transform(self, y):
         if _num_samples(y) == 0:
             return np.array([])
 
-        classes = np.unique(y)
-        if len(np.intersect1d(classes, self.classes_)) < len(classes):
-            diff = np.setdiff1d(classes, self.classes_)
-            raise ValueError(
-                    "y contains previously unseen labels: %s" % str(diff))
-        return np.searchsorted(self.classes_, y)
+        _, y = _encode(y, uniques=self.classes_, encode=True)
+        return y
 
     def inverse_transform(self, y):
         """Transform labels back to original encoding.
diff --git a/sklearn/preprocessing/tests/test_common.py b/sklearn/preprocessing/tests/test_common.py
index b3c8b7aed7..cbb77e4884 100755
--- a/sklearn/preprocessing/tests/test_common.py
+++ b/sklearn/preprocessing/tests/test_common.py
@@ -15,12 +15,14 @@
 from sklearn.preprocessing import scale
 from sklearn.preprocessing import power_transform
 from sklearn.preprocessing import quantile_transform
+from sklearn.preprocessing import robust_scale
 
 from sklearn.preprocessing import MaxAbsScaler
 from sklearn.preprocessing import MinMaxScaler
 from sklearn.preprocessing import StandardScaler
 from sklearn.preprocessing import PowerTransformer
 from sklearn.preprocessing import QuantileTransformer
+from sklearn.preprocessing import RobustScaler
 
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_allclose
@@ -40,7 +42,9 @@ def _get_valid_samples_by_column(X, col):
      (StandardScaler(), scale, False, False),
      (StandardScaler(with_mean=False), scale, True, False),
      (PowerTransformer(), power_transform, False, True),
-     (QuantileTransformer(n_quantiles=10), quantile_transform, True, False)]
+     (QuantileTransformer(n_quantiles=10), quantile_transform, True, False),
+     (RobustScaler(), robust_scale, False, False),
+     (RobustScaler(with_centering=False), robust_scale, True, False)]
 )
 def test_missing_value_handling(est, func, support_sparse, strictly_positive):
     # check that the preprocessing method let pass nan
diff --git a/sklearn/preprocessing/tests/test_data.py b/sklearn/preprocessing/tests/test_data.py
index f90fbee278..2ff9dfd776 100755
--- a/sklearn/preprocessing/tests/test_data.py
+++ b/sklearn/preprocessing/tests/test_data.py
@@ -906,6 +906,52 @@ def test_scale_input_finiteness_validation():
                         scale, X)
 
 
+def test_robust_scaler_error_sparse():
+    X_sparse = sparse.rand(1000, 10)
+    scaler = RobustScaler(with_centering=True)
+    err_msg = "Cannot center sparse matrices"
+    with pytest.raises(ValueError, match=err_msg):
+        scaler.fit(X_sparse)
+
+
+@pytest.mark.parametrize("with_centering", [True, False])
+@pytest.mark.parametrize("with_scaling", [True, False])
+@pytest.mark.parametrize("X", [np.random.randn(10, 3),
+                               sparse.rand(10, 3, density=0.5)])
+def test_robust_scaler_attributes(X, with_centering, with_scaling):
+    # check consistent type of attributes
+    if with_centering and sparse.issparse(X):
+        pytest.skip("RobustScaler cannot center sparse matrix")
+
+    scaler = RobustScaler(with_centering=with_centering,
+                          with_scaling=with_scaling)
+    scaler.fit(X)
+
+    if with_centering:
+        assert isinstance(scaler.center_, np.ndarray)
+    else:
+        assert scaler.center_ is None
+    if with_scaling:
+        assert isinstance(scaler.scale_, np.ndarray)
+    else:
+        assert scaler.scale_ is None
+
+
+def test_robust_scaler_col_zero_sparse():
+    # check that the scaler is working when there is not data materialized in a
+    # column of a sparse matrix
+    X = np.random.randn(10, 5)
+    X[:, 0] = 0
+    X = sparse.csr_matrix(X)
+
+    scaler = RobustScaler(with_centering=False)
+    scaler.fit(X)
+    assert scaler.scale_[0] == pytest.approx(1)
+
+    X_trans = scaler.transform(X)
+    assert_allclose(X[:, 0].toarray(), X_trans[:, 0].toarray())
+
+
 def test_robust_scaler_2d_arrays():
     # Test robust scaling of 2d array along first axis
     rng = np.random.RandomState(0)
@@ -919,6 +965,29 @@ def test_robust_scaler_2d_arrays():
     assert_array_almost_equal(X_scaled.std(axis=0)[0], 0)
 
 
+@pytest.mark.parametrize("density", [0, 0.05, 0.1, 0.5, 1])
+@pytest.mark.parametrize("strictly_signed",
+                         ['positive', 'negative', 'zeros', None])
+def test_robust_scaler_equivalence_dense_sparse(density, strictly_signed):
+    # Check the equivalence of the fitting with dense and sparse matrices
+    X_sparse = sparse.rand(1000, 5, density=density).tocsc()
+    if strictly_signed == 'positive':
+        X_sparse.data = np.abs(X_sparse.data)
+    elif strictly_signed == 'negative':
+        X_sparse.data = - np.abs(X_sparse.data)
+    elif strictly_signed == 'zeros':
+        X_sparse.data = np.zeros(X_sparse.data.shape, dtype=np.float64)
+    X_dense = X_sparse.toarray()
+
+    scaler_sparse = RobustScaler(with_centering=False)
+    scaler_dense = RobustScaler(with_centering=False)
+
+    scaler_sparse.fit(X_sparse)
+    scaler_dense.fit(X_dense)
+
+    assert_allclose(scaler_sparse.scale_, scaler_dense.scale_)
+
+
 def test_robust_scaler_transform_one_row_csr():
     # Check RobustScaler on transforming csr matrix with one row
     rng = np.random.RandomState(0)
diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py
index d5acd110e2..d4f8aaefc3 100755
--- a/sklearn/preprocessing/tests/test_encoders.py
+++ b/sklearn/preprocessing/tests/test_encoders.py
@@ -339,10 +339,10 @@ def test_one_hot_encoder_set_params():
 
 
 def check_categorical_onehot(X):
-    enc = OneHotEncoder()
+    enc = OneHotEncoder(categories='auto')
     Xtr1 = enc.fit_transform(X)
 
-    enc = OneHotEncoder(sparse=False)
+    enc = OneHotEncoder(categories='auto', sparse=False)
     Xtr2 = enc.fit_transform(X)
 
     assert_allclose(Xtr1.toarray(), Xtr2)
@@ -351,17 +351,20 @@ def check_categorical_onehot(X):
     return Xtr1.toarray()
 
 
-def test_one_hot_encoder():
-    X = [['abc', 1, 55], ['def', 2, 55]]
-
+@pytest.mark.parametrize("X", [
+    [['def', 1, 55], ['abc', 2, 55]],
+    np.array([[10, 1, 55], [5, 2, 55]]),
+    np.array([['b', 'A', 'cat'], ['a', 'B', 'cat']], dtype=object)
+    ], ids=['mixed', 'numeric', 'object'])
+def test_one_hot_encoder(X):
     Xtr = check_categorical_onehot(np.array(X)[:, [0]])
-    assert_allclose(Xtr, [[1, 0], [0, 1]])
+    assert_allclose(Xtr, [[0, 1], [1, 0]])
 
     Xtr = check_categorical_onehot(np.array(X)[:, [0, 1]])
-    assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
+    assert_allclose(Xtr, [[0, 1, 1, 0], [1, 0, 0, 1]])
 
-    Xtr = OneHotEncoder().fit_transform(X)
-    assert_allclose(Xtr.toarray(), [[1, 0, 1, 0,  1], [0, 1, 0, 1, 1]])
+    Xtr = OneHotEncoder(categories='auto').fit_transform(X)
+    assert_allclose(Xtr.toarray(), [[0, 1, 1, 0,  1], [1, 0, 0, 1, 1]])
 
 
 def test_one_hot_encoder_inverse():
@@ -449,7 +452,8 @@ def test_one_hot_encoder_specified_categories(X, X2, cats, cat_dtype):
     # when specifying categories manually, unknown categories should already
     # raise when fitting
     enc = OneHotEncoder(categories=cats)
-    assert_raises(ValueError, enc.fit, X2)
+    with pytest.raises(ValueError, match="Found unknown categories"):
+        enc.fit(X2)
     enc = OneHotEncoder(categories=cats, handle_unknown='ignore')
     exp = np.array([[1., 0., 0.], [0., 0., 0.]])
     assert_array_equal(enc.fit(X2).transform(X2).toarray(), exp)
@@ -458,10 +462,20 @@ def test_one_hot_encoder_specified_categories(X, X2, cats, cat_dtype):
 def test_one_hot_encoder_unsorted_categories():
     X = np.array([['a', 'b']], dtype=object).T
 
-    # unsorted passed categories raises for now
-    enc = OneHotEncoder(categories=[['c', 'b', 'a']])
-    msg = re.escape('Unsorted categories are not yet supported')
-    assert_raises_regex(ValueError, msg, enc.fit_transform, X)
+    enc = OneHotEncoder(categories=[['b', 'a', 'c']])
+    exp = np.array([[0., 1., 0.],
+                    [1., 0., 0.]])
+    assert_array_equal(enc.fit(X).transform(X).toarray(), exp)
+    assert_array_equal(enc.fit_transform(X).toarray(), exp)
+    assert enc.categories_[0].tolist() == ['b', 'a', 'c']
+    assert np.issubdtype(enc.categories_[0].dtype, np.object_)
+
+    # unsorted passed categories still raise for numerical values
+    X = np.array([[1, 2]]).T
+    enc = OneHotEncoder(categories=[[2, 1, 3]])
+    msg = 'Unsorted categories are not supported'
+    with pytest.raises(ValueError, match=msg):
+        enc.fit_transform(X)
 
 
 def test_one_hot_encoder_specified_categories_mixed_columns():
@@ -487,9 +501,12 @@ def test_one_hot_encoder_pandas():
     assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
 
 
-def test_ordinal_encoder():
-    X = [['abc', 2, 55], ['def', 1, 55]]
-
+@pytest.mark.parametrize("X", [
+    [['abc', 2, 55], ['def', 1, 55]],
+    np.array([[10, 2, 55], [20, 1, 55]]),
+    np.array([['a', 'B', 'cat'], ['b', 'A', 'cat']], dtype=object)
+    ], ids=['mixed', 'numeric', 'object'])
+def test_ordinal_encoder(X):
     enc = OrdinalEncoder()
     exp = np.array([[0, 1, 0],
                     [1, 0, 0]], dtype='int64')
diff --git a/sklearn/preprocessing/tests/test_label.py b/sklearn/preprocessing/tests/test_label.py
index faa0cc3ce2..f8f4ee4870 100755
--- a/sklearn/preprocessing/tests/test_label.py
+++ b/sklearn/preprocessing/tests/test_label.py
@@ -1,5 +1,7 @@
 import numpy as np
 
+import pytest
+
 from scipy.sparse import issparse
 from scipy.sparse import coo_matrix
 from scipy.sparse import csc_matrix
@@ -24,6 +26,7 @@
 
 from sklearn.preprocessing.label import _inverse_binarize_thresholding
 from sklearn.preprocessing.label import _inverse_binarize_multiclass
+from sklearn.preprocessing.label import _encode
 
 from sklearn import datasets
 
@@ -169,8 +172,33 @@ def test_label_binarizer_errors():
                   [1, 2, 3])
 
 
-def test_label_encoder():
-    # Test LabelEncoder's transform and inverse_transform methods
+@pytest.mark.parametrize(
+        "values, classes, unknown",
+        [(np.array([2, 1, 3, 1, 3], dtype='int64'),
+          np.array([1, 2, 3], dtype='int64'), np.array([4], dtype='int64')),
+         (np.array(['b', 'a', 'c', 'a', 'c'], dtype=object),
+          np.array(['a', 'b', 'c'], dtype=object),
+          np.array(['d'], dtype=object)),
+         (np.array(['b', 'a', 'c', 'a', 'c']),
+          np.array(['a', 'b', 'c']), np.array(['d']))],
+        ids=['int64', 'object', 'str'])
+def test_label_encoder(values, classes, unknown):
+    # Test LabelEncoder's transform, fit_transform and
+    # inverse_transform methods
+    le = LabelEncoder()
+    le.fit(values)
+    assert_array_equal(le.classes_, classes)
+    assert_array_equal(le.transform(values), [1, 0, 2, 0, 2])
+    assert_array_equal(le.inverse_transform([1, 0, 2, 0, 2]), values)
+    le = LabelEncoder()
+    ret = le.fit_transform(values)
+    assert_array_equal(ret, [1, 0, 2, 0, 2])
+
+    with pytest.raises(ValueError, match="unseen labels"):
+        le.transform(unknown)
+
+
+def test_label_encoder_negative_ints():
     le = LabelEncoder()
     le.fit([1, 1, 4, 5, -1, 0])
     assert_array_equal(le.classes_, [-1, 0, 1, 4, 5])
@@ -180,20 +208,13 @@ def test_label_encoder():
                        [0, 1, 4, 4, 5, -1, -1])
     assert_raises(ValueError, le.transform, [0, 6])
 
-    le.fit(["apple", "orange"])
-    msg = "bad input shape"
-    assert_raise_message(ValueError, msg, le.transform, "apple")
-
-
-def test_label_encoder_fit_transform():
-    # Test fit_transform
-    le = LabelEncoder()
-    ret = le.fit_transform([1, 1, 4, 5, -1, 0])
-    assert_array_equal(ret, [2, 2, 3, 4, 0, 1])
 
+@pytest.mark.parametrize("dtype", ['str', 'object'])
+def test_label_encoder_str_bad_shape(dtype):
     le = LabelEncoder()
-    ret = le.fit_transform(["paris", "paris", "tokyo", "amsterdam"])
-    assert_array_equal(ret, [1, 1, 2, 0])
+    le.fit(np.array(["apple", "orange"], dtype=dtype))
+    msg = "bad input shape"
+    assert_raise_message(ValueError, msg, le.transform, "apple")
 
 
 def test_label_encoder_errors():
@@ -214,9 +235,15 @@ def test_label_encoder_errors():
     assert_raise_message(ValueError, msg, le.inverse_transform, "")
 
 
-def test_label_encoder_empty_array():
+@pytest.mark.parametrize(
+        "values",
+        [np.array([2, 1, 3, 1, 3], dtype='int64'),
+         np.array(['b', 'a', 'c', 'a', 'c'], dtype=object),
+         np.array(['b', 'a', 'c', 'a', 'c'])],
+        ids=['int64', 'object', 'str'])
+def test_label_encoder_empty_array(values):
     le = LabelEncoder()
-    le.fit(np.array(["1", "2", "1", "2", "2"]))
+    le.fit(values)
     # test empty transform
     transformed = le.transform([])
     assert_array_equal(np.array([]), transformed)
@@ -536,3 +563,22 @@ def test_inverse_binarize_multiclass():
                                                    [0, 0, 0]]),
                                        np.arange(3))
     assert_array_equal(got, np.array([1, 1, 0]))
+
+
+@pytest.mark.parametrize(
+        "values, expected",
+        [(np.array([2, 1, 3, 1, 3], dtype='int64'),
+          np.array([1, 2, 3], dtype='int64')),
+         (np.array(['b', 'a', 'c', 'a', 'c'], dtype=object),
+          np.array(['a', 'b', 'c'], dtype=object)),
+         (np.array(['b', 'a', 'c', 'a', 'c']),
+          np.array(['a', 'b', 'c']))],
+        ids=['int64', 'object', 'str'])
+def test_encode_util(values, expected):
+    uniques = _encode(values)
+    assert_array_equal(uniques, expected)
+    uniques, encoded = _encode(values, encode=True)
+    assert_array_equal(uniques, expected)
+    assert_array_equal(encoded, np.array([1, 0, 2, 0, 2]))
+    _, encoded = _encode(values, uniques, encode=True)
+    assert_array_equal(encoded, np.array([1, 0, 2, 0, 2]))
diff --git a/sklearn/svm/classes.py b/sklearn/svm/classes.py
index 7b34a40f25..4cb23d9cd1 100755
--- a/sklearn/svm/classes.py
+++ b/sklearn/svm/classes.py
@@ -260,26 +260,23 @@ class LinearSVR(LinearModel, RegressorMixin):
 
     Parameters
     ----------
-    C : float, optional (default=1.0)
-        Penalty parameter C of the error term. The penalty is a squared
-        l2 penalty. The bigger this parameter, the less regularization is used.
-
-    loss : string, 'epsilon_insensitive' or 'squared_epsilon_insensitive' (default='epsilon_insensitive')
-        Specifies the loss function. 'l1' is the epsilon-insensitive loss
-        (standard SVR) while 'l2' is the squared epsilon-insensitive loss.
-
     epsilon : float, optional (default=0.1)
         Epsilon parameter in the epsilon-insensitive loss function. Note
         that the value of this parameter depends on the scale of the target
         variable y. If unsure, set ``epsilon=0``.
 
-    dual : bool, (default=True)
-        Select the algorithm to either solve the dual or primal
-        optimization problem. Prefer dual=False when n_samples > n_features.
-
     tol : float, optional (default=1e-4)
         Tolerance for stopping criteria.
 
+    C : float, optional (default=1.0)
+        Penalty parameter C of the error term. The penalty is a squared
+        l2 penalty. The bigger this parameter, the less regularization is used.
+
+    loss : string, optional (default='epsilon_insensitive')
+        Specifies the loss function. The epsilon-insensitive loss
+        (standard SVR) is the L1 loss, while the squared epsilon-insensitive
+        loss ('squared_epsilon_insensitive') is the L2 loss.
+
     fit_intercept : boolean, optional (default=True)
         Whether to calculate the intercept for this model. If set
         to false, no intercept will be used in calculations
@@ -296,6 +293,10 @@ class LinearSVR(LinearModel, RegressorMixin):
         To lessen the effect of regularization on synthetic feature weight
         (and therefore on the intercept) intercept_scaling has to be increased.
 
+    dual : bool, (default=True)
+        Select the algorithm to either solve the dual or primal
+        optimization problem. Prefer dual=False when n_samples > n_features.
+
     verbose : int, (default=0)
         Enable verbose output. Note that this setting takes advantage of a
         per-process runtime setting in liblinear that, if enabled, may not work
@@ -473,13 +474,13 @@ class SVC(BaseSVC):
         Independent term in kernel function.
         It is only significant in 'poly' and 'sigmoid'.
 
+    shrinking : boolean, optional (default=True)
+        Whether to use the shrinking heuristic.
+
     probability : boolean, optional (default=False)
         Whether to enable probability estimates. This must be enabled prior
         to calling `fit`, and will slow down that method.
 
-    shrinking : boolean, optional (default=True)
-        Whether to use the shrinking heuristic.
-
     tol : float, optional (default=1e-3)
         Tolerance for stopping criterion.
 
@@ -639,13 +640,13 @@ class NuSVC(BaseSVC):
         Independent term in kernel function.
         It is only significant in 'poly' and 'sigmoid'.
 
+    shrinking : boolean, optional (default=True)
+        Whether to use the shrinking heuristic.
+
     probability : boolean, optional (default=False)
         Whether to enable probability estimates. This must be enabled prior
         to calling `fit`, and will slow down that method.
 
-    shrinking : boolean, optional (default=True)
-        Whether to use the shrinking heuristic.
-
     tol : float, optional (default=1e-3)
         Tolerance for stopping criterion.
 
@@ -769,15 +770,6 @@ class SVR(BaseLibSVM, RegressorMixin):
 
     Parameters
     ----------
-    C : float, optional (default=1.0)
-        Penalty parameter C of the error term.
-
-    epsilon : float, optional (default=0.1)
-         Epsilon in the epsilon-SVR model. It specifies the epsilon-tube
-         within which no penalty is associated in the training loss function
-         with points predicted within a distance epsilon from the actual
-         value.
-
     kernel : string, optional (default='rbf')
          Specifies the kernel type to be used in the algorithm.
          It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or
@@ -803,12 +795,21 @@ class SVR(BaseLibSVM, RegressorMixin):
         Independent term in kernel function.
         It is only significant in 'poly' and 'sigmoid'.
 
-    shrinking : boolean, optional (default=True)
-        Whether to use the shrinking heuristic.
-
     tol : float, optional (default=1e-3)
         Tolerance for stopping criterion.
 
+    C : float, optional (default=1.0)
+        Penalty parameter C of the error term.
+
+    epsilon : float, optional (default=0.1)
+         Epsilon in the epsilon-SVR model. It specifies the epsilon-tube
+         within which no penalty is associated in the training loss function
+         with points predicted within a distance epsilon from the actual
+         value.
+
+    shrinking : boolean, optional (default=True)
+        Whether to use the shrinking heuristic.
+
     cache_size : float, optional
         Specify the size of the kernel cache (in MB).
 
@@ -894,14 +895,14 @@ class NuSVR(BaseLibSVM, RegressorMixin):
 
     Parameters
     ----------
-    C : float, optional (default=1.0)
-        Penalty parameter C of the error term.
-
     nu : float, optional
         An upper bound on the fraction of training errors and a lower bound of
         the fraction of support vectors. Should be in the interval (0, 1].  By
         default 0.5 will be taken.
 
+    C : float, optional (default=1.0)
+        Penalty parameter C of the error term.
+
     kernel : string, optional (default='rbf')
          Specifies the kernel type to be used in the algorithm.
          It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or
@@ -1020,12 +1021,6 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):
          If none is given, 'rbf' will be used. If a callable is given it is
          used to precompute the kernel matrix.
 
-    nu : float, optional
-        An upper bound on the fraction of training
-        errors and a lower bound of the fraction of support
-        vectors. Should be in the interval (0, 1]. By default 0.5
-        will be taken.
-
     degree : int, optional (default=3)
         Degree of the polynomial kernel function ('poly').
         Ignored by all other kernels.
@@ -1047,6 +1042,12 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):
     tol : float, optional
         Tolerance for stopping criterion.
 
+    nu : float, optional
+        An upper bound on the fraction of training
+        errors and a lower bound of the fraction of support
+        vectors. Should be in the interval (0, 1]. By default 0.5
+        will be taken.
+
     shrinking : boolean, optional
         Whether to use the shrinking heuristic.
 
diff --git a/sklearn/tests/test_docstring_parameters.py b/sklearn/tests/test_docstring_parameters.py
index cb7217e3ef..0fada63831 100755
--- a/sklearn/tests/test_docstring_parameters.py
+++ b/sklearn/tests/test_docstring_parameters.py
@@ -25,25 +25,16 @@
 # TODO Uncomment all modules and fix doc inconsistencies everywhere
 # The list of modules that are not tested for now
 IGNORED_MODULES = (
-    'cross_decomposition',
-    'covariance',
     'cluster',
     'datasets',
-    'decomposition',
-    'feature_extraction',
     'gaussian_process',
     'linear_model',
-    'manifold',
-    'metrics',
-    'discriminant_analysis',
     'ensemble',
     'feature_selection',
     'kernel_approximation',
     'model_selection',
     'multioutput',
-    'random_projection',
     'setup',
-    'svm',
     'utils',
     'neighbors',
     # Deprecated modules
diff --git a/sklearn/tests/test_impute.py b/sklearn/tests/test_impute.py
index 72b8087090..cf90481586 100755
--- a/sklearn/tests/test_impute.py
+++ b/sklearn/tests/test_impute.py
@@ -826,18 +826,18 @@ def test_missing_indicator_sparse_param(arr_type, missing_values,
 @pytest.mark.parametrize("imputer_constructor",
                          [SimpleImputer, ChainedImputer, MissingIndicator])
 @pytest.mark.parametrize(
-    "missing_values, X_missing_value, err_type, err_msg",
-    [("NaN", np.nan, ValueError, "contains"),
-     ("-1", -1, TypeError, "not compatible")])
+    "missing_values, X_missing_value, err_msg",
+    [("NaN", np.nan, "Input contains NaN"),
+     ("-1", -1, "data type of 'missing_values' and 'X' are not compatible")])
 def test_inconsistent_dtype_X_missing_values(imputer_constructor,
                                              missing_values, X_missing_value,
-                                             err_type, err_msg):
+                                             err_msg):
     # regression test for issue #11390. Comparison between incoherent dtype
     # for X and missing_values was not raising a proper error.
-    X = np.random.randn(1000, 10)
+    X = np.random.randn(10, 10)
     X[0, 0] = X_missing_value
 
     imputer = imputer_constructor(missing_values=missing_values)
 
-    with pytest.raises(err_type, match=err_msg):
+    with pytest.raises(ValueError, match=err_msg):
         imputer.fit_transform(X)
diff --git a/sklearn/tree/tree.py b/sklearn/tree/tree.py
index af216f1906..7105a86ce0 100755
--- a/sklearn/tree/tree.py
+++ b/sklearn/tree/tree.py
@@ -1152,7 +1152,7 @@ class ExtraTreeClassifier(DecisionTreeClassifier):
         The function to measure the quality of a split. Supported criteria are
         "gini" for the Gini impurity and "entropy" for the information gain.
 
-    splitter : string, optional (default="best")
+    splitter : string, optional (default="random")
         The strategy used to choose the split at each node. Supported
         strategies are "best" to choose the best split and "random" to choose
         the best random split.
@@ -1189,7 +1189,7 @@ class ExtraTreeClassifier(DecisionTreeClassifier):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    max_features : int, float, string or None, optional (default=None)
+    max_features : int, float, string or None, optional (default="auto")
         The number of features to consider when looking for the best split:
 
             - If int, then consider `max_features` features at each split.
@@ -1336,7 +1336,7 @@ class ExtraTreeRegressor(DecisionTreeRegressor):
         .. versionadded:: 0.18
            Mean Absolute Error (MAE) criterion.
 
-    splitter : string, optional (default="best")
+    splitter : string, optional (default="random")
         The strategy used to choose the split at each node. Supported
         strategies are "best" to choose the best split and "random" to choose
         the best random split.
@@ -1373,7 +1373,7 @@ class ExtraTreeRegressor(DecisionTreeRegressor):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    max_features : int, float, string or None, optional (default=None)
+    max_features : int, float, string or None, optional (default="auto")
         The number of features to consider when looking for the best split:
 
         - If int, then consider `max_features` features at each split.
diff --git a/sklearn/utils/estimator_checks.py b/sklearn/utils/estimator_checks.py
index fa06bac27f..61c9c14a04 100755
--- a/sklearn/utils/estimator_checks.py
+++ b/sklearn/utils/estimator_checks.py
@@ -78,9 +78,9 @@
                 'RANSACRegressor', 'RadiusNeighborsRegressor',
                 'RandomForestRegressor', 'Ridge', 'RidgeCV']
 
-ALLOW_NAN = ['Imputer', 'SimpleImputer', 'ChainedImputer',
-             'MaxAbsScaler', 'MinMaxScaler', 'StandardScaler',
-             'PowerTransformer', 'QuantileTransformer', 'MissingIndicator']
+ALLOW_NAN = ['Imputer', 'SimpleImputer', 'ChainedImputer', 'MissingIndicator',
+             'MaxAbsScaler', 'MinMaxScaler', 'RobustScaler', 'StandardScaler',
+             'PowerTransformer', 'QuantileTransformer']
 
 
 def _yield_non_meta_checks(name, estimator):
diff --git a/sklearn/utils/fixes.py b/sklearn/utils/fixes.py
index 0117770084..748670e4dd 100755
--- a/sklearn/utils/fixes.py
+++ b/sklearn/utils/fixes.py
@@ -12,6 +12,7 @@
 
 import os
 import errno
+import sys
 
 import numpy as np
 import scipy.sparse as sp
@@ -39,6 +40,7 @@ def _parse_version(version_string):
 
 np_version = _parse_version(np.__version__)
 sp_version = _parse_version(scipy.__version__)
+PY3_OR_LATER = sys.version_info[0] >= 3
 
 
 # Remove when minimum required NumPy >= 1.10
@@ -280,6 +282,19 @@ def nanpercentile(a, q):
     from numpy import nanpercentile  # noqa
 
 
+if np_version < (1, 9):
+    def nanmedian(a, axis=None):
+        if axis is None:
+            data = a.reshape(-1)
+            return np.median(np.compress(~np.isnan(data), data))
+        else:
+            data = a.T if not axis else a
+            return np.array([np.median(np.compress(~np.isnan(row), row))
+                             for row in data])
+else:
+    from numpy import nanmedian  # noqa
+
+
 # Fix for behavior inconsistency on numpy.equal for object dtypes.
 # For numpy versions < 1.13, numpy.equal tests element-wise identity of objects
 # instead of equality. This fix returns the mask of NaNs in an array of
diff --git a/sklearn/utils/seq_dataset.pyx b/sklearn/utils/seq_dataset.pyx
index 94e4868eef..b4e0997744 100755
--- a/sklearn/utils/seq_dataset.pyx
+++ b/sklearn/utils/seq_dataset.pyx
@@ -15,12 +15,44 @@ np.import_array()
 
 
 cdef class SequentialDataset:
-    """Base class for datasets with sequential data access. """
+    """Base class for datasets with sequential data access.
+
+    SequentialDataset is used to iterate over the rows of a matrix X and
+    corresponding target values y, i.e. to iterate over samples.
+    There are two methods to get the next sample:
+        - next : Iterate sequentially (optionally randomized)
+        - random : Iterate randomly (with replacement)
+
+    Attributes
+    ----------
+    index : np.ndarray
+        Index array for fast shuffling.
+
+    index_data_ptr : int
+        Pointer to the index array.
+
+    current_index : int
+        Index of current sample in ``index``.
+        The index of current sample in the data is given by
+        index_data_ptr[current_index].
+
+    n_samples : Py_ssize_t
+        Number of samples in the dataset.
+
+    seed : np.uint32_t
+        Seed used for random sampling.
+
+    """
 
     cdef void next(self, double **x_data_ptr, int **x_ind_ptr,
                    int *nnz, double *y, double *sample_weight) nogil:
         """Get the next example ``x`` from the dataset.
 
+        This method gets the next sample looping sequentially over all samples.
+        The order can be shuffled with the method ``shuffle``.
+        Shuffling once before iterating over all samples corresponds to a
+        random draw without replacement. It is used for instance in SGD solver.
+
         Parameters
         ----------
         x_data_ptr : double**
@@ -49,6 +81,10 @@ cdef class SequentialDataset:
                     int *nnz, double *y, double *sample_weight) nogil:
         """Get a random example ``x`` from the dataset.
 
+        This method gets next sample chosen randomly over a uniform
+        distribution. It corresponds to a random draw with replacement.
+        It is used for instance in SAG solver.
+
         Parameters
         ----------
         x_data_ptr : double**
@@ -71,8 +107,8 @@ cdef class SequentialDataset:
 
         Returns
         -------
-        index : int
-            The index sampled
+        current_index : int
+            Index of current sample.
         """
         cdef int current_index = self._get_random_index()
         self._sample(x_data_ptr, x_ind_ptr, nnz, y, sample_weight,
diff --git a/sklearn/utils/tests/test_fixes.py b/sklearn/utils/tests/test_fixes.py
index 8a55f74a4f..92f954439f 100755
--- a/sklearn/utils/tests/test_fixes.py
+++ b/sklearn/utils/tests/test_fixes.py
@@ -14,6 +14,7 @@
 
 from sklearn.utils.fixes import divide
 from sklearn.utils.fixes import MaskedArray
+from sklearn.utils.fixes import nanmedian
 from sklearn.utils.fixes import nanpercentile
 
 
@@ -31,6 +32,22 @@ def test_masked_array_obj_dtype_pickleable():
         assert_array_equal(marr.mask, marr_pickled.mask)
 
 
+@pytest.mark.parametrize(
+    "axis, expected_median",
+    [(None, 4.0),
+     (0, np.array([1., 3.5, 3.5, 4., 7., np.nan])),
+     (1, np.array([1., 6.]))]
+)
+def test_nanmedian(axis, expected_median):
+    X = np.array([[1, 1, 1, 2, np.nan, np.nan],
+                  [np.nan, 6, 6, 6, 7, np.nan]])
+    median = nanmedian(X, axis=axis)
+    if axis is None:
+        assert median == pytest.approx(expected_median)
+    else:
+        assert_allclose(median, expected_median)
+
+
 @pytest.mark.parametrize(
     "a, q, expected_percentile",
     [(np.array([1, 2, 3, np.nan]), [0, 50, 100], np.array([1., 2., 3.])),
diff --git a/sklearn/utils/tests/test_seq_dataset.py b/sklearn/utils/tests/test_seq_dataset.py
index aaa3e43fc9..45435371b8 100755
--- a/sklearn/utils/tests/test_seq_dataset.py
+++ b/sklearn/utils/tests/test_seq_dataset.py
@@ -1,4 +1,4 @@
-# Author: Tom Dupre la Tour <tom.dupre-la-tour@m4x.org>
+# Author: Tom Dupre la Tour
 #
 # License: BSD 3 clause
 
@@ -81,4 +81,3 @@ def test_seq_dataset_shuffle():
         _, _, _, idx1 = dataset1._random_py()
         _, _, _, idx2 = dataset2._random_py()
         assert_equal(idx1, idx2)
-
