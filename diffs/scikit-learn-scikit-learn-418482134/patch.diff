diff --git a/doc/datasets/openml.rst b/doc/datasets/openml.rst
index 53ab211df903..52dd45391952 100644
--- a/doc/datasets/openml.rst
+++ b/doc/datasets/openml.rst
@@ -23,7 +23,7 @@ For example, to download a dataset of gene expressions in mice brains::
   >>> mice = fetch_openml(name='miceprotein', version=4)
 
 To fully specify a dataset, you need to provide a name and a version, though
-the version is optional, see :ref:`openml_versions`_ below.
+the version is optional, see :ref:`openml_versions` below.
 The dataset contains a total of 1080 examples belonging to 8 different
 classes::
 
diff --git a/doc/modules/outlier_detection.rst b/doc/modules/outlier_detection.rst
index 6f7f65852197..9dbe013bef5d 100644
--- a/doc/modules/outlier_detection.rst
+++ b/doc/modules/outlier_detection.rst
@@ -306,10 +306,10 @@ This strategy is illustrated below.
 .. topic:: Examples:
 
    * See :ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`
-   for an illustration of the use of :class:`neighbors.LocalOutlierFactor`.
+     for an illustration of the use of :class:`neighbors.LocalOutlierFactor`.
 
    * See :ref:`sphx_glr_auto_examples_plot_anomaly_comparison.py` for a
-   comparison with other anomaly detection methods.
+     comparison with other anomaly detection methods.
 
 .. topic:: References:
 
diff --git a/examples/applications/plot_face_recognition.py b/examples/applications/plot_face_recognition.py
index 13a38d13bc00..dce3df1d3ee9 100644
--- a/examples/applications/plot_face_recognition.py
+++ b/examples/applications/plot_face_recognition.py
@@ -108,7 +108,8 @@
 t0 = time()
 param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],
               'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }
-clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)
+clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'),
+                   param_grid, cv=5)
 clf = clf.fit(X_train_pca, y_train)
 print("done in %0.3fs" % (time() - t0))
 print("Best estimator found by grid search:")
diff --git a/examples/applications/plot_stock_market.py b/examples/applications/plot_stock_market.py
index 379efb8e4dfe..e2edc25b7eb7 100644
--- a/examples/applications/plot_stock_market.py
+++ b/examples/applications/plot_stock_market.py
@@ -166,7 +166,7 @@
 
 # #############################################################################
 # Learn a graphical structure from the correlations
-edge_model = covariance.GraphicalLassoCV()
+edge_model = covariance.GraphicalLassoCV(cv=5)
 
 # standardize the time series: using correlations rather than covariance
 # is more efficient for structure recovery
diff --git a/examples/compose/plot_digits_pipe.py b/examples/compose/plot_digits_pipe.py
index b95d2847ada1..2352abba4584 100644
--- a/examples/compose/plot_digits_pipe.py
+++ b/examples/compose/plot_digits_pipe.py
@@ -54,7 +54,7 @@
 # Parameters of pipelines can be set using ‘__’ separated parameter names:
 estimator = GridSearchCV(pipe,
                          dict(pca__n_components=n_components,
-                              logistic__C=Cs))
+                              logistic__C=Cs), cv=5)
 estimator.fit(X_digits, y_digits)
 
 plt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,
diff --git a/examples/compose/plot_feature_union.py b/examples/compose/plot_feature_union.py
index 4798617f40cb..56d1e320c4e3 100644
--- a/examples/compose/plot_feature_union.py
+++ b/examples/compose/plot_feature_union.py
@@ -55,6 +55,6 @@
                   features__univ_select__k=[1, 2],
                   svm__C=[0.1, 1, 10])
 
-grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10)
+grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=10)
 grid_search.fit(X, y)
 print(grid_search.best_estimator_)
diff --git a/examples/covariance/plot_covariance_estimation.py b/examples/covariance/plot_covariance_estimation.py
index d33b77d68a43..acbe567c534f 100644
--- a/examples/covariance/plot_covariance_estimation.py
+++ b/examples/covariance/plot_covariance_estimation.py
@@ -83,7 +83,7 @@
 
 # GridSearch for an optimal shrinkage coefficient
 tuned_parameters = [{'shrinkage': shrinkages}]
-cv = GridSearchCV(ShrunkCovariance(), tuned_parameters)
+cv = GridSearchCV(ShrunkCovariance(), tuned_parameters, cv=5)
 cv.fit(X_train)
 
 # Ledoit-Wolf optimal shrinkage coefficient estimate
diff --git a/examples/covariance/plot_sparse_cov.py b/examples/covariance/plot_sparse_cov.py
index 313d2544c7e5..a2009bb330d9 100644
--- a/examples/covariance/plot_sparse_cov.py
+++ b/examples/covariance/plot_sparse_cov.py
@@ -83,7 +83,7 @@
 # Estimate the covariance
 emp_cov = np.dot(X.T, X) / n_samples
 
-model = GraphicalLassoCV()
+model = GraphicalLassoCV(cv=5)
 model.fit(X)
 cov_ = model.covariance_
 prec_ = model.precision_
diff --git a/examples/decomposition/plot_pca_vs_fa_model_selection.py b/examples/decomposition/plot_pca_vs_fa_model_selection.py
index b858434d910e..9d395f70c3dd 100644
--- a/examples/decomposition/plot_pca_vs_fa_model_selection.py
+++ b/examples/decomposition/plot_pca_vs_fa_model_selection.py
@@ -69,20 +69,20 @@ def compute_scores(X):
     for n in n_components:
         pca.n_components = n
         fa.n_components = n
-        pca_scores.append(np.mean(cross_val_score(pca, X)))
-        fa_scores.append(np.mean(cross_val_score(fa, X)))
+        pca_scores.append(np.mean(cross_val_score(pca, X, cv=5)))
+        fa_scores.append(np.mean(cross_val_score(fa, X, cv=5)))
 
     return pca_scores, fa_scores
 
 
 def shrunk_cov_score(X):
     shrinkages = np.logspace(-2, 0, 30)
-    cv = GridSearchCV(ShrunkCovariance(), {'shrinkage': shrinkages})
-    return np.mean(cross_val_score(cv.fit(X).best_estimator_, X))
+    cv = GridSearchCV(ShrunkCovariance(), {'shrinkage': shrinkages}, cv=5)
+    return np.mean(cross_val_score(cv.fit(X).best_estimator_, X, cv=5))
 
 
 def lw_score(X):
-    return np.mean(cross_val_score(LedoitWolf(), X))
+    return np.mean(cross_val_score(LedoitWolf(), X, cv=5))
 
 
 for X, title in [(X_homo, 'Homoscedastic Noise'),
diff --git a/examples/exercises/plot_cv_diabetes.py b/examples/exercises/plot_cv_diabetes.py
index 76b0d81b8998..d68fd21bd70a 100644
--- a/examples/exercises/plot_cv_diabetes.py
+++ b/examples/exercises/plot_cv_diabetes.py
@@ -29,7 +29,7 @@
 alphas = np.logspace(-4, -0.5, 30)
 
 tuned_parameters = [{'alpha': alphas}]
-n_folds = 3
+n_folds = 5
 
 clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False)
 clf.fit(X, y)
@@ -60,7 +60,7 @@
 # performs cross-validation on the training data it receives).
 # We use external cross-validation to see how much the automatically obtained
 # alphas differ across different cross-validation folds.
-lasso_cv = LassoCV(alphas=alphas, random_state=0)
+lasso_cv = LassoCV(alphas=alphas, cv=5, random_state=0)
 k_fold = KFold(3)
 
 print("Answer to the bonus question:",
diff --git a/examples/exercises/plot_cv_digits.py b/examples/exercises/plot_cv_digits.py
index a68f92afbdad..f51bcc7e0256 100644
--- a/examples/exercises/plot_cv_digits.py
+++ b/examples/exercises/plot_cv_digits.py
@@ -26,7 +26,7 @@
 scores_std = list()
 for C in C_s:
     svc.C = C
-    this_scores = cross_val_score(svc, X, y, n_jobs=1)
+    this_scores = cross_val_score(svc, X, y, cv=5, n_jobs=1)
     scores.append(np.mean(this_scores))
     scores_std.append(np.std(this_scores))
 
diff --git a/examples/feature_selection/plot_select_from_model_boston.py b/examples/feature_selection/plot_select_from_model_boston.py
index 17ef6d6bd014..400a736942b6 100644
--- a/examples/feature_selection/plot_select_from_model_boston.py
+++ b/examples/feature_selection/plot_select_from_model_boston.py
@@ -23,7 +23,7 @@
 X, y = boston['data'], boston['target']
 
 # We use the base estimator LassoCV since the L1 norm promotes sparsity of features.
-clf = LassoCV()
+clf = LassoCV(cv=5)
 
 # Set a minimum threshold of 0.25
 sfm = SelectFromModel(clf, threshold=0.25)
diff --git a/examples/linear_model/plot_omp.py b/examples/linear_model/plot_omp.py
index f07b7d723340..8a3b52fc588f 100644
--- a/examples/linear_model/plot_omp.py
+++ b/examples/linear_model/plot_omp.py
@@ -67,7 +67,7 @@
 
 # plot the noisy reconstruction with number of non-zeros set by CV
 ##################################################################
-omp_cv = OrthogonalMatchingPursuitCV()
+omp_cv = OrthogonalMatchingPursuitCV(cv=5)
 omp_cv.fit(X, y_noisy)
 coef = omp_cv.coef_
 idx_r, = coef.nonzero()
diff --git a/examples/linear_model/plot_sparse_logistic_regression_mnist.py b/examples/linear_model/plot_sparse_logistic_regression_mnist.py
index 7f5a328c08f0..523f5683a5a1 100644
--- a/examples/linear_model/plot_sparse_logistic_regression_mnist.py
+++ b/examples/linear_model/plot_sparse_logistic_regression_mnist.py
@@ -36,9 +36,7 @@
 train_samples = 5000
 
 # Load data from https://www.openml.org/d/554
-mnist = fetch_openml('mnist_784', version=1)
-X = mnist.data
-y = mnist.target
+X, y = fetch_openml('mnist_784', version=1, return_X_y=True)
 
 random_state = check_random_state(0)
 permutation = random_state.permutation(X.shape[0])
diff --git a/examples/model_selection/grid_search_text_feature_extraction.py b/examples/model_selection/grid_search_text_feature_extraction.py
index c3bd054c9951..c220a43ed858 100644
--- a/examples/model_selection/grid_search_text_feature_extraction.py
+++ b/examples/model_selection/grid_search_text_feature_extraction.py
@@ -113,7 +113,8 @@
 
     # find the best parameters for both the feature extraction and the
     # classifier
-    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)
+    grid_search = GridSearchCV(pipeline, parameters, cv=5,
+                               n_jobs=-1, verbose=1)
 
     print("Performing grid search...")
     print("pipeline:", [name for name, _ in pipeline.steps])
diff --git a/examples/model_selection/plot_randomized_search.py b/examples/model_selection/plot_randomized_search.py
index a1c408e510b0..2429c92e2642 100644
--- a/examples/model_selection/plot_randomized_search.py
+++ b/examples/model_selection/plot_randomized_search.py
@@ -61,7 +61,7 @@ def report(results, n_top=3):
 # run randomized search
 n_iter_search = 20
 random_search = RandomizedSearchCV(clf, param_distributions=param_dist,
-                                   n_iter=n_iter_search)
+                                   n_iter=n_iter_search, cv=5)
 
 start = time()
 random_search.fit(X, y)
@@ -77,7 +77,7 @@ def report(results, n_top=3):
               "criterion": ["gini", "entropy"]}
 
 # run grid search
-grid_search = GridSearchCV(clf, param_grid=param_grid)
+grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)
 start = time()
 grid_search.fit(X, y)
 
diff --git a/examples/multioutput/plot_classifier_chain_yeast.py b/examples/multioutput/plot_classifier_chain_yeast.py
index ea62eda756de..cb3a5085e316 100644
--- a/examples/multioutput/plot_classifier_chain_yeast.py
+++ b/examples/multioutput/plot_classifier_chain_yeast.py
@@ -47,9 +47,8 @@
 print(__doc__)
 
 # Load a multi-label dataset from https://www.openml.org/d/40597
-yeast = fetch_openml('yeast', version=4)
-X = yeast.data
-Y = yeast.target == 'TRUE'
+X, Y = fetch_openml('yeast', version=4, return_X_y=True)
+Y = Y == 'TRUE'
 X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2,
                                                     random_state=0)
 
diff --git a/examples/neighbors/plot_digits_kde_sampling.py b/examples/neighbors/plot_digits_kde_sampling.py
index 8367d16b955f..ca44c96f1302 100644
--- a/examples/neighbors/plot_digits_kde_sampling.py
+++ b/examples/neighbors/plot_digits_kde_sampling.py
@@ -27,7 +27,7 @@
 
 # use grid search cross-validation to optimize the bandwidth
 params = {'bandwidth': np.logspace(-1, 1, 20)}
-grid = GridSearchCV(KernelDensity(), params)
+grid = GridSearchCV(KernelDensity(), params, cv=5)
 grid.fit(data)
 
 print("best bandwidth: {0}".format(grid.best_estimator_.bandwidth))
diff --git a/examples/neural_networks/plot_mnist_filters.py b/examples/neural_networks/plot_mnist_filters.py
index bd8a9e96027a..ab50d4e59a81 100644
--- a/examples/neural_networks/plot_mnist_filters.py
+++ b/examples/neural_networks/plot_mnist_filters.py
@@ -27,9 +27,7 @@
 print(__doc__)
 
 # Load data from https://www.openml.org/d/554
-mnist = fetch_openml('mnist_784', version=1)
-X = mnist.data
-y = mnist.target
+X, y = fetch_openml('mnist_784', version=1, return_X_y=True)
 
 # rescale the data, use the traditional train/test split
 X_train, X_test = X[:60000], X[60000:]
diff --git a/examples/plot_missing_values.py b/examples/plot_missing_values.py
index 777120053a9d..755943fb55bd 100644
--- a/examples/plot_missing_values.py
+++ b/examples/plot_missing_values.py
@@ -39,7 +39,7 @@ def get_results(dataset):
     # Estimate the score on the entire dataset, with no missing values
     estimator = RandomForestRegressor(random_state=0, n_estimators=100)
     full_scores = cross_val_score(estimator, X_full, y_full,
-                                  scoring='neg_mean_squared_error')
+                                  scoring='neg_mean_squared_error', cv=5)
 
     # Add missing values in 75% of the lines
     missing_rate = 0.75
@@ -57,7 +57,8 @@ def get_results(dataset):
     y_missing = y_full.copy()
     estimator = RandomForestRegressor(random_state=0, n_estimators=100)
     zero_impute_scores = cross_val_score(estimator, X_missing, y_missing,
-                                         scoring='neg_mean_squared_error')
+                                         scoring='neg_mean_squared_error',
+                                         cv=5)
 
     # Estimate the score after imputation (mean strategy) of the missing values
     X_missing = X_full.copy()
@@ -68,7 +69,8 @@ def get_results(dataset):
                    MissingIndicator(missing_values=0)),
         RandomForestRegressor(random_state=0, n_estimators=100))
     mean_impute_scores = cross_val_score(estimator, X_missing, y_missing,
-                                         scoring='neg_mean_squared_error')
+                                         scoring='neg_mean_squared_error',
+                                         cv=5)
 
 
     return ((full_scores.mean(), full_scores.std()),
diff --git a/examples/svm/plot_svm_anova.py b/examples/svm/plot_svm_anova.py
index 45599f31f546..08f9fddf71db 100644
--- a/examples/svm/plot_svm_anova.py
+++ b/examples/svm/plot_svm_anova.py
@@ -45,7 +45,7 @@
 for percentile in percentiles:
     clf.set_params(anova__percentile=percentile)
     # Compute cross-validation score using 1 CPU
-    this_scores = cross_val_score(clf, X, y, n_jobs=1)
+    this_scores = cross_val_score(clf, X, y, cv=5, n_jobs=1)
     score_means.append(this_scores.mean())
     score_stds.append(this_scores.std())
 
diff --git a/sklearn/datasets/openml.py b/sklearn/datasets/openml.py
index 6864fa865abc..a35fa5130799 100644
--- a/sklearn/datasets/openml.py
+++ b/sklearn/datasets/openml.py
@@ -347,7 +347,7 @@ def _verify_target_data_type(features_dict, target_columns):
 
 
 def fetch_openml(name=None, version='active', data_id=None, data_home=None,
-                 target_column='default-target', cache=True):
+                 target_column='default-target', cache=True, return_X_y=False):
     """Fetch dataset from openml by name or dataset id.
 
     Datasets are uniquely identified by either an integer ID or by a
@@ -395,6 +395,10 @@ def fetch_openml(name=None, version='active', data_id=None, data_home=None,
     cache : boolean, default=True
         Whether to cache downloaded datasets using joblib.
 
+    return_X_y : boolean, default=False.
+        If True, returns ``(data, target)`` instead of a Bunch object. See
+        below for more information about the `data` and `target` objects.
+
     Returns
     -------
 
@@ -416,6 +420,8 @@ def fetch_openml(name=None, version='active', data_id=None, data_home=None,
         details : dict
             More metadata from OpenML
 
+    (data, target) : tuple if ``return_X_y`` is True
+
         .. note:: EXPERIMENTAL
 
             This interface is **experimental** as at version 0.20 and
@@ -557,6 +563,9 @@ def fetch_openml(name=None, version='active', data_id=None, data_home=None,
     elif y.shape[1] == 0:
         y = None
 
+    if return_X_y:
+        return X, y
+
     bunch = Bunch(
         data=X, target=y, feature_names=data_columns,
         DESCR=description, details=data_description,
diff --git a/sklearn/datasets/tests/test_openml.py b/sklearn/datasets/tests/test_openml.py
index da2b913eda7e..3a24213062fc 100644
--- a/sklearn/datasets/tests/test_openml.py
+++ b/sklearn/datasets/tests/test_openml.py
@@ -15,6 +15,8 @@
                                    assert_raise_message)
 from sklearn.externals.six import string_types
 from sklearn.externals.six.moves.urllib.error import HTTPError
+from sklearn.datasets.tests.test_common import check_return_X_y
+from functools import partial
 
 
 currdir = os.path.dirname(os.path.abspath(__file__))
@@ -124,6 +126,11 @@ def _fetch_dataset_from_openml(data_id, data_name, data_version,
         # np.isnan doesn't work on CSR matrix
         assert (np.count_nonzero(np.isnan(data_by_id.data)) ==
                 expected_missing)
+
+    # test return_X_y option
+    fetch_func = partial(fetch_openml, data_id=data_id, cache=False,
+                         target_column=target_column)
+    check_return_X_y(data_by_id, fetch_func)
     return data_by_id
 
 
diff --git a/sklearn/ensemble/forest.py b/sklearn/ensemble/forest.py
index 8f4a759c8bf2..125f48d5b0da 100644
--- a/sklearn/ensemble/forest.py
+++ b/sklearn/ensemble/forest.py
@@ -965,7 +965,7 @@ class labels (multi-output problem).
                 min_impurity_decrease=0.0, min_impurity_split=None,
                 min_samples_leaf='deprecated', min_samples_split=2,
                 min_weight_fraction_leaf='deprecated', n_estimators=100,
-                n_jobs=1, oob_score=False, random_state=0, verbose=0,
+                n_jobs=None, oob_score=False, random_state=0, verbose=0,
                 warm_start=False)
     >>> print(clf.feature_importances_)
     [0.14205973 0.76664038 0.0282433  0.06305659]
@@ -1222,7 +1222,7 @@ class RandomForestRegressor(ForestRegressor):
                min_impurity_decrease=0.0, min_impurity_split=None,
                min_samples_leaf='deprecated', min_samples_split=2,
                min_weight_fraction_leaf='deprecated', n_estimators=100,
-               n_jobs=1, oob_score=False, random_state=0, verbose=0,
+               n_jobs=None, oob_score=False, random_state=0, verbose=0,
                warm_start=False)
     >>> print(regr.feature_importances_)
     [0.18146984 0.81473937 0.00145312 0.00233767]
@@ -1244,11 +1244,18 @@ class RandomForestRegressor(ForestRegressor):
     search of the best split. To obtain a deterministic behaviour during
     fitting, ``random_state`` has to be fixed.
 
+    The default value ``max_features="auto"`` uses ``n_features`` 
+    rather than ``n_features / 3``. The latter was originally suggested in
+    [1], whereas the former was more recently justified empirically in [2].
+
     References
     ----------
 
     .. [1] L. Breiman, "Random Forests", Machine Learning, 45(1), 5-32, 2001.
 
+    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, "Extremely randomized 
+           trees", Machine Learning, 63(1), 3-42, 2006.
+
     See also
     --------
     DecisionTreeRegressor, ExtraTreesRegressor
@@ -1502,8 +1509,8 @@ class labels (multi-output problem).
     References
     ----------
 
-    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, "Extremely randomized trees",
-           Machine Learning, 63(1), 3-42, 2006.
+    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, "Extremely randomized 
+           trees", Machine Learning, 63(1), 3-42, 2006.
 
     See also
     --------
diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
index 32d81f7e86f2..6e9cd843d59b 100644
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -25,6 +25,7 @@
 
 from abc import ABCMeta
 from abc import abstractmethod
+import warnings
 
 from .base import BaseEnsemble
 from ..base import ClassifierMixin
@@ -1497,9 +1498,17 @@ def _fit_stages(self, X, y, y_pred, sample_weight, random_state,
         n_inbag = max(1, int(self.subsample * n_samples))
         loss_ = self.loss_
 
+        if self.min_weight_fraction_leaf != 'deprecated':
+            warnings.warn("'min_weight_fraction_leaf' is deprecated in 0.20 "
+                          "and will be fixed to a value of 0 in 0.22.",
+                          DeprecationWarning)
+            min_weight_fraction_leaf = self.min_weight_fraction_leaf
+        else:
+            min_weight_fraction_leaf = 0.
+
         # Set min_weight_leaf from min_weight_fraction_leaf
-        if self.min_weight_fraction_leaf != 0. and sample_weight is not None:
-            min_weight_leaf = (self.min_weight_fraction_leaf *
+        if min_weight_fraction_leaf != 0. and sample_weight is not None:
+            min_weight_leaf = (min_weight_fraction_leaf *
                                np.sum(sample_weight))
         else:
             min_weight_leaf = 0.
diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py
index 66beeadb53de..4ab267fc737a 100644
--- a/sklearn/ensemble/iforest.py
+++ b/sklearn/ensemble/iforest.py
@@ -5,7 +5,6 @@
 from __future__ import division
 
 import numpy as np
-import scipy as sp
 import warnings
 from warnings import warn
 from sklearn.utils.fixes import euler_gamma
@@ -136,7 +135,7 @@ class IsolationForest(BaseBagging, OutlierMixin):
     offset_ : float
         Offset used to define the decision function from the raw scores.
         We have the relation: ``decision_function = score_samples - offset_``.
-        Assuming behaviour == 'new', offset_ is defined as follows.
+        Assuming behaviour == 'new', ``offset_`` is defined as follows.
         When the contamination parameter is set to "auto", the offset is equal
         to -0.5 as the scores of inliers are close to 0 and the scores of
         outliers are close to -1. When a contamination parameter different
@@ -144,7 +143,7 @@ class IsolationForest(BaseBagging, OutlierMixin):
         the expected number of outliers (samples with decision function < 0)
         in training.
         Assuming the behaviour parameter is set to 'old', we always have
-        offset_ = -0.5, making the decision function independent from the
+        ``offset_ = -0.5``, making the decision function independent from the
         contamination parameter.
 
     References
diff --git a/sklearn/externals/joblib/memory.py b/sklearn/externals/joblib/memory.py
index 91204af01f8e..ae187950bcfa 100644
--- a/sklearn/externals/joblib/memory.py
+++ b/sklearn/externals/joblib/memory.py
@@ -515,8 +515,9 @@ def __reduce__(self):
             depending from it.
             In addition, when unpickling, we run the __init__
         """
-        return (self.__class__, (self.func, self.store_backend, self.ignore,
-                self.mmap_mode, self.compress, self._verbose))
+        return (self.__class__, (self.func, None),
+                {k: v for k, v in vars(self).items()
+                 if k not in ('timestamp', 'func')})
 
     # ------------------------------------------------------------------------
     # Private interface
@@ -775,12 +776,6 @@ class Memory(Logger):
             The 'local' backend is using regular filesystem operations to
             manipulate data (open, mv, etc) in the backend.
 
-        cachedir: str or None, optional
-
-            .. deprecated: 0.12
-                'cachedir' has been deprecated in 0.12 and will be
-                removed in 0.14. Use the 'location' parameter instead.
-
         mmap_mode: {None, 'r+', 'r', 'w+', 'c'}, optional
             The memmapping mode used when loading from cache
             numpy arrays. See numpy.load for the meaning of the
@@ -802,14 +797,20 @@ class Memory(Logger):
         backend_options: dict, optional
             Contains a dictionnary of named parameters used to configure
             the store backend.
+
+        cachedir: str or None, optional
+
+            .. deprecated: 0.12
+                'cachedir' has been deprecated in 0.12 and will be
+                removed in 0.14. Use the 'location' parameter instead.
     """
     # ------------------------------------------------------------------------
     # Public interface
     # ------------------------------------------------------------------------
 
-    def __init__(self, location=None, backend='local', cachedir=None,
-                 mmap_mode=None, compress=False, verbose=1, bytes_limit=None,
-                 backend_options={}):
+    def __init__(self, location=None, backend='local', mmap_mode=None,
+                 compress=False, verbose=1, bytes_limit=None,
+                 backend_options={}, cachedir=None):
         # XXX: Bad explanation of the None value of cachedir
         Logger.__init__(self)
         self._verbose = verbose
@@ -940,10 +941,5 @@ def __reduce__(self):
             depending from it.
             In addition, when unpickling, we run the __init__
         """
-        # We need to remove 'joblib' from the end of cachedir
-        location = (repr(self.store_backend)[:-7]
-                    if self.store_backend is not None else None)
-        compress = self.store_backend.compress \
-            if self.store_backend is not None else False
-        return (self.__class__, (location, self.backend, self.mmap_mode,
-                                 compress, self._verbose))
+        return (self.__class__, (), {k: v for k, v in vars(self).items()
+                                     if k != 'timestamp'})
diff --git a/sklearn/neighbors/lof.py b/sklearn/neighbors/lof.py
index d688f3b38a74..68fe777b3c48 100644
--- a/sklearn/neighbors/lof.py
+++ b/sklearn/neighbors/lof.py
@@ -122,7 +122,7 @@ class LocalOutlierFactor(NeighborsBase, KNeighborsMixin, UnsupervisedMixin,
     ----------
     negative_outlier_factor_ : numpy array, shape (n_samples,)
         The opposite LOF of the training samples. The higher, the more normal.
-        Inliers tend to have a LOF score close to 1 (`negative_outlier_factor_`
+        Inliers tend to have a LOF score close to 1 (``negative_outlier_factor_``
         close to -1), while outliers tend to have a larger LOF score.
 
         The local outlier factor (LOF) of a sample captures its
@@ -404,7 +404,7 @@ def score_samples(self):
         Also, the samples in X are not considered in the neighborhood of any
         point.
         The score_samples on training data is available by considering the
-        the negative_outlier_factor_ attribute.
+        the ``negative_outlier_factor_`` attribute.
 
         Parameters
         ----------
@@ -440,7 +440,7 @@ def _score_samples(self, X):
         Also, the samples in X are not considered in the neighborhood of any
         point.
         The score_samples on training data is available by considering the
-        the negative_outlier_factor_ attribute.
+        the ``negative_outlier_factor_`` attribute.
 
         Parameters
         ----------
diff --git a/sklearn/utils/stats.py b/sklearn/utils/stats.py
index 43f37bb95a6b..82b8912b7882 100644
--- a/sklearn/utils/stats.py
+++ b/sklearn/utils/stats.py
@@ -22,4 +22,6 @@ def _weighted_percentile(array, sample_weight, percentile=50):
     weight_cdf = stable_cumsum(sample_weight[sorted_idx])
     percentile_idx = np.searchsorted(
         weight_cdf, (percentile / 100.) * weight_cdf[-1])
+    # in rare cases, percentile_idx equals to len(sorted_idx)
+    percentile_idx = np.clip(percentile_idx, 0, len(sorted_idx)-1)
     return array[sorted_idx[percentile_idx]]
