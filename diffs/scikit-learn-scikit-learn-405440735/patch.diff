diff --git a/.circleci/config.yml b/.circleci/config.yml
index 7ad3e5427b27..fcc43270c668 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -91,4 +91,3 @@ workflows:
       - deploy:
           requires:
             - python3
-            - python2
diff --git a/.travis.yml b/.travis.yml
index 92363f82ad72..788b7203d830 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -38,13 +38,15 @@ matrix:
            NUMPY_VERSION="1.10.4" SCIPY_VERSION="0.16.1" CYTHON_VERSION="0.25.2"
            PILLOW_VERSION="4.0.0" COVERAGE=true
       if: type != cron
-    # This environment tests the newest supported Anaconda release (5.0.0)
-    # It also runs tests requiring Pandas and PyAMG
+    # This environment tests the newest supported Anaconda release.
+    # It runs tests requiring pandas and PyAMG.
+    # It also runs with the site joblib instead of the vendored copy of joblib.
     - env: DISTRIB="conda" PYTHON_VERSION="3.6.2" INSTALL_MKL="true"
            NUMPY_VERSION="1.14.2" SCIPY_VERSION="1.0.0" PANDAS_VERSION="0.20.3"
            CYTHON_VERSION="0.26.1" PYAMG_VERSION="3.3.2" PILLOW_VERSION="4.3.0"
-           COVERAGE=true
+           JOBLIB_VERSION="0.11" COVERAGE=true
            CHECK_PYTEST_SOFT_DEPENDENCY="true" TEST_DOCSTRINGS="true"
+           SKLEARN_SITE_JOBLIB=1
       if: type != cron
     # flake8 linting on diff wrt common ancestor with upstream/master
     - env: RUN_FLAKE8="true" SKIP_TESTS="true"
diff --git a/README.rst b/README.rst
index 4df228acd4c4..eb1957686aca 100644
--- a/README.rst
+++ b/README.rst
@@ -53,6 +53,9 @@ scikit-learn requires:
 - NumPy (>= 1.8.2)
 - SciPy (>= 0.13.3)
 
+**Scikit-learn 0.20 is the last version to support Python2.7.**
+Scikit-learn 0.21 and later will require Python 3.5 or newer.
+
 For running the examples Matplotlib >= 1.3.1 is required. A few examples
 require scikit-image >= 0.9.3 and a few examples require pandas >= 0.13.1.
 
diff --git a/appveyor.yml b/appveyor.yml
index 1a44e2d79d08..5eb4d08a8737 100644
--- a/appveyor.yml
+++ b/appveyor.yml
@@ -17,10 +17,6 @@ environment:
     SKLEARN_SKIP_NETWORK_TESTS: 1
 
   matrix:
-    - PYTHON: "C:\\Python37"
-      PYTHON_VERSION: "3.7.0"
-      PYTHON_ARCH: "32"
-
     - PYTHON: "C:\\Python37-x64"
       PYTHON_VERSION: "3.7.0"
       PYTHON_ARCH: "64"
@@ -29,10 +25,6 @@ environment:
       PYTHON_VERSION: "2.7.8"
       PYTHON_ARCH: "32"
 
-    - PYTHON: "C:\\Python27-x64"
-      PYTHON_VERSION: "2.7.8"
-      PYTHON_ARCH: "64"
-
 
 # Because we only have a single worker, we don't want to waste precious
 # appveyor CI time and make other PRs wait for repeated failures in a failing
@@ -49,7 +41,7 @@ install:
   # directly to master instead of just PR builds.
   # credits: JuliaLang developers.
   - ps: if ($env:APPVEYOR_PULL_REQUEST_NUMBER -and $env:APPVEYOR_BUILD_NUMBER -ne ((Invoke-RestMethod `
-        https://ci.appveyor.com/api/projects/$env:APPVEYOR_ACCOUNT_NAME/$env:APPVEYOR_PROJECT_SLUG/history?recordsNumber=50).builds | `
+        https://ci.appveyor.com/api/projects/$env:APPVEYOR_ACCOUNT_NAME/$env:APPVEYOR_PROJECT_SLUG/history?recordsNumber=500).builds | `
         Where-Object pullRequestId -eq $env:APPVEYOR_PULL_REQUEST_NUMBER)[0].buildNumber) { `
         throw "There are newer queued builds for this pull request, failing early." }
 
diff --git a/benchmarks/bench_covertype.py b/benchmarks/bench_covertype.py
index d5ee0c04eba6..c7b23f82d2d1 100644
--- a/benchmarks/bench_covertype.py
+++ b/benchmarks/bench_covertype.py
@@ -59,7 +59,7 @@
 from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
 from sklearn.ensemble import GradientBoostingClassifier
 from sklearn.metrics import zero_one_loss
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.utils import check_array
 
 # Memoize the data extraction and memory map the resulting
diff --git a/benchmarks/bench_mnist.py b/benchmarks/bench_mnist.py
index f84eed5f9479..0182cfad7a71 100644
--- a/benchmarks/bench_mnist.py
+++ b/benchmarks/bench_mnist.py
@@ -41,7 +41,7 @@
 from sklearn.ensemble import ExtraTreesClassifier
 from sklearn.ensemble import RandomForestClassifier
 from sklearn.dummy import DummyClassifier
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.kernel_approximation import Nystroem
 from sklearn.kernel_approximation import RBFSampler
 from sklearn.metrics import zero_one_loss
diff --git a/benchmarks/bench_plot_nmf.py b/benchmarks/bench_plot_nmf.py
index c48977a49a72..87885f091da8 100644
--- a/benchmarks/bench_plot_nmf.py
+++ b/benchmarks/bench_plot_nmf.py
@@ -22,7 +22,7 @@
 from sklearn.decomposition.nmf import _initialize_nmf
 from sklearn.decomposition.nmf import _beta_divergence
 from sklearn.decomposition.nmf import INTEGER_TYPES, _check_init
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.exceptions import ConvergenceWarning
 from sklearn.utils.extmath import safe_sparse_dot, squared_norm
 from sklearn.utils import check_array
diff --git a/benchmarks/bench_rcv1_logreg_convergence.py b/benchmarks/bench_rcv1_logreg_convergence.py
index 417cae5aac1d..a4116a68f6c3 100644
--- a/benchmarks/bench_rcv1_logreg_convergence.py
+++ b/benchmarks/bench_rcv1_logreg_convergence.py
@@ -8,7 +8,7 @@
 import gc
 import time
 
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.linear_model import (LogisticRegression, SGDClassifier)
 from sklearn.datasets import fetch_rcv1
 from sklearn.linear_model.sag import get_auto_step_size
diff --git a/benchmarks/bench_saga.py b/benchmarks/bench_saga.py
index 10aca379123a..9e79c536c5b2 100644
--- a/benchmarks/bench_saga.py
+++ b/benchmarks/bench_saga.py
@@ -12,7 +12,7 @@
 
 from sklearn.datasets import fetch_rcv1, load_iris, load_digits, \
     fetch_20newsgroups_vectorized
-from sklearn.externals.joblib import delayed, Parallel, Memory
+from sklearn.utils import delayed, Parallel, Memory
 from sklearn.linear_model import LogisticRegression
 from sklearn.metrics import log_loss
 from sklearn.model_selection import train_test_split
diff --git a/benchmarks/bench_tsne_mnist.py b/benchmarks/bench_tsne_mnist.py
index 26dde6aac312..36630eeb15d2 100644
--- a/benchmarks/bench_tsne_mnist.py
+++ b/benchmarks/bench_tsne_mnist.py
@@ -15,7 +15,7 @@
 import json
 import argparse
 
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.datasets import fetch_mldata
 from sklearn.manifold import TSNE
 from sklearn.neighbors import NearestNeighbors
diff --git a/build_tools/travis/install.sh b/build_tools/travis/install.sh
index 2b03f4a98039..c294ba29c09f 100755
--- a/build_tools/travis/install.sh
+++ b/build_tools/travis/install.sh
@@ -59,6 +59,10 @@ if [[ "$DISTRIB" == "conda" ]]; then
         TO_INSTALL="$TO_INSTALL pillow=$PILLOW_VERSION"
     fi
 
+    if [[ -n "$JOBLIB_VERSION" ]]; then
+        TO_INSTALL="$TO_INSTALL joblib=$JOBLIB_VERSION"
+    fi
+
     conda create -n testenv --yes $TO_INSTALL
     source activate testenv
 
diff --git a/doc/conftest.py b/doc/conftest.py
index 463df3f38221..11b190d8f66f 100644
--- a/doc/conftest.py
+++ b/doc/conftest.py
@@ -1,5 +1,6 @@
 from os.path import exists
 from os.path import join
+import warnings
 
 import numpy as np
 
@@ -75,6 +76,12 @@ def setup_impute():
         raise SkipTest("Skipping impute.rst, pandas not installed")
 
 
+def setup_unsupervised_learning():
+    # ignore deprecation warnings from scipy.misc.face
+    warnings.filterwarnings('ignore', 'The binary mode of fromstring',
+                            DeprecationWarning)
+
+
 def pytest_runtest_setup(item):
     fname = item.fspath.strpath
     is_index = fname.endswith('datasets/index.rst')
@@ -93,6 +100,8 @@ def pytest_runtest_setup(item):
         setup_compose()
     elif fname.endswith('modules/impute.rst'):
         setup_impute()
+    elif fname.endswith('statistical_inference/unsupervised_learning.rst'):
+        setup_unsupervised_learning()
 
 
 def pytest_runtest_teardown(item):
diff --git a/doc/datasets/index.rst b/doc/datasets/index.rst
index d8eabfaabd27..8979f74f09af 100644
--- a/doc/datasets/index.rst
+++ b/doc/datasets/index.rst
@@ -44,7 +44,7 @@ some contain ``feature_names`` and ``target_names``. See the dataset
 descriptions below for details.  
 
 **The dataset generation functions.** They can be used to generate controlled 
-synthetic datasets, described in the :ref:`generated_datasets` section.
+synthetic datasets, described in the :ref:`sample_generators` section.
 
 These functions return a tuple ``(X, y)`` consisting of a ``n_samples`` *
 ``n_features`` numpy array ``X`` and an array of length ``n_samples``
@@ -154,7 +154,7 @@ They can be loaded using the following functions:
 
 .. include:: ./kddcup99.rst
 
-.. _generated_datasets:
+.. _sample_generators:
 
 Generated datasets
 ==================
diff --git a/doc/developers/contributing.rst b/doc/developers/contributing.rst
index 854dbe444206..1b43400f4a7a 100644
--- a/doc/developers/contributing.rst
+++ b/doc/developers/contributing.rst
@@ -41,7 +41,7 @@ ticket to the
 also welcome to post feature requests or pull requests.
 
 
-=======
+==================
 Ways to contribute
 ==================
 
@@ -790,17 +790,35 @@ In the following example, k is deprecated and renamed to n_clusters::
 
     import warnings
 
-    def example_function(n_clusters=8, k=None):
-        if k is not None:
+    def example_function(n_clusters=8, k='not_used'):
+        if k != 'not_used':
             warnings.warn("'k' was renamed to n_clusters in version 0.13 and "
                           "will be removed in 0.15.", DeprecationWarning)
             n_clusters = k
 
+When the change is in a class, we validate and raise warning in ``fit``::
+
+  import warnings
+
+  class ExampleEstimator(BaseEstimator):
+      def __init__(self, n_clusters=8, k='not_used'):
+          self.n_clusters = n_clusters
+          self.k = k
+
+      def fit(self, X, y):
+          if k != 'not_used':
+              warnings.warn("'k' was renamed to n_clusters in version 0.13 and "
+                            "will be removed in 0.15.", DeprecationWarning)
+              self._n_clusters = k
+          else:
+              self._n_clusters = self.n_clusters
+
 As in these examples, the warning message should always give both the
 version in which the deprecation happened and the version in which the
 old behavior will be removed. If the deprecation happened in version
 0.x-dev, the message should say deprecation occurred in version 0.x and
-the removal will be in 0.(x+2). For example, if the deprecation happened
+the removal will be in 0.(x+2), so that users will have enough time to
+adapt their code to the new behaviour. For example, if the deprecation happened
 in version 0.18-dev, the message should say it happened in version 0.18
 and the old behavior will be removed in version 0.20.
 
@@ -812,6 +830,51 @@ same information as the deprecation warning as explained above. Use the
      ``k`` was renamed to ``n_clusters`` in version 0.13 and will be removed
      in 0.15.
 
+What's more, a deprecation requires a test which ensures that the warning is
+raised in relevant cases but not in other cases. The warning should be caught
+in all other tests (using e.g., ``@pytest.mark.filterwarnings``),
+and there should be no warning in the examples.
+
+
+Change the default value of a parameter
+---------------------------------------
+
+If the default value of a parameter needs to be changed, please replace the
+default value with a specific value (e.g., ``warn``) and raise
+``FutureWarning`` when users are using the default value. In the following
+example, we change the default value of ``n_clusters`` from 5 to 10
+(current version is 0.20)::
+
+    import warnings
+
+    def example_function(n_clusters='warn'):
+        if n_clusters == 'warn':
+            warnings.warn("The default value of n_clusters will change from "
+                          "5 to 10 in 0.22.", FutureWarning)
+            n_clusters = 5
+
+When the change is in a class, we validate and raise warning in ``fit``::
+
+  import warnings
+
+  class ExampleEstimator:
+      def __init__(self, n_clusters='warn'):
+          self.n_clusters = n_clusters
+
+      def fit(self, X, y):
+          if self.n_clusters == 'warn':
+            warnings.warn("The default value of n_clusters will change from "
+                          "5 to 10 in 0.22.", FutureWarning)
+            self._n_clusters = 5
+
+Similar to deprecations, the warning message should always give both the
+version in which the change happened and the version in which the old behavior
+will be removed. The docstring needs to be updated accordingly. We need a test
+which ensures that the warning is raised in relevant cases but not in other
+cases. The warning should be caught in all other tests
+(using e.g., ``@pytest.mark.filterwarnings``), and there should be no warning
+in the examples.
+
 
 .. currentmodule:: sklearn
 
diff --git a/doc/developers/utilities.rst b/doc/developers/utilities.rst
index b72b7c8e5c5d..e8e8a9723e07 100644
--- a/doc/developers/utilities.rst
+++ b/doc/developers/utilities.rst
@@ -45,7 +45,7 @@ should be used when applicable.
 
 - :func:`validation.check_memory` checks that input is ``joblib.Memory``-like,
   which means that it can be converted into a
-  ``sklearn.externals.joblib.Memory`` instance (typically a str denoting
+  ``sklearn.utils.Memory`` instance (typically a str denoting
   the ``cachedir``) or has the same interface.
 
 If your code relies on a random number generator, it should never use
diff --git a/doc/faq.rst b/doc/faq.rst
index 8d5a6f4f4dde..85ec39e45ba3 100644
--- a/doc/faq.rst
+++ b/doc/faq.rst
@@ -362,7 +362,7 @@ of a single numeric dtype. These do not explicitly represent categorical
 variables at present. Thus, unlike R's data.frames or pandas.DataFrame, we
 require explicit conversion of categorical features to numeric values, as
 discussed in :ref:`preprocessing_categorical_features`.
-See also :ref:`sphx_glr_auto_examples_compose_column_transformer_mixed_types.py` for an
+See also :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py` for an
 example of working with heterogeneous (e.g. categorical and numeric) data.
 
 Why does Scikit-learn not directly work with, for example, pandas.DataFrame?
diff --git a/doc/glossary.rst b/doc/glossary.rst
index cea07ed1a5cf..6a3780ba0c05 100644
--- a/doc/glossary.rst
+++ b/doc/glossary.rst
@@ -1485,7 +1485,7 @@ functions or non-estimator constructors.
           sometimes parallelism happens in prediction (e.g. in random forests).
         * Some parallelism uses a multi-threading backend by default, some
           a multi-processing backend.  It is possible to override the default
-          backend by using :func:`sklearn.externals.joblib.parallel.parallel_backend`.
+          backend by using :func:`sklearn.utils.parallel_backend`.
         * Whether parallel processing is helpful at improving runtime depends
           on many factors, and it's usually a good idea to experiment rather
           than assuming that increasing the number of jobs is always a good
diff --git a/doc/index.rst b/doc/index.rst
index cfcaedc38017..0de085b1d721 100644
--- a/doc/index.rst
+++ b/doc/index.rst
@@ -207,17 +207,17 @@
                     <li><em>On-going development:</em>
                     <a href="/dev/whats_new.html"><em>What's new</em> (Changelog)</a>
                     </li>
-                    <li><em>October 2017.</em> scikit-learn 0.19.1 is available for download (<a href="whats_new.html#version-0-19">Changelog</a>).
+                    <li><strong>Scikit-learn 0.21 will drop support for Python 2.7 and Python 3.4.</strong>
                     </li>
-                    <li><em>July 2017.</em> scikit-learn 0.19.0 is available for download (<a href="whats_new/v0.19.html#version-0-19">Changelog</a>).
+                    <li><em>July 2018.</em> scikit-learn 0.20 is available for download (<a href="whats_new.html#version-0-20">Changelog</a>).
                     </li>
-                    <li><em>June 2017.</em> scikit-learn 0.18.2 is available for download (<a href="whats_new/v0.18.html#version-0-18-2">Changelog</a>).
+                    <li><em>July 2018.</em> scikit-learn 0.19.2 is available for download (<a href="whats_new.html#version-0-19">Changelog</a>).
                     </li>
-                    <li><em>September 2016.</em> scikit-learn 0.18.0 is available for download (<a href="whats_new/v0.18.html#version-0-18">Changelog</a>).
+                    <li><em>October 2017.</em> scikit-learn 0.19.1 is available for download (<a href="whats_new.html#version-0-19">Changelog</a>).
                     </li>
-                    <li><em>November 2015.</em> scikit-learn 0.17.0 is available for download (<a href="whats_new/v0.17.html">Changelog</a>).
+                    <li><em>July 2017.</em> scikit-learn 0.19.0 is available for download (<a href="whats_new/v0.19.html#version-0-19">Changelog</a>).
                     </li>
-                    <li><em>March 2015.</em> scikit-learn 0.16.0 is available for download (<a href="whats_new/v0.16.html">Changelog</a>).
+                    <li><em>June 2017.</em> scikit-learn 0.18.2 is available for download (<a href="whats_new/v0.18.html#version-0-18-2">Changelog</a>).
                     </li>
                     </ul>
                 </div>
diff --git a/doc/install.rst b/doc/install.rst
index 20a409a6872d..89c1aca455c7 100644
--- a/doc/install.rst
+++ b/doc/install.rst
@@ -21,6 +21,12 @@ Scikit-learn requires:
 - NumPy (>= 1.8.2),
 - SciPy (>= 0.13.3).
 
+
+.. warning::
+
+    Scikit-learn 0.20 is the last version to support Python 2.7 and Python 3.4.
+    Scikit-learn 0.21 will require Python 3.5 or newer.
+
 If you already have a working installation of numpy and scipy,
 the easiest way to install scikit-learn is using ``pip`` ::
 
diff --git a/doc/modules/classes.rst b/doc/modules/classes.rst
index 3d91d021dbca..1753bf9b404b 100644
--- a/doc/modules/classes.rst
+++ b/doc/modules/classes.rst
@@ -98,6 +98,7 @@ Classes
    cluster.AgglomerativeClustering
    cluster.Birch
    cluster.DBSCAN
+   cluster.OPTICS
    cluster.FeatureAgglomeration
    cluster.KMeans
    cluster.MiniBatchKMeans
@@ -112,6 +113,7 @@ Functions
 
    cluster.affinity_propagation
    cluster.dbscan
+   cluster.optics
    cluster.estimate_bandwidth
    cluster.k_means
    cluster.mean_shift
@@ -653,7 +655,7 @@ Kernels:
    :template: class.rst
 
    impute.SimpleImputer
-   impute.ChainedImputer
+   impute.MissingIndicator
 
 .. _kernel_approximation_ref:
 
@@ -1472,6 +1474,22 @@ Low-level methods
    utils.testing.assert_raise_message
    utils.testing.all_estimators
 
+Utilities from joblib:
+
+.. autosummary::
+   :toctree: generated/
+   :template: class.rst
+
+   utils.Memory
+   utils.Parallel
+
+.. autosummary::
+   :toctree: generated/
+   :template: function.rst
+
+   utils.cpu_count
+   utils.delayed
+   utils.parallel_backend
 
 Recently deprecated
 ===================
diff --git a/doc/modules/clustering.rst b/doc/modules/clustering.rst
index 21c342d3ff1a..70b38aa77027 100644
--- a/doc/modules/clustering.rst
+++ b/doc/modules/clustering.rst
@@ -91,6 +91,12 @@ Overview of clustering methods
      - Non-flat geometry, uneven cluster sizes
      - Distances between nearest points
 
+   * - :ref:`OPTICS <optics>`
+     - minimum cluster membership
+     - Very large ``n_samples``, large ``n_clusters``
+     - Non-flat geometry, uneven cluster sizes, variable cluster density 
+     - Distances between points
+   
    * - :ref:`Gaussian mixtures <mixture>`
      - many
      - Not scalable
@@ -796,6 +802,10 @@ by black points below.
     be used (e.g. with sparse matrices). This matrix will consume n^2 floats.
     A couple of mechanisms for getting around this are:
 
+    - Use OPTICS clustering in conjunction with the `extract_dbscan` method. OPTICS
+      clustering also calculates the full pairwise matrix, but only keeps one row in
+      memory at a time (memory complexity n).
+
     - A sparse radius neighborhood graph (where missing entries are presumed to
       be out of eps) can be precomputed in a memory-efficient way and dbscan
       can be run over this with ``metric='precomputed'``.  See
@@ -814,6 +824,106 @@ by black points below.
    In Proceedings of the 2nd International Conference on Knowledge Discovery
    and Data Mining, Portland, OR, AAAI Press, pp. 226–231. 1996
 
+.. _optics:
+
+OPTICS
+======
+
+The :class:`OPTICS` algorithm shares many similarities with the
+:class:`DBSCAN` algorithm, and can be considered a generalization of
+DBSCAN that relaxes the ``eps`` requirement from a single value to a value
+range. The key difference between DBSCAN and OPTICS is that the OPTICS
+algorithm builds a *reachability* graph, which assigns each sample both a
+``reachability_`` distance, and a spot within the cluster ``ordering_``
+attribute; these two attributes are assigned when the model is fitted, and are
+used to determine cluster membership. If OPTICS is run with the default value
+of *inf* set for ``max_bound``, then DBSCAN style cluster extraction can be
+performed in linear time for any given ``eps`` value using the
+``extract_dbscan`` method. Setting ``max_bound`` to a lower value will result
+in shorter run times, and can be thought of as the maximum cluster object size
+(in diameter) that OPTICS will be able to extract.
+
+.. |optics_results| image:: ../auto_examples/cluster/images/sphx_glr_plot_optics_001.png
+        :target: ../auto_examples/cluster/plot_optics.html
+        :scale: 50
+
+.. centered:: |optics_results|
+
+The *reachability* distances generated by OPTICS allow for variable density
+extraction of clusters within a single data set. As shown in the above plot,
+combining *reachability* distances and data set ``ordering_`` produces a
+*reachability plot*, where point density is represented on the Y-axis, and
+points are ordered such that nearby points are adjacent. 'Cutting' the
+reachability plot at a single value produces DBSCAN like results; all points
+above the 'cut' are classified as noise, and each time that there is a break
+when reading from left to right signifies a new cluster. The default cluster
+extraction with OPTICS looks at changes in slope within the graph to guess at
+natural clusters. There are also other possibilities for analysis on the graph
+itself, such as generating hierarchical representations of the data through
+reachability-plot dendrograms. The plot above has been color-coded so that
+cluster colors in planar space match the linear segment clusters of the
+reachability plot-- note that the blue and red clusters are adjacent in the
+reachability plot, and can be hierarchically represented as children of a
+larger parent cluster.
+
+.. topic:: Examples:
+
+     * :ref:`sphx_glr_auto_examples_cluster_plot_optics.py`
+
+
+.. topic:: Comparison with DBSCAN
+    
+    The results from OPTICS ``extract_dbscan`` method and DBSCAN are not quite
+    identical. Specifically, while *core_samples* returned from both OPTICS
+    and DBSCAN are guaranteed to be identical, labeling of periphery and noise
+    points is not. This is in part because the first sample processed by
+    OPTICS will always have a reachability distance that is set to ``inf``,
+    and will thus generally be marked as noise rather than periphery. This
+    affects adjacent points when they are considered as candidates for being
+    marked as either periphery or noise. While this effect is quite local to
+    the starting point of the dataset and is unlikely to be noticed on even
+    moderately large datasets, it is worth also noting that non-core boundry
+    points may switch cluster labels on the rare occasion that they are
+    equidistant to a competeing cluster due to how the graph is read from left
+    to right when assigning labels. 
+
+    Note that for any single value of ``eps``, DBSCAN will tend to have a
+    shorter run time than OPTICS; however, for repeated runs at varying ``eps``
+    values, a single run of OPTICS may require less cumulative runtime than
+    DBSCAN. It is also important to note that OPTICS output can be unstable at
+    ``eps`` values very close to the initial ``max_bound`` value. OPTICS seems
+    to produce near identical results to DBSCAN provided that ``eps`` passed to
+    ``extract_dbscan`` is a half order of magnitude less than the inital
+    ``max_bound`` that was used to fit; using a value close to ``max_bound``
+    will throw a warning, and using a value larger will result in an exception. 
+
+.. topic:: Computational Complexity
+
+    Spatial indexing trees are used to avoid calculating the full distance
+    matrix, and allow for efficient memory usage on large sets of samples.
+    Different distance metrics can be supplied via the ``metric`` keyword.
+    
+    For large datasets, similar (but not identical) results can be obtained via
+    `HDBSCAN <https://hdbscan.readthedocs.io>`_. The HDBSCAN implementation is
+    multithreaded, and has better algorithmic runtime complexity than OPTICS--
+    at the cost of worse memory scaling. For extremely large datasets that
+    exhaust system memory using HDBSCAN, OPTICS will maintain *n* (as opposed
+    to *n^2* memory scaling); however, tuning of the ``max_bound`` parameter
+    will likely need to be used to give a solution in a reasonable amount of
+    wall time.
+
+.. topic:: References:
+
+ *  "OPTICS: ordering points to identify the clustering structure."
+    Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander.
+    In ACM Sigmod Record, vol. 28, no. 2, pp. 49-60. ACM, 1999.
+
+ *  "Automatic extraction of clusters from hierarchical clustering
+    representations."
+    Sander, Jörg, Xuejie Qin, Zhiyong Lu, Nan Niu, and Alex Kovarsky.
+    In Advances in knowledge discovery and data mining,
+    pp. 75-87. Springer Berlin Heidelberg, 2003. 
+
 .. _birch:
 
 Birch
@@ -1048,50 +1158,50 @@ Given the knowledge of the ground truth class assignments ``labels_true`` and
 our clustering algorithm assignments of the same samples ``labels_pred``, the
 **Mutual Information** is a function that measures the **agreement** of the two
 assignments, ignoring permutations.  Two different normalized versions of this
-measure are available, **Normalized Mutual Information(NMI)** and **Adjusted
-Mutual Information(AMI)**. NMI is often used in the literature while AMI was
+measure are available, **Normalized Mutual Information (NMI)** and **Adjusted
+Mutual Information (AMI)**. NMI is often used in the literature, while AMI was
 proposed more recently and is **normalized against chance**::
 
   >>> from sklearn import metrics
   >>> labels_true = [0, 0, 0, 1, 1, 1]
   >>> labels_pred = [0, 0, 1, 1, 2, 2]
 
-  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +ELLIPSIS
+  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   0.22504...
 
 One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get
 the same score::
 
   >>> labels_pred = [1, 1, 0, 0, 3, 3]
-  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +ELLIPSIS
+  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   0.22504...
 
 All, :func:`mutual_info_score`, :func:`adjusted_mutual_info_score` and
 :func:`normalized_mutual_info_score` are symmetric: swapping the argument does
 not change the score. Thus they can be used as a **consensus measure**::
 
-  >>> metrics.adjusted_mutual_info_score(labels_pred, labels_true)  # doctest: +ELLIPSIS
+  >>> metrics.adjusted_mutual_info_score(labels_pred, labels_true)  # doctest: +SKIP
   0.22504...
 
 Perfect labeling is scored 1.0::
 
   >>> labels_pred = labels_true[:]
-  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)
+  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   1.0
 
-  >>> metrics.normalized_mutual_info_score(labels_true, labels_pred)
+  >>> metrics.normalized_mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   1.0
 
 This is not true for ``mutual_info_score``, which is therefore harder to judge::
 
-  >>> metrics.mutual_info_score(labels_true, labels_pred)  # doctest: +ELLIPSIS
+  >>> metrics.mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   0.69...
 
 Bad (e.g. independent labelings) have non-positive scores::
 
   >>> labels_true = [0, 1, 2, 0, 3, 4, 5, 1]
   >>> labels_pred = [1, 1, 0, 0, 2, 2, 2, 2]
-  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +ELLIPSIS
+  >>> metrics.adjusted_mutual_info_score(labels_true, labels_pred)  # doctest: +SKIP
   -0.10526...
 
 
@@ -1102,17 +1212,11 @@ Advantages
   for any value of ``n_clusters`` and ``n_samples`` (which is not the
   case for raw Mutual Information or the V-measure for instance).
 
-- **Bounded range [0, 1]**:  Values close to zero indicate two label
+- **Upper bound  of 1**:  Values close to zero indicate two label
   assignments that are largely independent, while values close to one
-  indicate significant agreement. Further, values of exactly 0 indicate
-  **purely** independent label assignments and a AMI of exactly 1 indicates
+  indicate significant agreement. Further, an AMI of exactly 1 indicates
   that the two label assignments are equal (with or without permutation).
 
-- **No assumption is made on the cluster structure**: can be used
-  to compare clustering algorithms such as k-means which assumes isotropic
-  blob shapes with results of spectral clustering algorithms which can
-  find cluster with "folded" shapes.
-
 
 Drawbacks
 ~~~~~~~~~
@@ -1164,7 +1268,7 @@ It also can be expressed in set cardinality formulation:
 
 The normalized mutual information is defined as
 
-.. math:: \text{NMI}(U, V) = \frac{\text{MI}(U, V)}{\sqrt{H(U)H(V)}}
+.. math:: \text{NMI}(U, V) = \frac{\text{MI}(U, V)}{\text{mean}(H(U), H(V))}
 
 This value of the mutual information and also the normalized variant is not
 adjusted for chance and will tend to increase as the number of different labels
@@ -1172,7 +1276,7 @@ adjusted for chance and will tend to increase as the number of different labels
 between the label assignments.
 
 The expected value for the mutual information can be calculated using the
-following equation, from Vinh, Epps, and Bailey, (2009). In this equation,
+following equation [VEB2009]_. In this equation,
 :math:`a_i = |U_i|` (the number of elements in :math:`U_i`) and
 :math:`b_j = |V_j|` (the number of elements in :math:`V_j`).
 
@@ -1185,7 +1289,19 @@ following equation, from Vinh, Epps, and Bailey, (2009). In this equation,
 Using the expected value, the adjusted mutual information can then be
 calculated using a similar form to that of the adjusted Rand index:
 
-.. math:: \text{AMI} = \frac{\text{MI} - E[\text{MI}]}{\max(H(U), H(V)) - E[\text{MI}]}
+.. math:: \text{AMI} = \frac{\text{MI} - E[\text{MI}]}{\text{mean}(H(U), H(V)) - E[\text{MI}]}
+
+For normalized mutual information and adjusted mutual information, the normalizing
+value is typically some *generalized* mean of the entropies of each clustering.
+Various generalized means exist, and no firm rules exist for preferring one over the
+others.  The decision is largely a field-by-field basis; for instance, in community
+detection, the arithmetic mean is most common. Each
+normalizing method provides "qualitatively similar behaviours" [YAT2016]_. In our
+implementation, this is controlled by the ``average_method`` parameter.
+
+Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]_. Their
+'sqrt' and 'sum' averages are the geometric and arithmetic means; we use these
+more broadly common names.
 
 .. topic:: References
 
@@ -1194,22 +1310,29 @@ calculated using a similar form to that of the adjusted Rand index:
    Machine Learning Research 3: 583–617.
    `doi:10.1162/153244303321897735 <http://strehl.com/download/strehl-jmlr02.pdf>`_.
 
- * Vinh, Epps, and Bailey, (2009). "Information theoretic measures
+ * [VEB2009] Vinh, Epps, and Bailey, (2009). "Information theoretic measures
    for clusterings comparison". Proceedings of the 26th Annual International
    Conference on Machine Learning - ICML '09.
    `doi:10.1145/1553374.1553511 <https://dl.acm.org/citation.cfm?doid=1553374.1553511>`_.
    ISBN 9781605585161.
 
- * Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for
+ * [VEB2010] Vinh, Epps, and Bailey, (2010). "Information Theoretic Measures for
    Clusterings Comparison: Variants, Properties, Normalization and
-   Correction for Chance, JMLR
-   http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf
+   Correction for Chance". JMLR
+   <http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf>
 
  * `Wikipedia entry for the (normalized) Mutual Information
    <https://en.wikipedia.org/wiki/Mutual_Information>`_
 
  * `Wikipedia entry for the Adjusted Mutual Information
    <https://en.wikipedia.org/wiki/Adjusted_Mutual_Information>`_
+   
+ * [YAT2016] Yang, Algesheimer, and Tessone, (2016). "A comparative analysis of
+   community
+   detection algorithms on artificial networks". Scientific Reports 6: 30750.
+   `doi:10.1038/srep30750 <https://www.nature.com/articles/srep30750>`_.
+   
+   
 
 .. _homogeneity_completeness:
 
@@ -1249,7 +1372,7 @@ Their harmonic mean called **V-measure** is computed by
   0.51...
 
 The V-measure is actually equivalent to the mutual information (NMI)
-discussed above normalized by the sum of the label entropies [B2011]_.
+discussed above, with the aggregation function being the arithmetic mean [B2011]_.
 
 Homogeneity, completeness and V-measure can be computed at once using
 :func:`homogeneity_completeness_v_measure` as follows::
@@ -1424,7 +1547,7 @@ Advantages
   for any value of ``n_clusters`` and ``n_samples`` (which is not the
   case for raw Mutual Information or the V-measure for instance).
 
-- **Bounded range [0, 1]**:  Values close to zero indicate two label
+- **Upper-bounded at 1**:  Values close to zero indicate two label
   assignments that are largely independent, while values close to one
   indicate significant agreement. Further, values of exactly 0 indicate
   **purely** independent label assignments and a AMI of exactly 1 indicates
diff --git a/doc/modules/compose.rst b/doc/modules/compose.rst
index ebb879182b23..8817b6d83a38 100644
--- a/doc/modules/compose.rst
+++ b/doc/modules/compose.rst
@@ -413,7 +413,7 @@ variable, but apply a :class:`feature_extraction.text.CountVectorizer
 <sklearn.feature_extraction.text.CountVectorizer>` to the ``'title'`` column.
 As we might use multiple feature extraction methods on the same column, we give
 each transformer a unique name, say ``'city_category'`` and ``'title_bow'``.
-We can ignore the remaining rating columns by setting ``remainder='drop'``::
+By default, the remaining rating columns are ignored (``remainder='drop'``)::
 
   >>> from sklearn.compose import ColumnTransformer
   >>> from sklearn.feature_extraction.text import CountVectorizer
@@ -495,10 +495,10 @@ above example would be::
   ...     ('city', CountVectorizer(analyzer=lambda x: [x])),
   ...     ('title', CountVectorizer()))
   >>> column_trans # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
-  ColumnTransformer(n_jobs=1, remainder='passthrough', transformer_weights=None,
+  ColumnTransformer(n_jobs=1, remainder='drop', transformer_weights=None,
            transformers=[('countvectorizer-1', ...)
 
 .. topic:: Examples:
 
- * :ref:`sphx_glr_auto_examples_compose_column_transformer.py`
- * :ref:`sphx_glr_auto_examples_compose_column_transformer_mixed_types.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_column_transformer.py`
+ * :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py`
diff --git a/doc/modules/ensemble.rst b/doc/modules/ensemble.rst
index 83da35eb46ca..19e46d3eab25 100644
--- a/doc/modules/ensemble.rst
+++ b/doc/modules/ensemble.rst
@@ -965,7 +965,7 @@ The following example shows how to fit the majority rule classifier::
    >>> X, y = iris.data[:, 1:3], iris.target
 
    >>> clf1 = LogisticRegression(random_state=1)
-   >>> clf2 = RandomForestClassifier(random_state=1)
+   >>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)
    >>> clf3 = GaussianNB()
 
    >>> eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')
@@ -974,7 +974,7 @@ The following example shows how to fit the majority rule classifier::
    ...     scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')
    ...     print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))
    Accuracy: 0.90 (+/- 0.05) [Logistic Regression]
-   Accuracy: 0.93 (+/- 0.05) [Random Forest]
+   Accuracy: 0.94 (+/- 0.04) [Random Forest]
    Accuracy: 0.91 (+/- 0.04) [naive Bayes]
    Accuracy: 0.95 (+/- 0.05) [Ensemble]
 
diff --git a/doc/modules/feature_extraction.rst b/doc/modules/feature_extraction.rst
index 611c7ecb60ee..68d4295bd658 100644
--- a/doc/modules/feature_extraction.rst
+++ b/doc/modules/feature_extraction.rst
@@ -380,6 +380,37 @@ last document::
   >>> X_2[:, feature_index]     # doctest: +ELLIPSIS
   array([0, 0, 0, 1]...)
 
+.. _stop_words:
+
+Using stop words
+................
+
+Stop words are words like "and", "the", "him", which are presumed to be
+uninformative in representing the content of a text, and which may be
+removed to avoid them being construed as signal for prediction.  Sometimes,
+however, similar words are useful for prediction, such as in classifying
+writing style or personality.
+
+There are several known issues in our provided 'english' stop word list. See
+[NQY18]_.
+
+Please take care in choosing a stop word list.
+Popular stop word lists may include words that are highly informative to
+some tasks, such as *computer*.
+
+You should also make sure that the stop word list has had the same
+preprocessing and tokenization applied as the one used in the vectorizer.
+The word *we've* is split into *we* and *ve* by CountVectorizer's default
+tokenizer, so if *we've* is in ``stop_words``, but *ve* is not, *ve* will
+be retained from *we've* in transformed text.  Our vectorizers will try to
+identify and warn about some kinds of inconsistencies.
+
+.. topic:: References
+
+    .. [NQY18] J. Nothman, H. Qin and R. Yurchak (2018).
+               `"Stop Word Lists in Free Open-source Software Packages"
+               <http://aclweb.org/anthology/W18-2502>`__.
+               In *Proc. Workshop for NLP Open Source Software*.
 
 .. _tfidf:
 
diff --git a/doc/modules/feature_selection.rst b/doc/modules/feature_selection.rst
index ae630af183cd..7c6df892e5be 100644
--- a/doc/modules/feature_selection.rst
+++ b/doc/modules/feature_selection.rst
@@ -245,7 +245,7 @@ meta-transformer)::
   >>> X, y = iris.data, iris.target
   >>> X.shape
   (150, 4)
-  >>> clf = ExtraTreesClassifier()
+  >>> clf = ExtraTreesClassifier(n_estimators=50)
   >>> clf = clf.fit(X, y)
   >>> clf.feature_importances_  # doctest: +SKIP
   array([ 0.04...,  0.05...,  0.4...,  0.4...])
diff --git a/doc/modules/impute.rst b/doc/modules/impute.rst
index 0f9089c98178..0fd119857177 100644
--- a/doc/modules/impute.rst
+++ b/doc/modules/impute.rst
@@ -16,22 +16,6 @@ values. However, this comes at the price of losing data which may be valuable
 i.e., to infer them from the known part of the data. See the :ref:`glossary`
 entry on imputation.
 
-
-Univariate vs. Multivariate Imputation
-======================================
-
-One type of imputation algorithm is univariate, which imputes values in the i-th
-feature dimension using only non-missing values in that feature dimension
-(e.g. :class:`impute.SimpleImputer`). By contrast, multivariate imputation
-algorithms use the entire set of available feature dimensions to estimate the
-missing values (e.g. :class:`impute.ChainedImputer`).
-
-
-.. _single_imputer:
-
-Univariate feature imputation
-=============================
-
 The :class:`SimpleImputer` class provides basic strategies for imputing missing
 values. Missing values can be imputed with a provided constant value, or using
 the statistics (mean, median or most frequent) of each column in which the
@@ -56,19 +40,19 @@ that contain the missing values::
 The :class:`SimpleImputer` class also supports sparse matrices::
 
     >>> import scipy.sparse as sp
-    >>> X = sp.csc_matrix([[1, 2], [0, 3], [7, 6]])
-    >>> imp = SimpleImputer(missing_values=0, strategy='mean')
+    >>> X = sp.csc_matrix([[1, 2], [0, -1], [8, 4]])
+    >>> imp = SimpleImputer(missing_values=-1, strategy='mean')
     >>> imp.fit(X)                  # doctest: +NORMALIZE_WHITESPACE
-    SimpleImputer(copy=True, fill_value=None, missing_values=0, strategy='mean', verbose=0)
-    >>> X_test = sp.csc_matrix([[0, 2], [6, 0], [7, 6]])
-    >>> print(imp.transform(X_test))      # doctest: +NORMALIZE_WHITESPACE  +ELLIPSIS
-    [[4.          2.        ]
-     [6.          3.666...]
-     [7.          6.        ]]
+    SimpleImputer(copy=True, fill_value=None, missing_values=-1, strategy='mean', verbose=0)
+    >>> X_test = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]])
+    >>> print(imp.transform(X_test).toarray())      # doctest: +NORMALIZE_WHITESPACE
+    [[3. 2.]
+     [6. 3.]
+     [7. 6.]]
 
-Note that, here, missing values are encoded by 0 and are thus implicitly stored
-in the matrix. This format is thus suitable when there are many more missing
-values than observed values.
+Note that this format is not meant to be used to implicitly store missing values
+in the matrix because it would densify it at transform time. Missing values encoded
+by 0 must be used with dense input.
 
 The :class:`SimpleImputer` class also supports categorical data represented as
 string values or pandas categoricals when using the ``'most_frequent'`` or
@@ -87,58 +71,52 @@ string values or pandas categoricals when using the ``'most_frequent'`` or
      ['a' 'y']
      ['b' 'y']]
 
-.. _chained_imputer:
-
 
-Multivariate feature imputation
-===============================
-
-A more sophisticated approach is to use the :class:`ChainedImputer` class, which
-implements the imputation technique from MICE (Multivariate Imputation by
-Chained Equations). MICE models each feature with missing values as a function of
-other features, and uses that estimate for imputation. It does so in a round-robin
-fashion: at each step, a feature column is designated as output `y` and the other
-feature columns are treated as inputs `X`. A regressor is fit on `(X, y)` for known `y`.
-Then, the regressor is used to predict the unknown values of `y`. This is repeated
-for each feature in a chained fashion, and then is done for a number of imputation
-rounds. Here is an example snippet::
-
-    >>> import numpy as np
-    >>> from sklearn.impute import ChainedImputer
-    >>> imp = ChainedImputer(n_imputations=10, random_state=0)
-    >>> imp.fit([[1, 2], [np.nan, 3], [7, np.nan]])
-    ChainedImputer(imputation_order='ascending', initial_strategy='mean',
-            max_value=None, min_value=None, missing_values=nan, n_burn_in=10,
-            n_imputations=10, n_nearest_features=None, predictor=None,
-            random_state=0, verbose=False)
-    >>> X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]
-    >>> print(np.round(imp.transform(X_test)))
-    [[ 1.  2.]
-     [ 6.  4.]
-     [13.  6.]]
-
-Both :class:`SimpleImputer` and :class:`ChainedImputer` can be used in a Pipeline
-as a way to build a composite estimator that supports imputation.
-See :ref:`sphx_glr_auto_examples_plot_missing_values.py`.
-
-
-.. _multiple_imputation:
-
-Multiple vs. Single Imputation
-==============================
-
-In the statistics community, it is common practice to perform multiple imputations,
-generating, for example, 10 separate imputations for a single feature matrix.
-Each of these 10 imputations is then put through the subsequent analysis pipeline
-(e.g. feature engineering, clustering, regression, classification). The 10 final
-analysis results (e.g. held-out validation error) allow the data scientist to
-obtain understanding of the uncertainty inherent in the missing values. The above
-practice is called multiple imputation. As implemented, the :class:`ChainedImputer`
-class generates a single (averaged) imputation for each missing value because this
-is the most common use case for machine learning applications. However, it can also be used
-for multiple imputations by applying it repeatedly to the same dataset with different
-random seeds with the ``n_imputations`` parameter set to 1.
-
-Note that a call to the ``transform`` method of :class:`ChainedImputer` is not
-allowed to change the number of samples. Therefore multiple imputations cannot be
-achieved by a single call to ``transform``.
+:class:`SimpleImputer` can be used in a Pipeline as a way to build a composite
+estimator that supports imputation. See :ref:`sphx_glr_auto_examples_plot_missing_values.py`.
+
+.. _missing_indicator:
+
+Marking imputed values
+======================
+
+The :class:`MissingIndicator` transformer is useful to transform a dataset into
+corresponding binary matrix indicating the presence of missing values in the
+dataset. This transformation is useful in conjunction with imputation. When
+using imputation, preserving the information about which values had been
+missing can be informative.
+
+``NaN`` is usually used as the placeholder for missing values. However, it
+enforces the data type to be float. The parameter ``missing_values`` allows to
+specify other placeholder such as integer. In the following example, we will
+use ``-1`` as missing values::
+
+  >>> from sklearn.impute import MissingIndicator
+  >>> X = np.array([[-1, -1, 1, 3],
+  ...               [4, -1, 0, -1],
+  ...               [8, -1, 1, 0]])
+  >>> indicator = MissingIndicator(missing_values=-1)
+  >>> mask_missing_values_only = indicator.fit_transform(X)
+  >>> mask_missing_values_only
+  array([[ True,  True, False],
+         [False,  True,  True],
+         [False,  True, False]])
+
+The ``features`` parameter is used to choose the features for which the mask is
+constructed. By default, it is ``'missing-only'`` which returns the imputer
+mask of the features containing missing values at ``fit`` time::
+
+  >>> indicator.features_
+  array([0, 1, 3])
+
+The ``features`` parameter can be set to ``'all'`` to returned all features
+whether or not they contain missing values::
+    
+  >>> indicator = MissingIndicator(missing_values=-1, features="all")
+  >>> mask_all = indicator.fit_transform(X)
+  >>> mask_all
+  array([[ True,  True, False, False],
+         [False,  True, False,  True],
+         [False,  True, False, False]])
+  >>> indicator.features_
+  array([0, 1, 2, 3])
diff --git a/doc/modules/model_evaluation.rst b/doc/modules/model_evaluation.rst
index e55dc1cc1476..7638bcd7b955 100644
--- a/doc/modules/model_evaluation.rst
+++ b/doc/modules/model_evaluation.rst
@@ -98,9 +98,9 @@ Usage examples:
     >>> from sklearn.model_selection import cross_val_score
     >>> iris = datasets.load_iris()
     >>> X, y = iris.data, iris.target
-    >>> clf = svm.SVC(gamma='scale', probability=True, random_state=0)
-    >>> cross_val_score(clf, X, y, scoring='neg_log_loss') # doctest: +ELLIPSIS
-    array([-0.10..., -0.16..., -0.07...])
+    >>> clf = svm.SVC(gamma='scale', random_state=0)
+    >>> cross_val_score(clf, X, y, scoring='recall_macro') # doctest: +ELLIPSIS
+    array([0.980..., 0.960..., 0.979...])
     >>> model = svm.SVC()
     >>> cross_val_score(model, X, y, scoring='wrong_choice')
     Traceback (most recent call last):
diff --git a/doc/modules/outlier_detection.rst b/doc/modules/outlier_detection.rst
index f35f823c5c5a..b287f3d7bc73 100644
--- a/doc/modules/outlier_detection.rst
+++ b/doc/modules/outlier_detection.rst
@@ -99,6 +99,7 @@ but regular, observation outside the frontier.
    * See :ref:`sphx_glr_auto_examples_svm_plot_oneclass.py` for visualizing the
      frontier learned around some data by a
      :class:`svm.OneClassSVM` object.
+   * :ref:`sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py`
 
 .. figure:: ../auto_examples/svm/images/sphx_glr_plot_oneclass_001.png
    :target: ../auto_examples/svm/plot_oneclass.html
diff --git a/doc/modules/preprocessing.rst b/doc/modules/preprocessing.rst
index 5d3979ead65e..70f24def72f2 100644
--- a/doc/modules/preprocessing.rst
+++ b/doc/modules/preprocessing.rst
@@ -582,9 +582,9 @@ on a k-means clustering procedure performed on each feature independently.
 
 .. topic:: Examples:
 
-  * :ref:`sphx_glr_auto_examples_plot_discretization.py`
-  * :ref:`sphx_glr_auto_examples_plot_discretization_classification.py`
-  * :ref:`sphx_glr_auto_examples_plot_discretization_strategies.py`
+  * :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization.py`
+  * :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`
+  * :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_strategies.py`
 
 .. _preprocessing_binarization:
 
@@ -706,7 +706,7 @@ a transformer that applies a log transformation in a pipeline, do::
 
     >>> import numpy as np
     >>> from sklearn.preprocessing import FunctionTransformer
-    >>> transformer = FunctionTransformer(np.log1p)
+    >>> transformer = FunctionTransformer(np.log1p, validate=True)
     >>> X = np.array([[0, 1], [2, 3]])
     >>> transformer.transform(X)
     array([[0.        , 0.69314718],
diff --git a/doc/modules/svm.rst b/doc/modules/svm.rst
index aac074cc2d99..bd065c14f744 100644
--- a/doc/modules/svm.rst
+++ b/doc/modules/svm.rst
@@ -336,27 +336,10 @@ floating point values instead of integer values::
 Density estimation, novelty detection
 =======================================
 
-One-class SVM is used for novelty detection, that is, given a set of
-samples, it will detect the soft boundary of that set so as to
-classify new points as belonging to that set or not. The class that
-implements this is called :class:`OneClassSVM`.
-
-In this case, as it is a type of unsupervised learning, the fit method
-will only take as input an array X, as there are no class labels.
-
-See, section :ref:`outlier_detection` for more details on this usage.
-
-.. figure:: ../auto_examples/svm/images/sphx_glr_plot_oneclass_001.png
-   :target: ../auto_examples/svm/plot_oneclass.html
-   :align: center
-   :scale: 75
-
-
-.. topic:: Examples:
-
- * :ref:`sphx_glr_auto_examples_svm_plot_oneclass.py`
- * :ref:`sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py`
+The class :class:`OneClassSVM` implements a One-Class SVM which is used in
+outlier detection. 
 
+See :ref:`outlier_detection` for the description and usage of OneClassSVM.
 
 Complexity
 ==========
diff --git a/doc/tutorial/statistical_inference/model_selection.rst b/doc/tutorial/statistical_inference/model_selection.rst
index 3feba26c6a77..2146c62b9af8 100644
--- a/doc/tutorial/statistical_inference/model_selection.rst
+++ b/doc/tutorial/statistical_inference/model_selection.rst
@@ -215,15 +215,15 @@ estimator during the construction and exposes an estimator API::
     >>> Cs = np.logspace(-6, -1, 10)
     >>> clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),
     ...                    n_jobs=-1)
-    >>> clf.fit(X_digits[:1000], y_digits[:1000])        # doctest: +ELLIPSIS
+    >>> clf.fit(X_digits[:1000], y_digits[:1000])        # doctest: +SKIP
     GridSearchCV(cv=None,...
-    >>> clf.best_score_                                  # doctest: +ELLIPSIS
+    >>> clf.best_score_                                  # doctest: +SKIP
     0.925...
-    >>> clf.best_estimator_.C                            # doctest: +ELLIPSIS
+    >>> clf.best_estimator_.C                            # doctest: +SKIP
     0.0077...
 
     >>> # Prediction performance on test set is not as good as on train set
-    >>> clf.score(X_digits[1000:], y_digits[1000:])      # doctest: +ELLIPSIS
+    >>> clf.score(X_digits[1000:], y_digits[1000:])      # doctest: +SKIP
     0.943...
 
 
@@ -235,8 +235,7 @@ a stratified 3-fold.
 
     ::
 
-        >>> cross_val_score(clf, X_digits, y_digits)
-        ...                                               # doctest: +ELLIPSIS
+        >>> cross_val_score(clf, X_digits, y_digits) # doctest: +SKIP
         array([0.938..., 0.963..., 0.944...])
 
     Two cross-validation loops are performed in parallel: one by the
diff --git a/doc/whats_new/v0.19.rst b/doc/whats_new/v0.19.rst
index c28199716528..9b83278209ea 100644
--- a/doc/whats_new/v0.19.rst
+++ b/doc/whats_new/v0.19.rst
@@ -4,6 +4,23 @@
 
 .. _changes_0_19:
 
+Version 0.19.2
+==============
+
+**October, 2018**
+
+This release is exclusively in order to support Python 3.7.
+
+Related changes
+---------------
+
+- ``n_iter_`` may vary from previous releases in
+  :class:`linear_model.LogisticRegression` with ``solver='lbfgs'`` and
+  :class:`linear_model.HuberRegressor`.  For Scipy <= 1.0.0, the optimizer could
+  perform more than the requested maximum number of iterations. Now both
+  estimators will report at most ``max_iter`` iterations even if more were
+  performed. :issue:`10723` by `Joel Nothman`_.
+
 Version 0.19.1
 ==============
 
diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst
index 0df0635d57c7..8ed142b6367e 100644
--- a/doc/whats_new/v0.20.rst
+++ b/doc/whats_new/v0.20.rst
@@ -11,13 +11,17 @@ This release packs in a mountain of bug fixes, features and enhancements for
 the Scikit-learn library, and improvements to the documentation and examples.
 Thanks to our many contributors!
 
+.. warning::
+
+    Version 0.20 is the last version of scikit-learn to support Python 2.7 and Python 3.4.
+    Scikit-learn 0.21 will require Python 3.5 or higher.
+
 Highlights
 ----------
 
 We have tried to improve our support for common data-science use-cases
 including missing values, categorical variables, heterogeneous data, and
 features/targets with unusual distributions.
-
 Missing values in features, represented by NaNs, are now accepted in
 column-wise preprocessing such as scalers.  Each feature is fitted disregarding
 NaNs, and data containing NaNs can be transformed. The new :mod:`impute`
@@ -41,8 +45,6 @@ Beyond this, we have added :term:`sample_weight` support to several estimators
 :class:`~ensemble.GradientBoostingRegressor` and
 :class:`~linear_model.SGDRegressor`).
 
-.. FIXME: remove SGDRegressor if #9043 is not merged for release
-
 This release is also the first to be accompanied by a :ref:`glossary` developed
 by `Joel Nothman`_. The glossary is a reference resource to help users and
 contributors become familiar with the terminology and conventions used in
@@ -62,9 +64,9 @@ random sampling procedures.
 - :class:`linear_model.OrthogonalMatchingPursuit` (bug fix)
 - :class:`metrics.roc_auc_score` (bug fix)
 - :class:`metrics.roc_curve` (bug fix)
+- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)
 - :class:`neural_network.MLPRegressor` (bug fix)
 - :class:`neural_network.MLPClassifier` (bug fix)
-- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)
 - :class:`linear_model.SGDClassifier` (bug fix)
 - :class:`linear_model.SGDRegressor` (bug fix)
 - :class:`linear_model.PassiveAggressiveClassifier` (bug fix)
@@ -80,12 +82,6 @@ Details are listed in the changelog below.
 (While we are trying to better inform users by providing this information, we
 cannot assure that this list is complete.)
 
-**Other backward incompatible change** The vendored version of the joblib
-module is now found at `sklearn.externals._joblib` (:issue:`11166`). The
-main API of joblib is still exposed in `sklearn.externals.joblib`, but
-code doing imports of subpackages of `sklearn.externals.joblib` will
-break.
-
 Changelog
 ---------
 
@@ -137,7 +133,7 @@ Preprocessing
 - Added :class:`compose.ColumnTransformer`, which allows to apply
   different transformers to different columns of arrays or pandas
   DataFrames. :issue:`9012` by `Andreas Müller`_ and `Joris Van den Bossche`_,
-  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`_.
+  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`.
 
 - Added :class:`preprocessing.PowerTransformer`, which implements the Box-Cox
   power transformation, allowing users to map data from any distribution to a
@@ -151,10 +147,9 @@ Preprocessing
   back to the original space via an inverse transform. :issue:`9041` by
   `Andreas Müller`_ and :user:`Guillaume Lemaitre <glemaitre>`.
 
-- Added :class:`impute.ChainedImputer`, which is a strategy for imputing missing
-  values by modeling each feature with missing values as a function of
-  other features in a round-robin fashion. :issue:`8478` by
-  :user:`Sergey Feldman <sergeyf>`.
+- Added :class:`MissingIndicator` which generates a binary indicator for
+  missing values. :issue:`8075` by :user:`Maniteja Nandana <maniteja123>` and
+  :user:`Guillaume Lemaitre <glemaitre>`.
 
 - :class:`linear_model.SGDClassifier`, :class:`linear_model.SGDRegressor`,
   :class:`linear_model.PassiveAggressiveClassifier`,
@@ -177,6 +172,10 @@ Model evaluation
 
 Decomposition, manifold learning and clustering
 
+- A new clustering algorithm: :class:`cluster.OPTICS`: an algoritm
+  related to :class:`cluster.DBSCAN`, that has hyperparameters easier to
+  set and tat scales better, by :user:`Shane <espg>`.
+
 - :class:`cluster.AgglomerativeClustering` now supports Single Linkage
   clustering via ``linkage='single'``. :issue:`9372` by
   :user:`Leland McInnes <lmcinnes>` and :user:`Steve Astels <sastels>`.
@@ -195,6 +194,12 @@ Metrics
   :func:`metrics.roc_auc_score`. :issue:`3273` by
   :user:`Alexander Niederbühl <Alexander-N>`.
 
+- Added control over the normalization in 
+  :func:`metrics.normalized_mutual_information_score` and
+  :func:`metrics.adjusted_mutual_information_score` via the ``average_method``
+  parameter. In version 0.22, the default normalizer for each will become
+  the *arithmetic* mean of the entropies of each clustering. :issue:`11124` by
+  :user:`Arya McCarthy <aryamccarthy>`.
 - Added ``output_dict`` parameter in :func:`metrics.classification_report`
   to return classification statistics as dictionary.
   :issue:`11160` by :user:`Dan Barkhorn <danielbarkhorn>`.
@@ -207,7 +212,8 @@ Misc
   :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.
 
 - An environment variable to use the site joblib instead of the vendored
-  one was added (:ref:`environment_variable`).
+  one was added (:ref:`environment_variable`). The main API of joblib is now
+  exposed in :mod:`sklearn.utils`.
   :issue:`11166`by `Gael Varoquaux`_
 
 Enhancements
@@ -296,6 +302,11 @@ Preprocessing
   :class:`feature_extraction.text.CountVectorizer` initialized with a
   vocabulary. :issue:`10908` by :user:`Mohamed Maskani <maskani-moh>`.
 
+- :class:`preprocessing.OneHotEncoder` now supports the
+  :meth:`get_feature_names` method to obtain the transformed feature names.
+  :issue:`10181` by  :user:`Nirvan Anjirbag <Nirvan101>` and
+  `Joris Van den Bossche`_.
+
 - The ``transform`` method of :class:`sklearn.preprocessing.MultiLabelBinarizer`
   now ignores any unknown classes. A warning is raised stating the unknown classes
   classes found which are ignored.
@@ -381,12 +392,23 @@ Metrics
   faster. This avoids some reported freezes and MemoryErrors.
   :issue:`11135` by `Joel Nothman`_.
 
+- :func:`metrics.average_precision_score` now supports binary ``y_true``
+  other than ``{0, 1}`` or ``{-1, 1}`` through ``pos_label`` parameter.
+  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.
+
 Linear, kernelized and related models
 
 - Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the
   underlying implementation is not random.
   :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.
 
+Preprocessing and feature selection
+
+- Added select K best features functionality to
+  :class:`feature_selection.SelectFromModel`.
+  :issue:`6689` by :user:`Nihar Sheth <nsheth12>` and
+  :user:`Quazi Rahman <qmaruf>`.
+
 Decomposition, manifold learning and clustering
 
 - Deprecate ``precomputed`` parameter in function
@@ -520,6 +542,12 @@ Classifiers and regressors
   per-tree basis. The previous behavior over-weighted the Gini importance of
   features that appear in later stages. This issue only affected feature
   importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.
+  
+- Fixed a bug in :class:`tree.MAE` to ensure sample weights are being used 
+  during the calculation of tree MAE impurity. Previous behaviour could 
+  cause suboptimal splits to be chosen since the impurity calculation 
+  considered all samples to be of equal weight importance.
+  :issue:`11464` by :user:`John Stott <JohnStott>`.  
 
 Decomposition, manifold learning and clustering
 
@@ -575,6 +603,12 @@ Decomposition, manifold learning and clustering
   :class:`mixture.BayesianGaussianMixture`. :issue:`10740` by :user:`Erich
   Schubert <kno10>` and :user:`Guillaume Lemaitre <glemaitre>`.
 
+- Fixed a bug in :class:`mixture.BaseMixture` and its subclasses
+  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`
+  where the ``lower_bound_`` was not the max lower bound across all
+  initializations (when ``n_init > 1``), but just the lower bound of the last
+  initialization. :issue:`10869` by :user:`Aurélien Géron <ageron>`.
+
 - Fixed a bug in :class:`decomposition.SparseCoder` when running OMP sparse
   coding in parallel using readonly memory mapped datastructures. :issue:`5956`
   by :user:`Vighnesh Birodkar <vighneshbirodkar>` and
@@ -604,6 +638,10 @@ Metrics
   :func:`metrics.mutual_info_score`.
   :issue:`9772` by :user:`Kumar Ashutosh <thechargedneutron>`.
 
+- Fixed a bug where :func:`metrics.average_precision_score` will sometimes return
+  ``nan`` when ``sample_weight`` contains 0.
+  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.
+
 - Fixed a bug in :func:`metrics.fowlkes_mallows_score` to avoid integer
   overflow. Casted return value of `contingency_matrix` to `int64` and computed
   product of square roots rather than square root of product.
@@ -690,6 +728,15 @@ Datasets
 API changes summary
 -------------------
 
+Classifiers and regressors
+
+- The default value of the ``n_estimators`` parameter of 
+  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`, 
+  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`, 
+  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20 
+  to 100 in 0.22. A FutureWarning is raised when the default value is used.
+  :issue:`11542` by :user:`Anna Ayzenshtat <annaayzenshtat>`.
+
 Linear, kernelized and related models
 
 - Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the
@@ -749,6 +796,17 @@ Metrics
   due to floating point error in the input.
   :issue:`9851` by :user:`Hanmin Qin <qinhanmin2014>`.
 
+- In :func:`metrics.normalized_mutual_information_score` and
+  :func:`metrics.adjusted_mutual_information_score`, 
+  warn that ``average_method``
+  will have a new default value. In version 0.22, the default normalizer for each 
+  will become the *arithmetic* mean of the entropies of each clustering. Currently,
+  :func:`metrics.normalized_mutual_information_score` uses the default of
+  ``average_method='geometric'``, and :func:`metrics.adjusted_mutual_information_score`
+  uses the default of ``average_method='max'`` to match their behaviors in
+  version 0.19.
+  :issue:`11124` by :user:`Arya McCarthy <aryamccarthy>`.
+
 - The ``batch_size`` parameter to :func:`metrics.pairwise_distances_argmin_min`
   and :func:`metrics.pairwise_distances_argmin` is deprecated to be removed in
   v0.22.  It no longer has any effect, as batch size is determined by global
@@ -852,10 +910,18 @@ These changes mostly affect library developers.
   that accept pairwise data.
   :issue:`9701` by :user:`Kyle Johnson <gkjohns>`
 
-- Allow :func:`~utils.estimator_checks.check_estimator` to check that there is no
+- Allow :func:`utils.estimator_checks.check_estimator` to check that there is no
   private settings apart from parameters during estimator initialization.
   :issue:`9378` by :user:`Herilalaina Rakotoarison <herilalaina>`
 
+- The set of checks in :func:`utils.estimator_checks.check_estimator` now includes a
+  ``check_set_params`` test which checks that ``set_params`` is equivalent to
+  passing parameters in ``__init__`` and warns if it encounters parameter
+  validation. :issue:`7738` by :user:`Alvin Chiang <absolutelyNoWarranty>`
+  
+- Add invariance tests for clustering metrics. :issue:`8102` by :user:`Ankita
+  Sinha <anki08>` and :user:`Guillaume Lemaitre <glemaitre>`.
+
 - Add ``check_methods_subset_invariance`` to
   :func:`~utils.estimator_checks.check_estimator`, which checks that
   estimator methods are invariant if applied to a data subset.  :issue:`10420`
diff --git a/examples/applications/plot_prediction_latency.py b/examples/applications/plot_prediction_latency.py
index 8d4d9c746593..f5a3b5173599 100644
--- a/examples/applications/plot_prediction_latency.py
+++ b/examples/applications/plot_prediction_latency.py
@@ -102,7 +102,7 @@ def generate_dataset(n_train, n_test, n_features, noise=0.1, verbose=False):
 
     random_seed = 13
     X_train, X_test, y_train, y_test = train_test_split(
-        X, y, train_size=n_train, random_state=random_seed)
+        X, y, train_size=n_train, test_size=n_test, random_state=random_seed)
     X_train, y_train = shuffle(X_train, y_train, random_state=random_seed)
 
     X_scaler = StandardScaler()
@@ -285,7 +285,7 @@ def plot_benchmark_throughput(throughputs, configuration):
          'complexity_label': 'non-zero coefficients',
          'complexity_computer': lambda clf: np.count_nonzero(clf.coef_)},
         {'name': 'RandomForest',
-         'instance': RandomForestRegressor(),
+         'instance': RandomForestRegressor(n_estimators=100),
          'complexity_label': 'estimators',
          'complexity_computer': lambda clf: clf.n_estimators},
         {'name': 'SVR',
diff --git a/examples/applications/plot_species_distribution_modeling.py b/examples/applications/plot_species_distribution_modeling.py
index 754b9d7cb267..a16b5b7153ce 100644
--- a/examples/applications/plot_species_distribution_modeling.py
+++ b/examples/applications/plot_species_distribution_modeling.py
@@ -154,7 +154,7 @@ def plot_species_distribution(species=("bradypus_variegatus_0",
         else:
             print(" - plot coastlines from coverage")
             plt.contour(X, Y, land_reference,
-                        levels=[-9999], colors="k",
+                        levels=[-9998], colors="k",
                         linestyles="solid")
             plt.xticks([])
             plt.yticks([])
diff --git a/examples/applications/wikipedia_principal_eigenvector.py b/examples/applications/wikipedia_principal_eigenvector.py
index 3ef921bb3d05..da2a43de2790 100644
--- a/examples/applications/wikipedia_principal_eigenvector.py
+++ b/examples/applications/wikipedia_principal_eigenvector.py
@@ -45,7 +45,7 @@
 from scipy import sparse
 
 from sklearn.decomposition import randomized_svd
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.externals.six.moves.urllib.request import urlopen
 from sklearn.externals.six import iteritems
 
diff --git a/examples/classification/plot_classification_probability.py b/examples/classification/plot_classification_probability.py
index 3991a70cb4c0..4542362817d7 100644
--- a/examples/classification/plot_classification_probability.py
+++ b/examples/classification/plot_classification_probability.py
@@ -76,7 +76,7 @@ class dataset, and we classify it with a Support Vector classifier, L1
         plt.yticks(())
         idx = (y_pred == k)
         if idx.any():
-            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='k')
+            plt.scatter(X[idx, 0], X[idx, 1], marker='o', c='w', edgecolor='k')
 
 ax = plt.axes([0.15, 0.04, 0.7, 0.05])
 plt.title("Probability")
diff --git a/examples/classification/plot_lda_qda.py b/examples/classification/plot_lda_qda.py
index e10d0a356075..920785131f39 100644
--- a/examples/classification/plot_lda_qda.py
+++ b/examples/classification/plot_lda_qda.py
@@ -130,8 +130,8 @@ def plot_lda_cov(lda, splot):
 
 
 def plot_qda_cov(qda, splot):
-    plot_ellipse(splot, qda.means_[0], qda.covariances_[0], 'red')
-    plot_ellipse(splot, qda.means_[1], qda.covariances_[1], 'blue')
+    plot_ellipse(splot, qda.means_[0], qda.covariance_[0], 'red')
+    plot_ellipse(splot, qda.means_[1], qda.covariance_[1], 'blue')
 
 for i, (X, y) in enumerate([dataset_fixed_cov(), dataset_cov()]):
     # Linear Discriminant Analysis
diff --git a/examples/cluster/plot_cluster_comparison.py b/examples/cluster/plot_cluster_comparison.py
index 39d8bca458cc..f0853e88d9ff 100644
--- a/examples/cluster/plot_cluster_comparison.py
+++ b/examples/cluster/plot_cluster_comparison.py
@@ -116,6 +116,8 @@
         n_clusters=params['n_clusters'], eigen_solver='arpack',
         affinity="nearest_neighbors")
     dbscan = cluster.DBSCAN(eps=params['eps'])
+    optics = cluster.OPTICS(min_samples=30, maxima_ratio=.8,
+                            rejection_ratio=.4)
     affinity_propagation = cluster.AffinityPropagation(
         damping=params['damping'], preference=params['preference'])
     average_linkage = cluster.AgglomerativeClustering(
@@ -133,6 +135,7 @@
         ('Ward', ward),
         ('AgglomerativeClustering', average_linkage),
         ('DBSCAN', dbscan),
+        ('OPTICS', optics),
         ('Birch', birch),
         ('GaussianMixture', gmm)
     )
diff --git a/examples/cluster/plot_feature_agglomeration_vs_univariate_selection.py b/examples/cluster/plot_feature_agglomeration_vs_univariate_selection.py
index 0801899f7034..b5826105a5e7 100644
--- a/examples/cluster/plot_feature_agglomeration_vs_univariate_selection.py
+++ b/examples/cluster/plot_feature_agglomeration_vs_univariate_selection.py
@@ -30,7 +30,7 @@
 from sklearn.cluster import FeatureAgglomeration
 from sklearn.linear_model import BayesianRidge
 from sklearn.pipeline import Pipeline
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 from sklearn.model_selection import GridSearchCV
 from sklearn.model_selection import KFold
 
diff --git a/examples/cluster/plot_kmeans_silhouette_analysis.py b/examples/cluster/plot_kmeans_silhouette_analysis.py
index be622eeda65a..a3797ae061cb 100644
--- a/examples/cluster/plot_kmeans_silhouette_analysis.py
+++ b/examples/cluster/plot_kmeans_silhouette_analysis.py
@@ -139,4 +139,4 @@
                   "with n_clusters = %d" % n_clusters),
                  fontsize=14, fontweight='bold')
 
-    plt.show()
+plt.show()
diff --git a/examples/cluster/plot_optics.py b/examples/cluster/plot_optics.py
new file mode 100755
index 000000000000..964ca49f6983
--- /dev/null
+++ b/examples/cluster/plot_optics.py
@@ -0,0 +1,101 @@
+"""
+===================================
+Demo of OPTICS clustering algorithm
+===================================
+
+Finds core samples of high density and expands clusters from them.
+This example uses data that is generated so that the clusters have
+different densities.
+
+The clustering is first used in its automatic settings, which is the
+:class:`sklearn.cluster.OPTICS` algorithm, and then setting specific
+thresholds on the reachability, which corresponds to DBSCAN.
+
+We can see that the different clusters of OPTICS can be recovered with
+different choices of thresholds in DBSCAN.
+
+"""
+
+# Authors: Shane Grigsby <refuge@rocktalus.com>
+#          Amy X. Zhang <axz@mit.edu>
+# License: BSD 3 clause
+
+
+from sklearn.cluster import OPTICS
+import matplotlib.gridspec as gridspec
+
+
+import numpy as np
+
+import matplotlib.pyplot as plt
+
+# Generate sample data
+
+np.random.seed(0)
+n_points_per_cluster = 250
+
+C1 = [-5, -2] + .8 * np.random.randn(n_points_per_cluster, 2)
+C2 = [4, -1] + .1 * np.random.randn(n_points_per_cluster, 2)
+C3 = [1, -2] + .2 * np.random.randn(n_points_per_cluster, 2)
+C4 = [-2, 3] + .3 * np.random.randn(n_points_per_cluster, 2)
+C5 = [3, -2] + 1.6 * np.random.randn(n_points_per_cluster, 2)
+C6 = [5, 6] + 2 * np.random.randn(n_points_per_cluster, 2)
+X = np.vstack((C1, C2, C3, C4, C5, C6))
+
+clust = OPTICS(min_samples=9, rejection_ratio=0.5)
+
+# Run the fit
+clust.fit(X)
+
+_, labels_025 = clust.extract_dbscan(0.25)
+_, labels_075 = clust.extract_dbscan(0.75)
+
+space = np.arange(len(X))
+reachability = clust.reachability_[clust.ordering_]
+labels = clust.labels_[clust.ordering_]
+
+plt.figure(figsize=(10, 7))
+G = gridspec.GridSpec(2, 3)
+ax1 = plt.subplot(G[0, :])
+ax2 = plt.subplot(G[1, 0])
+ax3 = plt.subplot(G[1, 1])
+ax4 = plt.subplot(G[1, 2])
+
+# Reachability plot
+color = ['g.', 'r.', 'b.', 'y.', 'c.']
+for k, c in zip(range(0, 5), color):
+    Xk = space[labels == k]
+    Rk = reachability[labels == k]
+    ax1.plot(Xk, Rk, c, alpha=0.3)
+ax1.plot(space[labels == -1], reachability[labels == -1], 'k.', alpha=0.3)
+ax1.plot(space, np.ones_like(space) * 0.75, 'k-', alpha=0.5)
+ax1.plot(space, np.ones_like(space) * 0.25, 'k-.', alpha=0.5)
+ax1.set_ylabel('Reachability (epsilon distance)')
+ax1.set_title('Reachability Plot')
+
+# OPTICS
+color = ['g.', 'r.', 'b.', 'y.', 'c.']
+for k, c in zip(range(0, 5), color):
+    Xk = X[clust.labels_ == k]
+    ax2.plot(Xk[:, 0], Xk[:, 1], c, alpha=0.3)
+ax2.plot(X[clust.labels_ == -1, 0], X[clust.labels_ == -1, 1], 'k+', alpha=0.1)
+ax2.set_title('Automatic Clustering\nOPTICS')
+
+# DBSCAN at 0.25
+color = ['g', 'greenyellow', 'olive', 'r', 'b', 'c']
+for k, c in zip(range(0, 6), color):
+    Xk = X[labels_025 == k]
+    ax3.plot(Xk[:, 0], Xk[:, 1], c, alpha=0.3, marker='.')
+ax3.plot(X[labels_025 == -1, 0], X[labels_025 == -1, 1], 'k+', alpha=0.1)
+ax3.set_title('Clustering at 0.25 epsilon cut\nDBSCAN')
+
+# DBSCAN at 0.75
+color = ['g.', 'm.', 'y.', 'c.']
+for k, c in zip(range(0, 4), color):
+    Xk = X[labels_075 == k]
+    ax4.plot(Xk[:, 0], Xk[:, 1], c, alpha=0.3)
+ax4.plot(X[labels_075 == -1, 0], X[labels_075 == -1, 1], 'k+', alpha=0.1)
+ax4.set_title('Clustering at 0.75 epsilon cut\nDBSCAN')
+
+plt.tight_layout()
+plt.show()
diff --git a/examples/compose/plot_column_transformer.py b/examples/compose/plot_column_transformer.py
index 0161af7fe7e4..010717583ec0 100644
--- a/examples/compose/plot_column_transformer.py
+++ b/examples/compose/plot_column_transformer.py
@@ -40,7 +40,7 @@
 from sklearn.metrics import classification_report
 from sklearn.pipeline import Pipeline
 from sklearn.compose import ColumnTransformer
-from sklearn.svm import SVC
+from sklearn.svm import LinearSVC
 
 
 class TextStats(BaseEstimator, TransformerMixin):
@@ -117,7 +117,7 @@ def transform(self, posts):
     )),
 
     # Use a SVC classifier on the combined features
-    ('svc', SVC(kernel='linear')),
+    ('svc', LinearSVC()),
 ])
 
 # limit the list of categories to make running this example faster.
diff --git a/examples/compose/plot_compare_reduction.py b/examples/compose/plot_compare_reduction.py
index 0dc69b479276..89d4d417290e 100755
--- a/examples/compose/plot_compare_reduction.py
+++ b/examples/compose/plot_compare_reduction.py
@@ -104,7 +104,7 @@
 
 from tempfile import mkdtemp
 from shutil import rmtree
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 
 # Create a temporary folder to store the transformers of the pipeline
 cachedir = mkdtemp()
diff --git a/examples/decomposition/plot_sparse_coding.py b/examples/decomposition/plot_sparse_coding.py
index ebc3feade5b0..14cab3374373 100644
--- a/examples/decomposition/plot_sparse_coding.py
+++ b/examples/decomposition/plot_sparse_coding.py
@@ -16,6 +16,8 @@
 """
 print(__doc__)
 
+from distutils.version import LooseVersion
+
 import numpy as np
 import matplotlib.pyplot as plt
 
@@ -64,6 +66,8 @@ def ricker_matrix(width, resolution, n_components):
 estimators = [('OMP', 'omp', None, 15, 'navy'),
               ('Lasso', 'lasso_cd', 2, None, 'turquoise'), ]
 lw = 2
+# Avoid FutureWarning about default value change when numpy >= 1.14
+lstsq_rcond = None if LooseVersion(np.__version__) >= '1.14' else -1
 
 plt.figure(figsize=(13, 6))
 for subplot, (D, title) in enumerate(zip((D_fixed, D_multi),
@@ -88,7 +92,7 @@ def ricker_matrix(width, resolution, n_components):
                         transform_alpha=20)
     x = coder.transform(y.reshape(1, -1))
     _, idx = np.where(x != 0)
-    x[0, idx], _, _, _ = np.linalg.lstsq(D[idx, :].T, y)
+    x[0, idx], _, _, _ = np.linalg.lstsq(D[idx, :].T, y, rcond=lstsq_rcond)
     x = np.ravel(np.dot(x, D))
     squared_error = np.sum((y - x) ** 2)
     plt.plot(x, color='darkorange', lw=lw,
diff --git a/examples/ensemble/plot_ensemble_oob.py b/examples/ensemble/plot_ensemble_oob.py
index 19b01772d5c2..081025c8170d 100644
--- a/examples/ensemble/plot_ensemble_oob.py
+++ b/examples/ensemble/plot_ensemble_oob.py
@@ -45,15 +45,18 @@
 # error trajectory during training.
 ensemble_clfs = [
     ("RandomForestClassifier, max_features='sqrt'",
-        RandomForestClassifier(warm_start=True, oob_score=True,
+        RandomForestClassifier(n_estimators=100,
+                               warm_start=True, oob_score=True,
                                max_features="sqrt",
                                random_state=RANDOM_STATE)),
     ("RandomForestClassifier, max_features='log2'",
-        RandomForestClassifier(warm_start=True, max_features='log2',
+        RandomForestClassifier(n_estimators=100,
+                               warm_start=True, max_features='log2',
                                oob_score=True,
                                random_state=RANDOM_STATE)),
     ("RandomForestClassifier, max_features=None",
-        RandomForestClassifier(warm_start=True, max_features=None,
+        RandomForestClassifier(n_estimators=100,
+                               warm_start=True, max_features=None,
                                oob_score=True,
                                random_state=RANDOM_STATE))
 ]
diff --git a/examples/ensemble/plot_feature_transformation.py b/examples/ensemble/plot_feature_transformation.py
index bb1fd7ec6684..5dbc2754b3a3 100644
--- a/examples/ensemble/plot_feature_transformation.py
+++ b/examples/ensemble/plot_feature_transformation.py
@@ -62,7 +62,7 @@
 
 # Supervised transformation based on random forests
 rf = RandomForestClassifier(max_depth=3, n_estimators=n_estimator)
-rf_enc = OneHotEncoder()
+rf_enc = OneHotEncoder(categories='auto')
 rf_lm = LogisticRegression()
 rf.fit(X_train, y_train)
 rf_enc.fit(rf.apply(X_train))
@@ -72,7 +72,7 @@
 fpr_rf_lm, tpr_rf_lm, _ = roc_curve(y_test, y_pred_rf_lm)
 
 grd = GradientBoostingClassifier(n_estimators=n_estimator)
-grd_enc = OneHotEncoder()
+grd_enc = OneHotEncoder(categories='auto')
 grd_lm = LogisticRegression()
 grd.fit(X_train, y_train)
 grd_enc.fit(grd.apply(X_train)[:, :, 0])
diff --git a/examples/ensemble/plot_isolation_forest.py b/examples/ensemble/plot_isolation_forest.py
index e6c8ce3bf8ef..b43ee95c5820 100644
--- a/examples/ensemble/plot_isolation_forest.py
+++ b/examples/ensemble/plot_isolation_forest.py
@@ -40,7 +40,7 @@
 X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))
 
 # fit the model
-clf = IsolationForest(max_samples=100, random_state=rng)
+clf = IsolationForest(max_samples=100, random_state=rng, contamination='auto')
 clf.fit(X_train)
 y_pred_train = clf.predict(X_train)
 y_pred_test = clf.predict(X_test)
diff --git a/examples/ensemble/plot_random_forest_regression_multioutput.py b/examples/ensemble/plot_random_forest_regression_multioutput.py
index 44618357cda4..8b7803361a60 100644
--- a/examples/ensemble/plot_random_forest_regression_multioutput.py
+++ b/examples/ensemble/plot_random_forest_regression_multioutput.py
@@ -39,16 +39,17 @@
 y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T
 y += (0.5 - rng.rand(*y.shape))
 
-X_train, X_test, y_train, y_test = train_test_split(X, y,
-                                                    train_size=400,
-                                                    random_state=4)
+X_train, X_test, y_train, y_test = train_test_split(
+    X, y, train_size=400, test_size=200, random_state=4)
 
 max_depth = 30
-regr_multirf = MultiOutputRegressor(RandomForestRegressor(max_depth=max_depth,
+regr_multirf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100,
+                                                          max_depth=max_depth,
                                                           random_state=0))
 regr_multirf.fit(X_train, y_train)
 
-regr_rf = RandomForestRegressor(max_depth=max_depth, random_state=2)
+regr_rf = RandomForestRegressor(n_estimators=100, max_depth=max_depth,
+                                random_state=2)
 regr_rf.fit(X_train, y_train)
 
 # Predict on new data
diff --git a/examples/ensemble/plot_voting_decision_regions.py b/examples/ensemble/plot_voting_decision_regions.py
index b0a3fbe05745..86da618d48cd 100644
--- a/examples/ensemble/plot_voting_decision_regions.py
+++ b/examples/ensemble/plot_voting_decision_regions.py
@@ -39,7 +39,7 @@
 # Training classifiers
 clf1 = DecisionTreeClassifier(max_depth=4)
 clf2 = KNeighborsClassifier(n_neighbors=7)
-clf3 = SVC(kernel='rbf', probability=True)
+clf3 = SVC(gamma=.1, kernel='rbf', probability=True)
 eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2),
                                     ('svc', clf3)],
                         voting='soft', weights=[2, 1, 2])
diff --git a/examples/ensemble/plot_voting_probas.py b/examples/ensemble/plot_voting_probas.py
index 7bed271fbf9b..c729818620a6 100644
--- a/examples/ensemble/plot_voting_probas.py
+++ b/examples/ensemble/plot_voting_probas.py
@@ -30,7 +30,7 @@
 from sklearn.ensemble import VotingClassifier
 
 clf1 = LogisticRegression(random_state=123)
-clf2 = RandomForestClassifier(random_state=123)
+clf2 = RandomForestClassifier(n_estimators=100, random_state=123)
 clf3 = GaussianNB()
 X = np.array([[-1.0, -1.0], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])
 y = np.array([1, 1, 2, 2])
diff --git a/examples/gaussian_process/plot_gpc_xor.py b/examples/gaussian_process/plot_gpc_xor.py
index 957d9bd7edc3..04f014e13e8a 100644
--- a/examples/gaussian_process/plot_gpc_xor.py
+++ b/examples/gaussian_process/plot_gpc_xor.py
@@ -42,8 +42,8 @@
     image = plt.imshow(Z, interpolation='nearest',
                        extent=(xx.min(), xx.max(), yy.min(), yy.max()),
                        aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)
-    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,
-                           linetypes='--')
+    contours = plt.contour(xx, yy, Z, levels=[0.5], linewidths=2,
+                           colors=['k'])
     plt.scatter(X[:, 0], X[:, 1], s=30, c=Y, cmap=plt.cm.Paired,
                 edgecolors=(0, 0, 0))
     plt.xticks(())
diff --git a/examples/model_selection/grid_search_text_feature_extraction.py b/examples/model_selection/grid_search_text_feature_extraction.py
index 88090613fcd7..c3bd054c9951 100644
--- a/examples/model_selection/grid_search_text_feature_extraction.py
+++ b/examples/model_selection/grid_search_text_feature_extraction.py
@@ -22,7 +22,7 @@
   pipeline: ['vect', 'tfidf', 'clf']
   parameters:
   {'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07),
-   'clf__n_iter': (10, 50, 80),
+   'clf__max_iter': (10, 50, 80),
    'clf__penalty': ('l2', 'elasticnet'),
    'tfidf__use_idf': (True, False),
    'vect__max_n': (1, 2),
@@ -33,7 +33,7 @@
   Best score: 0.940
   Best parameters set:
       clf__alpha: 9.9999999999999995e-07
-      clf__n_iter: 50
+      clf__max_iter: 50
       clf__penalty: 'elasticnet'
       tfidf__use_idf: True
       vect__max_n: 2
@@ -97,14 +97,14 @@
 # increase processing time in a combinatorial way
 parameters = {
     'vect__max_df': (0.5, 0.75, 1.0),
-    #'vect__max_features': (None, 5000, 10000, 50000),
+    # 'vect__max_features': (None, 5000, 10000, 50000),
     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams
-    #'tfidf__use_idf': (True, False),
-    #'tfidf__norm': ('l1', 'l2'),
+    # 'tfidf__use_idf': (True, False),
+    # 'tfidf__norm': ('l1', 'l2'),
     'clf__max_iter': (5,),
     'clf__alpha': (0.00001, 0.000001),
     'clf__penalty': ('l2', 'elasticnet'),
-    #'clf__n_iter': (10, 50, 80),
+    # 'clf__max_iter': (10, 50, 80),
 }
 
 if __name__ == "__main__":
diff --git a/examples/model_selection/plot_multi_metric_evaluation.py b/examples/model_selection/plot_multi_metric_evaluation.py
index ea7d60dc20da..eaec4c8d1834 100644
--- a/examples/model_selection/plot_multi_metric_evaluation.py
+++ b/examples/model_selection/plot_multi_metric_evaluation.py
@@ -47,7 +47,7 @@
 # ``gs.best_index_``
 gs = GridSearchCV(DecisionTreeClassifier(random_state=42),
                   param_grid={'min_samples_split': range(2, 403, 10)},
-                  scoring=scoring, cv=5, refit='AUC')
+                  scoring=scoring, cv=5, refit='AUC', return_train_score=True)
 gs.fit(X, y)
 results = gs.cv_results_
 
@@ -61,9 +61,8 @@
 
 plt.xlabel("min_samples_split")
 plt.ylabel("Score")
-plt.grid()
 
-ax = plt.axes()
+ax = plt.gca()
 ax.set_xlim(0, 402)
 ax.set_ylim(0.73, 1)
 
diff --git a/examples/neighbors/plot_lof.py b/examples/neighbors/plot_lof.py
index 5c631de34245..f48e6b619694 100644
--- a/examples/neighbors/plot_lof.py
+++ b/examples/neighbors/plot_lof.py
@@ -34,7 +34,7 @@
 X = np.r_[X_inliers, X_outliers]
 
 # fit the model
-clf = LocalOutlierFactor(n_neighbors=20)
+clf = LocalOutlierFactor(n_neighbors=20, contamination='auto')
 y_pred = clf.fit_predict(X)
 
 # plot the level sets of the decision function
diff --git a/examples/neighbors/plot_nearest_centroid.py b/examples/neighbors/plot_nearest_centroid.py
index a9c6b712f9c2..78a0141e50fe 100644
--- a/examples/neighbors/plot_nearest_centroid.py
+++ b/examples/neighbors/plot_nearest_centroid.py
@@ -50,7 +50,7 @@
 
     # Plot also the training points
     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,
-                edgecolor='b', s=20)
+                edgecolor='k', s=20)
     plt.title("3-Class classification (shrink_threshold=%r)"
               % shrinkage)
     plt.axis('tight')
diff --git a/examples/neighbors/plot_species_kde.py b/examples/neighbors/plot_species_kde.py
index a333c7b6776d..d3669e8fee79 100644
--- a/examples/neighbors/plot_species_kde.py
+++ b/examples/neighbors/plot_species_kde.py
@@ -105,7 +105,7 @@
     else:
         print(" - plot coastlines from coverage")
         plt.contour(X, Y, land_reference,
-                    levels=[-9999], colors="k",
+                    levels=[-9998], colors="k",
                     linestyles="solid")
         plt.xticks([])
         plt.yticks([])
diff --git a/examples/plot_missing_values.py b/examples/plot_missing_values.py
index d238a16592ed..777120053a9d 100644
--- a/examples/plot_missing_values.py
+++ b/examples/plot_missing_values.py
@@ -3,26 +3,29 @@
 Imputing missing values before building an estimator
 ====================================================
 
+This example shows that imputing the missing values can give better
+results than discarding the samples containing any missing value.
+Imputing does not always improve the predictions, so please check via
+cross-validation.  Sometimes dropping rows or using marker values is
+more effective.
+
 Missing values can be replaced by the mean, the median or the most frequent
-value using the basic ``SimpleImputer``.
+value using the basic :func:`sklearn.impute.SimpleImputer`.
 The median is a more robust estimator for data with high magnitude variables
 which could dominate results (otherwise known as a 'long tail').
 
-Another option is the ``ChainedImputer``. This uses round-robin linear
-regression, treating every variable as an output in turn. The version
-implemented assumes Gaussian (output) variables. If your features are obviously
-non-Normal, consider transforming them to look more Normal so as to improve
-performance.
+In addition of using an imputing method, we can also keep an indication of the
+missing information using :func:`sklearn.impute.MissingIndicator` which might
+carry some information.
 """
-
 import numpy as np
 import matplotlib.pyplot as plt
 
 from sklearn.datasets import load_diabetes
 from sklearn.datasets import load_boston
 from sklearn.ensemble import RandomForestRegressor
-from sklearn.pipeline import Pipeline
-from sklearn.impute import SimpleImputer, ChainedImputer
+from sklearn.pipeline import make_pipeline, make_union
+from sklearn.impute import SimpleImputer, MissingIndicator
 from sklearn.model_selection import cross_val_score
 
 rng = np.random.RandomState(0)
@@ -60,25 +63,17 @@ def get_results(dataset):
     X_missing = X_full.copy()
     X_missing[np.where(missing_samples)[0], missing_features] = 0
     y_missing = y_full.copy()
-    estimator = Pipeline([("imputer", SimpleImputer(missing_values=0,
-                                                    strategy="mean")),
-                          ("forest", RandomForestRegressor(random_state=0,
-                                                           n_estimators=100))])
+    estimator = make_pipeline(
+        make_union(SimpleImputer(missing_values=0, strategy="mean"),
+                   MissingIndicator(missing_values=0)),
+        RandomForestRegressor(random_state=0, n_estimators=100))
     mean_impute_scores = cross_val_score(estimator, X_missing, y_missing,
                                          scoring='neg_mean_squared_error')
 
-    # Estimate the score after chained imputation of the missing values
-    estimator = Pipeline([("imputer", ChainedImputer(missing_values=0,
-                                                     random_state=0)),
-                          ("forest", RandomForestRegressor(random_state=0,
-                                                           n_estimators=100))])
-    chained_impute_scores = cross_val_score(estimator, X_missing, y_missing,
-                                            scoring='neg_mean_squared_error')
 
     return ((full_scores.mean(), full_scores.std()),
             (zero_impute_scores.mean(), zero_impute_scores.std()),
-            (mean_impute_scores.mean(), mean_impute_scores.std()),
-            (chained_impute_scores.mean(), chained_impute_scores.std()))
+            (mean_impute_scores.mean(), mean_impute_scores.std()))
 
 
 results_diabetes = np.array(get_results(load_diabetes()))
@@ -94,8 +89,7 @@ def get_results(dataset):
 
 x_labels = ['Full data',
             'Zero imputation',
-            'Mean Imputation',
-            'Chained Imputation']
+            'Mean Imputation']
 colors = ['r', 'g', 'b', 'orange']
 
 # plot diabetes results
diff --git a/examples/preprocessing/plot_discretization_classification.py b/examples/preprocessing/plot_discretization_classification.py
index 4dfe7e989d2d..7e6141c32597 100644
--- a/examples/preprocessing/plot_discretization_classification.py
+++ b/examples/preprocessing/plot_discretization_classification.py
@@ -99,10 +99,12 @@ def get_name(estimator):
                         n_clusters_per_class=1)
 ]
 
-figure = plt.figure(figsize=(21, 9))
+fig, axes = plt.subplots(nrows=len(datasets), ncols=len(classifiers) + 1,
+                         figsize=(21, 9))
+
 cm = plt.cm.PiYG
 cm_bright = ListedColormap(['#b30065', '#178000'])
-i = 1
+
 # iterate over datasets
 for ds_cnt, (X, y) in enumerate(datasets):
     print('\ndataset %d\n---------' % ds_cnt)
@@ -119,7 +121,7 @@ def get_name(estimator):
         np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
 
     # plot the dataset first
-    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
+    ax = axes[ds_cnt, 0]
     if ds_cnt == 0:
         ax.set_title("Input data")
     # plot the training points
@@ -132,11 +134,11 @@ def get_name(estimator):
     ax.set_ylim(yy.min(), yy.max())
     ax.set_xticks(())
     ax.set_yticks(())
-    i += 1
 
     # iterate over classifiers
-    for name, (estimator, param_grid) in zip(names, classifiers):
-        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
+    for est_idx, (name, (estimator, param_grid)) in \
+            enumerate(zip(names, classifiers)):
+        ax = axes[ds_cnt, est_idx + 1]
 
         clf = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5,
                            iid=False)
@@ -173,7 +175,6 @@ def get_name(estimator):
                 bbox=dict(boxstyle='round', alpha=0.8, facecolor='white'),
                 transform=ax.transAxes, horizontalalignment='right')
 
-        i += 1
 
 plt.tight_layout()
 
@@ -184,8 +185,8 @@ def get_name(estimator):
     'Feature discretization and linear classifiers',
     'Non-linear classifiers',
 ]
-for i, suptitle in zip([2, 4, 6], suptitles):
-    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)
+for i, suptitle in zip([1, 3, 5], suptitles):
+    ax = axes[0, i]
     ax.text(1.05, 1.25, suptitle, transform=ax.transAxes,
             horizontalalignment='center', size='x-large')
 plt.show()
diff --git a/examples/semi_supervised/plot_label_propagation_versus_svm_iris.py b/examples/semi_supervised/plot_label_propagation_versus_svm_iris.py
index 1746aa5b02e3..32235d412b38 100644
--- a/examples/semi_supervised/plot_label_propagation_versus_svm_iris.py
+++ b/examples/semi_supervised/plot_label_propagation_versus_svm_iris.py
@@ -42,7 +42,7 @@
 ls50 = (label_propagation.LabelSpreading().fit(X, y_50),
         y_50)
 ls100 = (label_propagation.LabelSpreading().fit(X, y), y)
-rbf_svc = (svm.SVC(kernel='rbf').fit(X, y), y)
+rbf_svc = (svm.SVC(kernel='rbf', gamma=.5).fit(X, y), y)
 
 # create a mesh to plot in
 x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
diff --git a/examples/svm/plot_svm_anova.py b/examples/svm/plot_svm_anova.py
index e223730eb82b..45599f31f546 100644
--- a/examples/svm/plot_svm_anova.py
+++ b/examples/svm/plot_svm_anova.py
@@ -10,17 +10,19 @@
 
 import numpy as np
 import matplotlib.pyplot as plt
-from sklearn import svm, datasets, feature_selection
+from sklearn.datasets import load_digits
+from sklearn.feature_selection import SelectPercentile, chi2
 from sklearn.model_selection import cross_val_score
 from sklearn.pipeline import Pipeline
+from sklearn.svm import SVC
+
 
 # #############################################################################
 # Import some data to play with
-digits = datasets.load_digits()
-y = digits.target
+X, y = load_digits(return_X_y=True)
 # Throw away data, to be in the curse of dimension settings
+X = X[:200]
 y = y[:200]
-X = digits.data[:200]
 n_samples = len(y)
 X = X.reshape((n_samples, -1))
 # add 200 non-informative features
@@ -30,9 +32,9 @@
 # Create a feature-selection transform and an instance of SVM that we
 # combine together to have an full-blown estimator
 
-transform = feature_selection.SelectPercentile(feature_selection.f_classif)
+transform = SelectPercentile(chi2)
 
-clf = Pipeline([('anova', transform), ('svc', svm.SVC(C=1.0))])
+clf = Pipeline([('anova', transform), ('svc', SVC(gamma="auto"))])
 
 # #############################################################################
 # Plot the cross-validation score as a function of percentile of features
diff --git a/examples/svm/plot_svm_scale_c.py b/examples/svm/plot_svm_scale_c.py
index 5459d45e2206..5502e6829ea4 100644
--- a/examples/svm/plot_svm_scale_c.py
+++ b/examples/svm/plot_svm_scale_c.py
@@ -119,9 +119,9 @@
 colors = ['navy', 'cyan', 'darkorange']
 lw = 2
 
-for fignum, (clf, cs, X, y) in enumerate(clf_sets):
+for clf, cs, X, y in clf_sets:
     # set up the plot for each regressor
-    plt.figure(fignum, figsize=(9, 10))
+    fig, axes = plt.subplots(nrows=2, sharey=True, figsize=(9, 10))
 
     for k, train_size in enumerate(np.linspace(0.3, 0.7, 3)[::-1]):
         param_grid = dict(C=cs)
@@ -129,6 +129,7 @@
         # reduce the variance
         grid = GridSearchCV(clf, refit=False, param_grid=param_grid,
                             cv=ShuffleSplit(train_size=train_size,
+                                            test_size=.3,
                                             n_splits=250, random_state=1))
         grid.fit(X, y)
         scores = grid.cv_results_['mean_test_score']
@@ -137,15 +138,14 @@
                   ((n_samples * train_size), '1/n_samples'),
                   ]
 
-        for subplotnum, (scaler, name) in enumerate(scales):
-            plt.subplot(2, 1, subplotnum + 1)
-            plt.xlabel('C')
-            plt.ylabel('CV Score')
+        for ax, (scaler, name) in zip(axes, scales):
+            ax.set_xlabel('C')
+            ax.set_ylabel('CV Score')
             grid_cs = cs * float(scaler)  # scale the C's
-            plt.semilogx(grid_cs, scores, label="fraction %.2f" %
-                         train_size, color=colors[k], lw=lw)
-            plt.title('scaling=%s, penalty=%s, loss=%s' %
-                      (name, clf.penalty, clf.loss))
+            ax.semilogx(grid_cs, scores, label="fraction %.2f" %
+                        train_size, color=colors[k], lw=lw)
+            ax.set_title('scaling=%s, penalty=%s, loss=%s' %
+                         (name, clf.penalty, clf.loss))
 
     plt.legend(loc="best")
 plt.show()
diff --git a/examples/svm/plot_weighted_samples.py b/examples/svm/plot_weighted_samples.py
index be625c1446f5..9cdb2dcb497c 100644
--- a/examples/svm/plot_weighted_samples.py
+++ b/examples/svm/plot_weighted_samples.py
@@ -48,10 +48,10 @@ def plot_decision_function(classifier, sample_weight, axis, title):
 # for reference, first fit without class weights
 
 # fit the model
-clf_weights = svm.SVC()
+clf_weights = svm.SVC(gamma=1)
 clf_weights.fit(X, y, sample_weight=sample_weight_last_ten)
 
-clf_no_weights = svm.SVC()
+clf_no_weights = svm.SVC(gamma=1)
 clf_no_weights.fit(X, y)
 
 fig, axes = plt.subplots(1, 2, figsize=(14, 6))
diff --git a/examples/text/plot_document_classification_20newsgroups.py b/examples/text/plot_document_classification_20newsgroups.py
index 8b9d66f9e09d..388439381815 100644
--- a/examples/text/plot_document_classification_20newsgroups.py
+++ b/examples/text/plot_document_classification_20newsgroups.py
@@ -249,9 +249,9 @@ def benchmark(clf):
 
 results = []
 for clf, name in (
-        (RidgeClassifier(tol=1e-2, solver="lsqr"), "Ridge Classifier"),
-        (Perceptron(n_iter=50, tol=1e-3), "Perceptron"),
-        (PassiveAggressiveClassifier(n_iter=50, tol=1e-3),
+        (RidgeClassifier(tol=1e-2, solver="sag"), "Ridge Classifier"),
+        (Perceptron(max_iter=50, tol=1e-3), "Perceptron"),
+        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3),
          "Passive-Aggressive"),
         (KNeighborsClassifier(n_neighbors=10), "kNN"),
         (RandomForestClassifier(n_estimators=100), "Random forest")):
@@ -267,16 +267,14 @@ def benchmark(clf):
                                        tol=1e-3)))
 
     # Train SGD model
-    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,
-                                           penalty=penalty,
-                                           max_iter=5)))
+    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,
+                                           penalty=penalty)))
 
 # Train SGD with Elastic Net penalty
 print('=' * 80)
 print("Elastic-Net penalty")
-results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,
-                                       penalty="elasticnet",
-                                       max_iter=5)))
+results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,
+                                       penalty="elasticnet")))
 
 # Train NearestCentroid without threshold
 print('=' * 80)
diff --git a/setup.cfg b/setup.cfg
index b02383bae3b5..09c5c9829ae2 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -8,25 +8,16 @@ addopts =
     --doctest-modules
     --disable-pytest-warnings
     -rs
+filterwarnings =
+    error::DeprecationWarning
+    error::FutureWarning
 
 [wheelhouse_uploader]
 artifact_indexes=
-    # OSX wheels built by travis (only for specific tags):
+    # Wheels built by travis (only for specific tags):
     # https://github.com/MacPython/scikit-learn-wheels
     http://wheels.scipy.org
-    # Windows wheels built by:
-    # https://ci.appveyor.com/project/sklearn-ci/scikit-learn/
-    http://windows-wheels.scikit-learn.org/
 
 [flake8]
 # Default flake8 3.5 ignored flags
 ignore=E121,E123,E126,E226,E24,E704,W503,W504
-
-# Uncomment the following under windows to build using:
-# http://sourceforge.net/projects/mingw/
-
-#[build_ext]
-#compiler=mingw32
-#
-#[build]
-#compiler=mingw32
diff --git a/sklearn/cluster/__init__.py b/sklearn/cluster/__init__.py
index c9afcd98f23c..e35670aac45b 100644
--- a/sklearn/cluster/__init__.py
+++ b/sklearn/cluster/__init__.py
@@ -11,6 +11,7 @@
                            FeatureAgglomeration)
 from .k_means_ import k_means, KMeans, MiniBatchKMeans
 from .dbscan_ import dbscan, DBSCAN
+from .optics_ import OPTICS, optics
 from .bicluster import SpectralBiclustering, SpectralCoclustering
 from .birch import Birch
 
@@ -18,6 +19,7 @@
            'AgglomerativeClustering',
            'Birch',
            'DBSCAN',
+           'OPTICS',
            'KMeans',
            'FeatureAgglomeration',
            'MeanShift',
@@ -30,6 +32,7 @@
            'k_means',
            'linkage_tree',
            'mean_shift',
+           'optics',
            'spectral_clustering',
            'ward_tree',
            'SpectralBiclustering',
diff --git a/sklearn/cluster/_k_means.pyx b/sklearn/cluster/_k_means.pyx
index e8800ee79238..66fd620a90cd 100644
--- a/sklearn/cluster/_k_means.pyx
+++ b/sklearn/cluster/_k_means.pyx
@@ -20,9 +20,6 @@ from sklearn.utils.sparsefuncs_fast import assign_rows_csr
 ctypedef np.float64_t DOUBLE
 ctypedef np.int32_t INT
 
-ctypedef floating (*DOT)(int N, floating *X, int incX, floating *Y,
-                         int incY)
-
 cdef extern from "cblas.h":
     double ddot "cblas_ddot"(int N, double *X, int incX, double *Y, int incY)
     float sdot "cblas_sdot"(int N, float *X, int incX, float *Y, int incY)
@@ -58,7 +55,6 @@ cpdef DOUBLE _assign_labels_array(np.ndarray[floating, ndim=2] X,
         DOUBLE inertia = 0.0
         DOUBLE min_dist
         DOUBLE dist
-        DOT dot
 
     if floating is float:
         center_squared_norms = np.zeros(n_clusters, dtype=np.float32)
@@ -130,7 +126,6 @@ cpdef DOUBLE _assign_labels_csr(X, np.ndarray[floating, ndim=1] sample_weight,
         DOUBLE inertia = 0.0
         DOUBLE min_dist
         DOUBLE dist
-        DOT dot
 
     if floating is float:
         center_squared_norms = np.zeros(n_clusters, dtype=np.float32)
diff --git a/sklearn/cluster/_optics_inner.pyx b/sklearn/cluster/_optics_inner.pyx
new file mode 100644
index 000000000000..24e861907854
--- /dev/null
+++ b/sklearn/cluster/_optics_inner.pyx
@@ -0,0 +1,31 @@
+cimport numpy as np
+import numpy as np
+cimport cython
+
+ctypedef np.float64_t DTYPE_t
+ctypedef np.int_t DTYPE
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+# Checks for smallest reachability distance
+# In case of tie, preserves order and returns first instance
+# as sorted by distance
+cpdef quick_scan(double[:] rdists, double[:] dists):
+    cdef Py_ssize_t n
+    cdef int idx
+    cdef int i
+    cdef double rdist
+    cdef double dist
+    rdist = np.inf
+    dist = np.inf
+    n = len(rdists)
+    for i from 0 <= i < n:
+        if rdists[i] < rdist:
+            rdist = rdists[i]
+            dist = dists[i]
+            idx = i
+        if rdists[i] == rdist:
+            if dists[i] < dist:
+                dist = dists[i]
+                idx = i
+    return idx
diff --git a/sklearn/cluster/affinity_propagation_.py b/sklearn/cluster/affinity_propagation_.py
index 307a4fde6fd5..2e646746eee7 100644
--- a/sklearn/cluster/affinity_propagation_.py
+++ b/sklearn/cluster/affinity_propagation_.py
@@ -290,6 +290,24 @@ class AffinityPropagation(BaseEstimator, ClusterMixin):
     n_iter_ : int
         Number of iterations taken to converge.
 
+    Examples
+    --------
+    >>> from sklearn.cluster import AffinityPropagation
+    >>> import numpy as np
+    >>> X = np.array([[1, 2], [1, 4], [1, 0],
+    ...               [4, 2], [4, 4], [4, 0]])
+    >>> clustering = AffinityPropagation().fit(X)
+    >>> clustering # doctest: +NORMALIZE_WHITESPACE
+    AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True,
+              damping=0.5, max_iter=200, preference=None, verbose=False)
+    >>> clustering.labels_
+    array([0, 0, 0, 1, 1, 1])
+    >>> clustering.predict([[0, 0], [4, 4]])
+    array([0, 1])
+    >>> clustering.cluster_centers_
+    array([[1, 2],
+           [4, 2]])
+
     Notes
     -----
     For an example, see :ref:`examples/cluster/plot_affinity_propagation.py
diff --git a/sklearn/cluster/hierarchical.py b/sklearn/cluster/hierarchical.py
index f630fa990b73..db1b2c36dfea 100644
--- a/sklearn/cluster/hierarchical.py
+++ b/sklearn/cluster/hierarchical.py
@@ -776,7 +776,8 @@ def fit(self, X, y=None):
         -------
         self
         """
-        if self.pooling_func != 'deprecated':
+        if (self.pooling_func != 'deprecated' and
+                not isinstance(self, AgglomerationTransform)):
             warnings.warn('Agglomerative "pooling_func" parameter is not used.'
                           ' It has been deprecated in version 0.20 and will be'
                           'removed in 0.22', DeprecationWarning)
diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py
index 42ca6402df06..fc71ddc8463f 100644
--- a/sklearn/cluster/k_means_.py
+++ b/sklearn/cluster/k_means_.py
@@ -29,8 +29,8 @@
 from ..utils import gen_batches
 from ..utils.validation import check_is_fitted
 from ..utils.validation import FLOAT_DTYPES
-from ..externals.joblib import Parallel
-from ..externals.joblib import delayed
+from ..utils import Parallel
+from ..utils import delayed
 from ..externals.six import string_types
 from ..exceptions import ConvergenceWarning
 from . import _k_means
@@ -889,7 +889,7 @@ class KMeans(BaseEstimator, ClusterMixin, TransformerMixin):
 
     Notes
     ------
-    The k-means problem is solved using Lloyd's algorithm.
+    The k-means problem is solved using either Lloyd's or Elkan's algorithm.
 
     The average complexity is given by O(k n T), were n is the number of
     samples and T is the number of iteration.
@@ -902,6 +902,12 @@ class KMeans(BaseEstimator, ClusterMixin, TransformerMixin):
     clustering algorithms available), but it falls in local minima. That's why
     it can be useful to restart it several times.
 
+    If the algorithm stops before fully converging (because of ``tol`` of
+    ``max_iter``), ``labels_`` and ``means_`` will not be consistent, i.e. the
+    ``means_`` will not be the means of the points in each cluster.
+    Also, the estimator will reassign ``labels_`` after the last iteration to
+    make ``labels_`` consistent with ``predict`` on the training set.
+
     """
 
     def __init__(self, n_clusters=8, init='k-means++', n_init=10,
diff --git a/sklearn/cluster/mean_shift_.py b/sklearn/cluster/mean_shift_.py
index 332531b13078..384bb9b73bc5 100644
--- a/sklearn/cluster/mean_shift_.py
+++ b/sklearn/cluster/mean_shift_.py
@@ -24,8 +24,8 @@
 from ..base import BaseEstimator, ClusterMixin
 from ..neighbors import NearestNeighbors
 from ..metrics.pairwise import pairwise_distances_argmin
-from ..externals.joblib import Parallel
-from ..externals.joblib import delayed
+from ..utils import Parallel
+from ..utils import delayed
 
 
 def estimate_bandwidth(X, quantile=0.3, n_samples=None, random_state=0,
diff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py
new file mode 100755
index 000000000000..d88b78e77302
--- /dev/null
+++ b/sklearn/cluster/optics_.py
@@ -0,0 +1,755 @@
+# -*- coding: utf-8 -*-
+"""Ordering Points To Identify the Clustering Structure (OPTICS)
+
+These routines execute the OPTICS algorithm, and implement various
+cluster extraction methods of the ordered list.
+
+Authors: Shane Grigsby <refuge@rocktalus.com>
+         Amy X. Zhang <axz@mit.edu>
+License: BSD 3 clause
+"""
+
+from __future__ import division
+import warnings
+import numpy as np
+
+from ..utils import check_array
+from ..utils.validation import check_is_fitted
+from ..neighbors import NearestNeighbors
+from ..base import BaseEstimator, ClusterMixin
+from ..metrics import pairwise_distances
+from ._optics_inner import quick_scan
+
+
+def optics(X, min_samples=5, max_bound=np.inf, metric='euclidean',
+           p=2, metric_params=None, maxima_ratio=.75,
+           rejection_ratio=.7, similarity_threshold=0.4,
+           significant_min=.003, min_cluster_size_ratio=.005,
+           min_maxima_ratio=0.001, algorithm='ball_tree',
+           leaf_size=30, n_jobs=1):
+    """Perform OPTICS clustering from vector array
+
+    OPTICS: Ordering Points To Identify the Clustering Structure
+    Equivalent to DBSCAN, finds core sample of high density and expands
+    clusters from them. Unlike DBSCAN, keeps cluster hierarchy for a variable
+    neighborhood radius. Optimized for usage on large point datasets.
+
+    Parameters
+    ----------
+    X : array, shape (n_samples, n_features)
+        The data.
+
+    min_samples : int
+        The number of samples in a neighborhood for a point to be considered
+        as a core point.
+
+    max_bound : float, optional
+        The maximum distance between two samples for them to be considered
+        as in the same neighborhood. This is also the largest object size
+        expected within the dataset. Default value of "np.inf" will identify
+        clusters across all scales; reducing `max_bound` will result in
+        shorter run times.
+
+    metric : string or callable, optional
+        The distance metric to use for neighborhood lookups. Default is
+        "minkowski". Other options include "euclidean", "manhattan",
+        "chebyshev", "haversine", "seuclidean", "hamming", "canberra",
+        and "braycurtis". The "wminkowski" and "mahalanobis" metrics are
+        also valid with an additional argument.
+
+    p : integer, optional (default=2)
+        Parameter for the Minkowski metric from
+        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is
+        equivalent to using manhattan_distance (l1), and euclidean_distance
+        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
+
+    metric_params : dict, optional (default=None)
+        Additional keyword arguments for the metric function.
+
+    maxima_ratio : float, optional
+        The maximum ratio we allow of average height of clusters on the
+        right and left to the local maxima in question. The higher the
+        ratio, the more generous the algorithm is to preserving local
+        minima, and the more cuts the resulting tree will have.
+
+    rejection_ratio : float, optional
+        Adjusts the fitness of the clustering. When the maxima_ratio is
+        exceeded, determine which of the clusters to the left and right to
+        reject based on rejection_ratio. Higher values will result in points
+        being more readily classified as noise; conversely, lower values will
+        result in more points being clustered.
+
+    similarity_threshold : float, optional
+        Used to check if nodes can be moved up one level, that is, if the
+        new cluster created is too "similar" to its parent, given the
+        similarity threshold. Similarity can be determined by 1) the size
+        of the new cluster relative to the size of the parent node or
+        2) the average of the reachability values of the new cluster
+        relative to the average of the reachability values of the parent
+        node. A lower value for the similarity threshold means less levels
+        in the tree.
+
+    significant_min : float, optional
+        Sets a lower threshold on how small a significant maxima can be.
+
+    min_cluster_size_ratio : float, optional
+        Minimum percentage of dataset expected for cluster membership.
+
+    min_maxima_ratio : float, optional
+        Used to determine neighborhood size for minimum cluster membership.
+
+    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional
+        Algorithm used to compute the nearest neighbors:
+        - 'ball_tree' will use :class:`BallTree`
+        - 'kd_tree' will use :class:`KDTree`
+        - 'brute' will use a brute-force search.
+        - 'auto' will attempt to decide the most appropriate algorithm
+          based on the values passed to :meth:`fit` method.
+
+        Note: fitting on sparse input will override the setting of
+        this parameter, using brute force.
+
+    leaf_size : int, optional (default=30)
+        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can
+        affect the speed of the construction and query, as well as the memory
+        required to store the tree. The optimal value depends on the
+        nature of the problem.
+
+    n_jobs : int, optional (default=1)
+        The number of parallel jobs to run for neighbors search.
+        If ``-1``, then the number of jobs is set to the number of CPU cores.
+
+    Returns
+    -------
+    core_sample_indices_ : array, shape (n_core_samples,)
+        The indices of the core samples.
+
+    labels_ : array, shape (n_samples,)
+        The estimated labels.
+
+    References
+    ----------
+    Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander.
+    "OPTICS: ordering points to identify the clustering structure." ACM SIGMOD
+    Record 28, no. 2 (1999): 49-60.
+    """
+
+    clust = OPTICS(min_samples, max_bound, metric, p, metric_params,
+                   maxima_ratio, rejection_ratio,
+                   similarity_threshold, significant_min,
+                   min_cluster_size_ratio, min_maxima_ratio,
+                   algorithm, leaf_size, n_jobs)
+    clust.fit(X)
+    return clust.core_sample_indices_, clust.labels_
+
+
+class OPTICS(BaseEstimator, ClusterMixin):
+    """Estimate clustering structure from vector array
+
+    OPTICS: Ordering Points To Identify the Clustering Structure
+    Equivalent to DBSCAN, finds core sample of high density and expands
+    clusters from them. Unlike DBSCAN, keeps cluster hierarchy for a variable
+    neighborhood radius. Optimized for usage on large point datasets.
+
+    Parameters
+    ----------
+    min_samples : int
+        The number of samples in a neighborhood for a point to be considered
+        as a core point.
+
+    max_bound : float, optional
+        The maximum distance between two samples for them to be considered
+        as in the same neighborhood. This is also the largest object size
+        expected within the dataset. Default value of "np.inf" will identify
+        clusters across all scales; reducing `max_bound` will result in
+        shorter run times.
+
+    metric : string or callable, optional
+        The distance metric to use for neighborhood lookups. Default is
+        "minkowski". Other options include "euclidean", "manhattan",
+        "chebyshev", "haversine", "seuclidean", "hamming", "canberra",
+        and "braycurtis". The "wminkowski" and "mahalanobis" metrics are
+        also valid with an additional argument.
+
+    p : integer, optional (default=2)
+        Parameter for the Minkowski metric from
+        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is
+        equivalent to using manhattan_distance (l1), and euclidean_distance
+        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
+
+    metric_params : dict, optional (default=None)
+        Additional keyword arguments for the metric function.
+
+    maxima_ratio : float, optional
+        The maximum ratio we allow of average height of clusters on the
+        right and left to the local maxima in question. The higher the
+        ratio, the more generous the algorithm is to preserving local
+        minima, and the more cuts the resulting tree will have.
+
+    rejection_ratio : float, optional
+        Adjusts the fitness of the clustering. When the maxima_ratio is
+        exceeded, determine which of the clusters to the left and right to
+        reject based on rejection_ratio. Higher values will result in points
+        being more readily classified as noise; conversely, lower values will
+        result in more points being clustered.
+
+    similarity_threshold : float, optional
+        Used to check if nodes can be moved up one level, that is, if the
+        new cluster created is too "similar" to its parent, given the
+        similarity threshold. Similarity can be determined by 1) the size
+        of the new cluster relative to the size of the parent node or
+        2) the average of the reachability values of the new cluster
+        relative to the average of the reachability values of the parent
+        node. A lower value for the similarity threshold means less levels
+        in the tree.
+
+    significant_min : float, optional
+        Sets a lower threshold on how small a significant maxima can be.
+
+    min_cluster_size_ratio : float, optional
+        Minimum percentage of dataset expected for cluster membership.
+
+    min_maxima_ratio : float, optional
+        Used to determine neighborhood size for minimum cluster membership.
+
+    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional
+        Algorithm used to compute the nearest neighbors:
+        - 'ball_tree' will use :class:`BallTree`
+        - 'kd_tree' will use :class:`KDTree`
+        - 'brute' will use a brute-force search.
+        - 'auto' will attempt to decide the most appropriate algorithm
+          based on the values passed to :meth:`fit` method.
+
+        Note: fitting on sparse input will override the setting of
+        this parameter, using brute force.
+
+    leaf_size : int, optional (default=30)
+        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can
+        affect the speed of the construction and query, as well as the memory
+        required to store the tree. The optimal value depends on the
+        nature of the problem.
+
+    n_jobs : int, optional (default=1)
+        The number of parallel jobs to run for neighbors search.
+        If ``-1``, then the number of jobs is set to the number of CPU cores.
+
+    Attributes
+    ----------
+    core_sample_indices_ : array, shape (n_core_samples,)
+        Indices of core samples.
+
+    labels_ : array, shape (n_samples,)
+        Cluster labels for each point in the dataset given to fit().
+        Noisy samples are given the label -1.
+
+    reachability_ : array, shape (n_samples,)
+        Reachability distances per sample.
+
+    ordering_ : array, shape (n_samples,)
+        The cluster ordered list of sample indices
+
+    core_distances_ : array, shape (n_samples,)
+        Distance at which each sample becomes a core point.
+        Points which will never be core have a distance of inf.
+
+    See also
+    --------
+
+    DBSCAN
+        CPU optimized algorithm that clusters at specified neighborhood
+        radius (eps).
+    HDBSCAN
+        Related clustering algorithm that calculates the minimum spanning tree
+        across mutual reachability space.
+
+    References
+    ----------
+    Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander.
+    "OPTICS: ordering points to identify the clustering structure." ACM SIGMOD
+    Record 28, no. 2 (1999): 49-60.
+    """
+
+    def __init__(self, min_samples=5, max_bound=np.inf, metric='euclidean',
+                 p=2, metric_params=None, maxima_ratio=.75,
+                 rejection_ratio=.7, similarity_threshold=0.4,
+                 significant_min=.003, min_cluster_size_ratio=.005,
+                 min_maxima_ratio=0.001, algorithm='ball_tree',
+                 leaf_size=30, n_jobs=1):
+
+        self.max_bound = max_bound
+        self.min_samples = min_samples
+        self.maxima_ratio = maxima_ratio
+        self.rejection_ratio = rejection_ratio
+        self.similarity_threshold = similarity_threshold
+        self.significant_min = significant_min
+        self.min_cluster_size_ratio = min_cluster_size_ratio
+        self.min_maxima_ratio = min_maxima_ratio
+        self.algorithm = algorithm
+        self.metric = metric
+        self.metric_params = metric_params
+        self.p = p
+        self.leaf_size = leaf_size
+        self.n_jobs = n_jobs
+
+    def fit(self, X, y=None):
+        """Perform OPTICS clustering
+
+        Extracts an ordered list of points and reachability distances, and
+        performs initial clustering using `max_bound` distance specified at
+        OPTICS object instantiation.
+
+        Parameters
+        ----------
+        X : array, shape (n_samples, n_features)
+            The data.
+
+        y : ignored
+
+        Returns
+        -------
+        self : instance of OPTICS
+            The instance.
+        """
+        X = check_array(X, dtype=np.float)
+
+        n_samples = len(X)
+        # Start all points as 'unprocessed' ##
+        self._processed = np.zeros((n_samples, 1), dtype=bool)
+        self.reachability_ = np.empty(n_samples)
+        self.reachability_.fill(np.inf)
+        self.core_distances_ = np.empty(n_samples)
+        self.core_distances_.fill(np.nan)
+        # Start all points as noise ##
+        self.labels_ = -np.ones(n_samples, dtype=int)
+        self.ordering_ = []
+
+        # Check for valid n_samples relative to min_samples
+        if self.min_samples > n_samples:
+            raise ValueError("Number of training samples (n_samples=%d) must "
+                             "be greater than min_samples (min_samples=%d) "
+                             "used for clustering." %
+                             (n_samples, self.min_samples))
+
+        nbrs = NearestNeighbors(n_neighbors=self.min_samples,
+                                algorithm=self.algorithm,
+                                leaf_size=self.leaf_size, metric=self.metric,
+                                metric_params=self.metric_params, p=self.p,
+                                n_jobs=self.n_jobs)
+
+        nbrs.fit(X)
+        self.core_distances_[:] = nbrs.kneighbors(X,
+                                                  self.min_samples)[0][:, -1]
+
+        # Main OPTICS loop. Not parallelizable. The order that entries are
+        # written to the 'ordering_' list is important!
+        for point in range(n_samples):
+            if not self._processed[point]:
+                self._expand_cluster_order(point, X, nbrs)
+
+        indices_, self.labels_ = _extract_optics(self.ordering_,
+                                                 self.reachability_,
+                                                 self.maxima_ratio,
+                                                 self.rejection_ratio,
+                                                 self.similarity_threshold,
+                                                 self.significant_min,
+                                                 self.min_cluster_size_ratio,
+                                                 self.min_maxima_ratio)
+        self.core_sample_indices_ = indices_
+        self.n_clusters_ = np.max(self.labels_)
+        return self
+
+    # OPTICS helper functions; these should not be public #
+
+    def _expand_cluster_order(self, point, X, nbrs):
+        # As above, not parallelizable. Parallelizing would allow items in
+        # the 'unprocessed' list to switch to 'processed'
+        if self.core_distances_[point] <= self.max_bound:
+            while not self._processed[point]:
+                self._processed[point] = True
+                self.ordering_.append(point)
+                point = self._set_reach_dist(point, X, nbrs)
+        else:  # For very noisy points
+            self.ordering_.append(point)
+            self._processed[point] = True
+
+    def _set_reach_dist(self, point_index, X, nbrs):
+        P = np.array(X[point_index]).reshape(1, -1)
+        indices = nbrs.radius_neighbors(P, radius=self.max_bound,
+                                        return_distance=False)[0]
+
+        # Getting indices of neighbors that have not been processed
+        unproc = np.compress((~np.take(self._processed, indices)).ravel(),
+                             indices, axis=0)
+        # Keep n_jobs = 1 in the following lines...please
+        if len(unproc) > 0:
+            dists = pairwise_distances(P, np.take(X, unproc, axis=0),
+                                       self.metric, n_jobs=1).ravel()
+
+            rdists = np.maximum(dists, self.core_distances_[point_index])
+            new_reach = np.minimum(np.take(self.reachability_, unproc), rdists)
+            self.reachability_[unproc] = new_reach
+
+        # Checks to see if everything is already processed;
+        # if so, return control to main loop
+        if unproc.size > 0:
+            # Define return order based on reachability distance
+            return(unproc[quick_scan(np.take(self.reachability_, unproc),
+                                     dists)])
+        else:
+            return point_index
+
+    def extract_dbscan(self, eps):
+        """Performs DBSCAN extraction for an arbitrary epsilon.
+
+        Extraction runs in linear time. Note that if the `max_bound` OPTICS
+        parameter was set to < inf for extracting reachability and ordering
+        arrays, DBSCAN extractions will be unstable for `eps` values close to
+        `max_bound`. Setting `eps` < (`max_bound` / 5.0) will guarantee
+        extraction parity with DBSCAN.
+
+        Parameters
+        ----------
+        eps : float or int, required
+            DBSCAN `eps` parameter. Must be set to < `max_bound`. Equivalence
+            with DBSCAN algorithm is achieved if `eps` is < (`max_bound` / 5)
+
+        Returns
+        -------
+        core_sample_indices_ : array, shape (n_core_samples,)
+            The indices of the core samples.
+
+        labels_ : array, shape (n_samples,)
+            The estimated labels.
+        """
+        check_is_fitted(self, 'reachability_')
+
+        if eps > self.max_bound:
+            raise ValueError('Specify an epsilon smaller than %s. Got %s.'
+                             % (self.max_bound, eps))
+
+        if eps * 5.0 > (self.max_bound * 1.05):
+            warnings.warn(
+                "Warning, max_bound (%s) is close to eps (%s): "
+                "Output may be unstable." % (self.max_bound, eps),
+                RuntimeWarning, stacklevel=2)
+        # Stability warning is documented in _extract_dbscan method...
+
+        return _extract_dbscan(self.ordering_, self.core_distances_,
+                               self.reachability_, eps)
+
+
+def _extract_dbscan(ordering, core_distances, reachability, eps):
+    """Performs DBSCAN extraction for an arbitrary epsilon (`eps`).
+
+    Parameters
+    ----------
+    ordering : array, shape (n_samples,)
+        OPTICS ordered point indices (`ordering_`)
+    core_distances : array, shape (n_samples,)
+        Distances at which points become core (`core_distances_`)
+    reachability : array, shape (n_samples,)
+        Reachability distances calculated by OPTICS (`reachability_`)
+    eps : float or int
+        DBSCAN `eps` parameter
+
+    Returns
+    -------
+    core_sample_indices_ : array, shape (n_core_samples,)
+        The indices of the core samples.
+
+    labels_ : array, shape (n_samples,)
+        The estimated labels.
+    """
+
+    n_samples = len(core_distances)
+    is_core = np.zeros(n_samples, dtype=bool)
+    labels = np.zeros(n_samples, dtype=int)
+
+    far_reach = reachability > eps
+    near_core = core_distances <= eps
+    labels[ordering] = np.cumsum(far_reach[ordering] & near_core[ordering]) - 1
+    labels[far_reach & ~near_core] = -1
+    is_core[near_core] = True
+    return np.arange(n_samples)[is_core], labels
+
+
+def _extract_optics(ordering, reachability, maxima_ratio=.75,
+                    rejection_ratio=.7, similarity_threshold=0.4,
+                    significant_min=.003, min_cluster_size_ratio=.005,
+                    min_maxima_ratio=0.001):
+    """Performs automatic cluster extraction for variable density data.
+
+    Parameters
+    ----------
+    ordering : array, shape (n_samples,)
+        OPTICS ordered point indices (`ordering_`)
+
+    reachability : array, shape (n_samples,)
+        Reachability distances calculated by OPTICS (`reachability_`)
+
+    maxima_ratio : float, optional
+        The maximum ratio we allow of average height of clusters on the
+        right and left to the local maxima in question. The higher the
+        ratio, the more generous the algorithm is to preserving local
+        minima, and the more cuts the resulting tree will have.
+
+    rejection_ratio : float, optional
+        Adjusts the fitness of the clustering. When the maxima_ratio is
+        exceeded, determine which of the clusters to the left and right to
+        reject based on rejection_ratio. Higher values will result in points
+        being more readily classified as noise; conversely, lower values will
+        result in more points being clustered.
+
+    similarity_threshold : float, optional
+        Used to check if nodes can be moved up one level, that is, if the
+        new cluster created is too "similar" to its parent, given the
+        similarity threshold. Similarity can be determined by 1) the size
+        of the new cluster relative to the size of the parent node or
+        2) the average of the reachability values of the new cluster
+        relative to the average of the reachability values of the parent
+        node. A lower value for the similarity threshold means less levels
+        in the tree.
+
+    significant_min : float, optional
+        Sets a lower threshold on how small a significant maxima can be.
+
+    min_cluster_size_ratio : float, optional
+        Minimum percentage of dataset expected for cluster membership.
+
+    min_maxima_ratio : float, optional
+        Used to determine neighborhood size for minimum cluster membership.
+
+    Returns
+    -------
+    core_sample_indices_ : array, shape (n_core_samples,)
+        The indices of the core samples.
+
+    labels_ : array, shape (n_samples,)
+        The estimated labels.
+    """
+
+    # Extraction wrapper
+    reachability = reachability / np.max(reachability[1:])
+    reachability_plot = reachability[ordering].tolist()
+    root_node = _automatic_cluster(reachability_plot, ordering,
+                                   maxima_ratio, rejection_ratio,
+                                   similarity_threshold, significant_min,
+                                   min_cluster_size_ratio, min_maxima_ratio)
+    leaves = _get_leaves(root_node, [])
+    # Start cluster id's at 0
+    clustid = 0
+    n_samples = len(reachability)
+    is_core = np.zeros(n_samples, dtype=bool)
+    labels = -np.ones(n_samples, dtype=int)
+    # Start all points as non-core noise
+    for leaf in leaves:
+        index = ordering[leaf.start:leaf.end]
+        labels[index] = clustid
+        is_core[index] = 1
+        clustid += 1
+    return np.arange(n_samples)[is_core], labels
+
+
+def _automatic_cluster(reachability_plot, ordering,
+                       maxima_ratio, rejection_ratio,
+                       similarity_threshold, significant_min,
+                       min_cluster_size_ratio, min_maxima_ratio):
+    """Converts reachability plot to cluster tree and returns root node.
+
+    Parameters
+    ----------
+
+    reachability_plot : list, required
+        Reachability distances ordered by OPTICS ordering index.
+
+    """
+
+    min_neighborhood_size = 2
+    min_cluster_size = int(min_cluster_size_ratio * len(ordering))
+    neighborhood_size = int(min_maxima_ratio * len(ordering))
+
+    # Should this check for < min_samples? Should this be public?
+    if min_cluster_size < 5:
+        min_cluster_size = 5
+
+    # Again, should this check < min_samples, should the parameter be public?
+    if neighborhood_size < min_neighborhood_size:
+        neighborhood_size = min_neighborhood_size
+
+    local_maxima_points = _find_local_maxima(reachability_plot,
+                                             neighborhood_size)
+    root_node = _TreeNode(ordering, 0, len(ordering), None)
+    _cluster_tree(root_node, None, local_maxima_points,
+                  reachability_plot, ordering, min_cluster_size,
+                  maxima_ratio, rejection_ratio,
+                  similarity_threshold, significant_min)
+
+    return root_node
+
+
+class _TreeNode(object):
+    # automatic cluster helper classes and functions
+    def __init__(self, points, start, end, parent_node):
+        self.points = points
+        self.start = start
+        self.end = end
+        self.parent_node = parent_node
+        self.children = []
+        self.split_point = -1
+
+    def assign_split_point(self, split_point):
+        self.split_point = split_point
+
+    def add_child(self, child):
+        self.children.append(child)
+
+
+def _is_local_maxima(index, reachability_plot, neighborhood_size):
+    right_idx = slice(index + 1, index + neighborhood_size + 1)
+    left_idx = slice(max(1, index - neighborhood_size - 1), index)
+    return (np.all(reachability_plot[index] >= reachability_plot[left_idx]) and
+            np.all(reachability_plot[index] >= reachability_plot[right_idx]))
+
+
+def _find_local_maxima(reachability_plot, neighborhood_size):
+    local_maxima_points = {}
+    # 1st and last points on Reachability Plot are not taken
+    # as local maxima points
+    for i in range(1, len(reachability_plot) - 1):
+        # if the point is a local maxima on the reachability plot with
+        # regard to neighborhood_size, insert it into priority queue and
+        # maxima list
+        if (reachability_plot[i] > reachability_plot[i - 1] and
+            reachability_plot[i] >= reachability_plot[i + 1] and
+            _is_local_maxima(i, np.array(reachability_plot),
+                             neighborhood_size) == 1):
+            local_maxima_points[i] = reachability_plot[i]
+
+    return sorted(local_maxima_points,
+                  key=local_maxima_points.__getitem__, reverse=True)
+
+
+def _cluster_tree(node, parent_node, local_maxima_points,
+                  reachability_plot, reachability_ordering,
+                  min_cluster_size, maxima_ratio, rejection_ratio,
+                  similarity_threshold, significant_min):
+    """Recursively builds cluster tree to hold hierarchical cluster structure
+
+    node is a node or the root of the tree in the first call
+    parent_node is parent node of N or None if node is root of the tree
+    local_maxima_points is list of local maxima points sorted in
+    descending order of reachability
+    """
+
+    if len(local_maxima_points) == 0:
+        return  # parent_node is a leaf
+
+    # take largest local maximum as possible separation between clusters
+    s = local_maxima_points[0]
+    node.assign_split_point(s)
+    local_maxima_points = local_maxima_points[1:]
+
+    # create two new nodes and add to list of nodes
+    node_1 = _TreeNode(reachability_ordering[node.start:s],
+                       node.start, s, node)
+    node_2 = _TreeNode(reachability_ordering[s + 1:node.end],
+                       s + 1, node.end, node)
+    local_max_1 = []
+    local_max_2 = []
+
+    for i in local_maxima_points:
+        if i < s:
+            local_max_1.append(i)
+        if i > s:
+            local_max_2.append(i)
+
+    node_list = []
+    node_list.append((node_1, local_max_1))
+    node_list.append((node_2, local_max_2))
+
+    if reachability_plot[s] < significant_min:
+        node.assign_split_point(-1)
+        # if split_point is not significant, ignore this split and continue
+        _cluster_tree(node, parent_node, local_maxima_points,
+                      reachability_plot, reachability_ordering,
+                      min_cluster_size, maxima_ratio, rejection_ratio,
+                      similarity_threshold, significant_min)
+        return
+
+    # only check a certain ratio of points in the child
+    # nodes formed to the left and right of the maxima
+    # ...should check_ratio be a user settable parameter?
+    check_ratio = .8
+    check_value_1 = int(np.round(check_ratio * len(node_1.points)))
+    check_value_2 = int(np.round(check_ratio * len(node_2.points)))
+    avg_reach1 = np.mean(reachability_plot[(node_1.end -
+                                            check_value_1):node_1.end])
+    avg_reach2 = np.mean(reachability_plot[node_2.start:(node_2.start
+                                                         + check_value_2)])
+
+    if ((avg_reach1 / reachability_plot[s]) > maxima_ratio or
+            (avg_reach2 / reachability_plot[s]) > maxima_ratio):
+
+        if (avg_reach1 / reachability_plot[s]) < rejection_ratio:
+            # reject node 2
+            node_list.remove((node_2, local_max_2))
+        if (avg_reach2 / reachability_plot[s]) < rejection_ratio:
+            # reject node 1
+            node_list.remove((node_1, local_max_1))
+        if ((avg_reach1 / reachability_plot[s]) >= rejection_ratio and
+                (avg_reach2 / reachability_plot[s]) >= rejection_ratio):
+            # since split_point is not significant,
+            # ignore this split and continue (reject both child nodes)
+            node.assign_split_point(-1)
+            _cluster_tree(node, parent_node, local_maxima_points,
+                          reachability_plot, reachability_ordering,
+                          min_cluster_size, maxima_ratio, rejection_ratio,
+                          similarity_threshold, significant_min)
+            return
+
+    # remove clusters that are too small
+    if (len(node_1.points) < min_cluster_size and
+            node_list.count((node_1, local_max_1)) > 0):
+        # cluster 1 is too small
+        node_list.remove((node_1, local_max_1))
+    if (len(node_2.points) < min_cluster_size and
+            node_list.count((node_2, local_max_2)) > 0):
+        # cluster 2 is too small
+        node_list.remove((node_2, local_max_2))
+    if not node_list:
+        # parent_node will be a leaf
+        node.assign_split_point(-1)
+        return
+
+    # Check if nodes can be moved up one level - the new cluster created
+    # is too "similar" to its parent, given the similarity threshold.
+    bypass_node = 0
+    if parent_node is not None:
+        if ((node.end - node.start) / (parent_node.end - parent_node.start) >
+                similarity_threshold):
+
+            parent_node.children.remove(node)
+            bypass_node = 1
+
+    for nl in node_list:
+        if bypass_node == 1:
+            parent_node.add_child(nl[0])
+            _cluster_tree(nl[0], parent_node, nl[1],
+                          reachability_plot, reachability_ordering,
+                          min_cluster_size, maxima_ratio, rejection_ratio,
+                          similarity_threshold, significant_min)
+        else:
+            node.add_child(nl[0])
+            _cluster_tree(nl[0], node, nl[1], reachability_plot,
+                          reachability_ordering, min_cluster_size,
+                          maxima_ratio, rejection_ratio,
+                          similarity_threshold, significant_min)
+
+
+def _get_leaves(node, arr):
+    if node is not None:
+        if node.split_point == -1:
+            arr.append(node)
+        for n in node.children:
+            _get_leaves(n, arr)
+    return arr
diff --git a/sklearn/cluster/setup.py b/sklearn/cluster/setup.py
index 99c4dcd6177b..5f3424eea8d5 100644
--- a/sklearn/cluster/setup.py
+++ b/sklearn/cluster/setup.py
@@ -23,6 +23,10 @@ def configuration(parent_package='', top_path=None):
                          sources=['_dbscan_inner.pyx'],
                          include_dirs=[numpy.get_include()],
                          language="c++")
+    config.add_extension('_optics_inner',
+                         sources=['_optics_inner.pyx'],
+                         include_dirs=[numpy.get_include()],
+                         libraries=libraries)
 
     config.add_extension('_hierarchical',
                          sources=['_hierarchical.pyx'],
diff --git a/sklearn/cluster/tests/test_feature_agglomeration.py b/sklearn/cluster/tests/test_feature_agglomeration.py
index 98d5dfc4b72c..5c992109ffab 100644
--- a/sklearn/cluster/tests/test_feature_agglomeration.py
+++ b/sklearn/cluster/tests/test_feature_agglomeration.py
@@ -4,7 +4,7 @@
 # Authors: Sergul Aydore 2017
 import numpy as np
 from sklearn.cluster import FeatureAgglomeration
-from sklearn.utils.testing import assert_true
+from sklearn.utils.testing import assert_true, assert_no_warnings
 from sklearn.utils.testing import assert_array_almost_equal
 
 
@@ -16,8 +16,8 @@ def test_feature_agglomeration():
                                       pooling_func=np.mean)
     agglo_median = FeatureAgglomeration(n_clusters=n_clusters,
                                         pooling_func=np.median)
-    agglo_mean.fit(X)
-    agglo_median.fit(X)
+    assert_no_warnings(agglo_mean.fit, X)
+    assert_no_warnings(agglo_median.fit, X)
     assert_true(np.size(np.unique(agglo_mean.labels_)) == n_clusters)
     assert_true(np.size(np.unique(agglo_median.labels_)) == n_clusters)
     assert_true(np.size(agglo_mean.labels_) == X.shape[1])
diff --git a/sklearn/cluster/tests/test_hierarchical.py b/sklearn/cluster/tests/test_hierarchical.py
index b3056b95d225..9f79e2e759d3 100644
--- a/sklearn/cluster/tests/test_hierarchical.py
+++ b/sklearn/cluster/tests/test_hierarchical.py
@@ -7,6 +7,7 @@
 # License: BSD 3 clause
 from tempfile import mkdtemp
 import shutil
+import pytest
 from functools import partial
 
 import numpy as np
@@ -142,6 +143,8 @@ def test_agglomerative_clustering_wrong_arg_memory():
     assert_raises(ValueError, clustering.fit, X)
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of nmi will "
+                            "change in version 0.22")
 def test_agglomerative_clustering():
     # Check that we obtain the correct number of clusters with
     # agglomerative clustering.
@@ -250,6 +253,8 @@ def test_ward_agglomeration():
     assert_raises(ValueError, agglo.fit, X[:0])
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of nmi will "
+                            "change in version 0.22")
 def test_single_linkage_clustering():
     # Check that we get the correct result in two emblematic cases
     moons, moon_labels = make_moons(noise=0.05, random_state=42)
@@ -311,6 +316,8 @@ def test_scikit_vs_scipy():
     assert_raises(ValueError, _hc_cut, n_leaves + 1, children, n_leaves)
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of nmi will "
+                            "change in version 0.22")
 def test_identical_points():
     # Ensure identical points are handled correctly when using mst with
     # a sparse connectivity matrix
diff --git a/sklearn/cluster/tests/test_k_means.py b/sklearn/cluster/tests/test_k_means.py
index 485b120b54ac..c6bac2bb1da8 100644
--- a/sklearn/cluster/tests/test_k_means.py
+++ b/sklearn/cluster/tests/test_k_means.py
@@ -917,7 +917,8 @@ def _sort_centers(centers):
 def test_weighted_vs_repeated():
     # a sample weight of N should yield the same result as an N-fold
     # repetition of the sample
-    sample_weight = np.random.randint(1, 5, size=n_samples)
+    rng = np.random.RandomState(0)
+    sample_weight = rng.randint(1, 5, size=n_samples)
     X_repeat = np.repeat(X, sample_weight, axis=0)
     estimators = [KMeans(init="k-means++", n_clusters=n_clusters,
                          random_state=42),
diff --git a/sklearn/cluster/tests/test_optics.py b/sklearn/cluster/tests/test_optics.py
new file mode 100755
index 000000000000..597785083cfe
--- /dev/null
+++ b/sklearn/cluster/tests/test_optics.py
@@ -0,0 +1,408 @@
+# Authors: Shane Grigsby <refuge@rocktalus.com>
+#          Amy X. Zhang <axz@mit.edu>
+# License: BSD 3 clause
+
+import numpy as np
+import pytest
+
+from sklearn.datasets.samples_generator import make_blobs
+from sklearn.cluster.optics_ import OPTICS
+from sklearn.cluster.optics_ import _TreeNode, _cluster_tree
+from sklearn.cluster.optics_ import _find_local_maxima
+from sklearn.metrics.cluster import contingency_matrix
+from sklearn.cluster.dbscan_ import DBSCAN
+from sklearn.utils.testing import assert_equal, assert_warns
+from sklearn.utils.testing import assert_array_almost_equal
+from sklearn.utils.testing import assert_array_equal
+from sklearn.utils.testing import assert_raise_message
+
+from sklearn.cluster.tests.common import generate_clustered_data
+
+
+def test_correct_number_of_clusters():
+    # in 'auto' mode
+
+    n_clusters = 3
+    X = generate_clustered_data(n_clusters=n_clusters)
+    # Parameters chosen specifically for this task.
+    # Compute OPTICS
+    clust = OPTICS(max_bound=5.0 * 6.0, min_samples=4, metric='euclidean')
+    clust.fit(X)
+    # number of clusters, ignoring noise if present
+    n_clusters_1 = len(set(clust.labels_)) - int(-1 in clust.labels_)
+    assert_equal(n_clusters_1, n_clusters)
+
+
+def test_minimum_number_of_sample_check():
+    # test that we check a minimum number of samples
+    msg = ("Number of training samples (n_samples=1) must be greater than "
+           "min_samples (min_samples=10) used for clustering.")
+
+    # Compute OPTICS
+    X = [[1, 1]]
+    clust = OPTICS(max_bound=5.0 * 0.3, min_samples=10)
+
+    # Run the fit
+    assert_raise_message(ValueError, msg, clust.fit, X)
+
+
+def test_empty_extract():
+    # Test extract where fit() has not yet been run.
+    msg = ("This OPTICS instance is not fitted yet. Call 'fit' with "
+           "appropriate arguments before using this method.")
+    clust = OPTICS(max_bound=5.0 * 0.3, min_samples=10)
+    assert_raise_message(ValueError, msg, clust.extract_dbscan, 0.01)
+
+
+def test_bad_extract():
+    # Test an extraction of eps too close to original eps
+    msg = "Specify an epsilon smaller than 0.015. Got 0.3."
+    centers = [[1, 1], [-1, -1], [1, -1]]
+    X, labels_true = make_blobs(n_samples=750, centers=centers,
+                                cluster_std=0.4, random_state=0)
+
+    # Compute OPTICS
+    clust = OPTICS(max_bound=5.0 * 0.003, min_samples=10)
+    clust2 = clust.fit(X)
+    assert_raise_message(ValueError, msg, clust2.extract_dbscan, 0.3)
+
+
+def test_close_extract():
+    # Test extract where extraction eps is close to scaled epsPrime
+
+    centers = [[1, 1], [-1, -1], [1, -1]]
+    X, labels_true = make_blobs(n_samples=750, centers=centers,
+                                cluster_std=0.4, random_state=0)
+
+    # Compute OPTICS
+    clust = OPTICS(max_bound=1.0, min_samples=10)
+    clust3 = clust.fit(X)
+    # check warning when centers are passed
+    assert_warns(RuntimeWarning, clust3.extract_dbscan, .3)
+    # Cluster ordering starts at 0; max cluster label = 2 is 3 clusters
+    assert_equal(max(clust3.extract_dbscan(.3)[1]), 2)
+
+
+@pytest.mark.parametrize('eps', [0.1, .3, .5])
+@pytest.mark.parametrize('min_samples', [3, 10, 20])
+def test_dbscan_optics_parity(eps, min_samples):
+    # Test that OPTICS clustering labels are <= 5% difference of DBSCAN
+
+    centers = [[1, 1], [-1, -1], [1, -1]]
+    X, labels_true = make_blobs(n_samples=750, centers=centers,
+                                cluster_std=0.4, random_state=0)
+
+    # calculate optics with dbscan extract at 0.3 epsilon
+    op = OPTICS(min_samples=min_samples).fit(X)
+    core_optics, labels_optics = op.extract_dbscan(eps)
+
+    # calculate dbscan labels
+    db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
+
+    contingency = contingency_matrix(db.labels_, labels_optics)
+    agree = min(np.sum(np.max(contingency, axis=0)),
+                np.sum(np.max(contingency, axis=1)))
+    disagree = X.shape[0] - agree
+
+    # verify core_labels match
+    assert_array_equal(core_optics, db.core_sample_indices_)
+
+    non_core_count = len(labels_optics) - len(core_optics)
+    percent_mismatch = np.round((disagree - 1) / non_core_count, 2)
+
+    # verify label mismatch is <= 5% labels
+    assert percent_mismatch <= 0.05
+
+
+def test_auto_extract_hier():
+    # Tests auto extraction gets correct # of clusters with varying density
+
+    # Generate sample data
+    rng = np.random.RandomState(0)
+    n_points_per_cluster = 250
+
+    C1 = [-5, -2] + .8 * rng.randn(n_points_per_cluster, 2)
+    C2 = [4, -1] + .1 * rng.randn(n_points_per_cluster, 2)
+    C3 = [1, -2] + .2 * rng.randn(n_points_per_cluster, 2)
+    C4 = [-2, 3] + .3 * rng.randn(n_points_per_cluster, 2)
+    C5 = [3, -2] + 1.6 * rng.randn(n_points_per_cluster, 2)
+    C6 = [5, 6] + 2 * rng.randn(n_points_per_cluster, 2)
+    X = np.vstack((C1, C2, C3, C4, C5, C6))
+
+    # Compute OPTICS
+
+    clust = OPTICS(min_samples=9)
+
+    # Run the fit
+    clust.fit(X)
+
+    assert_equal(len(set(clust.labels_)), 6)
+
+
+@pytest.mark.parametrize("reach, n_child, members", [
+    (np.array([np.inf, 0.9, 0.9, 1.0, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,
+               0.9, 0.89, 0.88, 10, .9, .9, .9, .9]), 2, np.r_[0:6]),
+    (np.array([np.inf, 0.9, 0.9, 0.9, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,
+               0.9, 0.89, 0.88, 100, .9, .9, .9, .9]), 1, np.r_[0:15])])
+def test_cluster_sigmin_pruning(reach, n_child, members):
+    # Tests pruning left and right, insignificant splitpoints, empty nodelists
+    # Parameters chosen specifically for this task
+
+    # Case 1: Three pseudo clusters, 2 of which are too small
+    # Case 2: Two pseudo clusters, 1 of which are too small
+    # Normalize
+    reach = reach / np.max(reach[1:])
+
+    ordering = np.r_[0:20]
+    cluster_boundaries = _find_local_maxima(reach, 5)
+    root = _TreeNode(ordering, 0, 20, None)
+
+    # Build cluster tree inplace on root node
+    _cluster_tree(root, None, cluster_boundaries, reach, ordering,
+                  5, .75, .7, .4, .3)
+    assert_equal(root.split_point, cluster_boundaries[0])
+    assert_equal(n_child, len(root.children))
+    assert_array_equal(members, root.children[0].points)
+
+
+def test_reach_dists():
+    # Tests against known extraction array
+
+    rng = np.random.RandomState(0)
+    n_points_per_cluster = 250
+
+    C1 = [-5, -2] + .8 * rng.randn(n_points_per_cluster, 2)
+    C2 = [4, -1] + .1 * rng.randn(n_points_per_cluster, 2)
+    C3 = [1, -2] + .2 * rng.randn(n_points_per_cluster, 2)
+    C4 = [-2, 3] + .3 * rng.randn(n_points_per_cluster, 2)
+    C5 = [3, -2] + 1.6 * rng.randn(n_points_per_cluster, 2)
+    C6 = [5, 6] + 2 * rng.randn(n_points_per_cluster, 2)
+    X = np.vstack((C1, C2, C3, C4, C5, C6))
+
+    # Compute OPTICS
+
+    clust = OPTICS(min_samples=10, metric='minkowski')
+
+    # Run the fit
+    clust.fit(X)
+
+    # Expected values, matches 'RD' results from:
+    # http://chemometria.us.edu.pl/download/optics.py
+
+    v = [np.inf, 0.606005, 0.472013, 0.162951, 0.161000, 0.385547, 0.179715,
+         0.213507, 0.348468, 0.308146, 0.560519, 0.266072, 0.764384, 0.253164,
+         0.435716, 0.153696, 0.363924, 0.194267, 0.392313, 0.230589, 0.260023,
+         0.535348, 0.168173, 0.296736, 0.310583, 0.277204, 0.250654, 0.153696,
+         0.215533, 0.175710, 0.168173, 0.283134, 0.256372, 0.313931, 0.234164,
+         0.179715, 0.352957, 0.277052, 0.180986, 0.203819, 0.296022, 0.356691,
+         0.515438, 0.219208, 0.265821, 0.346630, 0.275305, 0.229332, 0.433715,
+         0.153696, 0.584960, 0.265821, 0.471049, 0.259154, 0.461707, 0.400021,
+         0.422748, 0.300699, 0.162951, 0.290504, 0.315199, 0.327130, 0.168864,
+         0.462826, 0.188862, 0.259784, 0.216788, 0.259784, 0.195673, 0.315199,
+         0.313931, 0.189128, 0.461707, 0.265821, 0.233594, 0.433715, 0.222260,
+         0.251734, 0.352957, 0.218134, 0.453792, 0.179715, 0.296736, 0.260023,
+         0.311162, 0.214549, 0.266072, 0.318744, 0.180986, 0.194267, 0.262882,
+         0.420186, 0.352957, 0.288388, 0.360962, 0.328054, 0.293849, 0.198271,
+         0.248772, 0.461707, 0.216788, 0.396450, 0.352957, 0.289448, 0.241311,
+         0.213742, 0.220516, 0.218134, 0.153696, 0.516090, 0.218134, 0.221507,
+         0.328647, 0.255933, 0.195766, 0.233594, 0.205270, 0.296736, 0.726008,
+         0.251991, 0.168173, 0.214027, 0.262882, 0.342089, 0.260023, 0.266072,
+         0.253164, 0.230345, 0.262882, 0.296022, 0.227047, 0.205974, 0.328647,
+         0.184315, 0.196304, 0.831185, 0.514116, 0.168173, 0.189784, 0.664306,
+         0.327130, 0.379139, 0.208932, 0.266140, 0.362751, 0.168173, 0.764384,
+         0.327130, 0.187107, 0.194267, 0.414196, 0.251734, 0.220516, 0.363924,
+         0.166886, 0.327130, 0.233594, 0.203819, 0.230589, 0.203819, 0.222972,
+         0.311526, 0.218134, 0.422748, 0.314870, 0.315199, 0.315199, 0.594179,
+         0.328647, 0.415638, 0.244046, 0.250654, 0.214027, 0.203819, 0.213507,
+         0.260023, 0.311442, 0.168173, 0.389432, 0.229343, 0.162951, 0.311162,
+         0.153696, 0.214027, 0.250654, 0.315199, 0.172484, 0.153696, 0.352957,
+         0.314870, 0.328647, 0.546505, 0.378118, 0.260023, 0.387830, 0.199714,
+         0.262882, 0.250654, 0.345254, 0.396450, 0.250654, 0.179715, 0.328647,
+         0.179715, 0.263104, 0.265821, 0.231714, 0.514116, 0.213507, 0.474255,
+         0.212568, 0.376760, 0.196304, 0.844945, 0.194267, 0.264914, 0.210320,
+         0.316374, 0.184315, 0.179715, 0.250654, 0.153696, 0.162951, 0.315199,
+         0.179965, 0.297876, 0.213507, 0.475420, 0.439372, 0.241311, 0.260927,
+         0.194267, 0.422748, 0.222260, 0.411940, 0.414733, 0.260923, 0.396450,
+         0.380672, 0.333277, 0.290504, 0.196014, 0.844945, 0.506989, 0.153696,
+         0.218134, 0.392313, 0.698970, 0.168173, 0.227047, 0.028856, 0.033243,
+         0.028506, 0.057003, 0.038335, 0.051183, 0.063923, 0.022363, 0.030677,
+         0.036155, 0.017748, 0.062887, 0.036041, 0.051183, 0.078198, 0.068936,
+         0.032418, 0.040634, 0.022188, 0.022112, 0.036858, 0.040199, 0.025549,
+         0.083975, 0.032209, 0.025525, 0.032952, 0.034727, 0.068887, 0.040634,
+         0.048985, 0.047450, 0.022422, 0.023767, 0.028092, 0.047450, 0.029202,
+         0.026105, 0.030542, 0.032250, 0.062887, 0.038335, 0.026753, 0.028092,
+         0.099391, 0.021430, 0.020496, 0.021430, 0.025043, 0.023868, 0.050069,
+         0.023868, 0.044140, 0.038032, 0.022112, 0.044140, 0.031528, 0.028092,
+         0.020065, 0.055926, 0.031508, 0.025549, 0.028062, 0.036155, 0.023694,
+         0.029423, 0.026105, 0.028497, 0.023868, 0.044808, 0.035783, 0.033090,
+         0.038779, 0.032146, 0.038421, 0.057328, 0.020065, 0.020065, 0.028858,
+         0.021337, 0.041226, 0.022507, 0.028506, 0.030257, 0.057912, 0.050876,
+         0.120109, 0.020065, 0.034727, 0.038596, 0.037008, 0.031609, 0.095640,
+         0.083728, 0.064906, 0.030677, 0.057003, 0.037008, 0.018705, 0.030677,
+         0.044140, 0.034727, 0.045226, 0.032146, 0.032418, 0.029332, 0.030104,
+         0.033243, 0.030104, 0.032209, 0.026405, 0.024092, 0.048441, 0.036379,
+         0.030745, 0.023454, 0.018705, 0.124248, 0.041114, 0.020700, 0.042633,
+         0.042455, 0.028497, 0.029202, 0.057859, 0.053157, 0.036155, 0.029534,
+         0.032209, 0.038032, 0.024617, 0.023071, 0.033090, 0.023694, 0.047277,
+         0.024617, 0.023868, 0.043916, 0.025549, 0.046198, 0.041086, 0.042003,
+         0.022507, 0.021430, 0.038779, 0.025043, 0.036379, 0.036326, 0.029421,
+         0.023454, 0.058683, 0.025549, 0.039904, 0.022507, 0.046198, 0.029332,
+         0.032209, 0.036155, 0.038421, 0.025043, 0.023694, 0.030104, 0.022363,
+         0.048544, 0.035180, 0.030677, 0.022112, 0.030677, 0.036678, 0.022507,
+         0.024092, 0.064231, 0.022507, 0.032209, 0.025043, 0.221152, 0.029840,
+         0.038779, 0.040634, 0.024617, 0.032418, 0.025525, 0.033298, 0.028092,
+         0.045754, 0.032209, 0.017748, 0.033090, 0.017748, 0.048931, 0.038689,
+         0.022112, 0.027129, 0.032952, 0.036858, 0.027704, 0.032146, 0.052191,
+         0.042633, 0.071638, 0.044140, 0.022507, 0.046647, 0.028270, 0.050525,
+         0.036772, 0.058995, 0.038335, 0.025185, 0.022507, 0.040293, 0.032418,
+         0.064308, 0.026023, 0.036155, 0.032418, 0.038032, 0.018705, 0.040293,
+         0.030104, 0.030845, 0.064906, 0.025525, 0.036155, 0.022507, 0.022363,
+         0.032418, 0.021430, 0.032209, 0.102770, 0.036960, 0.031062, 0.025043,
+         0.036155, 0.031609, 0.036379, 0.030845, 0.048985, 0.021848, 0.025549,
+         0.022507, 0.035783, 0.023698, 0.034422, 0.032418, 0.022507, 0.023868,
+         0.020065, 0.023694, 0.040634, 0.055633, 0.054549, 0.044662, 0.087660,
+         0.048066, 0.143571, 0.068669, 0.065049, 0.076927, 0.044359, 0.041577,
+         0.052364, 0.100317, 0.062146, 0.067578, 0.054549, 0.047239, 0.062809,
+         0.033917, 0.087660, 0.077113, 0.055633, 0.061854, 0.059756, 0.059537,
+         0.052364, 0.060347, 0.170251, 0.108492, 0.046370, 0.070684, 0.049589,
+         0.044662, 0.049013, 0.043303, 0.069573, 0.075044, 0.054354, 0.065072,
+         0.073135, 0.046126, 0.055569, 0.047239, 0.062146, 0.056093, 0.059986,
+         0.096182, 0.100317, 0.051649, 0.054354, 0.077420, 0.100317, 0.046370,
+         0.043303, 0.045845, 0.061422, 0.091580, 0.206234, 0.051405, 0.071684,
+         0.061574, 0.063666, 0.052692, 0.051649, 0.100124, 0.077909, 0.033917,
+         0.058680, 0.044359, 0.065498, 0.080214, 0.123231, 0.052957, 0.056582,
+         0.061540, 0.076794, 0.043303, 0.054884, 0.044359, 0.145249, 0.081741,
+         0.041577, 0.056093, 0.076799, 0.044359, 0.068483, 0.051649, 0.092275,
+         0.044359, 0.108492, 0.092275, 0.046126, 0.106422, 0.054354, 0.052957,
+         0.073329, 0.046126, 0.086402, 0.048194, 0.128569, 0.104042, 0.061854,
+         0.069573, 0.070035, 0.050346, 0.043303, 0.053576, 0.054549, 0.033917,
+         0.063666, 0.058680, 0.099130, 0.080198, 0.050118, 0.054549, 0.041577,
+         0.143571, 0.095965, 0.047643, 0.052364, 0.105168, 0.048685, 0.043303,
+         0.052814, 0.076927, 0.054549, 0.041577, 0.066657, 0.189930, 0.046370,
+         0.075044, 0.121331, 0.043303, 0.223897, 0.198621, 0.150328, 0.100317,
+         0.053576, 0.070708, 0.100898, 0.047239, 0.043613, 0.065049, 0.049146,
+         0.068669, 0.055569, 0.062124, 0.096408, 0.044662, 0.087660, 0.083012,
+         0.050118, 0.069573, 0.046126, 0.049146, 0.049146, 0.050808, 0.080198,
+         0.059986, 0.071974, 0.047239, 0.050808, 0.059986, 0.065850, 0.044863,
+         0.052814, 0.044359, 0.052364, 0.108492, 0.143571, 0.050926, 0.049146,
+         0.049146, 0.055569, 0.033917, 0.527659, 0.143547, 0.077113, 0.046126,
+         0.106422, 0.068669, 0.108492, 0.063666, 0.054549, 0.054884, 0.056907,
+         0.068669, 0.080198, 0.120887, 0.054549, 0.052692, 0.085801, 0.054884,
+         0.050808, 0.094595, 0.059545, 0.054354, 0.062124, 0.087660, 0.052814,
+         0.086715, 0.146253, 0.046370, 0.041577, 0.116083, 0.076927, 0.047239,
+         0.084375, 0.134652, 0.217969, 0.063559, 0.061540, 0.044662, 0.054354,
+         0.063666, 0.145466, 0.101700, 0.090491, 0.078536, 0.054884, 0.062124,
+         0.041577, 0.043303, 0.194473, 0.079780, 0.059704, 0.054780, 0.048194,
+         0.062146, 0.069573, 0.086898, 0.046675, 0.056258, 0.074141, 0.048066,
+         0.052957, 0.057982, 0.058966, 0.061048, 0.050885, 0.049146, 0.080993,
+         0.056093, 0.061854, 0.124025, 0.062146, 0.060906, 0.150328, 0.058680,
+         0.077420, 0.051800, 0.102359, 0.113301, 0.073096, 0.116715, 0.131476,
+         0.140601, 0.097667, 0.051800, 0.051800, 0.127964, 0.108870, 0.111926,
+         0.093532, 0.102390, 0.144266, 0.098271, 0.102541, 0.136497, 0.127964,
+         0.085569, 0.157863, 0.096739, 0.054008, 0.106219, 0.076838, 0.099076,
+         0.093532, 0.059861, 0.079975, 0.116715, 0.133625, 0.053641, 0.066110,
+         0.122302, 0.081313, 0.140601, 0.259889, 0.094437, 0.098271, 0.105776,
+         0.225742, 0.100097, 0.147592, 0.099076, 0.093128, 0.093532, 0.134946,
+         0.133625, 0.120869, 0.065932, 0.103395, 0.125172, 0.147842, 0.105278,
+         0.173584, 0.168241, 0.111524, 0.093532, 0.099076, 0.100426, 0.137132,
+         0.065356, 0.091108, 0.141202, 0.054008, 0.075298, 0.073717, 0.122817,
+         0.105278, 0.094437, 0.067080, 0.108530, 0.115467, 0.093532, 0.085569,
+         0.145180, 0.100426, 0.116715, 0.151726, 0.073096, 0.193781, 0.090614,
+         0.081162, 0.051800, 0.133625, 0.136497, 0.100670, 0.081313, 0.506893,
+         0.084567, 0.108530, 0.087353, 0.063184, 0.123639, 0.168333, 0.314422,
+         0.091108, 0.079975, 0.091108, 0.136497, 0.122302, 0.167297, 0.067080,
+         0.144266, 0.065932, 0.087667, 0.100426, 0.099460, 0.091108, 0.100637,
+         0.116715, 0.079975, 0.077977, 0.090340, 0.136723, 1.943026, 0.108870,
+         0.090340, 0.065932, 0.102245, 0.157863, 0.157863, 0.215574, 0.156830,
+         0.093532, 0.122302, 0.097667, 0.063000, 0.116715, 0.076838, 0.148372,
+         0.093532, 0.099076, 0.141202, 0.096505, 0.096739, 0.091108, 0.099076,
+         0.079975, 0.108870, 0.102390, 0.079975, 0.244121, 0.167071, 0.096739,
+         0.102390, 0.103395, 0.073096, 0.094887, 0.065932, 0.190667, 0.099460,
+         0.102390, 0.096739, 0.102390, 0.116715, 0.100637, 0.256554, 0.103395,
+         0.081313, 0.068962, 0.109645, 0.059364, 0.147842, 0.099460, 0.079262,
+         0.099460, 0.065932, 0.123687, 0.090614, 0.131352, 0.098271, 0.102541,
+         0.098983, 0.057224, 0.074797, 0.057224, 0.250559, 0.079975, 0.103395,
+         0.100426, 0.065932, 0.120661, 0.079262, 0.065932, 0.118665, 0.081162,
+         0.066283, 0.099076, 0.102359, 0.108530, 0.079975, 0.168333, 0.096739,
+         0.168333, 0.097008, 0.055288, 0.172411, 0.092801, 0.051800, 0.102541,
+         0.084567, 0.054008, 0.090991, 0.172411, 0.057224, 0.148396, 0.200965,
+         0.076838, 0.157863, 0.053535, 0.121919, 0.126609, 0.123890, 0.118081,
+         0.097008, 0.125311, 0.099460, 0.122302, 0.134946, 0.080975, 0.084567,
+         0.110093, 0.102245, 0.103395, 0.171601, 0.094887, 0.126240, 0.137742,
+         0.099954, 0.108530, 0.157863, 0.096739, 0.051800, 0.127964, 0.066110,
+         0.061021, 0.105147, 0.100426, 0.079975, 0.088187, 0.116421, 0.076838,
+         0.098271, 0.116715, 0.137656, 0.075298, 0.148396, 0.112166, 1.083905,
+         0.326598, 0.428987, 0.395963, 0.224541, 0.326598, 0.030677, 0.410454,
+         0.122771, 1.140305, 0.641074, 0.432159, 0.429335, 0.422908, 0.461926,
+         0.293083, 0.477078, 0.714856, 0.515861, 0.405418, 0.054354, 0.341177,
+         0.410008, 0.514245, 0.641074, 0.816459, 0.455115, 0.400707, 0.382240,
+         0.431832, 1.618970, 0.683953, 0.182992, 0.763699, 0.515861, 0.717145,
+         0.409629, 0.074134, 0.398273, 0.864974, 0.400707, 0.591403, 0.435354,
+         0.514245, 1.337152, 0.841077, 0.410008, 0.683953, 0.338649, 0.557595,
+         0.442092, 0.326598, 0.984189, 0.429608, 0.395963, 1.152055, 0.587222,
+         1.748492, 0.477078, 0.395459, 0.717145, 0.575811, 0.210115, 0.487785,
+         0.431832, 0.383852, 0.806708, 0.428987, 0.278405, 0.395963, 0.395459,
+         0.383852, 1.083905, 0.428510, 0.326598, 0.108492, 0.541644, 0.612110,
+         0.382240, 0.833511, 0.382240, 0.456628, 0.326598, 0.458880, 0.398273,
+         0.957748, 0.326598, 0.295049, 0.629646, 0.429765, 0.439942, 0.633617,
+         0.566297, 0.429335, 0.086507, 0.477078, 0.526753, 0.375240, 0.584436,
+         0.355776, 0.395963, 0.644924, 0.129793, 0.484880, 0.470001, 0.572306,
+         0.383852, 1.110081, 0.841077, 0.395963, 0.683953, 0.428745, 0.387752,
+         0.545299, 0.686537, 0.635219, 0.840499, 0.527659, 0.400707, 0.480982,
+         0.541644, 0.714856, 0.942673, 0.398273, 0.428987, 0.356781, 0.428510,
+         1.140961, 0.395963, 0.356781, 0.410454, 0.541644, 0.641074, 0.484778,
+         0.410008, 0.433108, 0.278405, 0.278405, 0.503141, 0.428745, 0.125103,
+         0.633617, 0.410454, 0.124025, 0.461926, 0.398273, 0.410008, 1.181303,
+         0.635219, 0.593537, 0.395963, 0.717145, 0.409629, 0.492595, 0.806708,
+         0.503820, 0.423834, 0.557595, 0.429335, 0.470749, 0.461926, 1.890036,
+         0.236343, 0.806708, 0.123561, 0.433744, 0.427348, 0.427348, 0.962234,
+         0.395963, 0.409629, 0.527659, 0.425727, 0.602549, 0.901331, 0.326598,
+         0.635949, 0.541644, 0.375240, 0.598969, 1.140961, 0.391998, 0.719443,
+         0.410008, 0.515861, 0.714856, 0.842273, 0.410454, 0.389377, 0.431078,
+         0.515861, 0.515861, 0.429335, 0.332495, 0.398273, 0.428987, 0.635219,
+         0.387752, 0.384289, 0.383852, 0.430504, 0.428510, 0.431832, 0.375240,
+         0.278405, 0.374102, 0.428745, 0.692878, 1.152055, 0.503820, 0.428745,
+         0.352868, 0.429335, 0.375240, 0.400707, 0.427348, 0.256183, 0.962234,
+         0.505376, 0.058995, 0.410454, 0.172880, 0.395963, 0.470749, 0.356781,
+         1.332700, 0.683953, 0.395963, 0.806708, 0.400707, 0.330982, 0.427731,
+         0.934845, 0.375240, 0.191534, 0.047239, 1.083905, 0.348794, 0.409708,
+         0.503820, 0.557595, 0.429335, 0.498780, 0.293083, 0.363069, 0.442092,
+         1.152055, 0.375240, 0.335677, 0.452443, 0.655156, 0.929928, 0.614869,
+         1.411031, 1.101132, 0.469030, 0.404976, 0.538209, 0.655828, 0.674748,
+         0.365182, 0.641612, 0.555434, 0.521651, 0.386679, 0.386679, 0.980304,
+         0.659111, 0.651366, 0.538209, 0.521651, 0.884780, 1.287829, 0.558322,
+         0.446161, 0.817970, 0.568499, 0.533507, 0.639746, 0.484404, 0.591751,
+         0.913016, 0.446161, 0.533907, 0.606885, 0.672320, 1.150642, 0.655828,
+         0.365182, 0.665088, 1.094242, 0.629401, 0.540676, 0.733026, 1.248265,
+         1.273499, 0.867854, 0.538656, 0.386679, 0.922273, 0.515686, 1.321022,
+         0.624444, 0.655828, 0.922273, 0.386679, 0.762191, 0.779432, 0.601851,
+         0.655156, 0.926213, 0.762191, 0.641612, 0.558322, 1.025370, 0.641067,
+         0.651366, 0.633434, 0.459580, 0.859221, 0.552291, 0.591751, 0.819965,
+         0.669977, 1.185083, 0.499338, 0.533907, 0.752871, 0.571388, 0.539772,
+         0.449182, 1.025370, 0.365182, 1.321022, 0.926213, 0.886360, 0.562272,
+         0.669977, 0.796046, 0.557598, 0.596776, 0.672336, 0.659111, 0.453719,
+         0.477716, 0.477716, 1.592069, 0.591751, 0.539772, 0.641612, 0.946254,
+         0.744165, 0.386679, 0.593825, 0.539772, 0.449182, 0.604273, 0.794951,
+         0.752871, 0.539772, 0.648732, 0.469030, 0.665088, 1.332700, 1.341388,
+         0.533507, 0.544212, 1.025992, 0.645967, 0.612945, 0.868492, 0.648732,
+         0.752300, 0.624444, 1.219748, 0.446161, 0.520818, 0.469044, 0.669977,
+         0.926213, 0.638752, 0.762191, 0.922273, 0.794951, 0.606885, 0.669977,
+         0.550113, 0.641067, 0.733026, 0.604273, 0.648732, 0.533507, 0.746506,
+         0.733026, 0.980683, 0.538209, 0.669977, 0.469030, 0.648732, 0.609190,
+         1.219748, 0.373113, 0.539772, 1.744047, 1.004716, 0.926213, 0.562272,
+         0.752871, 0.538656, 0.449182, 0.365182, 0.469030, 0.446161, 0.484404,
+         0.768592, 0.648732, 0.655156, 0.521651, 0.779432, 0.446161, 0.596776,
+         0.538209, 0.726740, 0.539772, 0.469030, 0.521651, 0.561950, 0.601851,
+         0.533907, 0.922273, 1.248265, 0.476800, 0.737990, 0.817970, 0.792127,
+         0.533907, 0.486038, 0.624444, 0.798241, 0.476800, 1.059373, 0.645967,
+         0.619940, 0.528726, 0.669977, 0.865406, 0.980683, 0.980683, 0.834671,
+         1.001353, 0.752871, 0.449182, 1.096520, 0.449182, 0.593825, 0.636558,
+         0.762191, 0.638591, 0.538209, 0.865406, 0.779432, 0.469044, 0.645967,
+         0.557598, 0.499338, 0.484404, 0.515686, 0.794951, 0.619456, 0.733026,
+         0.821769, 0.752300, 0.643302, 0.636558, 0.655156, 0.655156, 0.484404,
+         0.648732, 0.726023, 0.365182, 0.606885, 0.499338, 0.520818, 0.612945,
+         0.446161, 0.557598, 0.469044, 1.134650, 0.629401, 0.538656, 0.561950,
+         1.364861, 0.459580, 1.025370, 0.980304, 0.607592, 0.533907, 1.134650,
+         0.446161, 0.629962]
+
+    assert_array_almost_equal(clust.reachability_, np.array(v))
diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py
index aeedd4e3eaf4..7c5cd2750a4d 100644
--- a/sklearn/compose/_column_transformer.py
+++ b/sklearn/compose/_column_transformer.py
@@ -12,7 +12,7 @@
 from scipy import sparse
 
 from ..base import clone, TransformerMixin
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals import six
 from ..pipeline import (
     _fit_one_transformer, _fit_transform_one, _transform_one, _name_estimators)
@@ -61,22 +61,24 @@ class ColumnTransformer(_BaseComposition, TransformerMixin):
             strings 'drop' and 'passthrough' are accepted as well, to
             indicate to drop the columns or to pass them through untransformed,
             respectively.
-        column(s) : string or int, array-like of string or int, slice or \
-boolean mask array
+        column(s) : string or int, array-like of string or int, slice, \
+boolean mask array or callable
             Indexes the data on its second axis. Integers are interpreted as
             positional columns, while strings can reference DataFrame columns
             by name.  A scalar string or int should be used where
             ``transformer`` expects X to be a 1d array-like (vector),
             otherwise a 2d array will be passed to the transformer.
-
-    remainder : {'passthrough', 'drop'} or estimator, default 'passthrough'
-        By default, all remaining columns that were not specified in
-        `transformers` will be automatically passed through (default of
-        ``'passthrough'``). This subset of columns is concatenated with the
-        output of the transformers.
-        By using ``remainder='drop'``, only the specified columns in
-        `transformers` are transformed and combined in the output, and the
-        non-specified columns are dropped.
+            A callable is passed the input data `X` and can return any of the
+            above.
+
+    remainder : {'passthrough', 'drop'} or estimator, default 'drop'
+        By default, only the specified columns in `transformers` are
+        transformed and combined in the output, and the non-specified
+        columns are dropped. (default of ``'drop'``).
+        By specifying ``remainder='passthrough'``, all remaining columns that
+        were not specified in `transformers` will be automatically passed
+        through. This subset of columns is concatenated with the output of
+        the transformers.
         By setting ``remainder`` to be an estimator, the remaining
         non-specified columns will use the ``remainder`` estimator. The
         estimator must support `fit` and `transform`.
@@ -139,7 +141,7 @@ class ColumnTransformer(_BaseComposition, TransformerMixin):
 
     """
 
-    def __init__(self, transformers, remainder='passthrough', n_jobs=1,
+    def __init__(self, transformers, remainder='drop', n_jobs=1,
                  transformer_weights=None):
         self.transformers = transformers
         self.remainder = remainder
@@ -499,6 +501,7 @@ def _get_column(X, key):
     Supported key types (key):
     - scalar: output is 1D
     - lists, slices, boolean masks: output is 2D
+    - callable that returns any of the above
 
     Supported key data types:
 
@@ -510,6 +513,9 @@ def _get_column(X, key):
           can use any hashable object as key).
 
     """
+    if callable(key):
+        key = key(X)
+
     # check whether we have string column names or integers
     if _check_key_type(key, int):
         column_names = False
@@ -551,6 +557,9 @@ def _get_column_indices(X, key):
     """
     n_columns = X.shape[1]
 
+    if callable(key):
+        key = key(X)
+
     if _check_key_type(key, int):
         if isinstance(key, int):
             return [key]
@@ -649,8 +658,7 @@ def make_column_transformer(*transformers, **kwargs):
     ...     (['numerical_column'], StandardScaler()),
     ...     (['categorical_column'], OneHotEncoder()))
     ...     # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
-    ColumnTransformer(n_jobs=1, remainder='passthrough',
-             transformer_weights=None,
+    ColumnTransformer(n_jobs=1, remainder='drop', transformer_weights=None,
              transformers=[('standardscaler',
                             StandardScaler(...),
                             ['numerical_column']),
@@ -660,7 +668,7 @@ def make_column_transformer(*transformers, **kwargs):
 
     """
     n_jobs = kwargs.pop('n_jobs', 1)
-    remainder = kwargs.pop('remainder', 'passthrough')
+    remainder = kwargs.pop('remainder', 'drop')
     if kwargs:
         raise TypeError('Unknown keyword arguments: "{}"'
                         .format(list(kwargs.keys())[0]))
diff --git a/sklearn/compose/tests/test_column_transformer.py b/sklearn/compose/tests/test_column_transformer.py
index f1f7f9a24474..c1363992c0da 100644
--- a/sklearn/compose/tests/test_column_transformer.py
+++ b/sklearn/compose/tests/test_column_transformer.py
@@ -99,6 +99,12 @@ def test_column_transformer():
         assert_array_equal(ct.fit_transform(X_array), res)
         assert_array_equal(ct.fit(X_array).transform(X_array), res)
 
+        # callable that returns any of the allowed specifiers
+        ct = ColumnTransformer([('trans', Trans(), lambda x: selection)],
+                               remainder='drop')
+        assert_array_equal(ct.fit_transform(X_array), res)
+        assert_array_equal(ct.fit(X_array).transform(X_array), res)
+
     ct = ColumnTransformer([('trans1', Trans(), [0]),
                             ('trans2', Trans(), [1])])
     assert_array_equal(ct.fit_transform(X_array), X_res_both)
@@ -166,6 +172,12 @@ def test_column_transformer_dataframe():
         assert_array_equal(ct.fit_transform(X_df), res)
         assert_array_equal(ct.fit(X_df).transform(X_df), res)
 
+        # callable that returns any of the allowed specifiers
+        ct = ColumnTransformer([('trans', Trans(), lambda X: selection)],
+                               remainder='drop')
+        assert_array_equal(ct.fit_transform(X_df), res)
+        assert_array_equal(ct.fit(X_df).transform(X_df), res)
+
     ct = ColumnTransformer([('trans1', Trans(), ['first']),
                             ('trans2', Trans(), ['second'])])
     assert_array_equal(ct.fit_transform(X_df), X_res_both)
@@ -393,7 +405,7 @@ def test_column_transformer_get_set_params():
                             ('trans2', StandardScaler(), [1])])
 
     exp = {'n_jobs': 1,
-           'remainder': 'passthrough',
+           'remainder': 'drop',
            'trans1': ct.transformers[0][1],
            'trans1__copy': True,
            'trans1__with_mean': True,
@@ -412,7 +424,7 @@ def test_column_transformer_get_set_params():
 
     ct.set_params(trans1='passthrough')
     exp = {'n_jobs': 1,
-           'remainder': 'passthrough',
+           'remainder': 'drop',
            'trans1': 'passthrough',
            'trans2': ct.transformers[1][1],
            'trans2__copy': True,
@@ -480,7 +492,8 @@ def test_column_transformer_get_feature_names():
         NotImplementedError, 'get_feature_names is not yet supported',
         ct.get_feature_names)
 
-    ct = ColumnTransformer([('trans', DictVectorizer(), 0)])
+    ct = ColumnTransformer([('trans', DictVectorizer(), 0)],
+                           remainder='passthrough')
     ct.fit(X)
     assert_raise_message(
         NotImplementedError, 'get_feature_names is not yet supported',
@@ -540,23 +553,22 @@ def test_column_transformer_remainder():
     X_res_second = np.array([2, 4, 6]).reshape(-1, 1)
     X_res_both = X_array
 
-    # default passthrough
-    ct = ColumnTransformer([('trans', Trans(), [0])])
-    assert_array_equal(ct.fit_transform(X_array), X_res_both)
-    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)
+    # default drop
+    ct = ColumnTransformer([('trans1', Trans(), [0])])
+    assert_array_equal(ct.fit_transform(X_array), X_res_first)
+    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_first)
     assert len(ct.transformers_) == 2
     assert ct.transformers_[-1][0] == 'remainder'
-    assert ct.transformers_[-1][1] == 'passthrough'
+    assert ct.transformers_[-1][1] == 'drop'
     assert_array_equal(ct.transformers_[-1][2], [1])
 
-    # specify to drop remaining columns
-    ct = ColumnTransformer([('trans1', Trans(), [0])],
-                           remainder='drop')
-    assert_array_equal(ct.fit_transform(X_array), X_res_first)
-    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_first)
+    # specify passthrough
+    ct = ColumnTransformer([('trans', Trans(), [0])], remainder='passthrough')
+    assert_array_equal(ct.fit_transform(X_array), X_res_both)
+    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)
     assert len(ct.transformers_) == 2
     assert ct.transformers_[-1][0] == 'remainder'
-    assert ct.transformers_[-1][1] == 'drop'
+    assert ct.transformers_[-1][1] == 'passthrough'
     assert_array_equal(ct.transformers_[-1][2], [1])
 
     # column order is not preserved (passed through added to end)
@@ -590,6 +602,9 @@ def test_column_transformer_remainder():
         "remainder keyword needs to be one of \'drop\', \'passthrough\', "
         "or estimator.", ct.fit_transform, X_array)
 
+    # check default for make_column_transformer
+    ct = make_column_transformer(([0], Trans()))
+    assert ct.remainder == 'drop'
 
 @pytest.mark.parametrize("key", [[0], np.array([0]), slice(0, 1),
                                  np.array([True, False])])
@@ -777,3 +792,31 @@ def test_column_transformer_no_estimators():
     assert len(ct.transformers_) == 1
     assert ct.transformers_[-1][0] == 'remainder'
     assert ct.transformers_[-1][2] == [0, 1, 2]
+
+
+def test_column_transformer_callable_specifier():
+    # assert that function gets the full array / dataframe
+    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T
+    X_res_first = np.array([[0, 1, 2]]).T
+
+    def func(X):
+        assert_array_equal(X, X_array)
+        return [0]
+
+    ct = ColumnTransformer([('trans', Trans(), func)],
+                           remainder='drop')
+    assert_array_equal(ct.fit_transform(X_array), X_res_first)
+    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_first)
+
+    pd = pytest.importorskip('pandas')
+    X_df = pd.DataFrame(X_array, columns=['first', 'second'])
+
+    def func(X):
+        assert_array_equal(X.columns, X_df.columns)
+        assert_array_equal(X.values, X_df.values)
+        return ['first']
+
+    ct = ColumnTransformer([('trans', Trans(), func)],
+                           remainder='drop')
+    assert_array_equal(ct.fit_transform(X_df), X_res_first)
+    assert_array_equal(ct.fit(X_df).transform(X_df), X_res_first)
diff --git a/sklearn/covariance/graph_lasso_.py b/sklearn/covariance/graph_lasso_.py
index b9d5821fc81d..2ed9e86c7829 100644
--- a/sklearn/covariance/graph_lasso_.py
+++ b/sklearn/covariance/graph_lasso_.py
@@ -19,11 +19,11 @@
 from ..exceptions import ConvergenceWarning
 from ..utils.validation import check_random_state, check_array
 from ..utils import deprecated
+from ..utils.fixes import _Sequence as Sequence
 from ..linear_model import lars_path
 from ..linear_model import cd_fast
 from ..model_selection import check_cv, cross_val_score
-from ..externals.joblib import Parallel, delayed
-import collections
+from ..utils import Parallel, delayed
 
 
 # Helper functions to compute the objective and dual objective functions
@@ -608,7 +608,7 @@ def fit(self, X, y=None):
         n_alphas = self.alphas
         inner_verbose = max(0, self.verbose - 1)
 
-        if isinstance(n_alphas, collections.Sequence):
+        if isinstance(n_alphas, Sequence):
             alphas = self.alphas
             n_refinements = 1
         else:
@@ -684,7 +684,7 @@ def fit(self, X, y=None):
                 alpha_1 = path[best_index - 1][0]
                 alpha_0 = path[best_index + 1][0]
 
-            if not isinstance(n_alphas, collections.Sequence):
+            if not isinstance(n_alphas, Sequence):
                 alphas = np.logspace(np.log10(alpha_1), np.log10(alpha_0),
                                      n_alphas + 2)
                 alphas = alphas[1:-1]
diff --git a/sklearn/covariance/tests/test_graphical_lasso.py b/sklearn/covariance/tests/test_graphical_lasso.py
index d476cc52373d..2c1b604e5cf7 100644
--- a/sklearn/covariance/tests/test_graphical_lasso.py
+++ b/sklearn/covariance/tests/test_graphical_lasso.py
@@ -4,6 +4,7 @@
 
 import numpy as np
 from scipy import linalg
+import pytest
 
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_array_less
@@ -15,6 +16,7 @@
 from sklearn.externals.six.moves import StringIO
 from sklearn.utils import check_random_state
 from sklearn import datasets
+from sklearn.utils.fixes import PY3_OR_LATER
 
 from numpy.testing import assert_equal
 
@@ -136,6 +138,8 @@ def test_graphical_lasso_cv(random_state=1):
     GraphicalLassoCV(alphas=[0.8, 0.5], tol=1e-1, n_jobs=1).fit(X)
 
 
+@pytest.mark.skipif(not PY3_OR_LATER,
+                    reason='On Python 2 DeprecationWarning is not issued for some unkown reason.')
 def test_deprecated_grid_scores(random_state=1):
     dim = 5
     n_samples = 6
@@ -151,6 +155,5 @@ def test_deprecated_grid_scores(random_state=1):
                     "0.19 and will be removed in 0.21. Use "
                     "``grid_scores_`` instead")
 
-    assert_warns_message(DeprecationWarning, depr_message,
-                         lambda: graphical_lasso.grid_scores)
-    assert_equal(graphical_lasso.grid_scores, graphical_lasso.grid_scores_)
+    with pytest.warns(DeprecationWarning, match=depr_message):
+        assert_equal(graphical_lasso.grid_scores, graphical_lasso.grid_scores_)
diff --git a/sklearn/datasets/descr/wine_data.rst b/sklearn/datasets/descr/wine_data.rst
index f43e6524130b..9d506b4ab70b 100644
--- a/sklearn/datasets/descr/wine_data.rst
+++ b/sklearn/datasets/descr/wine_data.rst
@@ -21,6 +21,7 @@ Wine recognition dataset
  		- Hue
  		- OD280/OD315 of diluted wines
  		- Proline
+
     - class:
             - class_0
             - class_1
@@ -91,4 +92,4 @@ School of Information and Computer Science.
   "THE CLASSIFICATION PERFORMANCE OF RDA" 
   Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of 
   Mathematics and Statistics, James Cook University of North Queensland. 
-  (Also submitted to Journal of Chemometrics).
\ No newline at end of file
+  (Also submitted to Journal of Chemometrics).
diff --git a/sklearn/datasets/lfw.py b/sklearn/datasets/lfw.py
index 16fb2c2ef744..1b110f82c443 100644
--- a/sklearn/datasets/lfw.py
+++ b/sklearn/datasets/lfw.py
@@ -31,7 +31,7 @@
 
 from .base import get_data_home, _fetch_remote, RemoteFileMetadata
 from ..utils import Bunch
-from ..externals.joblib import Memory
+from ..utils import Memory
 from ..externals.six import b
 
 logger = logging.getLogger(__name__)
diff --git a/sklearn/datasets/samples_generator.py b/sklearn/datasets/samples_generator.py
index 5cd54b438f13..f019139130fb 100644
--- a/sklearn/datasets/samples_generator.py
+++ b/sklearn/datasets/samples_generator.py
@@ -11,11 +11,11 @@
 import numpy as np
 from scipy import linalg
 import scipy.sparse as sp
-from collections import Iterable
 
 from ..preprocessing import MultiLabelBinarizer
 from ..utils import check_array, check_random_state
 from ..utils import shuffle as util_shuffle
+from ..utils.fixes import _Iterable as Iterable
 from ..utils.random import sample_without_replacement
 from ..externals import six
 map = six.moves.map
diff --git a/sklearn/datasets/svmlight_format.py b/sklearn/datasets/svmlight_format.py
index bf14edabea49..357b257e542b 100644
--- a/sklearn/datasets/svmlight_format.py
+++ b/sklearn/datasets/svmlight_format.py
@@ -132,7 +132,7 @@ def load_svmlight_file(f, n_features=None, dtype=np.float64,
     --------
     To use joblib.Memory to cache the svmlight file::
 
-        from sklearn.externals.joblib import Memory
+        from sklearn.utils import Memory
         from sklearn.datasets import load_svmlight_file
         mem = Memory("./mycache")
 
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index ef741c4edacc..64315823e291 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -15,7 +15,7 @@
 from numpy.lib.stride_tricks import as_strided
 
 from ..base import BaseEstimator, TransformerMixin
-from ..externals.joblib import Parallel, delayed, cpu_count
+from ..utils import Parallel, delayed, cpu_count
 from ..externals.six.moves import zip
 from ..utils import (check_array, check_random_state, gen_even_slices,
                      gen_batches, _get_n_jobs)
@@ -373,11 +373,13 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
     n_components = len(code)
     n_features = Y.shape[0]
     random_state = check_random_state(random_state)
-    # Residuals, computed 'in-place' for efficiency
-    R = -np.dot(dictionary, code)
-    R += Y
-    R = np.asfortranarray(R)
+    # Get BLAS functions
+    gemm, = linalg.get_blas_funcs(('gemm',), (dictionary, code, Y))
     ger, = linalg.get_blas_funcs(('ger',), (dictionary, code))
+    # Residuals, computed with BLAS for speed and efficiency
+    # R <- -1.0 * U * V^T + 1.0 * Y
+    # Outputs R as Fortran array for efficiency
+    R = gemm(-1.0, dictionary, code, 1.0, Y)
     for k in range(n_components):
         # R <- 1.0 * U_k * V_k^T + R
         R = ger(1.0, dictionary[:, k], code[k, :], a=R, overwrite_a=True)
diff --git a/sklearn/decomposition/online_lda.py b/sklearn/decomposition/online_lda.py
index fa40e2ef6802..b8be3fbc6823 100644
--- a/sklearn/decomposition/online_lda.py
+++ b/sklearn/decomposition/online_lda.py
@@ -21,7 +21,7 @@
                      gen_batches, gen_even_slices, _get_n_jobs)
 from ..utils.fixes import logsumexp
 from ..utils.validation import check_non_negative
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals.six.moves import xrange
 from ..exceptions import NotFittedError
 
diff --git a/sklearn/decomposition/pca.py b/sklearn/decomposition/pca.py
index a070f887d199..db183af45af0 100644
--- a/sklearn/decomposition/pca.py
+++ b/sklearn/decomposition/pca.py
@@ -129,7 +129,7 @@ class PCA(_BasePCA):
 
             n_components == min(n_samples, n_features)
 
-        If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka\'s
+        If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's
         MLE is used to guess the dimension. Use of ``n_components == 'mle'``
         will interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``.
 
diff --git a/sklearn/decomposition/sparse_pca.py b/sklearn/decomposition/sparse_pca.py
index 6de8567d9beb..0f12ce632c81 100644
--- a/sklearn/decomposition/sparse_pca.py
+++ b/sklearn/decomposition/sparse_pca.py
@@ -66,6 +66,9 @@ class SparsePCA(BaseEstimator, TransformerMixin):
         If None, the random number generator is the RandomState instance used
         by `np.random`.
 
+    variance : bool, optional
+        If true, compute the explained variance
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -77,9 +80,6 @@ class SparsePCA(BaseEstimator, TransformerMixin):
     n_iter_ : int
         Number of iterations run.
 
-    variance : bool, optional
-        If true, compute the explained variance
-
     explained_variance_ : array, [n_components]
         The explained variance versus component
 
@@ -144,8 +144,7 @@ def fit(self, X, y=None):
         self.components_ = Vt.T
         self.error_ = E
         if self.variance:
-            self.explained_variance_ = \
-                self._get_explained_variance(self.components_, X)
+            self.explained_variance_ = self._get_explained_variance(X)
         return self
 
     def transform(self, X, ridge_alpha='deprecated'):
@@ -361,7 +360,6 @@ def fit(self, X, y=None):
         self.components_ = Vt.T
 
         if self.variance:
-            self.explained_variance_ = \
-                self._get_explained_variance(self.components_, X)
+            self.explained_variance_ = self._get_explained_variance(X)
 
         return self
diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index 831af46e4613..b5852f470187 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -58,6 +58,8 @@ def test_dict_learning_overcomplete():
     assert_true(dico.components_.shape == (n_components, n_features))
 
 
+# positive lars deprecated 0.22
+@pytest.mark.filterwarnings('ignore::DeprecationWarning')
 @pytest.mark.parametrize("transform_algorithm", [
     "lasso_lars",
     "lasso_cd",
@@ -170,6 +172,8 @@ def test_dict_learning_online_shapes():
     assert_equal(np.dot(code, dictionary).shape, X.shape)
 
 
+# positive lars deprecated 0.22
+@pytest.mark.filterwarnings('ignore::DeprecationWarning')
 @pytest.mark.parametrize("transform_algorithm", [
     "lasso_lars",
     "lasso_cd",
@@ -306,6 +310,8 @@ def test_sparse_encode_shapes():
         assert_equal(code.shape, (n_samples, n_components))
 
 
+# positive lars deprecated 0.22
+@pytest.mark.filterwarnings('ignore::DeprecationWarning')
 @pytest.mark.parametrize("positive", [
     False,
     True,
diff --git a/sklearn/decomposition/tests/test_kernel_pca.py b/sklearn/decomposition/tests/test_kernel_pca.py
index 63281ce33dd1..b0f2c5aeae52 100644
--- a/sklearn/decomposition/tests/test_kernel_pca.py
+++ b/sklearn/decomposition/tests/test_kernel_pca.py
@@ -1,9 +1,10 @@
 import numpy as np
 import scipy.sparse as sp
+import pytest
 
 from sklearn.utils.testing import (assert_array_almost_equal, assert_less,
                                    assert_equal, assert_not_equal,
-                                   assert_raises)
+                                   assert_raises, ignore_warnings)
 
 from sklearn.decomposition import PCA, KernelPCA
 from sklearn.datasets import make_circles
@@ -172,6 +173,7 @@ def test_kernel_pca_invalid_kernel():
     assert_raises(ValueError, kpca.fit, X_fit)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch_pipeline():
     # Test if we can do a grid-search to find parameters to separate
     # circles with a perceptron model.
@@ -186,6 +188,7 @@ def test_gridsearch_pipeline():
     assert_equal(grid_search.best_score_, 1)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch_pipeline_precomputed():
     # Test if we can do a grid-search to find parameters to separate
     # circles with a perceptron model using a precomputed kernel.
diff --git a/sklearn/decomposition/tests/test_sparse_pca.py b/sklearn/decomposition/tests/test_sparse_pca.py
index 204e3b1aa198..19de6be4c92e 100644
--- a/sklearn/decomposition/tests/test_sparse_pca.py
+++ b/sklearn/decomposition/tests/test_sparse_pca.py
@@ -80,21 +80,27 @@ def test_fit_transform():
 
 
 def test_fit_transform_variance():
+    '''
+        This function asserts that the variance computed by SparsePCA is the
+        same as the variance in PCA when the components are orthogonal.
+    '''
     alpha = 1
     rng = np.random.RandomState(0)
-    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)  # wide array
+    X, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)  # wide array
+    # init spca and pca
     spca_lars = SparsePCA(n_components=3, method='lars', alpha=alpha,
                           random_state=0, variance=True)
     pca = PCA(n_components=3, random_state=0)
 
-    pca.fit(Y)
-    # no need to fit spca for this
-    spca_lars.fit(Y)
+    # fit PCA
+    pca.fit(X)
 
-    components = pca.components_
     explained_variance = pca.explained_variance_
-    spca_lars.components_ = components
-    explained_variance_sparse = spca_lars.explained_variance_
+
+    # force the components in spca_lars to be the same as in pca
+    spca_lars.components_ = pca.components_
+    # compute using private method
+    explained_variance_sparse = spca_lars._get_explained_variance(X)
 
     assert_array_almost_equal(explained_variance, explained_variance_sparse)
 
@@ -171,7 +177,7 @@ def test_mini_batch_fit_transform():
     U1 = spca_lars.transform(Y)
     # Test multiple CPUs
     if sys.platform == 'win32':  # fake parallelism for win32
-        import sklearn.externals.joblib.parallel as joblib_par
+        import sklearn.utils._joblib.parallel as joblib_par
         _mp = joblib_par.multiprocessing
         joblib_par.multiprocessing = None
         try:
diff --git a/sklearn/discriminant_analysis.py b/sklearn/discriminant_analysis.py
index 96f342145684..1ed28c975a69 100644
--- a/sklearn/discriminant_analysis.py
+++ b/sklearn/discriminant_analysis.py
@@ -622,9 +622,9 @@ def __init__(self, priors=None, reg_param=0., store_covariance=False,
         self.tol = tol
 
     @property
-    @deprecated("Attribute covariances_ was deprecated in version"
+    @deprecated("Attribute ``covariances_`` was deprecated in version"
                 " 0.19 and will be removed in 0.21. Use "
-                "covariance_ instead")
+                "``covariance_`` instead")
     def covariances_(self):
         return self.covariance_
 
diff --git a/sklearn/ensemble/bagging.py b/sklearn/ensemble/bagging.py
index 30324d6e0c87..777e25edec06 100644
--- a/sklearn/ensemble/bagging.py
+++ b/sklearn/ensemble/bagging.py
@@ -13,7 +13,7 @@
 
 from .base import BaseEnsemble, _partition_estimators
 from ..base import ClassifierMixin, RegressorMixin
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals.six import with_metaclass
 from ..externals.six.moves import zip
 from ..metrics import r2_score, accuracy_score
diff --git a/sklearn/ensemble/forest.py b/sklearn/ensemble/forest.py
index b7a349d4b5a8..5a9c3cac00ed 100644
--- a/sklearn/ensemble/forest.py
+++ b/sklearn/ensemble/forest.py
@@ -52,7 +52,7 @@ class calls the ``fit`` method of each sub-estimator on random samples
 
 
 from ..base import ClassifierMixin, RegressorMixin
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals import six
 from ..metrics import r2_score
 from ..preprocessing import OneHotEncoder
@@ -135,7 +135,7 @@ class BaseForest(six.with_metaclass(ABCMeta, BaseEnsemble)):
     @abstractmethod
     def __init__(self,
                  base_estimator,
-                 n_estimators=10,
+                 n_estimators=100,
                  estimator_params=tuple(),
                  bootstrap=False,
                  oob_score=False,
@@ -242,6 +242,12 @@ def fit(self, X, y, sample_weight=None):
         -------
         self : object
         """
+
+        if self.n_estimators == 'warn':
+            warnings.warn("The default value of n_estimators will change from "
+                          "10 in version 0.20 to 100 in 0.22.", FutureWarning)
+            self.n_estimators = 10
+
         # Validate or convert input data
         X = check_array(X, accept_sparse="csc", dtype=DTYPE)
         y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)
@@ -374,11 +380,12 @@ def feature_importances_(self):
         return sum(all_importances) / len(self.estimators_)
 
 
-# This is a utility function for joblib's Parallel. It can't go locally in
-# ForestClassifier or ForestRegressor, because joblib complains that it cannot
-# pickle it when placed there.
+def _accumulate_prediction(predict, X, out, lock):
+    """This is a utility function for joblib's Parallel.
 
-def accumulate_prediction(predict, X, out, lock):
+    It can't go locally in ForestClassifier or ForestRegressor, because joblib
+    complains that it cannot pickle it when placed there.
+    """
     prediction = predict(X, check_input=False)
     with lock:
         if len(out) == 1:
@@ -399,7 +406,7 @@ class ForestClassifier(six.with_metaclass(ABCMeta, BaseForest,
     @abstractmethod
     def __init__(self,
                  base_estimator,
-                 n_estimators=10,
+                 n_estimators=100,
                  estimator_params=tuple(),
                  bootstrap=False,
                  oob_score=False,
@@ -408,7 +415,6 @@ def __init__(self,
                  verbose=0,
                  warm_start=False,
                  class_weight=None):
-
         super(ForestClassifier, self).__init__(
             base_estimator,
             n_estimators=n_estimators,
@@ -584,7 +590,8 @@ class in a leaf.
                      for j in np.atleast_1d(self.n_classes_)]
         lock = threading.Lock()
         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend="threading")(
-            delayed(accumulate_prediction)(e.predict_proba, X, all_proba, lock)
+            delayed(_accumulate_prediction)(e.predict_proba, X, all_proba,
+                                            lock)
             for e in self.estimators_)
 
         for proba in all_proba:
@@ -638,7 +645,7 @@ class ForestRegressor(six.with_metaclass(ABCMeta, BaseForest, RegressorMixin)):
     @abstractmethod
     def __init__(self,
                  base_estimator,
-                 n_estimators=10,
+                 n_estimators=100,
                  estimator_params=tuple(),
                  bootstrap=False,
                  oob_score=False,
@@ -691,7 +698,7 @@ def predict(self, X):
         # Parallel loop
         lock = threading.Lock()
         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend="threading")(
-            delayed(accumulate_prediction)(e.predict, X, [y_hat], lock)
+            delayed(_accumulate_prediction)(e.predict, X, [y_hat], lock)
             for e in self.estimators_)
 
         y_hat /= len(self.estimators_)
@@ -758,27 +765,15 @@ class RandomForestClassifier(ForestClassifier):
     n_estimators : integer, optional (default=10)
         The number of trees in the forest.
 
+        .. versionchanged:: 0.20
+           The default value of ``n_estimators`` will change from 10 in
+           version 0.20 to 100 in version 0.22.
+
     criterion : string, optional (default="gini")
         The function to measure the quality of a split. Supported criteria are
         "gini" for the Gini impurity and "entropy" for the information gain.
         Note: this parameter is tree-specific.
 
-    max_features : int, float, string or None, optional (default="auto")
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=sqrt(n_features)`.
-        - If "sqrt", then `max_features=sqrt(n_features)` (same as "auto").
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
     max_depth : integer or None, optional (default=None)
         The maximum depth of the tree. If None, then nodes are expanded until
         all leaves are pure or until all leaves contain less than
@@ -811,20 +806,27 @@ class RandomForestClassifier(ForestClassifier):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
+    max_features : int, float, string or None, optional (default="auto")
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=sqrt(n_features)`.
+        - If "sqrt", then `max_features=sqrt(n_features)` (same as "auto").
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
     max_leaf_nodes : int or None, optional (default=None)
         Grow trees with ``max_leaf_nodes`` in best-first fashion.
         Best nodes are defined as relative reduction in impurity.
         If None then unlimited number of leaf nodes.
 
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
-
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
         greater than or equal to this value.
@@ -843,6 +845,15 @@ class RandomForestClassifier(ForestClassifier):
 
         .. versionadded:: 0.19
 
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
+
     bootstrap : boolean, optional (default=True)
         Whether bootstrap samples are used when building trees.
 
@@ -933,16 +944,17 @@ class labels (multi-output problem).
     >>> X, y = make_classification(n_samples=1000, n_features=4,
     ...                            n_informative=2, n_redundant=0,
     ...                            random_state=0, shuffle=False)
-    >>> clf = RandomForestClassifier(max_depth=2, random_state=0)
+    >>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,
+    ...                              random_state=0)
     >>> clf.fit(X, y)
     RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                 max_depth=2, max_features='auto', max_leaf_nodes=None,
                 min_impurity_decrease=0.0, min_impurity_split=None,
                 min_samples_leaf=1, min_samples_split=2,
-                min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
+                min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
                 oob_score=False, random_state=0, verbose=0, warm_start=False)
     >>> print(clf.feature_importances_)
-    [0.17287856 0.80608704 0.01884792 0.00218648]
+    [0.14205973 0.76664038 0.0282433  0.06305659]
     >>> print(clf.predict([[0, 0, 0, 0]]))
     [1]
 
@@ -971,7 +983,7 @@ class labels (multi-output problem).
     DecisionTreeClassifier, ExtraTreesClassifier
     """
     def __init__(self,
-                 n_estimators=10,
+                 n_estimators='warn',
                  criterion="gini",
                  max_depth=None,
                  min_samples_split=2,
@@ -1032,6 +1044,10 @@ class RandomForestRegressor(ForestRegressor):
     n_estimators : integer, optional (default=10)
         The number of trees in the forest.
 
+        .. versionchanged:: 0.20
+           The default value of ``n_estimators`` will change from 10 in
+           version 0.20 to 100 in version 0.22.
+
     criterion : string, optional (default="mse")
         The function to measure the quality of a split. Supported criteria
         are "mse" for the mean squared error, which is equal to variance
@@ -1041,22 +1057,6 @@ class RandomForestRegressor(ForestRegressor):
         .. versionadded:: 0.18
            Mean Absolute Error (MAE) criterion.
 
-    max_features : int, float, string or None, optional (default="auto")
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=n_features`.
-        - If "sqrt", then `max_features=sqrt(n_features)`.
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
     max_depth : integer or None, optional (default=None)
         The maximum depth of the tree. If None, then nodes are expanded until
         all leaves are pure or until all leaves contain less than
@@ -1089,20 +1089,27 @@ class RandomForestRegressor(ForestRegressor):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
+    max_features : int, float, string or None, optional (default="auto")
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=n_features`.
+        - If "sqrt", then `max_features=sqrt(n_features)`.
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
     max_leaf_nodes : int or None, optional (default=None)
         Grow trees with ``max_leaf_nodes`` in best-first fashion.
         Best nodes are defined as relative reduction in impurity.
         If None then unlimited number of leaf nodes.
 
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
-
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
         greater than or equal to this value.
@@ -1121,6 +1128,15 @@ class RandomForestRegressor(ForestRegressor):
 
         .. versionadded:: 0.19
 
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
+
     bootstrap : boolean, optional (default=True)
         Whether bootstrap samples are used when building trees.
 
@@ -1173,18 +1189,19 @@ class RandomForestRegressor(ForestRegressor):
     >>>
     >>> X, y = make_regression(n_features=4, n_informative=2,
     ...                        random_state=0, shuffle=False)
-    >>> regr = RandomForestRegressor(max_depth=2, random_state=0)
+    >>> regr = RandomForestRegressor(max_depth=2, random_state=0,
+    ...                              n_estimators=100)
     >>> regr.fit(X, y)
     RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,
                max_features='auto', max_leaf_nodes=None,
                min_impurity_decrease=0.0, min_impurity_split=None,
                min_samples_leaf=1, min_samples_split=2,
-               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
+               min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,
                oob_score=False, random_state=0, verbose=0, warm_start=False)
     >>> print(regr.feature_importances_)
-    [0.17339552 0.81594114 0.         0.01066333]
+    [0.18146984 0.81473937 0.00145312 0.00233767]
     >>> print(regr.predict([[0, 0, 0, 0]]))
-    [-2.50699856]
+    [-8.32987858]
 
     Notes
     -----
@@ -1211,7 +1228,7 @@ class RandomForestRegressor(ForestRegressor):
     DecisionTreeRegressor, ExtraTreesRegressor
     """
     def __init__(self,
-                 n_estimators=10,
+                 n_estimators='warn',
                  criterion="mse",
                  max_depth=None,
                  min_samples_split=2,
@@ -1268,26 +1285,14 @@ class ExtraTreesClassifier(ForestClassifier):
     n_estimators : integer, optional (default=10)
         The number of trees in the forest.
 
+        .. versionchanged:: 0.20
+           The default value of ``n_estimators`` will change from 10 in
+           version 0.20 to 100 in version 0.22.
+
     criterion : string, optional (default="gini")
         The function to measure the quality of a split. Supported criteria are
         "gini" for the Gini impurity and "entropy" for the information gain.
 
-    max_features : int, float, string or None, optional (default="auto")
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=sqrt(n_features)`.
-        - If "sqrt", then `max_features=sqrt(n_features)`.
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
     max_depth : integer or None, optional (default=None)
         The maximum depth of the tree. If None, then nodes are expanded until
         all leaves are pure or until all leaves contain less than
@@ -1320,20 +1325,27 @@ class ExtraTreesClassifier(ForestClassifier):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
+    max_features : int, float, string or None, optional (default="auto")
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=sqrt(n_features)`.
+        - If "sqrt", then `max_features=sqrt(n_features)`.
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
     max_leaf_nodes : int or None, optional (default=None)
         Grow trees with ``max_leaf_nodes`` in best-first fashion.
         Best nodes are defined as relative reduction in impurity.
         If None then unlimited number of leaf nodes.
 
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
-
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
         greater than or equal to this value.
@@ -1352,6 +1364,15 @@ class ExtraTreesClassifier(ForestClassifier):
 
         .. versionadded:: 0.19
 
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
+
     bootstrap : boolean, optional (default=False)
         Whether bootstrap samples are used when building trees.
 
@@ -1454,7 +1475,7 @@ class labels (multi-output problem).
         splits.
     """
     def __init__(self,
-                 n_estimators=10,
+                 n_estimators='warn',
                  criterion="gini",
                  max_depth=None,
                  min_samples_split=2,
@@ -1513,6 +1534,10 @@ class ExtraTreesRegressor(ForestRegressor):
     n_estimators : integer, optional (default=10)
         The number of trees in the forest.
 
+        .. versionchanged:: 0.20
+           The default value of ``n_estimators`` will change from 10 in
+           version 0.20 to 100 in version 0.22.
+
     criterion : string, optional (default="mse")
         The function to measure the quality of a split. Supported criteria
         are "mse" for the mean squared error, which is equal to variance
@@ -1522,22 +1547,6 @@ class ExtraTreesRegressor(ForestRegressor):
         .. versionadded:: 0.18
            Mean Absolute Error (MAE) criterion.
 
-    max_features : int, float, string or None, optional (default="auto")
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=n_features`.
-        - If "sqrt", then `max_features=sqrt(n_features)`.
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
     max_depth : integer or None, optional (default=None)
         The maximum depth of the tree. If None, then nodes are expanded until
         all leaves are pure or until all leaves contain less than
@@ -1570,20 +1579,27 @@ class ExtraTreesRegressor(ForestRegressor):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
+    max_features : int, float, string or None, optional (default="auto")
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=n_features`.
+        - If "sqrt", then `max_features=sqrt(n_features)`.
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
     max_leaf_nodes : int or None, optional (default=None)
         Grow trees with ``max_leaf_nodes`` in best-first fashion.
         Best nodes are defined as relative reduction in impurity.
         If None then unlimited number of leaf nodes.
 
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
-
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
         greater than or equal to this value.
@@ -1602,6 +1618,15 @@ class ExtraTreesRegressor(ForestRegressor):
 
         .. versionadded:: 0.19
 
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
+
     bootstrap : boolean, optional (default=False)
         Whether bootstrap samples are used when building trees.
 
@@ -1666,7 +1691,7 @@ class ExtraTreesRegressor(ForestRegressor):
     RandomForestRegressor: Ensemble regressor using trees with optimal splits.
     """
     def __init__(self,
-                 n_estimators=10,
+                 n_estimators='warn',
                  criterion="mse",
                  max_depth=None,
                  min_samples_split=2,
@@ -1728,6 +1753,10 @@ class RandomTreesEmbedding(BaseForest):
     n_estimators : integer, optional (default=10)
         Number of trees in the forest.
 
+        .. versionchanged:: 0.20
+           The default value of ``n_estimators`` will change from 10 in
+           version 0.20 to 100 in version 0.22.
+
     max_depth : integer, optional (default=5)
         The maximum depth of each tree. If None, then nodes are expanded until
         all leaves are pure or until all leaves contain less than
@@ -1765,15 +1794,6 @@ class RandomTreesEmbedding(BaseForest):
         Best nodes are defined as relative reduction in impurity.
         If None then unlimited number of leaf nodes.
 
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
-
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
         greater than or equal to this value.
@@ -1792,8 +1812,14 @@ class RandomTreesEmbedding(BaseForest):
 
         .. versionadded:: 0.19
 
-    bootstrap : boolean, optional (default=True)
-        Whether bootstrap samples are used when building trees.
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
 
     sparse_output : bool, optional (default=True)
         Whether or not to return a sparse CSR matrix, as default behavior,
@@ -1833,7 +1859,7 @@ class RandomTreesEmbedding(BaseForest):
     """
 
     def __init__(self,
-                 n_estimators=10,
+                 n_estimators='warn',
                  max_depth=5,
                  min_samples_split=2,
                  min_samples_leaf=1,
diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
index 4edf4dd1fa68..f32ac7699035 100644
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -64,13 +64,32 @@
 
 
 class QuantileEstimator(object):
-    """An estimator predicting the alpha-quantile of the training targets."""
+    """An estimator predicting the alpha-quantile of the training targets.
+
+    Parameters
+    ----------
+    alpha : float
+        The quantile
+    """
     def __init__(self, alpha=0.9):
         if not 0 < alpha < 1.0:
             raise ValueError("`alpha` must be in (0, 1.0) but was %r" % alpha)
         self.alpha = alpha
 
     def fit(self, X, y, sample_weight=None):
+        """Fit the estimator.
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Training data
+
+        y : array, shape (n_samples, n_targets)
+            Target values. Will be cast to X's dtype if necessary
+
+        sample_weight : numpy array of shape (n_samples,)
+            Individual weights for each sample
+        """
         if sample_weight is None:
             self.quantile = stats.scoreatpercentile(y, self.alpha * 100.0)
         else:
@@ -78,6 +97,18 @@ def fit(self, X, y, sample_weight=None):
                                                  self.alpha * 100.0)
 
     def predict(self, X):
+        """Predict labels
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Samples.
+
+        Returns
+        -------
+        y : array, shape (n_samples,)
+            Returns predicted values.
+        """
         check_is_fitted(self, 'quantile')
 
         y = np.empty((X.shape[0], 1), dtype=np.float64)
@@ -88,12 +119,37 @@ def predict(self, X):
 class MeanEstimator(object):
     """An estimator predicting the mean of the training targets."""
     def fit(self, X, y, sample_weight=None):
+        """Fit the estimator.
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Training data
+
+        y : array, shape (n_samples, n_targets)
+            Target values. Will be cast to X's dtype if necessary
+
+        sample_weight : numpy array of shape (n_samples,)
+            Individual weights for each sample
+        """
         if sample_weight is None:
             self.mean = np.mean(y)
         else:
             self.mean = np.average(y, weights=sample_weight)
 
     def predict(self, X):
+        """Predict labels
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Samples.
+
+        Returns
+        -------
+        y : array, shape (n_samples,)
+            Returns predicted values.
+        """
         check_is_fitted(self, 'mean')
 
         y = np.empty((X.shape[0], 1), dtype=np.float64)
@@ -106,6 +162,19 @@ class LogOddsEstimator(object):
     scale = 1.0
 
     def fit(self, X, y, sample_weight=None):
+        """Fit the estimator.
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Training data
+
+        y : array, shape (n_samples, n_targets)
+            Target values. Will be cast to X's dtype if necessary
+
+        sample_weight : numpy array of shape (n_samples,)
+            Individual weights for each sample
+        """
         # pre-cond: pos, neg are encoded as 1, 0
         if sample_weight is None:
             pos = np.sum(y)
@@ -119,6 +188,18 @@ def fit(self, X, y, sample_weight=None):
         self.prior = self.scale * np.log(pos / neg)
 
     def predict(self, X):
+        """Predict labels
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Samples.
+
+        Returns
+        -------
+        y : array, shape (n_samples,)
+            Returns predicted values.
+        """
         check_is_fitted(self, 'prior')
 
         y = np.empty((X.shape[0], 1), dtype=np.float64)
@@ -136,12 +217,37 @@ class PriorProbabilityEstimator(object):
     class in the training data.
     """
     def fit(self, X, y, sample_weight=None):
+        """Fit the estimator.
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Training data
+
+        y : array, shape (n_samples, n_targets)
+            Target values. Will be cast to X's dtype if necessary
+
+        sample_weight : array, shape (n_samples,)
+            Individual weights for each sample
+        """
         if sample_weight is None:
             sample_weight = np.ones_like(y, dtype=np.float64)
         class_counts = np.bincount(y, weights=sample_weight)
         self.priors = class_counts / class_counts.sum()
 
     def predict(self, X):
+        """Predict labels
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Samples.
+
+        Returns
+        -------
+        y : array, shape (n_samples,)
+            Returns predicted values.
+        """
         check_is_fitted(self, 'priors')
 
         y = np.empty((X.shape[0], self.priors.shape[0]), dtype=np.float64)
@@ -153,6 +259,19 @@ class ZeroEstimator(object):
     """An estimator that simply predicts zero. """
 
     def fit(self, X, y, sample_weight=None):
+        """Fit the estimator.
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Training data
+
+        y : numpy, shape (n_samples, n_targets)
+            Target values. Will be cast to X's dtype if necessary
+
+        sample_weight : array, shape (n_samples,)
+            Individual weights for each sample
+        """
         if np.issubdtype(y.dtype, np.signedinteger):
             # classification
             self.n_classes = np.unique(y).shape[0]
@@ -163,6 +282,18 @@ def fit(self, X, y, sample_weight=None):
             self.n_classes = 1
 
     def predict(self, X):
+        """Predict labels
+
+        Parameters
+        ----------
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Samples.
+
+        Returns
+        -------
+        y : array, shape (n_samples,)
+            Returns predicted values.
+        """
         check_is_fitted(self, 'n_classes')
 
         y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)
@@ -173,6 +304,11 @@ def predict(self, X):
 class LossFunction(six.with_metaclass(ABCMeta, object)):
     """Abstract base class for various loss functions.
 
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
+
     Attributes
     ----------
     K : int
@@ -192,17 +328,30 @@ def init_estimator(self):
 
     @abstractmethod
     def __call__(self, y, pred, sample_weight=None):
-        """Compute the loss of prediction ``pred`` and ``y``. """
+        """Compute the loss.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
 
     @abstractmethod
     def negative_gradient(self, y, y_pred, **kargs):
         """Compute the negative gradient.
 
         Parameters
-        ---------
-        y : np.ndarray, shape=(n,)
+        ----------
+        y : array, shape (n_samples,)
             The target labels.
-        y_pred : np.ndarray, shape=(n,):
+
+        y_pred : array, shape (n_samples,)
             The predictions.
         """
 
@@ -217,17 +366,17 @@ def update_terminal_regions(self, tree, X, y, residual, y_pred,
         ----------
         tree : tree.Tree
             The tree object.
-        X : ndarray, shape=(n, m)
+        X : array, shape (n, m)
             The data array.
-        y : ndarray, shape=(n,)
+        y : array, shape (n,)
             The target labels.
-        residual : ndarray, shape=(n,)
+        residual : array, shape (n,)
             The residuals (usually the negative gradient).
-        y_pred : ndarray, shape=(n,)
+        y_pred : array, shape (n,)
             The predictions.
-        sample_weight : ndarray, shape=(n,)
+        sample_weight : array, shape (n,)
             The weight of each sample.
-        sample_mask : ndarray, shape=(n,)
+        sample_mask : array, shape (n,)
             The sample mask to be used.
         learning_rate : float, default=0.1
             learning rate shrinks the contribution of each tree by
@@ -260,8 +409,13 @@ def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,
 
 
 class RegressionLossFunction(six.with_metaclass(ABCMeta, LossFunction)):
-    """Base class for regression loss functions. """
+    """Base class for regression loss functions.
 
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
+    """
     def __init__(self, n_classes):
         if n_classes != 1:
             raise ValueError("``n_classes`` must be 1 for regression but "
@@ -271,11 +425,31 @@ def __init__(self, n_classes):
 
 class LeastSquaresError(RegressionLossFunction):
     """Loss function for least squares (LS) estimation.
-    Terminal regions need not to be updated for least squares. """
+    Terminal regions need not to be updated for least squares.
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
+    """
+
     def init_estimator(self):
         return MeanEstimator()
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the least squares loss.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         if sample_weight is None:
             return np.mean((y - pred.ravel()) ** 2.0)
         else:
@@ -283,6 +457,16 @@ def __call__(self, y, pred, sample_weight=None):
                     np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))
 
     def negative_gradient(self, y, pred, **kargs):
+        """Compute the negative gradient.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            The target labels.
+
+        pred : array, shape (n_samples,)
+            The predictions.
+        """
         return y - pred.ravel()
 
     def update_terminal_regions(self, tree, X, y, residual, y_pred,
@@ -291,6 +475,28 @@ def update_terminal_regions(self, tree, X, y, residual, y_pred,
         """Least squares does not need to update terminal regions.
 
         But it has to update the predictions.
+
+        Parameters
+        ----------
+        tree : tree.Tree
+            The tree object.
+        X : array, shape (n, m)
+            The data array.
+        y : array, shape (n,)
+            The target labels.
+        residual : array, shape (n,)
+            The residuals (usually the negative gradient).
+        y_pred : array, shape (n,)
+            The predictions.
+        sample_weight : array, shape (n,)
+            The weight of each sample.
+        sample_mask : array, shape (n,)
+            The sample mask to be used.
+        learning_rate : float, default=0.1
+            learning rate shrinks the contribution of each tree by
+             ``learning_rate``.
+        k : int, default 0
+            The index of the estimator being updated.
         """
         # update predictions
         y_pred[:, k] += learning_rate * tree.predict(X).ravel()
@@ -301,11 +507,30 @@ def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,
 
 
 class LeastAbsoluteError(RegressionLossFunction):
-    """Loss function for least absolute deviation (LAD) regression. """
+    """Loss function for least absolute deviation (LAD) regression.
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
+    """
     def init_estimator(self):
         return QuantileEstimator(alpha=0.5)
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the least absolute error.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         if sample_weight is None:
             return np.abs(y - pred.ravel()).mean()
         else:
@@ -313,7 +538,18 @@ def __call__(self, y, pred, sample_weight=None):
                     np.sum(sample_weight * np.abs(y - pred.ravel())))
 
     def negative_gradient(self, y, pred, **kargs):
-        """1.0 if y - pred > 0.0 else -1.0"""
+        """Compute the negative gradient.
+
+        1.0 if y - pred > 0.0 else -1.0
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            The target labels.
+
+        pred : array, shape (n_samples,)
+            The predictions.
+        """
         pred = pred.ravel()
         return 2.0 * (y - pred > 0.0) - 1.0
 
@@ -335,6 +571,14 @@ class HuberLossFunction(RegressionLossFunction):
     ----------
     J. Friedman, Greedy Function Approximation: A Gradient Boosting
     Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
+
+    alpha : float
+        Percentile at which to extract score
     """
 
     def __init__(self, n_classes, alpha=0.9):
@@ -346,6 +590,19 @@ def init_estimator(self):
         return QuantileEstimator(alpha=0.5)
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the Huber loss.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         pred = pred.ravel()
         diff = y - pred
         gamma = self.gamma
@@ -368,6 +625,19 @@ def __call__(self, y, pred, sample_weight=None):
         return loss
 
     def negative_gradient(self, y, pred, sample_weight=None, **kargs):
+        """Compute the negative gradient.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            The target labels.
+
+        pred : array, shape (n_samples,)
+            The predictions.
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         pred = pred.ravel()
         diff = y - pred
         if sample_weight is None:
@@ -400,8 +670,15 @@ class QuantileLossFunction(RegressionLossFunction):
 
     Quantile regression allows to estimate the percentiles
     of the conditional distribution of the target.
-    """
 
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes.
+
+    alpha : float, optional (default = 0.9)
+        The percentile
+    """
     def __init__(self, n_classes, alpha=0.9):
         super(QuantileLossFunction, self).__init__(n_classes)
         self.alpha = alpha
@@ -411,6 +688,19 @@ def init_estimator(self):
         return QuantileEstimator(self.alpha)
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the Quantile loss.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         pred = pred.ravel()
         diff = y - pred
         alpha = self.alpha
@@ -426,6 +716,16 @@ def __call__(self, y, pred, sample_weight=None):
         return loss
 
     def negative_gradient(self, y, pred, **kargs):
+        """Compute the negative gradient.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            The target labels.
+
+        pred : array, shape (n_samples,)
+            The predictions.
+        """
         alpha = self.alpha
         pred = pred.ravel()
         mask = y > pred
@@ -465,6 +765,11 @@ class BinomialDeviance(ClassificationLossFunction):
 
     Binary classification is a special case; here, we only need to
     fit one tree instead of ``n_classes`` trees.
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes.
     """
     def __init__(self, n_classes):
         if n_classes != 2:
@@ -477,7 +782,19 @@ def init_estimator(self):
         return LogOddsEstimator()
 
     def __call__(self, y, pred, sample_weight=None):
-        """Compute the deviance (= 2 * negative log-likelihood). """
+        """Compute the deviance (= 2 * negative log-likelihood).
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         # logaddexp(0, v) == log(1.0 + exp(v))
         pred = pred.ravel()
         if sample_weight is None:
@@ -487,7 +804,16 @@ def __call__(self, y, pred, sample_weight=None):
                     np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))
 
     def negative_gradient(self, y, pred, **kargs):
-        """Compute the residual (= negative gradient). """
+        """Compute the residual (= negative gradient).
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+        """
         return y - expit(pred.ravel())
 
     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,
@@ -530,6 +856,11 @@ class MultinomialDeviance(ClassificationLossFunction):
 
     For multi-class classification we need to fit ``n_classes`` trees at
     each stage.
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes
     """
 
     is_multi_class = True
@@ -544,6 +875,19 @@ def init_estimator(self):
         return PriorProbabilityEstimator()
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the Multinomial deviance.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         # create one-hot label encoding
         Y = np.zeros((y.shape[0], self.K), dtype=np.float64)
         for k in range(self.K):
@@ -557,7 +901,19 @@ def __call__(self, y, pred, sample_weight=None):
                           logsumexp(pred, axis=1))
 
     def negative_gradient(self, y, pred, k=0, **kwargs):
-        """Compute negative gradient for the ``k``-th class. """
+        """Compute negative gradient for the ``k``-th class.
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            The target labels.
+
+        pred : array, shape (n_samples,)
+            The predictions.
+
+        k : int, optional (default=0)
+            The index of the class
+        """
         return y - np.nan_to_num(np.exp(pred[:, k] -
                                         logsumexp(pred, axis=1)))
 
@@ -598,6 +954,11 @@ class ExponentialLoss(ClassificationLossFunction):
     References
     ----------
     Greg Ridgeway, Generalized Boosted Models: A guide to the gbm package, 2007
+
+    Parameters
+    ----------
+    n_classes : int
+        Number of classes.
     """
     def __init__(self, n_classes):
         if n_classes != 2:
@@ -610,6 +971,19 @@ def init_estimator(self):
         return ScaledLogOddsEstimator()
 
     def __call__(self, y, pred, sample_weight=None):
+        """Compute the exponential loss
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+
+        sample_weight : array-like, shape (n_samples,), optional
+            Sample weights.
+        """
         pred = pred.ravel()
         if sample_weight is None:
             return np.mean(np.exp(-(2. * y - 1.) * pred))
@@ -618,6 +992,16 @@ def __call__(self, y, pred, sample_weight=None):
                     np.sum(sample_weight * np.exp(-(2 * y - 1) * pred)))
 
     def negative_gradient(self, y, pred, **kargs):
+        """Compute the residual (= negative gradient).
+
+        Parameters
+        ----------
+        y : array, shape (n_samples,)
+            True labels
+
+        pred : array, shape (n_samples,)
+            Predicted labels
+        """
         y_ = -(2. * y - 1.)
         return y_ * np.exp(y_ * pred.ravel())
 
@@ -664,15 +1048,28 @@ def _score_to_decision(self, score):
 class VerboseReporter(object):
     """Reports verbose output to stdout.
 
-    If ``verbose==1`` output is printed once in a while (when iteration mod
-    verbose_mod is zero).; if larger than 1 then output is printed for
-    each update.
+    Parameters
+    ----------
+    verbose : int
+        Verbosity level. If ``verbose==1`` output is printed once in a while
+        (when iteration mod verbose_mod is zero).; if larger than 1 then output
+        is printed for each update.
     """
 
     def __init__(self, verbose):
         self.verbose = verbose
 
     def init(self, est, begin_at_stage=0):
+        """Initialize reporter
+
+        Parameters
+        ----------
+        est : Estimator
+            The estimator
+
+        begin_at_stage : int
+            stage at which to begin reporting
+        """
         # header fields and line format str
         header_fields = ['Iter', 'Train Loss']
         verbose_fmt = ['{iter:>10d}', '{train_score:>16.4f}']
@@ -694,7 +1091,15 @@ def init(self, est, begin_at_stage=0):
         self.begin_at_stage = begin_at_stage
 
     def update(self, j, est):
-        """Update reporter with new iteration. """
+        """Update reporter with new iteration.
+
+        Parameters
+        ----------
+        j : int
+            The new iteration
+        est : Estimator
+            The estimator
+        """
         do_oob = est.subsample < 1
         # we need to take into account if we fit additional estimators.
         i = j - self.begin_at_stage  # iteration relative to the start iter
@@ -959,16 +1364,16 @@ def fit(self, X, y, sample_weight=None, monitor=None):
 
         Parameters
         ----------
-        X : array-like, shape = [n_samples, n_features]
+        X : array-like, shape (n_samples, n_features)
             Training vectors, where n_samples is the number of samples
             and n_features is the number of features.
 
-        y : array-like, shape = [n_samples]
+        y : array-like, shape (n_samples,)
             Target values (strings or integers in classification, real numbers
             in regression)
             For classification, labels must correspond to classes.
 
-        sample_weight : array-like, shape = [n_samples] or None
+        sample_weight : array-like, shape (n_samples,) or None
             Sample weights. If None, then samples are equally weighted. Splits
             that would create child nodes with net zero or negative weight are
             ignored while searching for a split in each node. In the case of
@@ -1197,14 +1602,14 @@ def _staged_decision_function(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        score : generator of array, shape = [n_samples, k]
+        score : generator of array, shape (n_samples, k)
             The decision function of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
             Regression and binary classification are special cases with
@@ -1223,7 +1628,7 @@ def feature_importances_(self):
 
         Returns
         -------
-        feature_importances_ : array, shape = [n_features]
+        feature_importances_ : array, shape (n_features,)
         """
         self._check_initialized()
 
@@ -1253,14 +1658,14 @@ def apply(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, its dtype will be converted to
             ``dtype=np.float32``. If a sparse matrix is provided, it will
             be converted to a sparse ``csr_matrix``.
 
         Returns
         -------
-        X_leaves : array_like, shape = [n_samples, n_estimators, n_classes]
+        X_leaves : array-like, shape (n_samples, n_estimators, n_classes)
             For each datapoint x in X and for each tree in the ensemble,
             return the index of the leaf x ends up in each estimator.
             In the case of binary classification n_classes is 1.
@@ -1311,11 +1716,12 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
         is fairly robust to over-fitting so a large number usually
         results in better performance.
 
-    max_depth : integer, optional (default=3)
-        maximum depth of the individual regression estimators. The maximum
-        depth limits the number of nodes in the tree. Tune this parameter
-        for best performance; the best value depends on the interaction
-        of the input variables.
+    subsample : float, optional (default=1.0)
+        The fraction of samples to be used for fitting the individual base
+        learners. If smaller than 1.0 this results in Stochastic Gradient
+        Boosting. `subsample` interacts with the parameter `n_estimators`.
+        Choosing `subsample < 1.0` leads to a reduction of variance
+        and an increase in bias.
 
     criterion : string, optional (default="friedman_mse")
         The function to measure the quality of a split. Supported criteria
@@ -1354,45 +1760,11 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    subsample : float, optional (default=1.0)
-        The fraction of samples to be used for fitting the individual base
-        learners. If smaller than 1.0 this results in Stochastic Gradient
-        Boosting. `subsample` interacts with the parameter `n_estimators`.
-        Choosing `subsample < 1.0` leads to a reduction of variance
-        and an increase in bias.
-
-    max_features : int, float, string or None, optional (default=None)
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=sqrt(n_features)`.
-        - If "sqrt", then `max_features=sqrt(n_features)`.
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Choosing `max_features < n_features` leads to a reduction of variance
-        and an increase in bias.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
-    max_leaf_nodes : int or None, optional (default=None)
-        Grow trees with ``max_leaf_nodes`` in best-first fashion.
-        Best nodes are defined as relative reduction in impurity.
-        If None then unlimited number of leaf nodes.
-
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
+    max_depth : integer, optional (default=3)
+        maximum depth of the individual regression estimators. The maximum
+        depth limits the number of nodes in the tree. Tune this parameter
+        for best performance; the best value depends on the interaction
+        of the input variables.
 
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
@@ -1412,27 +1784,60 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
 
         .. versionadded:: 0.19
 
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
+
     init : estimator, optional
         An estimator object that is used to compute the initial
         predictions. ``init`` has to provide ``fit`` and ``predict``.
         If None it uses ``loss.init_estimator``.
 
+    random_state : int, RandomState instance or None, optional (default=None)
+        If int, random_state is the seed used by the random number generator;
+        If RandomState instance, random_state is the random number generator;
+        If None, the random number generator is the RandomState instance used
+        by `np.random`.
+
+    max_features : int, float, string or None, optional (default=None)
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=sqrt(n_features)`.
+        - If "sqrt", then `max_features=sqrt(n_features)`.
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Choosing `max_features < n_features` leads to a reduction of variance
+        and an increase in bias.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
     verbose : int, default: 0
         Enable verbose output. If 1 then it prints progress and performance
         once in a while (the more trees the lower the frequency). If greater
         than 1 then it prints progress and performance for every tree.
 
+    max_leaf_nodes : int or None, optional (default=None)
+        Grow trees with ``max_leaf_nodes`` in best-first fashion.
+        Best nodes are defined as relative reduction in impurity.
+        If None then unlimited number of leaf nodes.
+
     warm_start : bool, default: False
         When set to ``True``, reuse the solution of the previous call to fit
         and add more estimators to the ensemble, otherwise, just erase the
         previous solution. See :term:`the Glossary <warm_start>`.
 
-    random_state : int, RandomState instance or None, optional (default=None)
-        If int, random_state is the seed used by the random number generator;
-        If RandomState instance, random_state is the random number generator;
-        If None, the random number generator is the RandomState instance used
-        by `np.random`.
-
     presort : bool or 'auto', optional (default='auto')
         Whether to presort the data to speed up the finding of best splits in
         fitting. Auto mode by default will use presorting on dense data and
@@ -1476,16 +1881,16 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
 
         .. versionadded:: 0.20
 
-    feature_importances_ : array, shape = [n_features]
+    feature_importances_ : array, shape (n_features,)
         The feature importances (the higher, the more important the feature).
 
-    oob_improvement_ : array, shape = [n_estimators]
+    oob_improvement_ : array, shape (n_estimators,)
         The improvement in loss (= deviance) on the out-of-bag samples
         relative to the previous iteration.
         ``oob_improvement_[0]`` is the improvement in
         loss of the first stage over the ``init`` estimator.
 
-    train_score_ : array, shape = [n_estimators]
+    train_score_ : array, shape (n_estimators,)
         The i-th score ``train_score_[i]`` is the deviance (= loss) of the
         model at iteration ``i`` on the in-bag sample.
         If ``subsample == 1`` this is the deviance on the training data.
@@ -1497,7 +1902,8 @@ class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):
         The estimator that provides the initial predictions.
         Set via the ``init`` argument or ``loss.init_estimator``.
 
-    estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, ``loss_.K``]
+    estimators_ : ndarray of DecisionTreeRegressor,\
+shape (n_estimators, ``loss_.K``)
         The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary
         classification, otherwise n_classes.
 
@@ -1570,14 +1976,14 @@ def decision_function(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        score : array, shape = [n_samples, n_classes] or [n_samples]
+        score : array, shape (n_samples, n_classes) or (n_samples,)
             The decision function of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
             Regression and binary classification produce an array of shape
@@ -1597,14 +2003,14 @@ def staged_decision_function(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        score : generator of array, shape = [n_samples, k]
+        score : generator of array, shape (n_samples, k)
             The decision function of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
             Regression and binary classification are special cases with
@@ -1619,14 +2025,14 @@ def predict(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        y : array of shape = [n_samples]
+        y : array, shape (n_samples,)
             The predicted values.
         """
         score = self.decision_function(X)
@@ -1641,14 +2047,14 @@ def staged_predict(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        y : generator of array of shape = [n_samples]
+        y : generator of array of shape (n_samples,)
             The predicted value of the input samples.
         """
         for score in self._staged_decision_function(X):
@@ -1660,7 +2066,7 @@ def predict_proba(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
@@ -1672,7 +2078,7 @@ def predict_proba(self, X):
 
         Returns
         -------
-        p : array of shape = [n_samples, n_classes]
+        p : array, shape (n_samples, n_classes)
             The class probabilities of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
         """
@@ -1690,7 +2096,7 @@ def predict_log_proba(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
@@ -1702,7 +2108,7 @@ def predict_log_proba(self, X):
 
         Returns
         -------
-        p : array of shape = [n_samples, n_classes]
+        p : array, shape (n_samples, n_classes)
             The class log-probabilities of the input samples. The order of the
             classes corresponds to that in the attribute `classes_`.
         """
@@ -1717,14 +2123,14 @@ def staged_predict_proba(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        y : generator of array of shape = [n_samples]
+        y : generator of array of shape (n_samples,)
             The predicted value of the input samples.
         """
         try:
@@ -1765,11 +2171,12 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
         is fairly robust to over-fitting so a large number usually
         results in better performance.
 
-    max_depth : integer, optional (default=3)
-        maximum depth of the individual regression estimators. The maximum
-        depth limits the number of nodes in the tree. Tune this parameter
-        for best performance; the best value depends on the interaction
-        of the input variables.
+    subsample : float, optional (default=1.0)
+        The fraction of samples to be used for fitting the individual base
+        learners. If smaller than 1.0 this results in Stochastic Gradient
+        Boosting. `subsample` interacts with the parameter `n_estimators`.
+        Choosing `subsample < 1.0` leads to a reduction of variance
+        and an increase in bias.
 
     criterion : string, optional (default="friedman_mse")
         The function to measure the quality of a split. Supported criteria
@@ -1808,45 +2215,11 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
         the input samples) required to be at a leaf node. Samples have
         equal weight when sample_weight is not provided.
 
-    subsample : float, optional (default=1.0)
-        The fraction of samples to be used for fitting the individual base
-        learners. If smaller than 1.0 this results in Stochastic Gradient
-        Boosting. `subsample` interacts with the parameter `n_estimators`.
-        Choosing `subsample < 1.0` leads to a reduction of variance
-        and an increase in bias.
-
-    max_features : int, float, string or None, optional (default=None)
-        The number of features to consider when looking for the best split:
-
-        - If int, then consider `max_features` features at each split.
-        - If float, then `max_features` is a fraction and
-          `int(max_features * n_features)` features are considered at each
-          split.
-        - If "auto", then `max_features=n_features`.
-        - If "sqrt", then `max_features=sqrt(n_features)`.
-        - If "log2", then `max_features=log2(n_features)`.
-        - If None, then `max_features=n_features`.
-
-        Choosing `max_features < n_features` leads to a reduction of variance
-        and an increase in bias.
-
-        Note: the search for a split does not stop until at least one
-        valid partition of the node samples is found, even if it requires to
-        effectively inspect more than ``max_features`` features.
-
-    max_leaf_nodes : int or None, optional (default=None)
-        Grow trees with ``max_leaf_nodes`` in best-first fashion.
-        Best nodes are defined as relative reduction in impurity.
-        If None then unlimited number of leaf nodes.
-
-    min_impurity_split : float,
-        Threshold for early stopping in tree growth. A node will split
-        if its impurity is above the threshold, otherwise it is a leaf.
-
-        .. deprecated:: 0.19
-           ``min_impurity_split`` has been deprecated in favor of
-           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
-           Use ``min_impurity_decrease`` instead.
+    max_depth : integer, optional (default=3)
+        maximum depth of the individual regression estimators. The maximum
+        depth limits the number of nodes in the tree. Tune this parameter
+        for best performance; the best value depends on the interaction
+        of the input variables.
 
     min_impurity_decrease : float, optional (default=0.)
         A node will be split if this split induces a decrease of the impurity
@@ -1866,31 +2239,64 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
 
         .. versionadded:: 0.19
 
-    alpha : float (default=0.9)
-        The alpha-quantile of the huber loss function and the quantile
-        loss function. Only if ``loss='huber'`` or ``loss='quantile'``.
+    min_impurity_split : float,
+        Threshold for early stopping in tree growth. A node will split
+        if its impurity is above the threshold, otherwise it is a leaf.
+
+        .. deprecated:: 0.19
+           ``min_impurity_split`` has been deprecated in favor of
+           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.
+           Use ``min_impurity_decrease`` instead.
 
     init : estimator, optional (default=None)
         An estimator object that is used to compute the initial
         predictions. ``init`` has to provide ``fit`` and ``predict``.
         If None it uses ``loss.init_estimator``.
 
+    random_state : int, RandomState instance or None, optional (default=None)
+        If int, random_state is the seed used by the random number generator;
+        If RandomState instance, random_state is the random number generator;
+        If None, the random number generator is the RandomState instance used
+        by `np.random`.
+
+    max_features : int, float, string or None, optional (default=None)
+        The number of features to consider when looking for the best split:
+
+        - If int, then consider `max_features` features at each split.
+        - If float, then `max_features` is a fraction and
+          `int(max_features * n_features)` features are considered at each
+          split.
+        - If "auto", then `max_features=n_features`.
+        - If "sqrt", then `max_features=sqrt(n_features)`.
+        - If "log2", then `max_features=log2(n_features)`.
+        - If None, then `max_features=n_features`.
+
+        Choosing `max_features < n_features` leads to a reduction of variance
+        and an increase in bias.
+
+        Note: the search for a split does not stop until at least one
+        valid partition of the node samples is found, even if it requires to
+        effectively inspect more than ``max_features`` features.
+
+    alpha : float (default=0.9)
+        The alpha-quantile of the huber loss function and the quantile
+        loss function. Only if ``loss='huber'`` or ``loss='quantile'``.
+
     verbose : int, default: 0
         Enable verbose output. If 1 then it prints progress and performance
         once in a while (the more trees the lower the frequency). If greater
         than 1 then it prints progress and performance for every tree.
 
+    max_leaf_nodes : int or None, optional (default=None)
+        Grow trees with ``max_leaf_nodes`` in best-first fashion.
+        Best nodes are defined as relative reduction in impurity.
+        If None then unlimited number of leaf nodes.
+
     warm_start : bool, default: False
         When set to ``True``, reuse the solution of the previous call to fit
         and add more estimators to the ensemble, otherwise, just erase the
         previous solution. See :term:`the Glossary <warm_start>`.
 
-    random_state : int, RandomState instance or None, optional (default=None)
-        If int, random_state is the seed used by the random number generator;
-        If RandomState instance, random_state is the random number generator;
-        If None, the random number generator is the RandomState instance used
-        by `np.random`.
-
     presort : bool or 'auto', optional (default='auto')
         Whether to presort the data to speed up the finding of best splits in
         fitting. Auto mode by default will use presorting on dense data and
@@ -1928,16 +2334,16 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
 
     Attributes
     ----------
-    feature_importances_ : array, shape = [n_features]
+    feature_importances_ : array, shape (n_features,)
         The feature importances (the higher, the more important the feature).
 
-    oob_improvement_ : array, shape = [n_estimators]
+    oob_improvement_ : array, shape (n_estimators,)
         The improvement in loss (= deviance) on the out-of-bag samples
         relative to the previous iteration.
         ``oob_improvement_[0]`` is the improvement in
         loss of the first stage over the ``init`` estimator.
 
-    train_score_ : array, shape = [n_estimators]
+    train_score_ : array, shape (n_estimators,)
         The i-th score ``train_score_[i]`` is the deviance (= loss) of the
         model at iteration ``i`` on the in-bag sample.
         If ``subsample == 1`` this is the deviance on the training data.
@@ -1949,7 +2355,7 @@ class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):
         The estimator that provides the initial predictions.
         Set via the ``init`` argument or ``loss.init_estimator``.
 
-    estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, 1]
+    estimators_ : array of DecisionTreeRegressor, shape (n_estimators, 1)
         The collection of fitted sub-estimators.
 
     Notes
@@ -2006,14 +2412,14 @@ def predict(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        y : array of shape = [n_samples]
+        y : array, shape (n_samples,)
             The predicted values.
         """
         X = check_array(X, dtype=DTYPE, order="C",  accept_sparse='csr')
@@ -2027,14 +2433,14 @@ def staged_predict(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, it will be converted to
             ``dtype=np.float32`` and if a sparse matrix is provided
             to a sparse ``csr_matrix``.
 
         Returns
         -------
-        y : generator of array of shape = [n_samples]
+        y : generator of array of shape (n_samples,)
             The predicted value of the input samples.
         """
         for y in self._staged_decision_function(X):
@@ -2047,14 +2453,14 @@ def apply(self, X):
 
         Parameters
         ----------
-        X : array-like or sparse matrix, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input samples. Internally, its dtype will be converted to
             ``dtype=np.float32``. If a sparse matrix is provided, it will
             be converted to a sparse ``csr_matrix``.
 
         Returns
         -------
-        X_leaves : array_like, shape = [n_samples, n_estimators]
+        X_leaves : array-like, shape (n_samples, n_estimators)
             For each datapoint x in X and for each tree in the ensemble,
             return the index of the leaf x ends up in each estimator.
         """
diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py
index a1eb7ccd286b..eafdcbe9de1c 100644
--- a/sklearn/ensemble/iforest.py
+++ b/sklearn/ensemble/iforest.py
@@ -70,6 +70,10 @@ class IsolationForest(BaseBagging, OutlierMixin):
         on the decision function. If 'auto', the decision function threshold is
         determined as in the original paper.
 
+        .. versionchanged:: 0.20
+           The default value of ``contamination`` will change from 0.1 in 0.20
+           to ``'auto'`` in 0.22.
+
     max_features : int or float, optional (default=1.0)
         The number of features to draw from X to train each base estimator.
 
@@ -150,12 +154,6 @@ def __init__(self,
             n_jobs=n_jobs,
             random_state=random_state,
             verbose=verbose)
-
-        if contamination == "legacy":
-            warnings.warn('default contamination parameter 0.1 will change '
-                          'in version 0.22 to "auto". This will change the '
-                          'predict method behavior.',
-                          DeprecationWarning)
         self.contamination = contamination
 
     def _set_oob_score(self, X, y):
@@ -178,6 +176,15 @@ def fit(self, X, y=None, sample_weight=None):
         -------
         self : object
         """
+        if self.contamination == "legacy":
+            warnings.warn('default contamination parameter 0.1 will change '
+                          'in version 0.22 to "auto". This will change the '
+                          'predict method behavior.',
+                          FutureWarning)
+            self._contamination = 0.1
+        else:
+            self._contamination = self.contamination
+
         X = check_array(X, accept_sparse=['csc'])
         if issparse(X):
             # Pre-sort indices to avoid that each individual tree of the
@@ -219,19 +226,16 @@ def fit(self, X, y=None, sample_weight=None):
                                           max_depth=max_depth,
                                           sample_weight=sample_weight)
 
-        if self.contamination == "auto":
+        if self._contamination == "auto":
             # 0.5 plays a special role as described in the original paper.
             # we take the opposite as we consider the opposite of their score.
             self.offset_ = -0.5
             # need to save (depreciated) threshold_ in this case:
             self._threshold_ = sp.stats.scoreatpercentile(
                 self.score_samples(X), 100. * 0.1)
-        elif self.contamination == "legacy":  # to be rm in 0.22
-            self.offset_ = sp.stats.scoreatpercentile(
-                self.score_samples(X), 100. * 0.1)
         else:
             self.offset_ = sp.stats.scoreatpercentile(
-                self.score_samples(X), 100. * self.contamination)
+                self.score_samples(X), 100. * self._contamination)
 
         return self
 
diff --git a/sklearn/ensemble/partial_dependence.py b/sklearn/ensemble/partial_dependence.py
index e8bfc2110bb9..3c1d91c8639f 100644
--- a/sklearn/ensemble/partial_dependence.py
+++ b/sklearn/ensemble/partial_dependence.py
@@ -10,7 +10,7 @@
 from scipy.stats.mstats import mquantiles
 
 from ..utils.extmath import cartesian
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals import six
 from ..externals.six.moves import map, range, zip
 from ..utils import check_array
@@ -198,11 +198,11 @@ def plot_partial_dependence(gbrt, X, features, feature_names=None,
         Only if gbrt is a multi-class model. Must be in ``gbrt.classes_``.
     n_cols : int
         The number of columns in the grid plot (default: 3).
+    grid_resolution : int, default=100
+        The number of equally spaced points on the axes.
     percentiles : (low, high), default=(0.05, 0.95)
         The lower and upper percentile used to create the extreme values
         for the PDP axes.
-    grid_resolution : int, default=100
-        The number of equally spaced points on the axes.
     n_jobs : int
         The number of CPUs to use to compute the PDs. -1 means 'all CPUs'.
         Defaults to 1.
@@ -216,7 +216,7 @@ def plot_partial_dependence(gbrt, X, features, feature_names=None,
     contour_kw : dict
         Dict with keywords passed to the ``matplotlib.pyplot.plot`` call.
         For two-way partial dependence plots.
-    fig_kw : dict
+    **fig_kw : dict
         Dict with keywords passed to the figure() call.
         Note that all keywords not recognized above will be automatically
         included here.
diff --git a/sklearn/ensemble/tests/test_bagging.py b/sklearn/ensemble/tests/test_bagging.py
index 626b34f58e5a..396bda20159f 100644
--- a/sklearn/ensemble/tests/test_bagging.py
+++ b/sklearn/ensemble/tests/test_bagging.py
@@ -5,6 +5,7 @@
 # Author: Gilles Louppe
 # License: BSD 3 clause
 
+import pytest
 import numpy as np
 
 from sklearn.base import BaseEstimator
@@ -33,7 +34,7 @@
 from sklearn.model_selection import train_test_split
 from sklearn.datasets import load_boston, load_iris, make_hastie_10_2
 from sklearn.utils import check_random_state
-from sklearn.preprocessing import Imputer
+from sklearn.preprocessing import FunctionTransformer
 
 from scipy.sparse import csc_matrix, csr_matrix
 
@@ -496,6 +497,7 @@ def test_parallel_regression():
     assert_array_almost_equal(y1, y3)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch():
     # Check that bagging ensembles can be grid-searched.
     # Transform iris into a binary classification task
@@ -755,6 +757,12 @@ def test_set_oob_score_label_encoding():
     assert_equal([x1, x2], [x3, x3])
 
 
+def replace(X):
+    X = X.copy().astype('float')
+    X[~np.isfinite(X)] = 0
+    return X
+
+
 def test_bagging_regressor_with_missing_inputs():
     # Check that BaggingRegressor can accept X with missing/infinite data
     X = np.array([
@@ -777,9 +785,7 @@ def test_bagging_regressor_with_missing_inputs():
     for y in y_values:
         regressor = DecisionTreeRegressor()
         pipeline = make_pipeline(
-            Imputer(),
-            Imputer(missing_values=np.inf),
-            Imputer(missing_values=np.NINF),
+            FunctionTransformer(replace, validate=False),
             regressor
         )
         pipeline.fit(X, y).predict(X)
@@ -807,9 +813,7 @@ def test_bagging_classifier_with_missing_inputs():
     y = np.array([3, 6, 6, 6, 6])
     classifier = DecisionTreeClassifier()
     pipeline = make_pipeline(
-        Imputer(),
-        Imputer(missing_values=np.inf),
-        Imputer(missing_values=np.NINF),
+        FunctionTransformer(replace, validate=False),
         classifier
     )
     pipeline.fit(X, y).predict(X)
diff --git a/sklearn/ensemble/tests/test_forest.py b/sklearn/ensemble/tests/test_forest.py
index 0054707ba5a0..cd7626b74759 100644
--- a/sklearn/ensemble/tests/test_forest.py
+++ b/sklearn/ensemble/tests/test_forest.py
@@ -31,6 +31,7 @@
 from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import assert_warns
 from sklearn.utils.testing import assert_warns_message
+from sklearn.utils.testing import assert_no_warnings
 from sklearn.utils.testing import ignore_warnings
 
 from sklearn import datasets
@@ -186,6 +187,7 @@ def check_regressor_attributes(name):
     assert_false(hasattr(r, "n_classes_"))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_REGRESSORS)
 def test_regressor_attributes(name):
     check_regressor_attributes(name)
@@ -432,17 +434,18 @@ def check_oob_score_raise_error(name):
                                                   bootstrap=False).fit, X, y)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_ESTIMATORS)
 def test_oob_score_raise_error(name):
     check_oob_score_raise_error(name)
 
-
 def check_gridsearch(name):
     forest = FOREST_CLASSIFIERS[name]()
     clf = GridSearchCV(forest, {'n_estimators': (1, 2), 'max_depth': (1, 2)})
     clf.fit(iris.data, iris.target)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS)
 def test_gridsearch(name):
     # Check that base trees can be grid-searched.
@@ -489,6 +492,7 @@ def check_pickle(name, X, y):
     assert_equal(score, score2)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS_REGRESSORS)
 def test_pickle(name):
     if name in FOREST_CLASSIFIERS:
@@ -526,6 +530,7 @@ def check_multioutput(name):
             assert_equal(log_proba[1].shape, (4, 4))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS_REGRESSORS)
 def test_multioutput(name):
     check_multioutput(name)
@@ -549,6 +554,7 @@ def check_classes_shape(name):
     assert_array_equal(clf.classes_, [[-1, 1], [-2, 2]])
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS)
 def test_classes_shape(name):
     check_classes_shape(name)
@@ -738,6 +744,7 @@ def check_min_samples_split(name):
                    "Failed with {0}".format(name))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_ESTIMATORS)
 def test_min_samples_split(name):
     check_min_samples_split(name)
@@ -775,6 +782,7 @@ def check_min_samples_leaf(name):
                    "Failed with {0}".format(name))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_ESTIMATORS)
 def test_min_samples_leaf(name):
     check_min_samples_leaf(name)
@@ -842,6 +850,7 @@ def check_sparse_input(name, X, X_sparse, y):
                                   dense.fit_transform(X).toarray())
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_ESTIMATORS)
 @pytest.mark.parametrize('sparse_matrix',
                          (csr_matrix, csc_matrix, coo_matrix))
@@ -899,6 +908,7 @@ def check_memory_layout(name, dtype):
     assert_array_almost_equal(est.fit(X, y).predict(X), y)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS_REGRESSORS)
 @pytest.mark.parametrize('dtype', (np.float64, np.float32))
 def test_memory_layout(name, dtype):
@@ -977,6 +987,7 @@ def check_class_weights(name):
     clf.fit(iris.data, iris.target, sample_weight=sample_weight)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS)
 def test_class_weights(name):
     check_class_weights(name)
@@ -996,6 +1007,7 @@ def check_class_weight_balanced_and_bootstrap_multi_output(name):
     clf.fit(X, _y)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS)
 def test_class_weight_balanced_and_bootstrap_multi_output(name):
     check_class_weight_balanced_and_bootstrap_multi_output(name)
@@ -1026,6 +1038,7 @@ def check_class_weight_errors(name):
     assert_raises(ValueError, clf.fit, X, _y)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 @pytest.mark.parametrize('name', FOREST_CLASSIFIERS)
 def test_class_weight_errors(name):
     check_class_weight_errors(name)
@@ -1163,6 +1176,7 @@ def test_warm_start_oob(name):
     check_warm_start_oob(name)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_dtype_convert(n_classes=15):
     classifier = RandomForestClassifier(random_state=0, bootstrap=False)
 
@@ -1201,6 +1215,7 @@ def test_decision_path(name):
     check_decision_path(name)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_min_impurity_split():
     # Test if min_impurity_split of base estimators is set
     # Regression test for #8006
@@ -1216,6 +1231,7 @@ def test_min_impurity_split():
             assert_equal(tree.min_impurity_split, 0.1)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_min_impurity_decrease():
     X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)
     all_estimators = [RandomForestClassifier, RandomForestRegressor,
@@ -1228,3 +1244,21 @@ def test_min_impurity_decrease():
             # Simply check if the parameter is passed on correctly. Tree tests
             # will suffice for the actual working of this param
             assert_equal(tree.min_impurity_decrease, 0.1)
+
+
+@pytest.mark.parametrize('forest',
+                         [RandomForestClassifier, RandomForestRegressor,
+                          ExtraTreesClassifier, ExtraTreesRegressor,
+                          RandomTreesEmbedding])
+def test_nestimators_future_warning(forest):
+    # FIXME: to be removed 0.22
+
+    # When n_estimators default value is used
+    msg_future = ("The default value of n_estimators will change from "
+                  "10 in version 0.20 to 100 in 0.22.")
+    est = forest()
+    est = assert_warns_message(FutureWarning, msg_future, est.fit, X, y)
+
+    # When n_estimators is a valid value not equal to the default
+    est = forest(n_estimators=100)
+    est = assert_no_warnings(est.fit, X, y)
diff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py
index 3833227ecfc2..bfeb689a78f0 100644
--- a/sklearn/ensemble/tests/test_iforest.py
+++ b/sklearn/ensemble/tests/test_iforest.py
@@ -62,6 +62,7 @@ def test_iforest():
                             **params).fit(X_train).predict(X_test)
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_iforest_sparse():
     """Check IForest for various parameter settings on sparse input."""
     rng = check_random_state(0)
@@ -89,6 +90,7 @@ def test_iforest_sparse():
             assert_array_equal(sparse_results, dense_results)
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_iforest_error():
     """Test that it gives proper exception on deficient input."""
     X = iris.data
@@ -127,6 +129,7 @@ def test_iforest_error():
     assert_raises(ValueError, IsolationForest().fit(X).predict, X[:, 1:])
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_recalculate_max_depth():
     """Check max_depth recalculation when max_samples is reset to n_samples"""
     X = iris.data
@@ -135,6 +138,7 @@ def test_recalculate_max_depth():
         assert_equal(est.max_depth, int(np.ceil(np.log2(X.shape[0]))))
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_max_samples_attribute():
     X = iris.data
     clf = IsolationForest().fit(X)
@@ -150,6 +154,7 @@ def test_max_samples_attribute():
     assert_equal(clf.max_samples_, 0.4*X.shape[0])
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_iforest_parallel_regression():
     """Check parallel regression."""
     rng = check_random_state(0)
@@ -174,6 +179,7 @@ def test_iforest_parallel_regression():
     assert_array_almost_equal(y1, y3)
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_iforest_performance():
     """Test Isolation Forest performs well"""
 
@@ -213,6 +219,7 @@ def test_iforest_works():
         assert_array_equal(pred, 6 * [1] + 2 * [-1])
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_max_samples_consistency():
     # Make sure validated max_samples in iforest and BaseBagging are identical
     X = iris.data
@@ -220,6 +227,7 @@ def test_max_samples_consistency():
     assert_equal(clf.max_samples_, clf._max_samples)
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_iforest_subsampled_features():
     # It tests non-regression for #5732 which failed at predict.
     rng = check_random_state(0)
@@ -244,6 +252,7 @@ def test_iforest_average_path_length():
                               [1., result_one, result_two], decimal=10)
 
 
+@pytest.mark.filterwarnings('ignore:default contamination')
 def test_score_samples():
     X_train = [[1, 1], [1, 2], [2, 1]]
     clf1 = IsolationForest(contamination=0.1).fit(X_train)
@@ -257,12 +266,15 @@ def test_score_samples():
 
 
 def test_deprecation():
-    assert_warns_message(DeprecationWarning,
+    X = [[0.0], [1.0]]
+    clf = IsolationForest()
+
+    assert_warns_message(FutureWarning,
                          'default contamination parameter 0.1 will change '
                          'in version 0.22 to "auto"',
-                         IsolationForest, )
-    X = [[0.0], [1.0]]
-    clf = IsolationForest().fit(X)
+                         clf.fit, X)
+
+    clf = IsolationForest(contamination='auto').fit(X)
     assert_warns_message(DeprecationWarning,
                          "threshold_ attribute is deprecated in 0.20 and will"
                          " be removed in 0.22.",
diff --git a/sklearn/ensemble/tests/test_partial_dependence.py b/sklearn/ensemble/tests/test_partial_dependence.py
index cec7efc46f03..5bdb563199eb 100644
--- a/sklearn/ensemble/tests/test_partial_dependence.py
+++ b/sklearn/ensemble/tests/test_partial_dependence.py
@@ -1,6 +1,7 @@
 """
 Testing for the partial dependence module.
 """
+import pytest
 
 import numpy as np
 from numpy.testing import assert_array_equal
@@ -103,6 +104,8 @@ def test_partial_dependecy_input():
     assert_raises(ValueError, partial_dependence, clf, [0], grid=grid)
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
+# matplotlib Python3.7 warning
 @if_matplotlib
 def test_plot_partial_dependence():
     # Test partial dependence plot function.
@@ -135,6 +138,8 @@ def test_plot_partial_dependence():
     assert all(ax.has_data for ax in axs)
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
+# matplotlib Python3.7 warning
 @if_matplotlib
 def test_plot_partial_dependence_input():
     # Test partial dependence plot function input checks.
@@ -170,6 +175,8 @@ def test_plot_partial_dependence_input():
                   clf, X, [{'foo': 'bar'}])
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
+# matplotlib Python3.7 warning
 @if_matplotlib
 def test_plot_partial_dependence_multiclass():
     # Test partial dependence plot function on multi-class input.
diff --git a/sklearn/ensemble/tests/test_voting_classifier.py b/sklearn/ensemble/tests/test_voting_classifier.py
index d5a8e055f5d4..f5bfdbd101be 100644
--- a/sklearn/ensemble/tests/test_voting_classifier.py
+++ b/sklearn/ensemble/tests/test_voting_classifier.py
@@ -1,6 +1,8 @@
 """Testing for the VotingClassifier"""
 
+import pytest
 import numpy as np
+
 from sklearn.utils.testing import assert_almost_equal, assert_array_equal
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_equal, assert_true, assert_false
@@ -74,6 +76,7 @@ def test_notfitted():
     assert_raise_message(NotFittedError, msg, eclf.predict_proba, X)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_majority_label_iris():
     """Check classification by majority label on dataset iris."""
     clf1 = LogisticRegression(random_state=123)
@@ -86,6 +89,7 @@ def test_majority_label_iris():
     assert_almost_equal(scores.mean(), 0.95, decimal=2)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_tie_situation():
     """Check voting classifier selects smaller class label in tie situation."""
     clf1 = LogisticRegression(random_state=123)
@@ -97,6 +101,7 @@ def test_tie_situation():
     assert_equal(eclf.fit(X, y).predict(X)[73], 1)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_weights_iris():
     """Check classification by average probabilities on dataset iris."""
     clf1 = LogisticRegression(random_state=123)
@@ -110,6 +115,7 @@ def test_weights_iris():
     assert_almost_equal(scores.mean(), 0.93, decimal=2)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_predict_on_toy_problem():
     """Manually check predicted class labels for toy dataset."""
     clf1 = LogisticRegression(random_state=123)
@@ -142,6 +148,7 @@ def test_predict_on_toy_problem():
     assert_equal(all(eclf.fit(X, y).predict(X)), all([1, 1, 1, 2, 2, 2]))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_predict_proba_on_toy_problem():
     """Calculate predicted probabilities on toy dataset."""
     clf1 = LogisticRegression(random_state=123)
@@ -209,6 +216,7 @@ def test_multilabel():
         return
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_gridsearch():
     """Check GridSearch support."""
     clf1 = LogisticRegression(random_state=1)
@@ -226,6 +234,7 @@ def test_gridsearch():
     grid.fit(iris.data, iris.target)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_parallel_fit():
     """Check parallel backend of VotingClassifier on toy dataset."""
     clf1 = LogisticRegression(random_state=123)
@@ -247,6 +256,7 @@ def test_parallel_fit():
     assert_array_almost_equal(eclf1.predict_proba(X), eclf2.predict_proba(X))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_sample_weight():
     """Tests sample_weight parameter of VotingClassifier"""
     clf1 = LogisticRegression(random_state=123)
@@ -290,6 +300,7 @@ def fit(self, X, y, *args, **sample_weight):
     eclf.fit(X, y, sample_weight=np.ones((len(y),)))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_set_params():
     """set_params should be able to set estimators"""
     clf1 = LogisticRegression(random_state=123, C=1.0)
@@ -324,6 +335,7 @@ def test_set_params():
                  eclf1.get_params()["lr"].get_params()['C'])
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_set_estimator_none():
     """VotingClassifier set_params should be able to set estimators as None"""
     # Test predict
@@ -359,10 +371,12 @@ def test_set_estimator_none():
     X1 = np.array([[1], [2]])
     y1 = np.array([1, 2])
     eclf1 = VotingClassifier(estimators=[('rf', clf2), ('nb', clf3)],
-                             voting='soft', weights=[0, 0.5]).fit(X1, y1)
+                             voting='soft', weights=[0, 0.5],
+                             flatten_transform=False).fit(X1, y1)
 
     eclf2 = VotingClassifier(estimators=[('rf', clf2), ('nb', clf3)],
-                             voting='soft', weights=[1, 0.5])
+                             voting='soft', weights=[1, 0.5],
+                             flatten_transform=False)
     eclf2.set_params(rf=None).fit(X1, y1)
     assert_array_almost_equal(eclf1.transform(X1),
                               np.array([[[0.7, 0.3], [0.3, 0.7]],
@@ -376,6 +390,7 @@ def test_set_estimator_none():
     assert_array_equal(eclf2.transform(X1), np.array([[0], [1]]))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_estimator_weights_format():
     # Test estimator weights inputs as list and array
     clf1 = LogisticRegression(random_state=123)
@@ -393,6 +408,7 @@ def test_estimator_weights_format():
     assert_array_almost_equal(eclf1.predict_proba(X), eclf2.predict_proba(X))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_transform():
     """Check transform method of VotingClassifier on toy dataset."""
     clf1 = LogisticRegression(random_state=123)
diff --git a/sklearn/ensemble/tests/test_weight_boosting.py b/sklearn/ensemble/tests/test_weight_boosting.py
index 4a8a806ed6a6..8a0beba2207f 100755
--- a/sklearn/ensemble/tests/test_weight_boosting.py
+++ b/sklearn/ensemble/tests/test_weight_boosting.py
@@ -1,6 +1,8 @@
 """Testing for the boost module (sklearn.ensemble.boost)."""
 
+import pytest
 import numpy as np
+
 from sklearn.utils.testing import assert_array_equal, assert_array_less
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_equal, assert_true, assert_greater
@@ -194,6 +196,7 @@ def test_staged_predict():
     assert_array_almost_equal(score, staged_scores[-1])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch():
     # Check that base trees can be grid-searched.
     # AdaBoost classification
@@ -277,6 +280,7 @@ def test_error():
                   X, y_class, sample_weight=np.asarray([-1]))
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_base_estimator():
     # Test different base estimators.
     from sklearn.ensemble import RandomForestClassifier
diff --git a/sklearn/ensemble/voting_classifier.py b/sklearn/ensemble/voting_classifier.py
index 2b0d63d2140b..7ce8bcd80aa4 100644
--- a/sklearn/ensemble/voting_classifier.py
+++ b/sklearn/ensemble/voting_classifier.py
@@ -18,7 +18,7 @@
 from ..base import TransformerMixin
 from ..base import clone
 from ..preprocessing import LabelEncoder
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..utils.validation import has_fit_parameter, check_is_fitted
 from ..utils.metaestimators import _BaseComposition
 from ..utils import Bunch
@@ -91,7 +91,7 @@ class VotingClassifier(_BaseComposition, ClassifierMixin, TransformerMixin):
     >>> from sklearn.naive_bayes import GaussianNB
     >>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier
     >>> clf1 = LogisticRegression(random_state=1)
-    >>> clf2 = RandomForestClassifier(random_state=1)
+    >>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)
     >>> clf3 = GaussianNB()
     >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
     >>> y = np.array([1, 1, 1, 2, 2, 2])
@@ -319,7 +319,7 @@ def set_params(self, **params):
 
         Parameters
         ----------
-        params : keyword arguments
+        **params : keyword arguments
             Specific parameters using e.g. set_params(parameter_name=new_value)
             In addition, to setting the parameters of the ``VotingClassifier``,
             the individual classifiers of the ``VotingClassifier`` can also be
@@ -342,7 +342,7 @@ def get_params(self, deep=True):
 
         Parameters
         ----------
-        deep: bool
+        deep : bool
             Setting it to True gets the various classifiers and the parameters
             of the classifiers as well
         """
diff --git a/sklearn/externals/copy_joblib.sh b/sklearn/externals/copy_joblib.sh
index 8db0da232c64..878413297759 100755
--- a/sklearn/externals/copy_joblib.sh
+++ b/sklearn/externals/copy_joblib.sh
@@ -12,14 +12,14 @@ else
 fi
 
 pip install $JOBLIB --target $INSTALL_FOLDER
-cp -r $INSTALL_FOLDER/joblib _joblib
+cp -r $INSTALL_FOLDER/joblib joblib
 rm -rf $INSTALL_FOLDER
 
 # Needed to rewrite the doctests
 # Note: BSD sed -i needs an argument unders OSX
 # so first renaming to .bak and then deleting backup files
-find _joblib -name "*.py" | xargs sed -i.bak "s/from joblib/from sklearn.externals.joblib/"
-find _joblib -name "*.bak" | xargs rm
+find joblib -name "*.py" | xargs sed -i.bak "s/from joblib/from sklearn.externals.joblib/"
+find joblib -name "*.bak" | xargs rm
 
 # Remove the tests folders to speed-up test time for scikit-learn.
 # joblib is already tested on its own CI infrastructure upstream.
diff --git a/sklearn/externals/_joblib/__init__.py b/sklearn/externals/joblib/__init__.py
similarity index 97%
rename from sklearn/externals/_joblib/__init__.py
rename to sklearn/externals/joblib/__init__.py
index 3455b7d79b51..6561afbc211d 100644
--- a/sklearn/externals/_joblib/__init__.py
+++ b/sklearn/externals/joblib/__init__.py
@@ -58,7 +58,7 @@
    inputs and  outputs: Python functions. Joblib can save their
    computation to disk and rerun it only if necessary::
 
-      >>> from sklearn.externals.joblib import Memory
+      >>> from sklearn.utils import Memory
       >>> mem = Memory(cachedir='/tmp/joblib')
       >>> import numpy as np
       >>> a = np.vander(np.arange(3)).astype(np.float)
@@ -77,7 +77,7 @@
 2) **Embarrassingly parallel helper:** to make it easy to write readable
    parallel code and debug it quickly::
 
-      >>> from sklearn.externals.joblib import Parallel, delayed
+      >>> from sklearn.utils import Parallel, delayed
       >>> from math import sqrt
       >>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))
       [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
diff --git a/sklearn/externals/_joblib/_compat.py b/sklearn/externals/joblib/_compat.py
similarity index 100%
rename from sklearn/externals/_joblib/_compat.py
rename to sklearn/externals/joblib/_compat.py
diff --git a/sklearn/externals/_joblib/_memory_helpers.py b/sklearn/externals/joblib/_memory_helpers.py
similarity index 100%
rename from sklearn/externals/_joblib/_memory_helpers.py
rename to sklearn/externals/joblib/_memory_helpers.py
diff --git a/sklearn/externals/_joblib/_multiprocessing_helpers.py b/sklearn/externals/joblib/_multiprocessing_helpers.py
similarity index 100%
rename from sklearn/externals/_joblib/_multiprocessing_helpers.py
rename to sklearn/externals/joblib/_multiprocessing_helpers.py
diff --git a/sklearn/externals/_joblib/_parallel_backends.py b/sklearn/externals/joblib/_parallel_backends.py
similarity index 100%
rename from sklearn/externals/_joblib/_parallel_backends.py
rename to sklearn/externals/joblib/_parallel_backends.py
diff --git a/sklearn/externals/_joblib/backports.py b/sklearn/externals/joblib/backports.py
similarity index 100%
rename from sklearn/externals/_joblib/backports.py
rename to sklearn/externals/joblib/backports.py
diff --git a/sklearn/externals/_joblib/disk.py b/sklearn/externals/joblib/disk.py
similarity index 100%
rename from sklearn/externals/_joblib/disk.py
rename to sklearn/externals/joblib/disk.py
diff --git a/sklearn/externals/_joblib/format_stack.py b/sklearn/externals/joblib/format_stack.py
similarity index 100%
rename from sklearn/externals/_joblib/format_stack.py
rename to sklearn/externals/joblib/format_stack.py
diff --git a/sklearn/externals/_joblib/func_inspect.py b/sklearn/externals/joblib/func_inspect.py
similarity index 100%
rename from sklearn/externals/_joblib/func_inspect.py
rename to sklearn/externals/joblib/func_inspect.py
diff --git a/sklearn/externals/_joblib/hashing.py b/sklearn/externals/joblib/hashing.py
similarity index 100%
rename from sklearn/externals/_joblib/hashing.py
rename to sklearn/externals/joblib/hashing.py
diff --git a/sklearn/externals/_joblib/logger.py b/sklearn/externals/joblib/logger.py
similarity index 100%
rename from sklearn/externals/_joblib/logger.py
rename to sklearn/externals/joblib/logger.py
diff --git a/sklearn/externals/_joblib/memory.py b/sklearn/externals/joblib/memory.py
similarity index 100%
rename from sklearn/externals/_joblib/memory.py
rename to sklearn/externals/joblib/memory.py
diff --git a/sklearn/externals/_joblib/my_exceptions.py b/sklearn/externals/joblib/my_exceptions.py
similarity index 100%
rename from sklearn/externals/_joblib/my_exceptions.py
rename to sklearn/externals/joblib/my_exceptions.py
diff --git a/sklearn/externals/_joblib/numpy_pickle.py b/sklearn/externals/joblib/numpy_pickle.py
similarity index 100%
rename from sklearn/externals/_joblib/numpy_pickle.py
rename to sklearn/externals/joblib/numpy_pickle.py
diff --git a/sklearn/externals/_joblib/numpy_pickle_compat.py b/sklearn/externals/joblib/numpy_pickle_compat.py
similarity index 100%
rename from sklearn/externals/_joblib/numpy_pickle_compat.py
rename to sklearn/externals/joblib/numpy_pickle_compat.py
diff --git a/sklearn/externals/_joblib/numpy_pickle_utils.py b/sklearn/externals/joblib/numpy_pickle_utils.py
similarity index 100%
rename from sklearn/externals/_joblib/numpy_pickle_utils.py
rename to sklearn/externals/joblib/numpy_pickle_utils.py
diff --git a/sklearn/externals/_joblib/parallel.py b/sklearn/externals/joblib/parallel.py
similarity index 98%
rename from sklearn/externals/_joblib/parallel.py
rename to sklearn/externals/joblib/parallel.py
index 6f2091d91fad..96c90423e636 100644
--- a/sklearn/externals/_joblib/parallel.py
+++ b/sklearn/externals/joblib/parallel.py
@@ -384,7 +384,7 @@ class Parallel(Logger):
         A simple example:
 
         >>> from math import sqrt
-        >>> from sklearn.externals.joblib import Parallel, delayed
+        >>> from sklearn.utils import Parallel, delayed
         >>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))
         [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
 
@@ -392,7 +392,7 @@ class Parallel(Logger):
         values:
 
         >>> from math import modf
-        >>> from sklearn.externals.joblib import Parallel, delayed
+        >>> from sklearn.utils import Parallel, delayed
         >>> r = Parallel(n_jobs=1)(delayed(modf)(i/2.) for i in range(10))
         >>> res, i = zip(*r)
         >>> res
@@ -404,7 +404,7 @@ class Parallel(Logger):
         messages:
 
         >>> from time import sleep
-        >>> from sklearn.externals.joblib import Parallel, delayed
+        >>> from sklearn.utils import Parallel, delayed
         >>> r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(10)) #doctest: +SKIP
         [Parallel(n_jobs=2)]: Done   1 out of  10 | elapsed:    0.1s remaining:    0.9s
         [Parallel(n_jobs=2)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.5s
@@ -418,7 +418,7 @@ class Parallel(Logger):
         child process:
 
         >>> from heapq import nlargest
-        >>> from sklearn.externals.joblib import Parallel, delayed
+        >>> from sklearn.utils import Parallel, delayed
         >>> Parallel(n_jobs=2)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) #doctest: +SKIP
         #...
         ---------------------------------------------------------------------------
@@ -449,7 +449,7 @@ class Parallel(Logger):
         number of iterations cannot be reported in the progress messages:
 
         >>> from math import sqrt
-        >>> from sklearn.externals.joblib import Parallel, delayed
+        >>> from sklearn.utils import Parallel, delayed
         >>> def producer():
         ...     for i in range(6):
         ...         print('Produced %s' % i)
diff --git a/sklearn/externals/_joblib/pool.py b/sklearn/externals/joblib/pool.py
similarity index 100%
rename from sklearn/externals/_joblib/pool.py
rename to sklearn/externals/joblib/pool.py
diff --git a/sklearn/externals/setup.py b/sklearn/externals/setup.py
index d3869f3ed757..936f0327226d 100644
--- a/sklearn/externals/setup.py
+++ b/sklearn/externals/setup.py
@@ -4,6 +4,6 @@
 def configuration(parent_package='', top_path=None):
     from numpy.distutils.misc_util import Configuration
     config = Configuration('externals', parent_package, top_path)
-    config.add_subpackage('_joblib')
+    config.add_subpackage('joblib')
 
     return config
diff --git a/sklearn/feature_extraction/dict_vectorizer.py b/sklearn/feature_extraction/dict_vectorizer.py
index 3ab717d1cf29..d078a325b69a 100644
--- a/sklearn/feature_extraction/dict_vectorizer.py
+++ b/sklearn/feature_extraction/dict_vectorizer.py
@@ -3,7 +3,6 @@
 # License: BSD 3 clause
 
 from array import array
-from collections import Mapping
 from operator import itemgetter
 
 import numpy as np
@@ -13,6 +12,7 @@
 from ..externals import six
 from ..externals.six.moves import xrange
 from ..utils import check_array, tosequence
+from ..utils.fixes import _Mapping as Mapping
 
 
 def _tosequence(X):
diff --git a/sklearn/feature_extraction/tests/test_image.py b/sklearn/feature_extraction/tests/test_image.py
index dc9367980600..4908cbde5610 100644
--- a/sklearn/feature_extraction/tests/test_image.py
+++ b/sklearn/feature_extraction/tests/test_image.py
@@ -11,7 +11,8 @@
 from sklearn.feature_extraction.image import (
     img_to_graph, grid_to_graph, extract_patches_2d,
     reconstruct_from_patches_2d, PatchExtractor, extract_patches)
-from sklearn.utils.testing import assert_equal, assert_true, assert_raises
+from sklearn.utils.testing import (assert_equal, assert_true, assert_raises,
+                                   ignore_warnings)
 
 
 def test_img_to_graph():
@@ -55,6 +56,7 @@ def test_grid_to_graph():
     assert_true(A.dtype == np.float64)
 
 
+@ignore_warnings(category=DeprecationWarning)  # scipy deprecation inside face
 def test_connect_regions():
     try:
         face = sp.face(gray=True)
@@ -68,6 +70,7 @@ def test_connect_regions():
         assert_equal(ndimage.label(mask)[1], connected_components(graph)[0])
 
 
+@ignore_warnings(category=DeprecationWarning)  # scipy deprecation inside face
 def test_connect_regions_with_grid():
     try:
         face = sp.face(gray=True)
diff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py
index 9cbc7004a227..db7abc0e756e 100644
--- a/sklearn/feature_extraction/tests/test_text.py
+++ b/sklearn/feature_extraction/tests/test_text.py
@@ -4,6 +4,7 @@
 import pytest
 from scipy import sparse
 
+from sklearn.externals.six import PY2
 from sklearn.feature_extraction.text import strip_tags
 from sklearn.feature_extraction.text import strip_accents_unicode
 from sklearn.feature_extraction.text import strip_accents_ascii
@@ -31,10 +32,10 @@
                                    assert_in, assert_less, assert_greater,
                                    assert_warns_message, assert_raise_message,
                                    clean_warning_registry, ignore_warnings,
-                                   SkipTest, assert_raises,
+                                   SkipTest, assert_raises, assert_no_warnings,
                                    assert_allclose_dense_sparse)
-
-from collections import defaultdict, Mapping
+from sklearn.utils.fixes import _Mapping as Mapping
+from collections import defaultdict
 from functools import partial
 import pickle
 from io import StringIO
@@ -730,6 +731,7 @@ def test_vectorizer_inverse_transform(Vectorizer):
         assert_array_equal(np.sort(terms), np.sort(terms2))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_count_vectorizer_pipeline_grid_selection():
     # raw documents
     data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS
@@ -766,6 +768,7 @@ def test_count_vectorizer_pipeline_grid_selection():
     assert_equal(best_vectorizer.ngram_range, (1, 1))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_vectorizer_pipeline_grid_selection():
     # raw documents
     data = JUNK_FOOD_DOCS + NOTJUNK_FOOD_DOCS
@@ -1104,3 +1107,26 @@ def test_vectorizers_invalid_ngram_range(vec):
     if isinstance(vec, HashingVectorizer):
         assert_raise_message(
             ValueError, message, vec.transform, ["good news everyone"])
+
+
+def test_vectorizer_stop_words_inconsistent():
+    if PY2:
+        lstr = "[u'and', u'll', u've']"
+    else:
+        lstr = "['and', 'll', 've']"
+    message = ('Your stop_words may be inconsistent with your '
+               'preprocessing. Tokenizing the stop words generated '
+               'tokens %s not in stop_words.' % lstr)
+    for vec in [CountVectorizer(),
+                TfidfVectorizer(), HashingVectorizer()]:
+        vec.set_params(stop_words=["you've", "you", "you'll", 'AND'])
+        assert_warns_message(UserWarning, message, vec.fit_transform,
+                             ['hello world'])
+
+    # Only one warning per stop list
+    assert_no_warnings(vec.fit_transform, ['hello world'])
+
+    # Test caching of inconsistency assessment
+    vec.set_params(stop_words=["you've", "you", "you'll", 'blah', 'AND'])
+    assert_warns_message(UserWarning, message, vec.fit_transform,
+                         ['hello world'])
diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py
index 10a3d6f76cd9..05f60d2805c7 100644
--- a/sklearn/feature_extraction/text.py
+++ b/sklearn/feature_extraction/text.py
@@ -14,7 +14,7 @@
 from __future__ import unicode_literals, division
 
 import array
-from collections import Mapping, defaultdict
+from collections import defaultdict
 import numbers
 from operator import itemgetter
 import re
@@ -32,6 +32,8 @@
 from .stop_words import ENGLISH_STOP_WORDS
 from ..utils.validation import check_is_fitted, check_array, FLOAT_DTYPES
 from ..utils.fixes import sp_version
+from ..utils.fixes import _Mapping as Mapping  # noqa
+
 
 __all__ = ['CountVectorizer',
            'ENGLISH_STOP_WORDS',
@@ -266,6 +268,23 @@ def get_stop_words(self):
         """Build or fetch the effective stop words list"""
         return _check_stop_list(self.stop_words)
 
+    def _check_stop_words_consistency(self, stop_words, preprocess, tokenize):
+        # NB: stop_words is validated, unlike self.stop_words
+        if id(self.stop_words) != getattr(self, '_stop_words_id', None):
+            inconsistent = set()
+            for w in stop_words or ():
+                tokens = list(tokenize(preprocess(w)))
+                for token in tokens:
+                    if token not in stop_words:
+                        inconsistent.add(token)
+            self._stop_words_id = id(self.stop_words)
+
+            if inconsistent:
+                warnings.warn('Your stop_words may be inconsistent with your '
+                              'preprocessing. Tokenizing the stop words '
+                              'generated tokens %r not in stop_words.' %
+                              sorted(inconsistent))
+
     def build_analyzer(self):
         """Return a callable that handles preprocessing and tokenization"""
         if callable(self.analyzer):
@@ -283,7 +302,8 @@ def build_analyzer(self):
         elif self.analyzer == 'word':
             stop_words = self.get_stop_words()
             tokenize = self.build_tokenizer()
-
+            self._check_stop_words_consistency(stop_words, preprocess,
+                                               tokenize)
             return lambda doc: self._word_ngrams(
                 tokenize(preprocess(self.decode(doc))), stop_words)
 
@@ -425,6 +445,8 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
 
     stop_words : string {'english'}, list, or None (default)
         If 'english', a built-in stop word list for English is used.
+        There are several known issues with 'english' and you should
+        consider an alternative (see :ref:`stop_words`).
 
         If a list, that list is assumed to contain stop words, all of which
         will be removed from the resulting tokens.
@@ -479,6 +501,19 @@ class HashingVectorizer(BaseEstimator, VectorizerMixin, TransformerMixin):
     dtype : type, optional
         Type of the matrix returned by fit_transform() or transform().
 
+    Examples
+    --------
+    >>> from sklearn.feature_extraction.text import HashingVectorizer
+    >>> corpus = [
+    ...     'This is the first document.',
+    ...     'This document is the second document.',
+    ...     'And this is the third one.',
+    ...     'Is this the first document?',
+    ... ]
+    >>> vectorizer = HashingVectorizer(n_features=2**4)
+    >>> X = vectorizer.fit_transform(corpus)
+    >>> print(X.shape)
+    (4, 16)
 
     See also
     --------
@@ -667,6 +702,8 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):
 
     stop_words : string {'english'}, list, or None (default)
         If 'english', a built-in stop word list for English is used.
+        There are several known issues with 'english' and you should
+        consider an alternative (see :ref:`stop_words`).
 
         If a list, that list is assumed to contain stop words, all of which
         will be removed from the resulting tokens.
@@ -746,6 +783,25 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):
 
         This is only available if no vocabulary was given.
 
+    Examples
+    --------
+    >>> from sklearn.feature_extraction.text import CountVectorizer
+    >>> corpus = [
+    ...     'This is the first document.',
+    ...     'This document is the second document.',
+    ...     'And this is the third one.',
+    ...     'Is this the first document?',
+    ... ]
+    >>> vectorizer = CountVectorizer()
+    >>> X = vectorizer.fit_transform(corpus)
+    >>> print(vectorizer.get_feature_names())
+    ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']
+    >>> print(X.toarray())  # doctest: +NORMALIZE_WHITESPACE
+    [[0 1 1 1 0 0 1 0 1]
+     [0 2 0 1 0 1 1 0 1]
+     [1 0 0 1 1 0 1 1 1]
+     [0 1 1 1 0 0 1 0 1]]
+
     See also
     --------
     HashingVectorizer, TfidfVectorizer
@@ -1290,6 +1346,8 @@ class TfidfVectorizer(CountVectorizer):
         If a string, it is passed to _check_stop_list and the appropriate stop
         list is returned. 'english' is currently the only supported string
         value.
+        There are several known issues with 'english' and you should
+        consider an alternative (see :ref:`stop_words`).
 
         If a list, that list is assumed to contain stop words, all of which
         will be removed from the resulting tokens.
@@ -1377,6 +1435,22 @@ class TfidfVectorizer(CountVectorizer):
 
         This is only available if no vocabulary was given.
 
+    Examples
+    --------
+    >>> from sklearn.feature_extraction.text import TfidfVectorizer
+    >>> corpus = [
+    ...     'This is the first document.',
+    ...     'This document is the second document.',
+    ...     'And this is the third one.',
+    ...     'Is this the first document?',
+    ... ]
+    >>> vectorizer = TfidfVectorizer()
+    >>> X = vectorizer.fit_transform(corpus)
+    >>> print(vectorizer.get_feature_names())
+    ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']
+    >>> print(X.shape)
+    (4, 9)
+
     See also
     --------
     CountVectorizer
diff --git a/sklearn/feature_selection/base.py b/sklearn/feature_selection/base.py
index 3067d6ef31bc..5bb0b3ea890c 100644
--- a/sklearn/feature_selection/base.py
+++ b/sklearn/feature_selection/base.py
@@ -72,7 +72,7 @@ def transform(self, X):
         X_r : array of shape [n_samples, n_selected_features]
             The input samples with only the selected features.
         """
-        X = check_array(X, accept_sparse='csr')
+        X = check_array(X, dtype=None, accept_sparse='csr')
         mask = self.get_support()
         if not mask.any():
             warn("No features were selected: either the data is"
@@ -111,7 +111,7 @@ def inverse_transform(self, X):
             return Xt
 
         support = self.get_support()
-        X = check_array(X)
+        X = check_array(X, dtype=None)
         if support.sum() != X.shape[1]:
             raise ValueError("X has a different shape than during fitting.")
 
diff --git a/sklearn/feature_selection/from_model.py b/sklearn/feature_selection/from_model.py
index 657259f39ea1..f6f9c2776b78 100644
--- a/sklearn/feature_selection/from_model.py
+++ b/sklearn/feature_selection/from_model.py
@@ -2,6 +2,7 @@
 # License: BSD 3 clause
 
 import numpy as np
+import numbers
 
 from .base import SelectorMixin
 from ..base import BaseEstimator, clone, MetaEstimatorMixin
@@ -113,6 +114,13 @@ class SelectFromModel(BaseEstimator, SelectorMixin, MetaEstimatorMixin):
         ``threshold`` in the case where the ``coef_`` attribute of the
         estimator is of dimension 2.
 
+    max_features : int or None, optional
+        The maximum number of features selected scoring above ``threshold``.
+        To disable ``threshold`` and only select based on ``max_features``,
+        set ``threshold=-np.inf``.
+
+        .. versionadded:: 0.20
+
     Attributes
     ----------
     estimator_ : an estimator
@@ -123,11 +131,13 @@ class SelectFromModel(BaseEstimator, SelectorMixin, MetaEstimatorMixin):
     threshold_ : float
         The threshold value used for feature selection.
     """
-    def __init__(self, estimator, threshold=None, prefit=False, norm_order=1):
+    def __init__(self, estimator, threshold=None, prefit=False,
+                 norm_order=1, max_features=None):
         self.estimator = estimator
         self.threshold = threshold
         self.prefit = prefit
         self.norm_order = norm_order
+        self.max_features = max_features
 
     def _get_support_mask(self):
         # SelectFromModel can directly call on transform.
@@ -136,12 +146,20 @@ def _get_support_mask(self):
         elif hasattr(self, 'estimator_'):
             estimator = self.estimator_
         else:
-            raise ValueError(
-                'Either fit SelectFromModel before transform or set "prefit='
-                'True" and pass a fitted estimator to the constructor.')
+            raise ValueError('Either fit the model before transform or set'
+                             ' "prefit=True" while passing the fitted'
+                             ' estimator to the constructor.')
         scores = _get_feature_importances(estimator, self.norm_order)
         threshold = _calculate_threshold(estimator, scores, self.threshold)
-        return scores >= threshold
+        if self.max_features is not None:
+            mask = np.zeros_like(scores, dtype=bool)
+            candidate_indices = \
+                np.argsort(-scores, kind='mergesort')[:self.max_features]
+            mask[candidate_indices] = True
+        else:
+            mask = np.ones_like(scores, dtype=bool)
+        mask[scores < threshold] = False
+        return mask
 
     def fit(self, X, y=None, **fit_params):
         """Fit the SelectFromModel meta-transformer.
@@ -161,6 +179,16 @@ def fit(self, X, y=None, **fit_params):
         -------
         self : object
         """
+        if self.max_features is not None:
+            if not isinstance(self.max_features, numbers.Integral):
+                raise TypeError("'max_features' should be an integer between"
+                                " 0 and {} features. Got {!r} instead."
+                                .format(X.shape[1], self.max_features))
+            elif self.max_features < 0 or self.max_features > X.shape[1]:
+                raise ValueError("'max_features' should be 0 and {} features."
+                                 "Got {} instead."
+                                 .format(X.shape[1], self.max_features))
+
         if self.prefit:
             raise NotFittedError(
                 "Since 'prefit=True', call transform directly")
diff --git a/sklearn/feature_selection/rfe.py b/sklearn/feature_selection/rfe.py
index 84761451c8f2..31c0133b2c69 100644
--- a/sklearn/feature_selection/rfe.py
+++ b/sklearn/feature_selection/rfe.py
@@ -15,7 +15,7 @@
 from ..base import MetaEstimatorMixin
 from ..base import clone
 from ..base import is_classifier
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..model_selection import check_cv
 from ..model_selection._validation import _score
 from ..metrics.scorer import check_scoring
diff --git a/sklearn/feature_selection/tests/test_from_model.py b/sklearn/feature_selection/tests/test_from_model.py
index 6efec43dce37..e6bb76c5e19a 100644
--- a/sklearn/feature_selection/tests/test_from_model.py
+++ b/sklearn/feature_selection/tests/test_from_model.py
@@ -1,3 +1,4 @@
+import pytest
 import numpy as np
 
 from sklearn.utils.testing import assert_true
@@ -8,6 +9,7 @@
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_almost_equal
+from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_raises
 from sklearn.utils.testing import skip_if_32bit
 
@@ -17,6 +19,7 @@
 from sklearn.feature_selection import SelectFromModel
 from sklearn.ensemble import RandomForestClassifier
 from sklearn.linear_model import PassiveAggressiveClassifier
+from sklearn.base import BaseEstimator
 
 iris = datasets.load_iris()
 data, y = iris.data, iris.target
@@ -32,6 +35,7 @@ def test_invalid_input():
         assert_raises(ValueError, model.transform, data)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_input_estimator_unchanged():
     # Test that SelectFromModel fits on a clone of the estimator.
     est = RandomForestClassifier()
@@ -40,6 +44,121 @@ def test_input_estimator_unchanged():
     assert_true(transformer.estimator is est)
 
 
+@pytest.mark.parametrize(
+    "max_features, err_type, err_msg",
+    [(-1, ValueError, "'max_features' should be 0 and"),
+     (data.shape[1] + 1, ValueError, "'max_features' should be 0 and"),
+     ('gobbledigook', TypeError, "should be an integer"),
+     ('all', TypeError, "should be an integer")]
+)
+def test_max_features_error(max_features, err_type, err_msg):
+    clf = RandomForestClassifier(n_estimators=50, random_state=0)
+
+    transformer = SelectFromModel(estimator=clf,
+                                  max_features=max_features,
+                                  threshold=-np.inf)
+    with pytest.raises(err_type, match=err_msg):
+        transformer.fit(data, y)
+
+
+@pytest.mark.parametrize("max_features", [0, 2, data.shape[1]])
+def test_max_features_dim(max_features):
+    clf = RandomForestClassifier(n_estimators=50, random_state=0)
+    transformer = SelectFromModel(estimator=clf,
+                                  max_features=max_features,
+                                  threshold=-np.inf)
+    X_trans = transformer.fit_transform(data, y)
+    assert X_trans.shape[1] == max_features
+
+
+class FixedImportanceEstimator(BaseEstimator):
+    def __init__(self, importances):
+        self.importances = importances
+
+    def fit(self, X, y=None):
+        self.feature_importances_ = np.array(self.importances)
+
+
+def test_max_features():
+    # Test max_features parameter using various values
+    X, y = datasets.make_classification(
+        n_samples=1000, n_features=10, n_informative=3, n_redundant=0,
+        n_repeated=0, shuffle=False, random_state=0)
+    max_features = X.shape[1]
+    est = RandomForestClassifier(n_estimators=50, random_state=0)
+
+    transformer1 = SelectFromModel(estimator=est,
+                                   threshold=-np.inf)
+    transformer2 = SelectFromModel(estimator=est,
+                                   max_features=max_features,
+                                   threshold=-np.inf)
+    X_new1 = transformer1.fit_transform(X, y)
+    X_new2 = transformer2.fit_transform(X, y)
+    assert_allclose(X_new1, X_new2)
+
+    # Test max_features against actual model.
+    transformer1 = SelectFromModel(estimator=Lasso(alpha=0.025,
+                                                   random_state=42))
+    X_new1 = transformer1.fit_transform(X, y)
+    scores1 = np.abs(transformer1.estimator_.coef_)
+    candidate_indices1 = np.argsort(-scores1, kind='mergesort')
+
+    for n_features in range(1, X_new1.shape[1] + 1):
+        transformer2 = SelectFromModel(estimator=Lasso(alpha=0.025,
+                                       random_state=42),
+                                       max_features=n_features,
+                                       threshold=-np.inf)
+        X_new2 = transformer2.fit_transform(X, y)
+        scores2 = np.abs(transformer2.estimator_.coef_)
+        candidate_indices2 = np.argsort(-scores2, kind='mergesort')
+        assert_allclose(X[:, candidate_indices1[:n_features]],
+                        X[:, candidate_indices2[:n_features]])
+    assert_allclose(transformer1.estimator_.coef_,
+                    transformer2.estimator_.coef_)
+
+
+def test_max_features_tiebreak():
+    # Test if max_features can break tie among feature importance
+    X, y = datasets.make_classification(
+        n_samples=1000, n_features=10, n_informative=3, n_redundant=0,
+        n_repeated=0, shuffle=False, random_state=0)
+    max_features = X.shape[1]
+
+    feature_importances = np.array([4, 4, 4, 4, 3, 3, 3, 2, 2, 1])
+    for n_features in range(1, max_features + 1):
+        transformer = SelectFromModel(
+            FixedImportanceEstimator(feature_importances),
+            max_features=n_features,
+            threshold=-np.inf)
+        X_new = transformer.fit_transform(X, y)
+        selected_feature_indices = np.where(transformer._get_support_mask())[0]
+        assert_array_equal(selected_feature_indices, np.arange(n_features))
+        assert X_new.shape[1] == n_features
+
+
+def test_threshold_and_max_features():
+    X, y = datasets.make_classification(
+        n_samples=1000, n_features=10, n_informative=3, n_redundant=0,
+        n_repeated=0, shuffle=False, random_state=0)
+    est = RandomForestClassifier(n_estimators=50, random_state=0)
+
+    transformer1 = SelectFromModel(estimator=est, max_features=3,
+                                   threshold=-np.inf)
+    X_new1 = transformer1.fit_transform(X, y)
+
+    transformer2 = SelectFromModel(estimator=est, threshold=0.04)
+    X_new2 = transformer2.fit_transform(X, y)
+
+    transformer3 = SelectFromModel(estimator=est, max_features=3,
+                                   threshold=0.04)
+    X_new3 = transformer3.fit_transform(X, y)
+    assert X_new3.shape[1] == min(X_new1.shape[1], X_new2.shape[1])
+    selected_indices = transformer3.transform(
+        np.arange(X.shape[1])[np.newaxis, :])
+    assert_allclose(X_new3, X[:, selected_indices[0]])
+
+
+@skip_if_32bit
 def test_feature_importances():
     X, y = datasets.make_classification(
         n_samples=1000, n_features=10, n_informative=3, n_redundant=0,
@@ -87,7 +206,8 @@ def test_coef_default_threshold():
         n_repeated=0, shuffle=False, random_state=0)
 
     # For the Lasso and related models, the threshold defaults to 1e-5
-    transformer = SelectFromModel(estimator=Lasso(alpha=0.1))
+    transformer = SelectFromModel(estimator=Lasso(alpha=0.1,
+                                  random_state=42))
     transformer.fit(X, y)
     X_new = transformer.transform(X)
     mask = np.abs(transformer.estimator_.coef_) > 1e-5
@@ -119,6 +239,7 @@ def test_2d_coef():
             assert_array_almost_equal(X_new, X[:, feature_mask])
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_partial_fit():
     est = PassiveAggressiveClassifier(random_state=0, shuffle=False,
                                       max_iter=5, tol=None)
diff --git a/sklearn/feature_selection/tests/test_rfe.py b/sklearn/feature_selection/tests/test_rfe.py
index 3cee0fa6f605..e8533d808daf 100644
--- a/sklearn/feature_selection/tests/test_rfe.py
+++ b/sklearn/feature_selection/tests/test_rfe.py
@@ -1,6 +1,7 @@
 """
 Testing Recursive feature elimination
 """
+import pytest
 import numpy as np
 from numpy.testing import assert_array_almost_equal, assert_array_equal
 from scipy import sparse
@@ -336,6 +337,7 @@ def test_rfe_cv_n_jobs():
     assert_array_almost_equal(rfecv.grid_scores_, rfecv_grid_scores)
 
 
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_rfe_cv_groups():
     generator = check_random_state(0)
     iris = load_iris()
diff --git a/sklearn/gaussian_process/kernels.py b/sklearn/gaussian_process/kernels.py
index 4581b87ba948..7ab1ad8c90ee 100644
--- a/sklearn/gaussian_process/kernels.py
+++ b/sklearn/gaussian_process/kernels.py
@@ -199,7 +199,13 @@ def set_params(self, **params):
         return self
 
     def clone_with_theta(self, theta):
-        """Returns a clone of self with given hyperparameters theta. """
+        """Returns a clone of self with given hyperparameters theta.
+
+        Parameters
+        ----------
+        theta : array, shape (n_dims,)
+            The hyperparameters
+        """
         cloned = clone(self)
         cloned.theta = theta
         return cloned
@@ -395,6 +401,11 @@ class CompoundKernel(Kernel):
     """Kernel which is composed of a set of other kernels.
 
     .. versionadded:: 0.18
+
+    Parameters
+    ----------
+    kernels : list of Kernel objects
+        The other kernels
     """
 
     def __init__(self, kernels):
@@ -1268,7 +1279,7 @@ class Matern(RBF):
     length_scale_bounds : pair of floats >= 0, default: (1e-5, 1e5)
         The lower and upper bound on length_scale
 
-    nu: float, default: 1.5
+    nu : float, default: 1.5
         The parameter nu controlling the smoothness of the learned function.
         The smaller nu, the less smooth the approximated function is.
         For nu=inf, the kernel becomes equivalent to the RBF kernel and for
@@ -1755,7 +1766,7 @@ class PairwiseKernel(Kernel):
 
     Parameters
     ----------
-    gamma: float >= 0, default: 1.0
+    gamma : float >= 0, default: 1.0
         Parameter gamma of the pairwise kernel specified by metric
 
     gamma_bounds : pair of floats >= 0, default: (1e-5, 1e5)
diff --git a/sklearn/impute.py b/sklearn/impute.py
index 8acec9d010da..c89a24b3e3c2 100644
--- a/sklearn/impute.py
+++ b/sklearn/impute.py
@@ -3,8 +3,6 @@
 #          Sergey Feldman <sergeyfeldman@gmail.com>
 # License: BSD 3 clause
 
-from __future__ import division
-
 import warnings
 from time import time
 import numbers
@@ -13,12 +11,9 @@
 import numpy.ma as ma
 from scipy import sparse
 from scipy import stats
-from collections import namedtuple
 
 from .base import BaseEstimator, TransformerMixin
-from .base import clone
-from .preprocessing import normalize
-from .utils import check_array, check_random_state, safe_indexing
+from .utils import check_array
 from .utils.sparsefuncs import _get_median
 from .utils.validation import check_is_fitted
 from .utils.validation import FLOAT_DTYPES
@@ -30,19 +25,24 @@
 zip = six.moves.zip
 map = six.moves.map
 
-ImputerTriplet = namedtuple('ImputerTriplet', ['feat_idx',
-                                               'neighbor_feat_idx',
-                                               'predictor'])
-
 __all__ = [
+    'MissingIndicator',
     'SimpleImputer',
-    'ChainedImputer',
 ]
 
 
+def _check_inputs_dtype(X, missing_values):
+    if (X.dtype.kind in ("f", "i", "u") and
+            not isinstance(missing_values, numbers.Real)):
+        raise ValueError("'X' and 'missing_values' types are expected to be"
+                         " both numerical. Got X.dtype={} and "
+                         " type(missing_values)={}."
+                         .format(X.dtype, type(missing_values)))
+
+
 def _get_mask(X, value_to_mask):
     """Compute the boolean mask X == missing_values."""
-    if value_to_mask is np.nan:
+    if is_scalar_nan(value_to_mask):
         if X.dtype.kind == "f":
             return np.isnan(X)
         elif X.dtype.kind in ("i", "u"):
@@ -51,7 +51,6 @@ def _get_mask(X, value_to_mask):
         else:
             # np.isnan does not work on object dtypes.
             return _object_dtype_isnan(X)
-
     else:
         # X == value_to_mask with object dytpes does not always perform
         # element-wise for old versions of numpy
@@ -133,7 +132,6 @@ class SimpleImputer(BaseEstimator, TransformerMixin):
         a new copy will always be made, even if `copy=False`:
 
         - If X is not an array of floating values;
-        - If X is sparse and `missing_values=0`;
         - If X is encoded as a CSR matrix.
 
     Attributes
@@ -183,6 +181,7 @@ def _validate_input(self, X):
             else:
                 raise ve
 
+        _check_inputs_dtype(X, self.missing_values)
         if X.dtype.kind not in ("i", "u", "f", "O"):
             raise ValueError("SimpleImputer does not support data with dtype "
                              "{0}. Please provide either a numeric array (with"
@@ -227,10 +226,17 @@ def fit(self, X, y=None):
                              "data".format(fill_value))
 
         if sparse.issparse(X):
-            self.statistics_ = self._sparse_fit(X,
-                                                self.strategy,
-                                                self.missing_values,
-                                                fill_value)
+            # missing_values = 0 not allowed with sparse data as it would
+            # force densification
+            if self.missing_values == 0:
+                raise ValueError("Imputation not possible when missing_values "
+                                 "== 0 and input is sparse. Provide a dense "
+                                 "array instead.")
+            else:
+                self.statistics_ = self._sparse_fit(X,
+                                                    self.strategy,
+                                                    self.missing_values,
+                                                    fill_value)
         else:
             self.statistics_ = self._dense_fit(X,
                                                self.strategy,
@@ -241,80 +247,41 @@ def fit(self, X, y=None):
 
     def _sparse_fit(self, X, strategy, missing_values, fill_value):
         """Fit the transformer on sparse data."""
-        # Count the zeros
-        if missing_values == 0:
-            n_zeros_axis = np.zeros(X.shape[1], dtype=int)
-        else:
-            n_zeros_axis = X.shape[0] - np.diff(X.indptr)
+        mask_data = _get_mask(X.data, missing_values)
+        n_implicit_zeros = X.shape[0] - np.diff(X.indptr)
 
-        # Mean
-        if strategy == "mean":
-            if missing_values != 0:
-                n_non_missing = n_zeros_axis
-
-                # Mask the missing elements
-                mask_missing_values = _get_mask(X.data, missing_values)
-                mask_valids = np.logical_not(mask_missing_values)
-
-                # Sum only the valid elements
-                new_data = X.data.copy()
-                new_data[mask_missing_values] = 0
-                X = sparse.csc_matrix((new_data, X.indices, X.indptr),
-                                      copy=False)
-                sums = X.sum(axis=0)
-
-                # Count the elements != 0
-                mask_non_zeros = sparse.csc_matrix(
-                    (mask_valids.astype(np.float64),
-                     X.indices,
-                     X.indptr), copy=False)
-                s = mask_non_zeros.sum(axis=0)
-                n_non_missing = np.add(n_non_missing, s)
-
-            else:
-                sums = X.sum(axis=0)
-                n_non_missing = np.diff(X.indptr)
+        statistics = np.empty(X.shape[1])
 
-            # Ignore the error, columns with a np.nan statistics_
-            # are not an error at this point. These columns will
-            # be removed in transform
-            with np.errstate(all="ignore"):
-                return np.ravel(sums) / np.ravel(n_non_missing)
+        if strategy == "constant":
+            # for constant strategy, self.statistcs_ is used to store
+            # fill_value in each column
+            statistics.fill(fill_value)
 
-        # Median + Most frequent + Constant
         else:
-            # Remove the missing values, for each column
-            columns_all = np.hsplit(X.data, X.indptr[1:-1])
-            mask_missing_values = _get_mask(X.data, missing_values)
-            mask_valids = np.hsplit(np.logical_not(mask_missing_values),
-                                    X.indptr[1:-1])
-
-            # astype necessary for bug in numpy.hsplit before v1.9
-            columns = [col[mask.astype(bool, copy=False)]
-                       for col, mask in zip(columns_all, mask_valids)]
-
-            # Median
-            if strategy == "median":
-                median = np.empty(len(columns))
-                for i, column in enumerate(columns):
-                    median[i] = _get_median(column, n_zeros_axis[i])
-
-                return median
-
-            # Most frequent
-            elif strategy == "most_frequent":
-                most_frequent = np.empty(len(columns))
-
-                for i, column in enumerate(columns):
-                    most_frequent[i] = _most_frequent(column,
-                                                      0,
-                                                      n_zeros_axis[i])
-
-                return most_frequent
-
-            # Constant
-            elif strategy == "constant":
-                return np.full(X.shape[1], fill_value)
+            for i in range(X.shape[1]):
+                column = X.data[X.indptr[i]:X.indptr[i+1]]
+                mask_column = mask_data[X.indptr[i]:X.indptr[i+1]]
+                column = column[~mask_column]
+
+                # combine explicit and implicit zeros
+                mask_zeros = _get_mask(column, 0)
+                column = column[~mask_zeros]
+                n_explicit_zeros = mask_zeros.sum()
+                n_zeros = n_implicit_zeros[i] + n_explicit_zeros
+
+                if strategy == "mean":
+                    s = column.size + n_zeros
+                    statistics[i] = np.nan if s == 0 else column.sum() / s
+
+                elif strategy == "median":
+                    statistics[i] = _get_median(column,
+                                                n_zeros)
+
+                elif strategy == "most_frequent":
+                    statistics[i] = _most_frequent(column,
+                                                   0,
+                                                   n_zeros)
+        return statistics
 
     def _dense_fit(self, X, strategy, missing_values, fill_value):
         """Fit the transformer on dense data."""
@@ -364,6 +331,8 @@ def _dense_fit(self, X, strategy, missing_values, fill_value):
 
         # Constant
         elif strategy == "constant":
+            # for constant strategy, self.statistcs_ is used to store
+            # fill_value in each column
             return np.full(X.shape[1], fill_value, dtype=X.dtype)
 
     def transform(self, X):
@@ -402,17 +371,19 @@ def transform(self, X):
                 X = X[:, valid_statistics_indexes]
 
         # Do actual imputation
-        if sparse.issparse(X) and self.missing_values != 0:
-            mask = _get_mask(X.data, self.missing_values)
-            indexes = np.repeat(np.arange(len(X.indptr) - 1, dtype=np.int),
-                                np.diff(X.indptr))[mask]
+        if sparse.issparse(X):
+            if self.missing_values == 0:
+                raise ValueError("Imputation not possible when missing_values "
+                                 "== 0 and input is sparse. Provide a dense "
+                                 "array instead.")
+            else:
+                mask = _get_mask(X.data, self.missing_values)
+                indexes = np.repeat(np.arange(len(X.indptr) - 1, dtype=np.int),
+                                    np.diff(X.indptr))[mask]
 
-            X.data[mask] = valid_statistics[indexes].astype(X.dtype,
-                                                            copy=False)
+                X.data[mask] = valid_statistics[indexes].astype(X.dtype,
+                                                                copy=False)
         else:
-            if sparse.issparse(X):
-                X = X.toarray()
-
             mask = _get_mask(X, self.missing_values)
             n_missing = np.sum(mask, axis=0)
             values = np.repeat(valid_statistics, n_missing)
@@ -423,545 +394,223 @@ def transform(self, X):
         return X
 
 
-class ChainedImputer(BaseEstimator, TransformerMixin):
-    """Chained imputer transformer to impute missing values.
-
-    Basic implementation of chained imputer from MICE (Multivariate
-    Imputations by Chained Equations) package from R. This version assumes all
-    of the features are Gaussian.
-
-    Read more in the :ref:`User Guide <mice>`.
+class MissingIndicator(BaseEstimator, TransformerMixin):
+    """Binary indicators for missing values.
 
     Parameters
     ----------
-    missing_values : int, np.nan, optional (default=np.nan)
+    missing_values : number, string, np.nan (default) or None
         The placeholder for the missing values. All occurrences of
-        ``missing_values`` will be imputed.
-
-    imputation_order : str, optional (default="ascending")
-        The order in which the features will be imputed. Possible values:
-
-        "ascending"
-            From features with fewest missing values to most.
-        "descending"
-            From features with most missing values to fewest.
-        "roman"
-            Left to right.
-        "arabic"
-            Right to left.
-        "random"
-            A random order for each round.
-
-    n_imputations : int, optional (default=100)
-        Number of chained imputation rounds to perform, the results of which
-        will be used in the final average.
-
-    n_burn_in : int, optional (default=10)
-        Number of initial imputation rounds to perform the results of which
-        will not be returned.
-
-    predictor : estimator object, default=BayesianRidge()
-        The predictor to use at each step of the round-robin imputation.
-        It must support ``return_std`` in its ``predict`` method.
-
-    n_nearest_features : int, optional (default=None)
-        Number of other features to use to estimate the missing values of
-        the each feature column. Nearness between features is measured using
-        the absolute correlation coefficient between each feature pair (after
-        initial imputation). Can provide significant speed-up when the number
-        of features is huge. If ``None``, all features will be used.
-
-    initial_strategy : str, optional (default="mean")
-        Which strategy to use to initialize the missing values. Same as the
-        ``strategy`` parameter in :class:`sklearn.impute.SimpleImputer`
-        Valid values: {"mean", "median", "most_frequent", or "constant"}.
-
-    min_value : float, optional (default=None)
-        Minimum possible imputed value. Default of ``None`` will set minimum
-        to negative infinity.
-
-    max_value : float, optional (default=None)
-        Maximum possible imputed value. Default of ``None`` will set maximum
-        to positive infinity.
-
-    verbose : int, optional (default=0)
-        Verbosity flag, controls the debug messages that are issued
-        as functions are evaluated. The higher, the more verbose. Can be 0, 1,
-        or 2.
-
-    random_state : int, RandomState instance or None, optional (default=None)
-        The seed of the pseudo random number generator to use when shuffling
-        the data.  If int, random_state is the seed used by the random number
-        generator; If RandomState instance, random_state is the random number
-        generator; If None, the random number generator is the RandomState
-        instance used by ``np.random``.
+        `missing_values` will be imputed.
 
-    Attributes
-    ----------
-    initial_imputer_ : object of class :class:`sklearn.preprocessing.Imputer`'
-        The imputer used to initialize the missing values.
+    features : str, optional
+        Whether the imputer mask should represent all or a subset of
+        features.
 
-    imputation_sequence_ : list of tuples
-        Each tuple has ``(feat_idx, neighbor_feat_idx, predictor)``, where
-        ``feat_idx`` is the current feature to be imputed,
-        ``neighbor_feat_idx`` is the array of other features used to impute the
-        current feature, and ``predictor`` is the trained predictor used for
-        the imputation.
+        - If "missing-only" (default), the imputer mask will only represent
+          features containing missing values during fit time.
+        - If "all", the imputer mask will represent all features.
 
-    Notes
-    -----
-    The R version of MICE does not have inductive functionality, i.e. first
-    fitting on ``X_train`` and then transforming any ``X_test`` without
-    additional fitting. We do this by storing each feature's predictor during
-    the round-robin ``fit`` phase, and predicting without refitting (in order)
-    during the ``transform`` phase.
+    sparse : boolean or "auto", optional
+        Whether the imputer mask format should be sparse or dense.
 
-    Features which contain all missing values at ``fit`` are discarded upon
-    ``transform``.
+        - If "auto" (default), the imputer mask will be of same type as
+          input.
+        - If True, the imputer mask will be a sparse matrix.
+        - If False, the imputer mask will be a numpy array.
 
-    Features with missing values in transform which did not have any missing
-    values in fit will be imputed with the initial imputation method only.
+    error_on_new : boolean, optional
+        If True (default), transform will raise an error when there are
+        features with missing values in transform that have no missing values
+        in fit This is applicable only when ``features="missing-only"``.
 
-    References
+    Attributes
     ----------
-    .. [1] `Stef van Buuren, Karin Groothuis-Oudshoorn (2011). "mice:
-        Multivariate Imputation by Chained Equations in R". Journal of
-        Statistical Software 45: 1-67.
-        <https://www.jstatsoft.org/article/view/v045i03>`_
-    """
+    features_ : ndarray, shape (n_missing_features,) or (n_features,)
+        The features indices which will be returned when calling ``transform``.
+        They are computed during ``fit``. For ``features='all'``, it is
+        to ``range(n_features)``.
+
+    Examples
+    --------
+    >>> import numpy as np
+    >>> from sklearn.impute import MissingIndicator
+    >>> X1 = np.array([[np.nan, 1, 3],
+    ...                [4, 0, np.nan],
+    ...                [8, 1, 0]])
+    >>> X2 = np.array([[5, 1, np.nan],
+    ...                [np.nan, 2, 3],
+    ...                [2, 4, 0]])
+    >>> indicator = MissingIndicator()
+    >>> indicator.fit(X1)
+    MissingIndicator(error_on_new=True, features='missing-only',
+             missing_values=nan, sparse='auto')
+    >>> X2_tr = indicator.transform(X2)
+    >>> X2_tr
+    array([[False,  True],
+           [ True, False],
+           [False, False]])
 
-    def __init__(self,
-                 missing_values=np.nan,
-                 imputation_order='ascending',
-                 n_imputations=100,
-                 n_burn_in=10,
-                 predictor=None,
-                 n_nearest_features=None,
-                 initial_strategy="mean",
-                 min_value=None,
-                 max_value=None,
-                 verbose=False,
-                 random_state=None):
+    """
 
+    def __init__(self, missing_values=np.nan, features="missing-only",
+                 sparse="auto", error_on_new=True):
         self.missing_values = missing_values
-        self.imputation_order = imputation_order
-        self.n_imputations = n_imputations
-        self.n_burn_in = n_burn_in
-        self.predictor = predictor
-        self.n_nearest_features = n_nearest_features
-        self.initial_strategy = initial_strategy
-        self.min_value = min_value
-        self.max_value = max_value
-        self.verbose = verbose
-        self.random_state = random_state
-
-    def _impute_one_feature(self,
-                            X_filled,
-                            mask_missing_values,
-                            feat_idx,
-                            neighbor_feat_idx,
-                            predictor=None,
-                            fit_mode=True):
-        """Impute a single feature from the others provided.
-
-        This function predicts the missing values of one of the features using
-        the current estimates of all the other features. The ``predictor`` must
-        support ``return_std=True`` in its ``predict`` method for this function
-        to work.
+        self.features = features
+        self.sparse = sparse
+        self.error_on_new = error_on_new
+
+    def _get_missing_features_info(self, X):
+        """Compute the imputer mask and the indices of the features
+        containing missing values.
 
         Parameters
         ----------
-        X_filled : ndarray
-            Input data with the most recent imputations.
-
-        mask_missing_values : ndarray
-            Input data's missing indicator matrix.
-
-        feat_idx : int
-            Index of the feature currently being imputed.
-
-        neighbor_feat_idx : ndarray
-            Indices of the features to be used in imputing ``feat_idx``.
-
-        predictor : object
-            The predictor to use at this step of the round-robin imputation.
-            It must support ``return_std`` in its ``predict`` method.
-            If None, it will be cloned from self._predictor.
-
-        fit_mode : boolean, default=True
-            Whether to fit and predict with the predictor or just predict.
+        X : {ndarray or sparse matrix}, shape (n_samples, n_features)
+            The input data with missing values. Note that ``X`` has been
+            checked in ``fit`` and ``transform`` before to call this function.
 
         Returns
         -------
-        X_filled : ndarray
-            Input data with ``X_filled[missing_row_mask, feat_idx]`` updated.
+        imputer_mask : {ndarray or sparse matrix}, shape \
+(n_samples, n_features) or (n_samples, n_features_with_missing)
+            The imputer mask of the original data.
 
-        predictor : predictor with sklearn API
-            The fitted predictor used to impute
-            ``X_filled[missing_row_mask, feat_idx]``.
-        """
-
-        # if nothing is missing, just return the default
-        # (should not happen at fit time because feat_ids would be excluded)
-        missing_row_mask = mask_missing_values[:, feat_idx]
-        if not np.any(missing_row_mask):
-            return X_filled, predictor
-
-        if predictor is None and fit_mode is False:
-            raise ValueError("If fit_mode is False, then an already-fitted "
-                             "predictor should be passed in.")
-
-        if predictor is None:
-            predictor = clone(self._predictor)
-
-        if fit_mode:
-            X_train = safe_indexing(X_filled[:, neighbor_feat_idx],
-                                    ~missing_row_mask)
-            y_train = safe_indexing(X_filled[:, feat_idx],
-                                    ~missing_row_mask)
-            predictor.fit(X_train, y_train)
-
-        # get posterior samples
-        X_test = safe_indexing(X_filled[:, neighbor_feat_idx],
-                               missing_row_mask)
-        mus, sigmas = predictor.predict(X_test, return_std=True)
-        good_sigmas = sigmas > 0
-        imputed_values = np.zeros(mus.shape, dtype=X_filled.dtype)
-        imputed_values[~good_sigmas] = mus[~good_sigmas]
-        imputed_values[good_sigmas] = self.random_state_.normal(
-            loc=mus[good_sigmas], scale=sigmas[good_sigmas])
-
-        # clip the values
-        imputed_values = np.clip(imputed_values,
-                                 self._min_value,
-                                 self._max_value)
-
-        # update the feature
-        X_filled[missing_row_mask, feat_idx] = imputed_values
-        return X_filled, predictor
-
-    def _get_neighbor_feat_idx(self,
-                               n_features,
-                               feat_idx,
-                               abs_corr_mat):
-        """Get a list of other features to predict ``feat_idx``.
-
-        If self.n_nearest_features is less than or equal to the total
-        number of features, then use a probability proportional to the absolute
-        correlation between ``feat_idx`` and each other feature to randomly
-        choose a subsample of the other features (without replacement).
-
-        Parameters
-        ----------
-        n_features : int
-            Number of features in ``X``.
-
-        feat_idx : int
-            Index of the feature currently being imputed.
-
-        abs_corr_mat : ndarray, shape (n_features, n_features)
-            Absolute correlation matrix of ``X``. The diagonal has been zeroed
-            out and each feature has been normalized to sum to 1. Can be None.
+        features_with_missing : ndarray, shape (n_features_with_missing)
+            The features containing missing values.
 
-        Returns
-        -------
-        neighbor_feat_idx : array-like
-            The features to use to impute ``feat_idx``.
         """
-        if (self.n_nearest_features is not None and
-                self.n_nearest_features < n_features):
-            p = abs_corr_mat[:, feat_idx]
-            neighbor_feat_idx = self.random_state_.choice(
-                np.arange(n_features), self.n_nearest_features, replace=False,
-                p=p)
+        if sparse.issparse(X) and self.missing_values != 0:
+            mask = _get_mask(X.data, self.missing_values)
+
+            # The imputer mask will be constructed with the same sparse format
+            # as X.
+            sparse_constructor = (sparse.csr_matrix if X.format == 'csr'
+                                  else sparse.csc_matrix)
+            imputer_mask = sparse_constructor(
+                (mask, X.indices.copy(), X.indptr.copy()),
+                shape=X.shape, dtype=bool)
+
+            missing_values_mask = imputer_mask.copy()
+            missing_values_mask.eliminate_zeros()
+            features_with_missing = (
+                np.flatnonzero(np.diff(missing_values_mask.indptr))
+                if missing_values_mask.format == 'csc'
+                else np.unique(missing_values_mask.indices))
+
+            if self.sparse is False:
+                imputer_mask = imputer_mask.toarray()
+            elif imputer_mask.format == 'csr':
+                imputer_mask = imputer_mask.tocsc()
         else:
-            inds_left = np.arange(feat_idx)
-            inds_right = np.arange(feat_idx + 1, n_features)
-            neighbor_feat_idx = np.concatenate((inds_left, inds_right))
-        return neighbor_feat_idx
+            if sparse.issparse(X):
+                # case of sparse matrix with 0 as missing values. Implicit and
+                # explicit zeros are considered as missing values.
+                X = X.toarray()
+            imputer_mask = _get_mask(X, self.missing_values)
+            features_with_missing = np.flatnonzero(imputer_mask.sum(axis=0))
 
-    def _get_ordered_idx(self, mask_missing_values):
-        """Decide in what order we will update the features.
+            if self.sparse is True:
+                imputer_mask = sparse.csc_matrix(imputer_mask)
 
-        As a homage to the MICE R package, we will have 4 main options of
-        how to order the updates, and use a random order if anything else
-        is specified.
+        return imputer_mask, features_with_missing
 
-        Also, this function skips features which have no missing values.
+    def fit(self, X, y=None):
+        """Fit the transformer on X.
 
         Parameters
         ----------
-        mask_missing_values : array-like, shape (n_samples, n_features)
-            Input data's missing indicator matrix, where "n_samples" is the
-            number of samples and "n_features" is the number of features.
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            Input data, where ``n_samples`` is the number of samples and
+            ``n_features`` is the number of features.
 
         Returns
         -------
-        ordered_idx : ndarray, shape (n_features,)
-            The order in which to impute the features.
+        self : object
+            Returns self.
         """
-        frac_of_missing_values = mask_missing_values.mean(axis=0)
-        missing_values_idx = np.nonzero(frac_of_missing_values)[0]
-        if self.imputation_order == 'roman':
-            ordered_idx = missing_values_idx
-        elif self.imputation_order == 'arabic':
-            ordered_idx = missing_values_idx[::-1]
-        elif self.imputation_order == 'ascending':
-            n = len(frac_of_missing_values) - len(missing_values_idx)
-            ordered_idx = np.argsort(frac_of_missing_values,
-                                     kind='mergesort')[n:][::-1]
-        elif self.imputation_order == 'descending':
-            n = len(frac_of_missing_values) - len(missing_values_idx)
-            ordered_idx = np.argsort(frac_of_missing_values,
-                                     kind='mergesort')[n:]
-        elif self.imputation_order == 'random':
-            ordered_idx = missing_values_idx
-            self.random_state_.shuffle(ordered_idx)
+        if not is_scalar_nan(self.missing_values):
+            force_all_finite = True
         else:
-            raise ValueError("Got an invalid imputation order: '{0}'. It must "
-                             "be one of the following: 'roman', 'arabic', "
-                             "'ascending', 'descending', or "
-                             "'random'.".format(self.imputation_order))
-        return ordered_idx
+            force_all_finite = "allow-nan"
+        X = check_array(X, accept_sparse=('csc', 'csr'),
+                        force_all_finite=force_all_finite)
+        _check_inputs_dtype(X, self.missing_values)
 
-    def _get_abs_corr_mat(self, X_filled, tolerance=1e-6):
-        """Get absolute correlation matrix between features.
+        self._n_features = X.shape[1]
 
-        Parameters
-        ----------
-        X_filled : ndarray, shape (n_samples, n_features)
-            Input data with the most recent imputations.
+        if self.features not in ('missing-only', 'all'):
+            raise ValueError("'features' has to be either 'missing-only' or "
+                             "'all'. Got {} instead.".format(self.features))
 
-        tolerance : float, optional (default=1e-6)
-            ``abs_corr_mat`` can have nans, which will be replaced
-            with ``tolerance``.
+        if not ((isinstance(self.sparse, six.string_types) and
+                self.sparse == "auto") or isinstance(self.sparse, bool)):
+            raise ValueError("'sparse' has to be a boolean or 'auto'. "
+                             "Got {!r} instead.".format(self.sparse))
 
-        Returns
-        -------
-        abs_corr_mat : ndarray, shape (n_features, n_features)
-            Absolute correlation matrix of ``X`` at the beginning of the
-            current round. The diagonal has been zeroed out and each feature's
-            absolute correlations with all others have been normalized to sum
-            to 1.
-        """
-        n_features = X_filled.shape[1]
-        if (self.n_nearest_features is None or
-                self.n_nearest_features >= n_features):
-            return None
-        abs_corr_mat = np.abs(np.corrcoef(X_filled.T))
-        # np.corrcoef is not defined for features with zero std
-        abs_corr_mat[np.isnan(abs_corr_mat)] = tolerance
-        # ensures exploration, i.e. at least some probability of sampling
-        np.clip(abs_corr_mat, tolerance, None, out=abs_corr_mat)
-        # features are not their own neighbors
-        np.fill_diagonal(abs_corr_mat, 0)
-        # needs to sum to 1 for np.random.choice sampling
-        abs_corr_mat = normalize(abs_corr_mat, norm='l1', axis=0, copy=False)
-        return abs_corr_mat
-
-    def _initial_imputation(self, X):
-        """Perform initial imputation for input X.
+        self.features_ = (self._get_missing_features_info(X)[1]
+                          if self.features == 'missing-only'
+                          else np.arange(self._n_features))
+
+        return self
+
+    def transform(self, X):
+        """Generate missing values indicator for X.
 
         Parameters
         ----------
-        X : ndarray, shape (n_samples, n_features)
-            Input data, where "n_samples" is the number of samples and
-            "n_features" is the number of features.
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
+            The input data to complete.
 
         Returns
         -------
-        Xt : ndarray, shape (n_samples, n_features)
-            Input data, where "n_samples" is the number of samples and
-            "n_features" is the number of features.
+        Xt : {ndarray or sparse matrix}, shape (n_samples, n_features)
+            The missing indicator for input data. The data type of ``Xt``
+            will be boolean.
 
-        X_filled : ndarray, shape (n_samples, n_features)
-            Input data with the most recent imputations.
-
-        mask_missing_values : ndarray, shape (n_samples, n_features)
-            Input data's missing indicator matrix, where "n_samples" is the
-            number of samples and "n_features" is the number of features.
         """
-        if is_scalar_nan(self.missing_values):
-            force_all_finite = "allow-nan"
-        else:
-            force_all_finite = True
+        check_is_fitted(self, "features_")
 
-        X = check_array(X, dtype=FLOAT_DTYPES, order="F",
-                        force_all_finite=force_all_finite)
-
-        mask_missing_values = _get_mask(X, self.missing_values)
-        if self.initial_imputer_ is None:
-            self.initial_imputer_ = SimpleImputer(
-                                            missing_values=self.missing_values,
-                                            strategy=self.initial_strategy)
-            X_filled = self.initial_imputer_.fit_transform(X)
+        if not is_scalar_nan(self.missing_values):
+            force_all_finite = True
         else:
-            X_filled = self.initial_imputer_.transform(X)
-
-        valid_mask = np.flatnonzero(np.logical_not(
-            np.isnan(self.initial_imputer_.statistics_)))
-        Xt = X[:, valid_mask]
-        mask_missing_values = mask_missing_values[:, valid_mask]
-
-        return Xt, X_filled, mask_missing_values
-
-    def fit_transform(self, X, y=None):
-        """Fits the imputer on X and return the transformed X.
+            force_all_finite = "allow-nan"
+        X = check_array(X, accept_sparse=('csc', 'csr'),
+                        force_all_finite=force_all_finite)
+        _check_inputs_dtype(X, self.missing_values)
 
-        Parameters
-        ----------
-        X : array-like, shape (n_samples, n_features)
-            Input data, where "n_samples" is the number of samples and
-            "n_features" is the number of features.
+        if X.shape[1] != self._n_features:
+            raise ValueError("X has a different number of features "
+                             "than during fitting.")
 
-        y : ignored.
+        imputer_mask, features = self._get_missing_features_info(X)
 
-        Returns
-        -------
-        Xt : array-like, shape (n_samples, n_features)
-             The imputed input data.
-        """
-        self.random_state_ = getattr(self, "random_state_",
-                                     check_random_state(self.random_state))
+        if self.features == "missing-only":
+            features_diff_fit_trans = np.setdiff1d(features, self.features_)
+            if (self.error_on_new and features_diff_fit_trans.size > 0):
+                raise ValueError("The features {} have missing values "
+                                 "in transform but have no missing values "
+                                 "in fit.".format(features_diff_fit_trans))
 
-        if self.predictor is None:
-            from .linear_model import BayesianRidge
-            self._predictor = BayesianRidge()
-        else:
-            self._predictor = clone(self.predictor)
-
-        self._min_value = np.nan if self.min_value is None else self.min_value
-        self._max_value = np.nan if self.max_value is None else self.max_value
-
-        self.initial_imputer_ = None
-        X, X_filled, mask_missing_values = self._initial_imputation(X)
-
-        # edge case: in case the user specifies 0 for n_imputations,
-        # then there is no need to do burn in and the result should be
-        # just the initial imputation (before clipping)
-        if self.n_imputations < 1:
-            return X_filled
-
-        X_filled = np.clip(X_filled, self._min_value, self._max_value)
-
-        # order in which to impute
-        # note this is probably too slow for large feature data (d > 100000)
-        # and a better way would be good.
-        # see: https://goo.gl/KyCNwj and subsequent comments
-        ordered_idx = self._get_ordered_idx(mask_missing_values)
-
-        abs_corr_mat = self._get_abs_corr_mat(X_filled)
-
-        # impute data
-        n_rounds = self.n_burn_in + self.n_imputations
-        n_samples, n_features = X_filled.shape
-        Xt = np.zeros((n_samples, n_features), dtype=X.dtype)
-        self.imputation_sequence_ = []
-        if self.verbose > 0:
-            print("[ChainedImputer] Completing matrix with shape %s"
-                  % (X.shape,))
-        start_t = time()
-        for i_rnd in range(n_rounds):
-            if self.imputation_order == 'random':
-                ordered_idx = self._get_ordered_idx(mask_missing_values)
-
-            for feat_idx in ordered_idx:
-                neighbor_feat_idx = self._get_neighbor_feat_idx(n_features,
-                                                                feat_idx,
-                                                                abs_corr_mat)
-                X_filled, predictor = self._impute_one_feature(
-                    X_filled, mask_missing_values, feat_idx, neighbor_feat_idx,
-                    predictor=None, fit_mode=True)
-                predictor_triplet = ImputerTriplet(feat_idx,
-                                                   neighbor_feat_idx,
-                                                   predictor)
-                self.imputation_sequence_.append(predictor_triplet)
-
-            if i_rnd >= self.n_burn_in:
-                Xt += X_filled
-            if self.verbose > 0:
-                print('[ChainedImputer] Ending imputation round '
-                      '%d/%d, elapsed time %0.2f'
-                      % (i_rnd + 1, n_rounds, time() - start_t))
-
-        Xt /= self.n_imputations
-        Xt[~mask_missing_values] = X[~mask_missing_values]
-        return Xt
+            if (self.features_.size > 0 and
+                    self.features_.size < self._n_features):
+                imputer_mask = imputer_mask[:, self.features_]
 
-    def transform(self, X):
-        """Imputes all missing values in X.
+        return imputer_mask
 
-        Note that this is stochastic, and that if random_state is not fixed,
-        repeated calls, or permuted input, will yield different results.
+    def fit_transform(self, X, y=None):
+        """Generate missing values indicator for X.
 
         Parameters
         ----------
-        X : array-like, shape = [n_samples, n_features]
+        X : {array-like, sparse matrix}, shape (n_samples, n_features)
             The input data to complete.
 
         Returns
         -------
-        Xt : array-like, shape (n_samples, n_features)
-             The imputed input data.
-        """
-        check_is_fitted(self, 'initial_imputer_')
-
-        X, X_filled, mask_missing_values = self._initial_imputation(X)
-
-        # edge case: in case the user specifies 0 for n_imputations,
-        # then there is no need to do burn in and the result should be
-        # just the initial imputation (before clipping)
-        if self.n_imputations < 1:
-            return X_filled
-
-        X_filled = np.clip(X_filled, self._min_value, self._max_value)
-
-        n_rounds = self.n_burn_in + self.n_imputations
-        n_imputations = len(self.imputation_sequence_)
-        imputations_per_round = n_imputations // n_rounds
-        i_rnd = 0
-        Xt = np.zeros(X.shape, dtype=X.dtype)
-        if self.verbose > 0:
-            print("[ChainedImputer] Completing matrix with shape %s"
-                  % (X.shape,))
-        start_t = time()
-        for it, predictor_triplet in enumerate(self.imputation_sequence_):
-            X_filled, _ = self._impute_one_feature(
-                X_filled,
-                mask_missing_values,
-                predictor_triplet.feat_idx,
-                predictor_triplet.neighbor_feat_idx,
-                predictor=predictor_triplet.predictor,
-                fit_mode=False
-            )
-            if not (it + 1) % imputations_per_round:
-                if i_rnd >= self.n_burn_in:
-                    Xt += X_filled
-                if self.verbose > 1:
-                    print('[ChainedImputer] Ending imputation round '
-                          '%d/%d, elapsed time %0.2f'
-                          % (i_rnd + 1, n_rounds, time() - start_t))
-                i_rnd += 1
-
-        Xt /= self.n_imputations
-        Xt[~mask_missing_values] = X[~mask_missing_values]
-        return Xt
-
-    def fit(self, X, y=None):
-        """Fits the imputer on X and return self.
-
-        Parameters
-        ----------
-        X : array-like, shape (n_samples, n_features)
-            Input data, where "n_samples" is the number of samples and
-            "n_features" is the number of features.
-
-        y : ignored
+        Xt : {ndarray or sparse matrix}, shape (n_samples, n_features)
+            The missing indicator for input data. The data type of ``Xt``
+            will be boolean.
 
-        Returns
-        -------
-        self : object
-            Returns self.
         """
-        self.fit_transform(X)
-        return self
+        return self.fit(X, y).transform(X)
diff --git a/sklearn/kernel_approximation.py b/sklearn/kernel_approximation.py
index a0720a85689d..4044a8f6a996 100644
--- a/sklearn/kernel_approximation.py
+++ b/sklearn/kernel_approximation.py
@@ -459,6 +459,25 @@ class Nystroem(BaseEstimator, TransformerMixin):
         Normalization matrix needed for embedding.
         Square root of the kernel matrix on ``components_``.
 
+    Examples
+    --------
+    >>> from sklearn import datasets, svm
+    >>> from sklearn.kernel_approximation import Nystroem
+    >>> digits = datasets.load_digits(n_class=9)
+    >>> data = digits.data / 16.
+    >>> clf = svm.LinearSVC()
+    >>> feature_map_nystroem = Nystroem(gamma=.2,
+    ...                                 random_state=1,
+    ...                                 n_components=300)
+    >>> data_transformed = feature_map_nystroem.fit_transform(data)
+    >>> clf.fit(data_transformed, digits.target)
+    ... # doctest: +NORMALIZE_WHITESPACE
+    LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
+         intercept_scaling=1, loss='squared_hinge', max_iter=1000,
+         multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
+         verbose=0)
+    >>> clf.score(data_transformed, digits.target) # doctest: +ELLIPSIS
+    0.9987...
 
     References
     ----------
diff --git a/sklearn/linear_model/base.py b/sklearn/linear_model/base.py
index 09c389cb336d..a363493019d2 100644
--- a/sklearn/linear_model/base.py
+++ b/sklearn/linear_model/base.py
@@ -24,7 +24,7 @@
 from scipy import sparse
 
 from ..externals import six
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..base import BaseEstimator, ClassifierMixin, RegressorMixin
 from ..utils import check_array, check_X_y
 from ..utils.validation import FLOAT_DTYPES
@@ -50,6 +50,29 @@ def make_dataset(X, y, sample_weight, random_state=None):
 
     This also returns the ``intercept_decay`` which is different
     for sparse datasets.
+
+    Parameters
+    ----------
+    X : array_like, shape (n_samples, n_features)
+        Training data
+
+    y : array_like, shape (n_samples, )
+        Target values.
+
+    sample_weight : numpy array of shape (n_samples,)
+        The weight of each sample
+
+    random_state : int, RandomState instance or None (default)
+        Determines random number generation for dataset shuffling and noise.
+        Pass an int for reproducible output across multiple function calls.
+        See :term:`Glossary <random_state>`.
+
+    Returns
+    -------
+    dataset
+        The ``Dataset`` abstraction
+    intercept_decay
+        The intercept decay
     """
 
     rng = check_random_state(random_state)
@@ -171,12 +194,12 @@ def predict(self, X):
 
         Parameters
         ----------
-        X : {array-like, sparse matrix}, shape = (n_samples, n_features)
+        X : array_like or sparse matrix, shape (n_samples, n_features)
             Samples.
 
         Returns
         -------
-        C : array, shape = (n_samples,)
+        C : array, shape (n_samples,)
             Returns predicted values.
         """
         return self._decision_function(X)
@@ -209,7 +232,7 @@ def decision_function(self, X):
 
         Parameters
         ----------
-        X : {array-like, sparse matrix}, shape = (n_samples, n_features)
+        X : array_like or sparse matrix, shape (n_samples, n_features)
             Samples.
 
         Returns
@@ -239,12 +262,12 @@ def predict(self, X):
 
         Parameters
         ----------
-        X : {array-like, sparse matrix}, shape = [n_samples, n_features]
+        X : array_like or sparse matrix, shape (n_samples, n_features)
             Samples.
 
         Returns
         -------
-        C : array, shape = [n_samples]
+        C : array, shape [n_samples]
             Predicted class label per sample.
         """
         scores = self.decision_function(X)
@@ -386,10 +409,10 @@ def fit(self, X, y, sample_weight=None):
 
         Parameters
         ----------
-        X : numpy array or sparse matrix of shape [n_samples,n_features]
+        X : array-like or sparse matrix, shape (n_samples, n_features)
             Training data
 
-        y : numpy array of shape [n_samples, n_targets]
+        y : array_like, shape (n_samples, n_targets)
             Target values. Will be cast to X's dtype if necessary
 
         sample_weight : numpy array of shape [n_samples]
diff --git a/sklearn/linear_model/cd_fast.pyx b/sklearn/linear_model/cd_fast.pyx
index 4fbfe8b2489d..a51d1bdbdbc9 100644
--- a/sklearn/linear_model/cd_fast.pyx
+++ b/sklearn/linear_model/cd_fast.pyx
@@ -18,11 +18,6 @@ import warnings
 
 ctypedef np.float64_t DOUBLE
 ctypedef np.uint32_t UINT32_t
-ctypedef floating (*DOT)(int N, floating *X, int incX, floating *Y,
-                         int incY) nogil
-ctypedef void (*AXPY)(int N, floating alpha, floating *X, int incX,
-                      floating *Y, int incY) nogil
-ctypedef floating (*ASUM)(int N, floating *X, int incX) nogil
 
 np.import_array()
 
@@ -162,10 +157,6 @@ def enet_coordinate_descent(np.ndarray[floating, ndim=1] w,
     """
 
     # fused types version of BLAS functions
-    cdef DOT dot
-    cdef AXPY axpy
-    cdef ASUM asum
-
     if floating is float:
         dtype = np.float32
         dot = sdot
@@ -355,9 +346,6 @@ def sparse_enet_coordinate_descent(floating [:] w,
     cdef floating[:] XtA
 
     # fused types version of BLAS functions
-    cdef DOT dot
-    cdef ASUM asum
-
     if floating is float:
         dtype = np.float32
         n_tasks = y.strides[0] / sizeof(float)
@@ -559,10 +547,6 @@ def enet_coordinate_descent_gram(floating[:] w, floating alpha, floating beta,
     """
 
     # fused types version of BLAS functions
-    cdef DOT dot
-    cdef AXPY axpy
-    cdef ASUM asum
-
     if floating is float:
         dtype = np.float32
         dot = sdot
@@ -713,10 +697,6 @@ def enet_coordinate_descent_multi_task(floating[::1, :] W, floating l1_reg,
 
     """
     # fused types version of BLAS functions
-    cdef DOT dot
-    cdef AXPY axpy
-    cdef ASUM asum
-
     if floating is float:
         dtype = np.float32
         dot = sdot
diff --git a/sklearn/linear_model/coordinate_descent.py b/sklearn/linear_model/coordinate_descent.py
index bdad75bc6197..38650b887f5b 100644
--- a/sklearn/linear_model/coordinate_descent.py
+++ b/sklearn/linear_model/coordinate_descent.py
@@ -18,7 +18,7 @@
 from ..utils import check_array, check_X_y
 from ..utils.validation import check_random_state
 from ..model_selection import check_cv
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals import six
 from ..externals.six.moves import xrange
 from ..utils.extmath import safe_sparse_dot
diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py
index cd10edcc4e94..f0409545a26b 100644
--- a/sklearn/linear_model/least_angle.py
+++ b/sklearn/linear_model/least_angle.py
@@ -23,7 +23,7 @@
 from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated
 from ..model_selection import check_cv
 from ..exceptions import ConvergenceWarning
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals.six.moves import xrange
 from ..externals.six import string_types
 
diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index e4ea696ce714..0f79b9a60bb7 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -32,7 +32,7 @@
 from ..exceptions import (NotFittedError, ConvergenceWarning,
                           ChangedBehaviorWarning)
 from ..utils.multiclass import check_classification_targets
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..model_selection import check_cv
 from ..externals import six
 from ..metrics import get_scorer
@@ -684,7 +684,6 @@ def logistic_regression_path(X, y, pos_class=None, Cs=10, fit_intercept=True,
             else:
                 w0[:, :coef.shape[1]] = coef
 
-
     if multi_class == 'multinomial':
         # fmin_l_bfgs_b and newton-cg accepts only ravelled parameters.
         if solver in ['lbfgs', 'newton-cg']:
@@ -711,10 +710,12 @@ def logistic_regression_path(X, y, pos_class=None, Cs=10, fit_intercept=True,
     n_iter = np.zeros(len(Cs), dtype=np.int32)
     for i, C in enumerate(Cs):
         if solver == 'lbfgs':
+            iprint = [-1, 50, 1, 100, 101][
+                np.searchsorted(np.array([0, 1, 2, 3]), verbose)]
             w0, loss, info = optimize.fmin_l_bfgs_b(
                 func, w0, fprime=None,
                 args=(X, target, 1. / C, sample_weight),
-                iprint=(verbose > 0) - 1, pgtol=tol, maxiter=max_iter)
+                iprint=iprint, pgtol=tol, maxiter=max_iter)
             if info["warnflag"] == 1:
                 warnings.warn("lbfgs failed to converge. Increase the number "
                               "of iterations.", ConvergenceWarning)
diff --git a/sklearn/linear_model/omp.py b/sklearn/linear_model/omp.py
index 777b915d0339..09d58e72b886 100644
--- a/sklearn/linear_model/omp.py
+++ b/sklearn/linear_model/omp.py
@@ -16,7 +16,7 @@
 from ..base import RegressorMixin
 from ..utils import as_float_array, check_array, check_X_y
 from ..model_selection import check_cv
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 
 premature = """ Orthogonal matching pursuit ended prematurely due to linear
 dependence in the dictionary. The requested precision might not have been met.
diff --git a/sklearn/linear_model/passive_aggressive.py b/sklearn/linear_model/passive_aggressive.py
index dc48b7362b5d..7fd15d171024 100644
--- a/sklearn/linear_model/passive_aggressive.py
+++ b/sklearn/linear_model/passive_aggressive.py
@@ -45,11 +45,6 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -57,6 +52,11 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
@@ -137,17 +137,17 @@ class PassiveAggressiveClassifier(BaseSGDClassifier):
     >>> from sklearn.datasets import make_classification
     >>>
     >>> X, y = make_classification(n_features=4, random_state=0)
-    >>> clf = PassiveAggressiveClassifier(random_state=0)
+    >>> clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0)
     >>> clf.fit(X, y)
     PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,
                   early_stopping=False, fit_intercept=True, loss='hinge',
-                  max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=1,
+                  max_iter=1000, n_iter=None, n_iter_no_change=5, n_jobs=1,
                   random_state=0, shuffle=True, tol=None,
                   validation_fraction=0.1, verbose=0, warm_start=False)
     >>> print(clf.coef_)
-    [[0.49324685 1.0552176  1.49519589 1.33798314]]
+    [[0.29509834 0.33711843 0.56127352 0.60105546]]
     >>> print(clf.intercept_)
-    [2.18438388]
+    [2.54153383]
     >>> print(clf.predict([[0, 0, 0, 0]]))
     [1]
 
@@ -297,11 +297,6 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -309,6 +304,11 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     shuffle : bool, default=True
         Whether or not the training data should be shuffled after each epoch.
 
@@ -375,11 +375,11 @@ class PassiveAggressiveRegressor(BaseSGDRegressor):
     >>> from sklearn.datasets import make_regression
     >>>
     >>> X, y = make_regression(n_features=4, random_state=0)
-    >>> regr = PassiveAggressiveRegressor(random_state=0)
+    >>> regr = PassiveAggressiveRegressor(max_iter=100, random_state=0)
     >>> regr.fit(X, y)
     PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                   epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',
-                  max_iter=None, n_iter=None, n_iter_no_change=5,
+                  max_iter=100, n_iter=None, n_iter_no_change=5,
                   random_state=0, shuffle=True, tol=None,
                   validation_fraction=0.1, verbose=0, warm_start=False)
     >>> print(regr.coef_)
diff --git a/sklearn/linear_model/perceptron.py b/sklearn/linear_model/perceptron.py
index 64cbecef7ec4..1a01e1ba2236 100644
--- a/sklearn/linear_model/perceptron.py
+++ b/sklearn/linear_model/perceptron.py
@@ -68,11 +68,6 @@ class Perceptron(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -80,6 +75,11 @@ class Perceptron(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
diff --git a/sklearn/linear_model/randomized_l1.py b/sklearn/linear_model/randomized_l1.py
index 1b8cb567b661..f75a59db5e76 100644
--- a/sklearn/linear_model/randomized_l1.py
+++ b/sklearn/linear_model/randomized_l1.py
@@ -19,7 +19,7 @@
 from .base import _preprocess_data
 from ..base import BaseEstimator
 from ..externals import six
-from ..externals.joblib import Memory, Parallel, delayed
+from ..utils import Memory, Parallel, delayed
 from ..feature_selection.base import SelectorMixin
 from ..utils import (as_float_array, check_random_state, check_X_y, safe_mask,
                      deprecated)
@@ -109,7 +109,7 @@ def fit(self, X, y):
             memory = Memory(cachedir=memory, verbose=0)
         elif not isinstance(memory, Memory):
             raise ValueError("'memory' should either be a string or"
-                             " a sklearn.externals.joblib.Memory"
+                             " a sklearn.utils.Memory"
                              " instance, got 'memory={!r}' instead.".format(
                                  type(memory)))
 
@@ -296,7 +296,7 @@ class RandomizedLasso(BaseRandomizedLinearModel):
     Examples
     --------
     >>> from sklearn.linear_model import RandomizedLasso
-    >>> randomized_lasso = RandomizedLasso()
+    >>> randomized_lasso = RandomizedLasso() # doctest: +SKIP
 
     References
     ----------
@@ -490,7 +490,7 @@ class RandomizedLogisticRegression(BaseRandomizedLinearModel):
     Examples
     --------
     >>> from sklearn.linear_model import RandomizedLogisticRegression
-    >>> randomized_logistic = RandomizedLogisticRegression()
+    >>> randomized_logistic = RandomizedLogisticRegression() # doctest: +SKIP
 
     References
     ----------
diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py
index 80778132bb24..6ff0bd4f9300 100644
--- a/sklearn/linear_model/ridge.py
+++ b/sklearn/linear_model/ridge.py
@@ -59,7 +59,12 @@ def _mv(x):
             # w = X.T * inv(X X^t + alpha*Id) y
             C = sp_linalg.LinearOperator(
                 (n_samples, n_samples), matvec=mv, dtype=X.dtype)
-            coef, info = sp_linalg.cg(C, y_column, tol=tol)
+            # FIXME atol
+            try:
+                coef, info = sp_linalg.cg(C, y_column, tol=tol, atol='legacy')
+            except TypeError:
+                # old scipy
+                coef, info = sp_linalg.cg(C, y_column, tol=tol)
             coefs[i] = X1.rmatvec(coef)
         else:
             # linear ridge
@@ -67,8 +72,15 @@ def _mv(x):
             y_column = X1.rmatvec(y_column)
             C = sp_linalg.LinearOperator(
                 (n_features, n_features), matvec=mv, dtype=X.dtype)
-            coefs[i], info = sp_linalg.cg(C, y_column, maxiter=max_iter,
-                                          tol=tol)
+            # FIXME atol
+            try:
+                coefs[i], info = sp_linalg.cg(C, y_column, maxiter=max_iter,
+                                              tol=tol, atol='legacy')
+            except TypeError:
+                # old scipy
+                coefs[i], info = sp_linalg.cg(C, y_column, maxiter=max_iter,
+                                              tol=tol)
+
         if info < 0:
             raise ValueError("Failed with error code %d" % info)
 
diff --git a/sklearn/linear_model/stochastic_gradient.py b/sklearn/linear_model/stochastic_gradient.py
index e5bc20e837d2..20107c233d67 100644
--- a/sklearn/linear_model/stochastic_gradient.py
+++ b/sklearn/linear_model/stochastic_gradient.py
@@ -9,7 +9,7 @@
 
 from abc import ABCMeta, abstractmethod
 
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 
 from .base import LinearClassifierMixin, SparseCoefMixin
 from .base import make_dataset
@@ -352,6 +352,42 @@ def fit_binary(est, i, X, y, alpha, C, learning_rate, max_iter,
     """Fit a single binary classifier.
 
     The i'th class is considered the "positive" class.
+
+    Parameters
+    ----------
+    est : Estimator object
+        The estimator to fit
+
+    i : int
+        Index of the positive class
+
+    X : numpy array or sparse matrix of shape [n_samples,n_features]
+        Training data
+
+    y : numpy array of shape [n_samples, ]
+        Target values
+
+    alpha : float
+        The regularization parameter
+
+    C : float
+        Maximum step size for passive aggressive
+
+    learning_rate : string
+        The learning rate. Accepted values are 'constant', 'optimal',
+        'invscaling', 'pa1' and 'pa2'.
+
+    max_iter : int
+        The maximum number of iterations (epochs)
+
+    pos_weight : float
+        The weight of the positive class
+
+    neg_weight : float
+        The weight of the negative class
+
+    sample_weight : numpy array of shape [n_samples, ]
+        The weight of each sample
     """
     # if average is not true, average_coef, and average_intercept will be
     # unused
@@ -815,11 +851,6 @@ class SGDClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -827,6 +858,11 @@ class SGDClassifier(BaseSGDClassifier):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     class_weight : dict, {class_label: weight} or "balanced" or None, optional
         Preset for the class_weight fit parameter.
 
@@ -885,12 +921,12 @@ class SGDClassifier(BaseSGDClassifier):
     >>> from sklearn import linear_model
     >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
     >>> Y = np.array([1, 1, 2, 2])
-    >>> clf = linear_model.SGDClassifier()
+    >>> clf = linear_model.SGDClassifier(max_iter=1000)
     >>> clf.fit(X, Y)
     ... #doctest: +NORMALIZE_WHITESPACE
     SGDClassifier(alpha=0.0001, average=False, class_weight=None,
            early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
-           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,
+           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,
            n_iter=None, n_iter_no_change=5, n_jobs=1, penalty='l2',
            power_t=0.5, random_state=None, shuffle=True, tol=None,
            validation_fraction=0.1, verbose=0, warm_start=False)
@@ -1424,11 +1460,6 @@ class SGDRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
-    n_iter_no_change : int, default=5
-        Number of iterations with no improvement to wait before early stopping.
-
-        .. versionadded:: 0.20
-
     validation_fraction : float, default=0.1
         The proportion of training data to set aside as validation set for
         early stopping. Must be between 0 and 1.
@@ -1436,6 +1467,11 @@ class SGDRegressor(BaseSGDRegressor):
 
         .. versionadded:: 0.20
 
+    n_iter_no_change : int, default=5
+        Number of iterations with no improvement to wait before early stopping.
+
+        .. versionadded:: 0.20
+
     warm_start : bool, optional
         When set to True, reuse the solution of the previous call to fit as
         initialization, otherwise, just erase the previous solution.
@@ -1488,12 +1524,12 @@ class SGDRegressor(BaseSGDRegressor):
     >>> np.random.seed(0)
     >>> y = np.random.randn(n_samples)
     >>> X = np.random.randn(n_samples, n_features)
-    >>> clf = linear_model.SGDRegressor()
+    >>> clf = linear_model.SGDRegressor(max_iter=1000)
     >>> clf.fit(X, y)
     ... #doctest: +NORMALIZE_WHITESPACE
     SGDRegressor(alpha=0.0001, average=False, early_stopping=False,
            epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
-           learning_rate='invscaling', loss='squared_loss', max_iter=None,
+           learning_rate='invscaling', loss='squared_loss', max_iter=1000,
            n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,
            random_state=None, shuffle=True, tol=None, validation_fraction=0.1,
            verbose=0, warm_start=False)
diff --git a/sklearn/linear_model/tests/test_least_angle.py b/sklearn/linear_model/tests/test_least_angle.py
index 630559fe4fef..15df84177e66 100644
--- a/sklearn/linear_model/tests/test_least_angle.py
+++ b/sklearn/linear_model/tests/test_least_angle.py
@@ -1,5 +1,7 @@
 import warnings
 
+from distutils.version import LooseVersion
+
 import numpy as np
 from scipy import linalg
 
@@ -88,16 +90,22 @@ def test_all_precomputed():
             assert_array_almost_equal(expected, got)
 
 
+@pytest.mark.filterwarnings('ignore: `rcond` parameter will change')
+# numpy deprecation
 def test_lars_lstsq():
     # Test that Lars gives least square solution at the end
     # of the path
     X1 = 3 * diabetes.data  # use un-normalized dataset
     clf = linear_model.LassoLars(alpha=0.)
     clf.fit(X1, y)
-    coef_lstsq = np.linalg.lstsq(X1, y)[0]
+    # Avoid FutureWarning about default value change when numpy >= 1.14
+    rcond = None if LooseVersion(np.__version__) >= '1.14' else -1
+    coef_lstsq = np.linalg.lstsq(X1, y, rcond=rcond)[0]
     assert_array_almost_equal(clf.coef_, coef_lstsq)
 
 
+@pytest.mark.filterwarnings('ignore:`rcond` parameter will change')
+# numpy deprecation
 def test_lasso_gives_lstsq_solution():
     # Test that Lars Lasso gives least square solution at the end
     # of the path
@@ -473,6 +481,7 @@ def test_lars_path_readonly_data():
         _lars_path_residues(X_train, y_train, X_test, y_test, copy=False)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_lars_path_positive_constraint():
     # this is the main test for the positive parameter on the lars_path method
     # the estimator classes just make use of this function
@@ -487,12 +496,10 @@ def test_lars_path_positive_constraint():
     # assert_raises(ValueError, linear_model.lars_path, diabetes['data'],
     #               diabetes['target'], method='lar', positive=True)
 
-    with warnings.catch_warnings(record=True) as w:
+    with pytest.warns(DeprecationWarning, match="broken"):
         linear_model.lars_path(diabetes['data'], diabetes['target'],
                                return_path=True, method='lar',
                                positive=True)
-    assert_true(len(w) == 1)
-    assert "broken" in str(w[0].message)
 
     method = 'lasso'
     alpha, active, coefs = \
diff --git a/sklearn/linear_model/tests/test_randomized_l1.py b/sklearn/linear_model/tests/test_randomized_l1.py
index c783bfc7d493..564fbd4e7827 100644
--- a/sklearn/linear_model/tests/test_randomized_l1.py
+++ b/sklearn/linear_model/tests/test_randomized_l1.py
@@ -1,5 +1,6 @@
 # Authors: Alexandre Gramfort <alexandre.gramfort@inria.fr>
 # License: BSD 3 clause
+
 from tempfile import mkdtemp
 import shutil
 
@@ -15,8 +16,8 @@
 from sklearn.utils.testing import assert_warns_message
 
 from sklearn.linear_model.randomized_l1 import(lasso_stability_path,
-                                                RandomizedLasso,
-                                                RandomizedLogisticRegression)
+                                               RandomizedLasso,
+                                               RandomizedLogisticRegression)
 
 from sklearn.datasets import load_diabetes, load_iris
 from sklearn.feature_selection import f_regression, f_classif
@@ -56,7 +57,7 @@ def test_randomized_lasso_error_memory():
                           selection_threshold=selection_threshold,
                           memory=tempdir)
     assert_raises_regex(ValueError, "'memory' should either be a string or"
-                        " a sklearn.externals.joblib.Memory instance",
+                        " a sklearn.utils.Memory instance",
                         clf.fit, X, y)
 
 
@@ -111,6 +112,7 @@ def test_randomized_lasso():
     assert_raises(ValueError, clf.fit, X, y)
 
 
+@ignore_warnings(category=DeprecationWarning)
 def test_randomized_lasso_precompute():
     # Check randomized lasso for different values of precompute
     n_resampling = 20
diff --git a/sklearn/linear_model/tests/test_ridge.py b/sklearn/linear_model/tests/test_ridge.py
index 2f574b88ba7b..fc0c0a943b70 100644
--- a/sklearn/linear_model/tests/test_ridge.py
+++ b/sklearn/linear_model/tests/test_ridge.py
@@ -172,7 +172,8 @@ def test_ridge_sample_weights():
         for (alpha, intercept, solver) in param_grid:
 
             # Ridge with explicit sample_weight
-            est = Ridge(alpha=alpha, fit_intercept=intercept, solver=solver)
+            est = Ridge(alpha=alpha, fit_intercept=intercept,
+                        solver=solver, tol=1e-6)
             est.fit(X, y, sample_weight=sample_weight)
             coefs = est.coef_
             inter = est.intercept_
@@ -488,6 +489,7 @@ def check_dense_sparse(test_func):
         assert_array_almost_equal(ret_dense, ret_sparse, decimal=3)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 @pytest.mark.parametrize(
         'test_func',
         (_test_ridge_loo, _test_ridge_cv, _test_ridge_cv_normalize,
@@ -639,6 +641,7 @@ def test_ridge_classifier_cv_store_cv_values():
     assert r.cv_values_.shape == (n_samples, n_targets, n_alphas)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_ridgecv_sample_weight():
     rng = np.random.RandomState(0)
     alphas = (0.1, 1.0, 10.0)
diff --git a/sklearn/linear_model/tests/test_sag.py b/sklearn/linear_model/tests/test_sag.py
index 02a557d56ef7..81193d1b92c2 100644
--- a/sklearn/linear_model/tests/test_sag.py
+++ b/sklearn/linear_model/tests/test_sag.py
@@ -17,6 +17,7 @@
 from sklearn.utils.extmath import row_norms
 from sklearn.utils.testing import assert_almost_equal
 from sklearn.utils.testing import assert_array_almost_equal
+from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_greater
 from sklearn.utils.testing import assert_raise_message
 from sklearn.utils.testing import ignore_warnings
@@ -269,7 +270,6 @@ def test_classifier_matching():
         assert_array_almost_equal(intercept2, clf.intercept_, decimal=9)
 
 
-@ignore_warnings
 def test_regressor_matching():
     n_samples = 10
     n_features = 5
@@ -295,10 +295,10 @@ def test_regressor_matching():
                                dloss=squared_dloss,
                                fit_intercept=fit_intercept)
 
-    assert_array_almost_equal(weights1, clf.coef_, decimal=10)
-    assert_array_almost_equal(intercept1, clf.intercept_, decimal=10)
-    assert_array_almost_equal(weights2, clf.coef_, decimal=10)
-    assert_array_almost_equal(intercept2, clf.intercept_, decimal=10)
+    assert_allclose(weights1, clf.coef_)
+    assert_allclose(intercept1, clf.intercept_)
+    assert_allclose(weights2, clf.coef_)
+    assert_allclose(intercept2, clf.intercept_)
 
 
 @ignore_warnings
diff --git a/sklearn/linear_model/tests/test_sgd.py b/sklearn/linear_model/tests/test_sgd.py
index ee1c47370718..15e29ce4d41d 100644
--- a/sklearn/linear_model/tests/test_sgd.py
+++ b/sklearn/linear_model/tests/test_sgd.py
@@ -319,7 +319,7 @@ def test_validation_set_not_used_for_training(self):
 
         assert_array_equal(clf1.coef_, clf2.coef_)
 
-    @ignore_warnings(ConvergenceWarning)
+    @ignore_warnings(category=ConvergenceWarning)
     def test_n_iter_no_change(self):
         # test that n_iter_ increases monotonically with n_iter_no_change
         for early_stopping in [True, False]:
diff --git a/sklearn/linear_model/theil_sen.py b/sklearn/linear_model/theil_sen.py
index 544f79f9df05..de71e24cc690 100644
--- a/sklearn/linear_model/theil_sen.py
+++ b/sklearn/linear_model/theil_sen.py
@@ -21,7 +21,7 @@
 from ..base import RegressorMixin
 from ..utils import check_random_state
 from ..utils import check_X_y, _get_n_jobs
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals.six.moves import xrange as range
 from ..exceptions import ConvergenceWarning
 
diff --git a/sklearn/manifold/mds.py b/sklearn/manifold/mds.py
index 5aa032b89f1c..130dc9a0e9d1 100644
--- a/sklearn/manifold/mds.py
+++ b/sklearn/manifold/mds.py
@@ -12,8 +12,8 @@
 from ..base import BaseEstimator
 from ..metrics import euclidean_distances
 from ..utils import check_random_state, check_array, check_symmetric
-from ..externals.joblib import Parallel
-from ..externals.joblib import delayed
+from ..utils import Parallel
+from ..utils import delayed
 from ..isotonic import IsotonicRegression
 
 
diff --git a/sklearn/manifold/tests/test_spectral_embedding.py b/sklearn/manifold/tests/test_spectral_embedding.py
index bc32b58c6e7f..d236c17e5dbb 100644
--- a/sklearn/manifold/tests/test_spectral_embedding.py
+++ b/sklearn/manifold/tests/test_spectral_embedding.py
@@ -86,6 +86,8 @@ def test_sparse_graph_connected_component():
         assert_array_equal(component_1, component_2)
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of nmi will "
+                            "change in version 0.22")
 def test_spectral_embedding_two_components(seed=36):
     # Test spectral embedding with two components
     random_state = np.random.RandomState(seed)
@@ -180,6 +182,8 @@ def test_spectral_embedding_amg_solver(seed=36):
     assert_true(_check_with_col_sign_flipping(embed_amg, embed_arpack, 0.05))
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of nmi will "
+                            "change in version 0.22")
 def test_pipeline_spectral_clustering(seed=36):
     # Test using pipeline to do spectral clustering
     random_state = np.random.RandomState(seed)
diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py
index 381f51777b6a..2f084c4fced9 100644
--- a/sklearn/metrics/cluster/supervised.py
+++ b/sklearn/metrics/cluster/supervised.py
@@ -11,11 +11,13 @@
 #          Thierry Guillemot <thierry.guillemot.work@gmail.com>
 #          Gregory Stupp <stuppie@gmail.com>
 #          Joel Nothman <joel.nothman@gmail.com>
+#          Arya McCarthy <arya@jhu.edu>
 # License: BSD 3 clause
 
 from __future__ import division
 
 from math import log
+import warnings
 
 import numpy as np
 from scipy import sparse as sp
@@ -59,6 +61,21 @@ def check_clusterings(labels_true, labels_pred):
     return labels_true, labels_pred
 
 
+def _generalized_average(U, V, average_method):
+    """Return a particular mean of two numbers."""
+    if average_method == "min":
+        return min(U, V)
+    elif average_method == "geometric":
+        return np.sqrt(U * V)
+    elif average_method == "arithmetic":
+        return np.mean([U, V])
+    elif average_method == "max":
+        return max(U, V)
+    else:
+        raise ValueError("'average_method' must be 'min', 'geometric', "
+                         "'arithmetic', or 'max'")
+
+
 def contingency_matrix(labels_true, labels_pred, eps=None, sparse=False):
     """Build a contingency matrix describing the relationship between labels.
 
@@ -245,7 +262,9 @@ def homogeneity_completeness_v_measure(labels_true, labels_pred):
 
     V-Measure is furthermore symmetric: swapping ``labels_true`` and
     ``label_pred`` will give the same score. This does not hold for
-    homogeneity and completeness.
+    homogeneity and completeness. V-Measure is identical to
+    :func:`normalized_mutual_info_score` with the arithmetic averaging
+    method.
 
     Read more in the :ref:`User Guide <homogeneity_completeness>`.
 
@@ -444,7 +463,8 @@ def completeness_score(labels_true, labels_pred):
 def v_measure_score(labels_true, labels_pred):
     """V-measure cluster labeling given a ground truth.
 
-    This score is identical to :func:`normalized_mutual_info_score`.
+    This score is identical to :func:`normalized_mutual_info_score` with
+    the ``'arithmetic'`` option for averaging.
 
     The V-measure is the harmonic mean between homogeneity and completeness::
 
@@ -459,6 +479,7 @@ def v_measure_score(labels_true, labels_pred):
     measure the agreement of two independent label assignments strategies
     on the same dataset when the real ground truth is not known.
 
+
     Read more in the :ref:`User Guide <homogeneity_completeness>`.
 
     Parameters
@@ -485,6 +506,7 @@ def v_measure_score(labels_true, labels_pred):
     --------
     homogeneity_score
     completeness_score
+    normalized_mutual_info_score
 
     Examples
     --------
@@ -617,7 +639,8 @@ def mutual_info_score(labels_true, labels_pred, contingency=None):
     return mi.sum()
 
 
-def adjusted_mutual_info_score(labels_true, labels_pred):
+def adjusted_mutual_info_score(labels_true, labels_pred,
+                               average_method='warn'):
     """Adjusted Mutual Information between two clusterings.
 
     Adjusted Mutual Information (AMI) is an adjustment of the Mutual
@@ -626,7 +649,7 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
     clusters, regardless of whether there is actually more information shared.
     For two clusterings :math:`U` and :math:`V`, the AMI is given as::
 
-        AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [max(H(U), H(V)) - E(MI(U, V))]
+        AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]
 
     This metric is independent of the absolute values of the labels:
     a permutation of the class or cluster label values won't change the
@@ -650,9 +673,17 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
     labels_pred : array, shape = [n_samples]
         A clustering of the data into disjoint subsets.
 
+    average_method : string, optional (default: 'warn')
+        How to compute the normalizer in the denominator. Possible options
+        are 'min', 'geometric', 'arithmetic', and 'max'.
+        If 'warn', 'max' will be used. The default will change to
+        'arithmetic' in version 0.22.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
-    ami: float(upperlimited by 1.0)
+    ami: float (upperlimited by 1.0)
        The AMI returns a value of 1 when the two partitions are identical
        (ie perfectly matched). Random partitions (independent labellings) have
        an expected AMI around 0 on average hence can be negative.
@@ -670,14 +701,17 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
 
       >>> from sklearn.metrics.cluster import adjusted_mutual_info_score
       >>> adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
+      ... # doctest: +SKIP
       1.0
       >>> adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
+      ... # doctest: +SKIP
       1.0
 
     If classes members are completely split across different clusters,
     the assignment is totally in-complete, hence the AMI is null::
 
       >>> adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
+      ... # doctest: +SKIP
       0.0
 
     References
@@ -691,6 +725,12 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
        <https://en.wikipedia.org/wiki/Adjusted_Mutual_Information>`_
 
     """
+    if average_method == 'warn':
+        warnings.warn("The behavior of AMI will change in version 0.22. "
+                      "To match the behavior of 'v_measure_score', AMI will "
+                      "use average_method='arithmetic' by default.",
+                      FutureWarning)
+        average_method = 'max'
     labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
     n_samples = labels_true.shape[0]
     classes = np.unique(labels_true)
@@ -709,17 +749,29 @@ def adjusted_mutual_info_score(labels_true, labels_pred):
     emi = expected_mutual_information(contingency, n_samples)
     # Calculate entropy for each labeling
     h_true, h_pred = entropy(labels_true), entropy(labels_pred)
-    ami = (mi - emi) / (max(h_true, h_pred) - emi)
+    normalizer = _generalized_average(h_true, h_pred, average_method)
+    denominator = normalizer - emi
+    # Avoid 0.0 / 0.0 when expectation equals maximum, i.e a perfect match.
+    # normalizer should always be >= emi, but because of floating-point
+    # representation, sometimes emi is slightly larger. Correct this
+    # by preserving the sign.
+    if denominator < 0:
+        denominator = min(denominator, -np.finfo('float64').eps)
+    else:
+        denominator = max(denominator, np.finfo('float64').eps)
+    ami = (mi - emi) / denominator
     return ami
 
 
-def normalized_mutual_info_score(labels_true, labels_pred):
+def normalized_mutual_info_score(labels_true, labels_pred,
+                                 average_method='warn'):
     """Normalized Mutual Information between two clusterings.
 
     Normalized Mutual Information (NMI) is an normalization of the Mutual
     Information (MI) score to scale the results between 0 (no mutual
     information) and 1 (perfect correlation). In this function, mutual
-    information is normalized by ``sqrt(H(labels_true) * H(labels_pred))``.
+    information is normalized by some generalized mean of ``H(labels_true)``
+    and ``H(labels_pred))``, defined by the `average_method`.
 
     This measure is not adjusted for chance. Therefore
     :func:`adjusted_mustual_info_score` might be preferred.
@@ -743,6 +795,14 @@ def normalized_mutual_info_score(labels_true, labels_pred):
     labels_pred : array, shape = [n_samples]
         A clustering of the data into disjoint subsets.
 
+    average_method : string, optional (default: 'warn')
+        How to compute the normalizer in the denominator. Possible options
+        are 'min', 'geometric', 'arithmetic', and 'max'.
+        If 'warn', 'geometric' will be used. The default will change to
+        'arithmetic' in version 0.22.
+
+        .. versionadded:: 0.20
+
     Returns
     -------
     nmi : float
@@ -750,6 +810,7 @@ def normalized_mutual_info_score(labels_true, labels_pred):
 
     See also
     --------
+    v_measure_score: V-Measure (NMI with arithmetic mean option.)
     adjusted_rand_score: Adjusted Rand Index
     adjusted_mutual_info_score: Adjusted Mutual Information (adjusted
         against chance)
@@ -762,17 +823,26 @@ def normalized_mutual_info_score(labels_true, labels_pred):
 
       >>> from sklearn.metrics.cluster import normalized_mutual_info_score
       >>> normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
+      ... # doctest: +SKIP
       1.0
       >>> normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
+      ... # doctest: +SKIP
       1.0
 
     If classes members are completely split across different clusters,
     the assignment is totally in-complete, hence the NMI is null::
 
-      >>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
+      >>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])i
+      ... # doctest: +SKIP
       0.0
 
     """
+    if average_method == 'warn':
+        warnings.warn("The behavior of NMI will change in version 0.22. "
+                      "To match the behavior of 'v_measure_score', NMI will "
+                      "use average_method='arithmetic' by default.",
+                      FutureWarning)
+        average_method = 'geometric'
     labels_true, labels_pred = check_clusterings(labels_true, labels_pred)
     classes = np.unique(labels_true)
     clusters = np.unique(labels_pred)
@@ -789,7 +859,10 @@ def normalized_mutual_info_score(labels_true, labels_pred):
     # Calculate the expected value for the mutual information
     # Calculate entropy for each labeling
     h_true, h_pred = entropy(labels_true), entropy(labels_pred)
-    nmi = mi / max(np.sqrt(h_true * h_pred), 1e-10)
+    normalizer = _generalized_average(h_true, h_pred, average_method)
+    # Avoid 0.0 / 0.0 when either entropy is zero.
+    normalizer = max(normalizer, np.finfo('float64').eps)
+    nmi = mi / normalizer
     return nmi
 
 
diff --git a/sklearn/metrics/cluster/tests/test_common.py b/sklearn/metrics/cluster/tests/test_common.py
index a7e54d22cc7c..c186a3ad5a4c 100644
--- a/sklearn/metrics/cluster/tests/test_common.py
+++ b/sklearn/metrics/cluster/tests/test_common.py
@@ -15,7 +15,7 @@
 from sklearn.metrics.cluster import calinski_harabaz_score
 from sklearn.metrics.cluster import davies_bouldin_score
 
-from sklearn.utils.testing import assert_allclose
+from sklearn.utils.testing import assert_allclose, ignore_warnings
 
 
 # Dictionaries of metrics
@@ -83,6 +83,8 @@ def test_symmetric_non_symmetric_union():
             sorted(SUPERVISED_METRICS))
 
 
+# 0.22 AMI and NMI changes
+@pytest.mark.filterwarnings('ignore::FutureWarning')
 @pytest.mark.parametrize(
     'metric_name, y1, y2',
     [(name, y1, y2) for name in SYMMETRIC_METRICS]
@@ -101,6 +103,8 @@ def test_non_symmetry(metric_name, y1, y2):
     assert metric(y1, y2) != pytest.approx(metric(y2, y1))
 
 
+# 0.22 AMI and NMI changes
+@pytest.mark.filterwarnings('ignore::FutureWarning')
 @pytest.mark.parametrize("metric_name", NORMALIZED_METRICS)
 def test_normalized_output(metric_name):
     upper_bound_1 = [0, 0, 0, 1, 1, 1]
@@ -119,13 +123,15 @@ def test_normalized_output(metric_name):
     assert not (score < 0).any()
 
 
-# All clustering metrics do not change score due to permutations of labels
-# that is when 0 and 1 exchanged.
+# 0.22 AMI and NMI changes
+@pytest.mark.filterwarnings('ignore::FutureWarning')
 @pytest.mark.parametrize(
     "metric_name",
     dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
 )
 def test_permute_labels(metric_name):
+    # All clustering metrics do not change score due to permutations of labels
+    # that is when 0 and 1 exchanged.
     y_label = np.array([0, 0, 0, 1, 1, 0, 1])
     y_pred = np.array([1, 0, 1, 0, 1, 1, 0])
     if metric_name in SUPERVISED_METRICS:
@@ -141,11 +147,13 @@ def test_permute_labels(metric_name):
         assert_allclose(score_1, metric(X, 1 - y_pred))
 
 
-# For all clustering metrics Input parameters can be both
+# 0.22 AMI and NMI changes
+@pytest.mark.filterwarnings('ignore::FutureWarning')
 @pytest.mark.parametrize(
     "metric_name",
     dict(SUPERVISED_METRICS, **UNSUPERVISED_METRICS)
 )
+# For all clustering metrics Input parameters can be both
 # in the form of arrays lists, positive, negetive or string
 def test_format_invariance(metric_name):
     y_true = [0, 0, 0, 0, 1, 1, 1, 1]
diff --git a/sklearn/metrics/cluster/tests/test_supervised.py b/sklearn/metrics/cluster/tests/test_supervised.py
index 8be39cd220d2..46b95cfd8fda 100644
--- a/sklearn/metrics/cluster/tests/test_supervised.py
+++ b/sklearn/metrics/cluster/tests/test_supervised.py
@@ -12,10 +12,12 @@
 from sklearn.metrics.cluster import mutual_info_score
 from sklearn.metrics.cluster import normalized_mutual_info_score
 from sklearn.metrics.cluster import v_measure_score
+from sklearn.metrics.cluster.supervised import _generalized_average
 
 from sklearn.utils import assert_all_finite
 from sklearn.utils.testing import (
         assert_equal, assert_almost_equal, assert_raise_message,
+        assert_warns_message, ignore_warnings
 )
 from numpy.testing import assert_array_almost_equal
 
@@ -30,6 +32,18 @@
 ]
 
 
+def test_future_warning():
+    score_funcs_with_changing_means = [
+        normalized_mutual_info_score,
+        adjusted_mutual_info_score,
+    ]
+    warning_msg = "The behavior of "
+    args = [0, 0, 0], [0, 0, 0]
+    for score_func in score_funcs_with_changing_means:
+        assert_warns_message(FutureWarning, warning_msg, score_func, *args)
+
+
+@ignore_warnings(category=FutureWarning)
 def test_error_messages_on_wrong_input():
     for score_func in score_funcs:
         expected = ('labels_true and labels_pred must have same size,'
@@ -46,6 +60,17 @@ def test_error_messages_on_wrong_input():
                              [0, 1, 0], [[1, 1], [0, 0]])
 
 
+def test_generalized_average():
+    a, b = 1, 2
+    methods = ["min", "geometric", "arithmetic", "max"]
+    means = [_generalized_average(a, b, method) for method in methods]
+    assert means[0] <= means[1] <= means[2] <= means[3]
+    c, d = 12, 12
+    means = [_generalized_average(c, d, method) for method in methods]
+    assert means[0] == means[1] == means[2] == means[3]
+
+
+@ignore_warnings(category=FutureWarning)
 def test_perfect_matches():
     for score_func in score_funcs:
         assert_equal(score_func([], []), 1.0)
@@ -55,6 +80,20 @@ def test_perfect_matches():
         assert_equal(score_func([0., 1., 0.], [42., 7., 42.]), 1.0)
         assert_equal(score_func([0., 1., 2.], [42., 7., 2.]), 1.0)
         assert_equal(score_func([0, 1, 2], [42, 7, 2]), 1.0)
+    score_funcs_with_changing_means = [
+        normalized_mutual_info_score,
+        adjusted_mutual_info_score,
+    ]
+    means = {"min", "geometric", "arithmetic", "max"}
+    for score_func in score_funcs_with_changing_means:
+        for mean in means:
+            assert score_func([], [], mean) == 1.0
+            assert score_func([0], [1], mean) == 1.0
+            assert score_func([0, 0, 0], [0, 0, 0], mean) == 1.0
+            assert score_func([0, 1, 0], [42, 7, 42], mean) == 1.0
+            assert score_func([0., 1., 0.], [42., 7., 42.], mean) == 1.0
+            assert score_func([0., 1., 2.], [42., 7., 2.], mean) == 1.0
+            assert score_func([0, 1, 2], [42, 7, 2], mean) == 1.0
 
 
 def test_homogeneous_but_not_complete_labeling():
@@ -87,7 +126,7 @@ def test_not_complete_and_not_homogeneous_labeling():
     assert_almost_equal(v, 0.52, 2)
 
 
-def test_non_consicutive_labels():
+def test_non_consecutive_labels():
     # regression tests for labels with gaps
     h, c, v = homogeneity_completeness_v_measure(
         [0, 0, 0, 2, 2, 2],
@@ -109,6 +148,7 @@ def test_non_consicutive_labels():
     assert_almost_equal(ari_2, 0.24, 2)
 
 
+@ignore_warnings(category=FutureWarning)
 def uniform_labelings_scores(score_func, n_samples, k_range, n_runs=10,
                              seed=42):
     # Compute score for random uniform cluster labelings
@@ -122,6 +162,7 @@ def uniform_labelings_scores(score_func, n_samples, k_range, n_runs=10,
     return scores
 
 
+@ignore_warnings(category=FutureWarning)
 def test_adjustment_for_chance():
     # Check that adjusted scores are almost zero on random labels
     n_clusters_range = [2, 10, 50, 90]
@@ -135,6 +176,7 @@ def test_adjustment_for_chance():
     assert_array_almost_equal(max_abs_scores, [0.02, 0.03, 0.03, 0.02], 2)
 
 
+@ignore_warnings(category=FutureWarning)
 def test_adjusted_mutual_info_score():
     # Compute the Adjusted Mutual Information and test against known values
     labels_a = np.array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])
@@ -215,6 +257,7 @@ def test_contingency_matrix_sparse():
                                     eps=1e-10, sparse=True)
 
 
+@ignore_warnings(category=FutureWarning)
 def test_exactly_zero_info_score():
     # Check numerical stability when information is exactly zero
     for i in np.logspace(1, 4, 4).astype(np.int):
@@ -224,6 +267,11 @@ def test_exactly_zero_info_score():
         assert_equal(v_measure_score(labels_a, labels_b), 0.0)
         assert_equal(adjusted_mutual_info_score(labels_a, labels_b), 0.0)
         assert_equal(normalized_mutual_info_score(labels_a, labels_b), 0.0)
+        for method in ["min", "geometric", "arithmetic", "max"]:
+            assert adjusted_mutual_info_score(labels_a, labels_b,
+                                              method) == 0.0
+            assert normalized_mutual_info_score(labels_a, labels_b,
+                                                method) == 0.0
 
 
 def test_v_measure_and_mutual_information(seed=36):
@@ -235,6 +283,11 @@ def test_v_measure_and_mutual_information(seed=36):
         assert_almost_equal(v_measure_score(labels_a, labels_b),
                             2.0 * mutual_info_score(labels_a, labels_b) /
                             (entropy(labels_a) + entropy(labels_b)), 0)
+        avg = 'arithmetic'
+        assert_almost_equal(v_measure_score(labels_a, labels_b),
+                            normalized_mutual_info_score(labels_a, labels_b,
+                                                         average_method=avg)
+                            )
 
 
 def test_fowlkes_mallows_score():
diff --git a/sklearn/metrics/pairwise.py b/sklearn/metrics/pairwise.py
index b4928ed7492f..9e16fa6d0b5c 100644
--- a/sklearn/metrics/pairwise.py
+++ b/sklearn/metrics/pairwise.py
@@ -24,9 +24,9 @@
 from ..utils import gen_batches, get_chunk_n_rows
 from ..utils.extmath import row_norms, safe_sparse_dot
 from ..preprocessing import normalize
-from ..externals.joblib import Parallel
-from ..externals.joblib import delayed
-from ..externals.joblib import cpu_count
+from ..utils import Parallel
+from ..utils import delayed
+from ..utils import cpu_count
 
 from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan
 
diff --git a/sklearn/metrics/ranking.py b/sklearn/metrics/ranking.py
index 5039c5f874a5..fd6e28a20ae0 100644
--- a/sklearn/metrics/ranking.py
+++ b/sklearn/metrics/ranking.py
@@ -20,6 +20,8 @@
 from __future__ import division
 
 import warnings
+from functools import partial
+
 import numpy as np
 from scipy.sparse import csr_matrix
 from scipy.stats import rankdata
@@ -125,7 +127,7 @@ def auc(x, y, reorder='deprecated'):
     return area
 
 
-def average_precision_score(y_true, y_score, average="macro",
+def average_precision_score(y_true, y_score, average="macro", pos_label=1,
                             sample_weight=None):
     """Compute average precision (AP) from prediction scores
 
@@ -150,7 +152,7 @@ def average_precision_score(y_true, y_score, average="macro",
     Parameters
     ----------
     y_true : array, shape = [n_samples] or [n_samples, n_classes]
-        True binary labels (either {0, 1} or {-1, 1}).
+        True binary labels or binary label indicators.
 
     y_score : array, shape = [n_samples] or [n_samples, n_classes]
         Target scores, can either be probability estimates of the positive
@@ -173,6 +175,10 @@ def average_precision_score(y_true, y_score, average="macro",
         ``'samples'``:
             Calculate metrics for each instance, and find their average.
 
+    pos_label : int or str (default=1)
+        The label of the positive class. Only applied to binary ``y_true``.
+        For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.
+
     sample_weight : array-like of shape = [n_samples], optional
         Sample weights.
 
@@ -209,17 +215,23 @@ def average_precision_score(y_true, y_score, average="macro",
       are weighted by the change in recall since the last operating point.
     """
     def _binary_uninterpolated_average_precision(
-            y_true, y_score, sample_weight=None):
+            y_true, y_score, pos_label=1, sample_weight=None):
         precision, recall, _ = precision_recall_curve(
-            y_true, y_score, sample_weight=sample_weight)
+            y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)
         # Return the step function integral
         # The following works because the last entry of precision is
         # guaranteed to be 1, as returned by precision_recall_curve
         return -np.sum(np.diff(recall) * np.array(precision)[:-1])
 
-    return _average_binary_score(_binary_uninterpolated_average_precision,
-                                 y_true, y_score, average,
-                                 sample_weight=sample_weight)
+    y_type = type_of_target(y_true)
+    if y_type == "multilabel-indicator" and pos_label != 1:
+        raise ValueError("Parameter pos_label is fixed to 1 for "
+                         "multilabel-indicator y_true. Do not set "
+                         "pos_label or set pos_label to 1.")
+    average_precision = partial(_binary_uninterpolated_average_precision,
+                                pos_label=pos_label)
+    return _average_binary_score(average_precision, y_true, y_score,
+                                 average, sample_weight=sample_weight)
 
 
 def roc_auc_score(y_true, y_score, average="macro", sample_weight=None,
@@ -501,6 +513,7 @@ def precision_recall_curve(y_true, probas_pred, pos_label=None,
                                              sample_weight=sample_weight)
 
     precision = tps / (tps + fps)
+    precision[np.isnan(precision)] = 0
     recall = tps / tps[-1]
 
     # stop when full recall attained
diff --git a/sklearn/metrics/scorer.py b/sklearn/metrics/scorer.py
index 590b9826b4ef..021f1eca3762 100644
--- a/sklearn/metrics/scorer.py
+++ b/sklearn/metrics/scorer.py
@@ -19,7 +19,6 @@
 # License: Simplified BSD
 
 from abc import ABCMeta
-from collections import Iterable
 
 import numpy as np
 
@@ -40,6 +39,7 @@
 from .cluster import fowlkes_mallows_score
 
 from ..utils.multiclass import type_of_target
+from ..utils.fixes import _Iterable as Iterable
 from ..externals import six
 from ..base import is_regressor
 
diff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py
index b858868a7454..b804a97f1534 100644
--- a/sklearn/metrics/tests/test_common.py
+++ b/sklearn/metrics/tests/test_common.py
@@ -198,22 +198,20 @@ def precision_recall_curve_padded_thresholds(*args, **kwargs):
 
     "brier_score_loss": brier_score_loss,
 
-    "roc_auc_score": roc_auc_score,
+    "roc_auc_score": roc_auc_score,  # default: average="macro"
     "weighted_roc_auc": partial(roc_auc_score, average="weighted"),
     "samples_roc_auc": partial(roc_auc_score, average="samples"),
     "micro_roc_auc": partial(roc_auc_score, average="micro"),
-    "macro_roc_auc": partial(roc_auc_score, average="macro"),
     "partial_roc_auc": partial(roc_auc_score, max_fpr=0.5),
 
-    "average_precision_score": average_precision_score,
+    "average_precision_score":
+    average_precision_score,  # default: average="macro"
     "weighted_average_precision_score":
     partial(average_precision_score, average="weighted"),
     "samples_average_precision_score":
     partial(average_precision_score, average="samples"),
     "micro_average_precision_score":
     partial(average_precision_score, average="micro"),
-    "macro_average_precision_score":
-    partial(average_precision_score, average="macro"),
     "label_ranking_average_precision_score":
     label_ranking_average_precision_score,
 }
@@ -241,13 +239,6 @@ def precision_recall_curve_padded_thresholds(*args, **kwargs):
     "samples_precision_score",
     "samples_recall_score",
     "coverage_error",
-
-    "average_precision_score",
-    "weighted_average_precision_score",
-    "micro_average_precision_score",
-    "macro_average_precision_score",
-    "samples_average_precision_score",
-
     "label_ranking_loss",
     "label_ranking_average_precision_score",
 }
@@ -260,10 +251,14 @@ def precision_recall_curve_padded_thresholds(*args, **kwargs):
     "roc_auc_score",
     "micro_roc_auc",
     "weighted_roc_auc",
-    "macro_roc_auc",
     "samples_roc_auc",
     "partial_roc_auc",
 
+    "average_precision_score",
+    "weighted_average_precision_score",
+    "micro_average_precision_score",
+    "samples_average_precision_score",
+
     # with default average='binary', multiclass is prohibited
     "precision_score",
     "recall_score",
@@ -299,6 +294,11 @@ def precision_recall_curve_padded_thresholds(*args, **kwargs):
 
     "precision_score", "recall_score", "f1_score", "f2_score", "f0.5_score",
 
+    "average_precision_score",
+    "weighted_average_precision_score",
+    "micro_average_precision_score",
+    "samples_average_precision_score",
+
     # pos_label support deprecated; to be removed in 0.18:
     "weighted_f0.5_score", "weighted_f1_score", "weighted_f2_score",
     "weighted_precision_score", "weighted_recall_score",
@@ -348,11 +348,10 @@ def precision_recall_curve_padded_thresholds(*args, **kwargs):
     "unnormalized_log_loss",
 
     "roc_auc_score", "weighted_roc_auc", "samples_roc_auc",
-    "micro_roc_auc", "macro_roc_auc", "partial_roc_auc",
+    "micro_roc_auc", "partial_roc_auc",
 
     "average_precision_score", "weighted_average_precision_score",
     "samples_average_precision_score", "micro_average_precision_score",
-    "macro_average_precision_score",
 
     "coverage_error", "label_ranking_loss",
     "label_ranking_average_precision_score",
@@ -667,7 +666,7 @@ def test_thresholded_invariance_string_vs_numbers_labels(name):
                                err_msg="{0} failed string vs number "
                                        "invariance test".format(name))
 
-            measure_with_strobj = metric(y1_str.astype('O'), y2)
+            measure_with_strobj = metric_str(y1_str.astype('O'), y2)
             assert_array_equal(measure_with_number, measure_with_strobj,
                                err_msg="{0} failed string object vs number "
                                        "invariance test".format(name))
diff --git a/sklearn/metrics/tests/test_ranking.py b/sklearn/metrics/tests/test_ranking.py
index 5e9a8a0c847a..33406e35ae89 100644
--- a/sklearn/metrics/tests/test_ranking.py
+++ b/sklearn/metrics/tests/test_ranking.py
@@ -430,6 +430,7 @@ def test_auc():
     assert_array_almost_equal(auc(x, y), 0.5)
 
 
+@pytest.mark.filterwarnings("ignore: The 'reorder' parameter")  # 0.22
 def test_auc_duplicate_values():
     # Test Area Under Curve (AUC) computation with duplicate values
 
@@ -437,6 +438,8 @@ def test_auc_duplicate_values():
     # from numpy.argsort(x), which was reordering the tied 0's in this example
     # and resulting in an incorrect area computation. This test detects the
     # error.
+
+    # This will not work again in the future! so regression?
     x = [-2.0, 0.0, 0.0, 0.0, 1.0]
     y1 = [2.0, 0.0, 0.5, 1.0, 1.0]
     y2 = [2.0, 1.0, 0.0, 0.5, 1.0]
@@ -681,6 +684,18 @@ def test_average_precision_constant_values():
     assert_equal(average_precision_score(y_true, y_score), .25)
 
 
+def test_average_precision_score_pos_label_multilabel_indicator():
+    # Raise an error for multilabel-indicator y_true with
+    # pos_label other than 1
+    y_true = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])
+    y_pred = np.array([[0.9, 0.1], [0.1, 0.9], [0.8, 0.2], [0.2, 0.8]])
+    erorr_message = ("Parameter pos_label is fixed to 1 for multilabel"
+                     "-indicator y_true. Do not set pos_label or set "
+                     "pos_label to 1.")
+    assert_raise_message(ValueError, erorr_message, average_precision_score,
+                         y_true, y_pred, pos_label=0)
+
+
 def test_score_scale_invariance():
     # Test that average_precision_score and roc_auc_score are invariant by
     # the scaling or shifting of probabilities
diff --git a/sklearn/metrics/tests/test_score_objects.py b/sklearn/metrics/tests/test_score_objects.py
index 6ce2955a127d..33a0fc110939 100644
--- a/sklearn/metrics/tests/test_score_objects.py
+++ b/sklearn/metrics/tests/test_score_objects.py
@@ -413,6 +413,8 @@ def test_thresholded_scorers_multilabel_indicator_data():
     assert_almost_equal(score1, score2)
 
 
+@pytest.mark.filterwarnings("ignore:the behavior of ")
+# AMI and NMI changes for 0.22
 def test_supervised_cluster_scorers():
     # Test clustering scorers against gold standard labeling.
     X, y = make_blobs(random_state=0, centers=2)
diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py
index 1cf8a0fb9355..49265e437930 100644
--- a/sklearn/mixture/base.py
+++ b/sklearn/mixture/base.py
@@ -172,11 +172,14 @@ def _initialize(self, X, resp):
     def fit(self, X, y=None):
         """Estimate model parameters with the EM algorithm.
 
-        The method fits the model `n_init` times and set the parameters with
+        The method fits the model ``n_init`` times and sets the parameters with
         which the model has the largest likelihood or lower bound. Within each
-        trial, the method iterates between E-step and M-step for `max_iter`
+        trial, the method iterates between E-step and M-step for ``max_iter``
         times until the change of likelihood or lower bound is less than
-        `tol`, otherwise, a `ConvergenceWarning` is raised.
+        ``tol``, otherwise, a ``ConvergenceWarning`` is raised.
+        If ``warm_start`` is ``True``, then ``n_init`` is ignored and a single
+        initialization is performed upon the first call. Upon consecutive
+        calls, training starts where it left off.
 
         Parameters
         ----------
@@ -232,27 +235,28 @@ def fit_predict(self, X, y=None):
 
             if do_init:
                 self._initialize_parameters(X, random_state)
-                self.lower_bound_ = -np.infty
+
+            lower_bound = (-np.infty if do_init else self.lower_bound_)
 
             for n_iter in range(1, self.max_iter + 1):
-                prev_lower_bound = self.lower_bound_
+                prev_lower_bound = lower_bound
 
                 log_prob_norm, log_resp = self._e_step(X)
                 self._m_step(X, log_resp)
-                self.lower_bound_ = self._compute_lower_bound(
+                lower_bound = self._compute_lower_bound(
                     log_resp, log_prob_norm)
 
-                change = self.lower_bound_ - prev_lower_bound
+                change = lower_bound - prev_lower_bound
                 self._print_verbose_msg_iter_end(n_iter, change)
 
                 if abs(change) < self.tol:
                     self.converged_ = True
                     break
 
-            self._print_verbose_msg_init_end(self.lower_bound_)
+            self._print_verbose_msg_init_end(lower_bound)
 
-            if self.lower_bound_ > max_lower_bound:
-                max_lower_bound = self.lower_bound_
+            if lower_bound > max_lower_bound:
+                max_lower_bound = lower_bound
                 best_params = self._get_parameters()
                 best_n_iter = n_iter
 
@@ -265,6 +269,7 @@ def fit_predict(self, X, y=None):
 
         self._set_parameters(best_params)
         self.n_iter_ = best_n_iter
+        self.lower_bound_ = max_lower_bound
 
         return log_resp.argmax(axis=1)
 
diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py
index 5673db5f98a0..2c5f9b6cf151 100644
--- a/sklearn/mixture/gaussian_mixture.py
+++ b/sklearn/mixture/gaussian_mixture.py
@@ -512,6 +512,8 @@ class GaussianMixture(BaseMixture):
         If 'warm_start' is True, the solution of the last fitting is used as
         initialization for the next call of fit(). This can speed up
         convergence when fit is called several times on similar problems.
+        In that case, 'n_init' is ignored and only a single initialization
+        occurs upon the first call.
         See :term:`the Glossary <warm_start>`.
 
     verbose : int, default to 0.
@@ -575,7 +577,8 @@ class GaussianMixture(BaseMixture):
         Number of step used by the best fit of EM to reach the convergence.
 
     lower_bound_ : float
-        Log-likelihood of the best fit of EM.
+        Lower bound value on the log-likelihood (of the training data with
+        respect to the model) of the best fit of EM.
 
     See Also
     --------
diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py
index 3b17bf17bf7e..2f0a01b4a684 100644
--- a/sklearn/mixture/tests/test_gaussian_mixture.py
+++ b/sklearn/mixture/tests/test_gaussian_mixture.py
@@ -764,7 +764,6 @@ def test_gaussian_mixture_verbose():
 
 
 def test_warm_start():
-
     random_state = 0
     rng = np.random.RandomState(random_state)
     n_samples, n_features, n_components = 500, 2, 2
@@ -806,6 +805,25 @@ def test_warm_start():
     assert_true(h.converged_)
 
 
+@ignore_warnings(category=ConvergenceWarning)
+def test_convergence_detected_with_warm_start():
+    # We check that convergence is detected when warm_start=True
+    rng = np.random.RandomState(0)
+    rand_data = RandomData(rng)
+    n_components = rand_data.n_components
+    X = rand_data.X['full']
+
+    for max_iter in (1, 2, 50):
+        gmm = GaussianMixture(n_components=n_components, warm_start=True,
+                              max_iter=max_iter, random_state=rng)
+        for _ in range(100):
+            gmm.fit(X)
+            if gmm.converged_:
+                break
+        assert gmm.converged_
+        assert max_iter >= gmm.n_iter_
+
+
 def test_score():
     covar_type = 'full'
     rng = np.random.RandomState(0)
@@ -991,14 +1009,14 @@ def test_sample():
 @ignore_warnings(category=ConvergenceWarning)
 def test_init():
     # We check that by increasing the n_init number we have a better solution
-    random_state = 0
-    rand_data = RandomData(np.random.RandomState(random_state), scale=1)
-    n_components = rand_data.n_components
-    X = rand_data.X['full']
+    for random_state in range(25):
+        rand_data = RandomData(np.random.RandomState(random_state), scale=1)
+        n_components = rand_data.n_components
+        X = rand_data.X['full']
 
-    gmm1 = GaussianMixture(n_components=n_components, n_init=1,
-                           max_iter=1, random_state=random_state).fit(X)
-    gmm2 = GaussianMixture(n_components=n_components, n_init=100,
-                           max_iter=1, random_state=random_state).fit(X)
+        gmm1 = GaussianMixture(n_components=n_components, n_init=1,
+                               max_iter=1, random_state=random_state).fit(X)
+        gmm2 = GaussianMixture(n_components=n_components, n_init=10,
+                               max_iter=1, random_state=random_state).fit(X)
 
-    assert_greater(gmm2.lower_bound_, gmm1.lower_bound_)
+        assert gmm2.lower_bound_ >= gmm1.lower_bound_
diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py
index a45a4bf5b4e6..effee28cb20c 100644
--- a/sklearn/model_selection/_search.py
+++ b/sklearn/model_selection/_search.py
@@ -13,7 +13,7 @@
 # License: BSD 3 clause
 
 from abc import ABCMeta, abstractmethod
-from collections import Mapping, namedtuple, defaultdict, Sequence, Iterable
+from collections import namedtuple, defaultdict
 from functools import partial, reduce
 from itertools import product
 import operator
@@ -29,11 +29,13 @@
 from ._validation import _fit_and_score
 from ._validation import _aggregate_score_dicts
 from ..exceptions import NotFittedError
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..externals import six
 from ..utils import check_random_state
 from ..utils.fixes import sp_version
 from ..utils.fixes import MaskedArray
+from ..utils.fixes import _Mapping as Mapping, _Sequence as Sequence
+from ..utils.fixes import _Iterable as Iterable
 from ..utils.random import sample_without_replacement
 from ..utils.validation import indexable, check_is_fitted
 from ..utils.metaestimators import if_delegate_has_method
@@ -936,8 +938,8 @@ class GridSearchCV(BaseSearchCV):
     >>> iris = datasets.load_iris()
     >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
     >>> svc = svm.SVC(gamma="scale")
-    >>> clf = GridSearchCV(svc, parameters)
-    >>> clf.fit(iris.data, iris.target)
+    >>> clf = GridSearchCV(svc, parameters) # doctest: +SKIP
+    >>> clf.fit(iris.data, iris.target) # doctest: +SKIP
     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
     GridSearchCV(cv=None, error_score=...,
            estimator=SVC(C=1.0, cache_size=..., class_weight=..., coef0=...,
@@ -948,7 +950,7 @@ class GridSearchCV(BaseSearchCV):
            fit_params=None, iid=..., n_jobs=1,
            param_grid=..., pre_dispatch=..., refit=..., return_train_score=...,
            scoring=..., verbose=...)
-    >>> sorted(clf.cv_results_.keys())
+    >>> sorted(clf.cv_results_.keys()) # doctest: +SKIP
     ...                             # doctest: +NORMALIZE_WHITESPACE +ELLIPSIS
     ['mean_fit_time', 'mean_score_time', 'mean_test_score',...
      'mean_train_score', 'param_C', 'param_kernel', 'params',...
diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py
index c0367a2349e8..ded8b66b3af3 100644
--- a/sklearn/model_selection/_split.py
+++ b/sklearn/model_selection/_split.py
@@ -15,7 +15,6 @@
 
 import warnings
 from itertools import chain, combinations
-from collections import Iterable
 from math import ceil, floor
 import numbers
 from abc import ABCMeta, abstractmethod
@@ -29,6 +28,7 @@
 from ..externals.six import with_metaclass
 from ..externals.six.moves import zip
 from ..utils.fixes import signature, comb
+from ..utils.fixes import _Iterable as Iterable
 from ..base import _pprint
 
 __all__ = ['BaseCrossValidator',
diff --git a/sklearn/model_selection/_validation.py b/sklearn/model_selection/_validation.py
index 9241d05fd432..5a46ca0bf792 100644
--- a/sklearn/model_selection/_validation.py
+++ b/sklearn/model_selection/_validation.py
@@ -25,7 +25,8 @@
 from ..utils.deprecation import DeprecationDict
 from ..utils.validation import _is_arraylike, _num_samples
 from ..utils.metaestimators import _safe_split
-from ..externals.joblib import Parallel, delayed, logger
+from ..utils import Parallel, delayed
+from ..utils._joblib import logger
 from ..externals.six.moves import zip
 from ..metrics.scorer import check_scoring, _check_multimetric_scoring
 from ..exceptions import FitFailedWarning
@@ -184,7 +185,8 @@ def cross_validate(estimator, X, y=None, groups=None, scoring=None, cv=None,
     (please refer the ``scoring`` parameter doc for more information)
 
     >>> scores = cross_validate(lasso, X, y,
-    ...                         scoring=('r2', 'neg_mean_squared_error'))
+    ...                         scoring=('r2', 'neg_mean_squared_error'),
+    ...                         return_train_score=True)
     >>> print(scores['test_neg_mean_squared_error'])      # doctest: +ELLIPSIS
     [-3635.5... -3573.3... -6114.7...]
     >>> print(scores['train_r2'])                         # doctest: +ELLIPSIS
diff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py
index d80e39f9f0c4..9bd4c475d190 100644
--- a/sklearn/model_selection/tests/test_search.py
+++ b/sklearn/model_selection/tests/test_search.py
@@ -1,6 +1,5 @@
 """Test the search module"""
 
-from collections import Iterable, Sized
 from sklearn.externals.six.moves import cStringIO as StringIO
 from sklearn.externals.six.moves import xrange
 from itertools import chain, product
@@ -8,6 +7,7 @@
 import sys
 from types import GeneratorType
 import re
+import warnings
 
 import numpy as np
 import scipy.sparse as sp
@@ -15,6 +15,7 @@
 
 from sklearn.utils.fixes import sp_version
 from sklearn.utils.fixes import PY3_OR_LATER
+from sklearn.utils.fixes import _Iterable as Iterable, _Sized as Sized
 from sklearn.utils.testing import assert_equal
 from sklearn.utils.testing import assert_not_equal
 from sklearn.utils.testing import assert_raises
@@ -177,6 +178,7 @@ def test_parameter_grid():
     assert_grid_iter_equals_getitem(has_empty)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search():
     # Test that the best estimator contains the right value for foo_param
     clf = MockClassifier()
@@ -220,14 +222,19 @@ def check_hyperparameter_searcher_with_fit_params(klass, **klass_kwargs):
     searcher.fit(X, y, spam=np.ones(10), eggs=np.zeros(10))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_with_fit_params():
-    check_hyperparameter_searcher_with_fit_params(GridSearchCV)
+    check_hyperparameter_searcher_with_fit_params(GridSearchCV,
+                                                  error_score='raise')
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_random_search_with_fit_params():
-    check_hyperparameter_searcher_with_fit_params(RandomizedSearchCV, n_iter=1)
+    check_hyperparameter_searcher_with_fit_params(RandomizedSearchCV, n_iter=1,
+                                                  error_score='raise')
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_fit_params_deprecation():
     # NOTE: Remove this test in v0.21
 
@@ -241,6 +248,7 @@ def test_grid_search_fit_params_deprecation():
     assert_warns(DeprecationWarning, grid_search.fit, X, y)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_fit_params_two_places():
     # NOTE: Remove this test in v0.21
 
@@ -264,10 +272,16 @@ def test_grid_search_fit_params_two_places():
 
     # Verify that `fit` prefers its own kwargs by giving valid
     # kwargs in the constructor and invalid in the method call
-    grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]},
-                               fit_params={'spam': np.ones(10)})
-    assert_raise_message(AssertionError, "Fit parameter spam has length 1",
-                         grid_search.fit, X, y, spam=np.ones(1))
+    with warnings.catch_warnings():
+        # JvR: As passing fit params to the constructor is deprecated, this
+        # unit test raises a warning (unit test can be removed after version
+        # 0.22)
+        warnings.filterwarnings("ignore", category=DeprecationWarning)
+        grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]},
+                                   fit_params={'spam': np.ones(10)},
+                                   error_score='raise')
+        assert_raise_message(AssertionError, "Fit parameter spam has length 1",
+                             grid_search.fit, X, y, spam=np.ones(1))
 
 
 @ignore_warnings
@@ -296,6 +310,7 @@ def test_grid_search_no_score():
                          [[1]])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_score_method():
     X, y = make_classification(n_samples=100, n_classes=2, flip_y=.2,
                                random_state=0)
@@ -305,7 +320,8 @@ def test_grid_search_score_method():
     search_no_scoring = GridSearchCV(clf, grid, scoring=None).fit(X, y)
     search_accuracy = GridSearchCV(clf, grid, scoring='accuracy').fit(X, y)
     search_no_score_method_auc = GridSearchCV(LinearSVCNoScore(), grid,
-                                              scoring='roc_auc').fit(X, y)
+                                              scoring='roc_auc'
+                                              ).fit(X, y)
     search_auc = GridSearchCV(clf, grid, scoring='roc_auc').fit(X, y)
 
     # Check warning only occurs in situation where behavior changed:
@@ -324,6 +340,7 @@ def test_grid_search_score_method():
     assert_almost_equal(score_auc, score_no_score_auc)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_groups():
     # Check if ValueError (when groups is None) propagates to GridSearchCV
     # And also check if groups is correctly passed to the cv object
@@ -388,6 +405,7 @@ def test_return_train_score_warn():
             assert_no_warnings(result['warn'].get, key)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_classes__property():
     # Test that classes_ property matches best_estimator_.classes_
     X = np.arange(100).reshape(10, 10)
@@ -415,6 +433,7 @@ def test_classes__property():
     assert_false(hasattr(grid_search, 'classes_'))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_trivial_cv_results_attr():
     # Test search over a "grid" with only one point.
     clf = MockClassifier()
@@ -427,6 +446,7 @@ def test_trivial_cv_results_attr():
     assert_true(hasattr(grid_search, "cv_results_"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_no_refit():
     # Test that GSCV can be used for model selection alone without refitting
     clf = MockClassifier()
@@ -452,10 +472,12 @@ def test_no_refit():
                              "parameter refit must be set to a scorer key",
                              GridSearchCV(clf, {}, refit=refit,
                                           scoring={'acc': 'accuracy',
-                                                   'prec': 'precision'}).fit,
+                                                   'prec': 'precision'}
+                                          ).fit,
                              X, y)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_error():
     # Test that grid search will capture errors on data with different length
     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)
@@ -465,11 +487,12 @@ def test_grid_search_error():
     assert_raises(ValueError, cv.fit, X_[:180], y_)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_one_grid_point():
     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)
     param_dict = {"C": [1.0], "kernel": ["rbf"], "gamma": [0.1]}
 
-    clf = SVC()
+    clf = SVC(gamma='auto')
     cv = GridSearchCV(clf, param_dict)
     cv.fit(X_, y_)
 
@@ -479,6 +502,7 @@ def test_grid_search_one_grid_point():
     assert_array_equal(clf.dual_coef_, cv.best_estimator_.dual_coef_)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_when_param_grid_includes_range():
     # Test that the best estimator contains the right value for foo_param
     clf = MockClassifier()
@@ -491,9 +515,10 @@ def test_grid_search_when_param_grid_includes_range():
     assert_equal(grid_search.best_estimator_.foo_param, 2)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_bad_param_grid():
     param_dict = {"C": 1.0}
-    clf = SVC()
+    clf = SVC(gamma='auto')
     assert_raise_message(
         ValueError,
         "Parameter values for parameter (C) need to be a sequence"
@@ -508,7 +533,7 @@ def test_grid_search_bad_param_grid():
         GridSearchCV, clf, param_dict)
 
     param_dict = {"C": "1,2,3"}
-    clf = SVC()
+    clf = SVC(gamma='auto')
     assert_raise_message(
         ValueError,
         "Parameter values for parameter (C) need to be a sequence"
@@ -520,6 +545,7 @@ def test_grid_search_bad_param_grid():
     assert_raises(ValueError, GridSearchCV, clf, param_dict)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_sparse():
     # Test that grid search works with both dense and sparse matrices
     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)
@@ -541,6 +567,7 @@ def test_grid_search_sparse():
     assert_equal(C, C2)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_sparse_scoring():
     X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)
 
@@ -576,6 +603,7 @@ def f1_loss(y_true_, y_pred_):
     assert_array_equal(y_pred, y_pred3)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_precomputed_kernel():
     # Test that grid search works when the input features are given in the
     # form of a precomputed kernel matrix
@@ -604,6 +632,7 @@ def test_grid_search_precomputed_kernel():
     assert_raises(ValueError, cv.fit, K_train.tolist(), y_train)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_precomputed_kernel_error_nonsquare():
     # Test that grid search returns an error with a non-square precomputed
     # training kernel matrix
@@ -641,6 +670,7 @@ def test_refit():
     clf.fit(X, y)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch_nd():
     # Pass X as list in GridSearchCV
     X_4d = np.arange(10 * 5 * 3 * 2).reshape(10, 5, 3, 2)
@@ -653,6 +683,7 @@ def test_gridsearch_nd():
     assert_true(hasattr(grid_search, "cv_results_"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_X_as_list():
     # Pass X as list in GridSearchCV
     X = np.arange(100).reshape(10, 10)
@@ -665,6 +696,7 @@ def test_X_as_list():
     assert_true(hasattr(grid_search, "cv_results_"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_y_as_list():
     # Pass y as list in GridSearchCV
     X = np.arange(100).reshape(10, 10)
@@ -708,6 +740,7 @@ def check_series(x):
         assert_true(hasattr(grid_search, "cv_results_"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_unsupervised_grid_search():
     # test grid-search with unsupervised estimator
     X, y = make_blobs(random_state=0)
@@ -734,6 +767,7 @@ def test_unsupervised_grid_search():
     assert_equal(grid_search.best_params_["n_clusters"], 4)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_gridsearch_no_predict():
     # test grid-search with an estimator without predict.
     # slight duplication of a test from KDE
@@ -822,7 +856,7 @@ def test_grid_search_cv_results():
 
     for iid in (False, True):
         search = GridSearchCV(SVC(gamma='scale'), cv=n_splits, iid=iid,
-                              param_grid=params)
+                              param_grid=params, return_train_score=True)
         search.fit(X, y)
         assert_equal(iid, search.iid)
         cv_results = search.cv_results_
@@ -873,7 +907,8 @@ def test_random_search_cv_results():
     for iid in (False, True):
         search = RandomizedSearchCV(SVC(gamma='scale'), n_iter=n_search_iter,
                                     cv=n_splits, iid=iid,
-                                    param_distributions=params)
+                                    param_distributions=params,
+                                    return_train_score=True)
         search.fit(X, y)
         assert_equal(iid, search.iid)
         cv_results = search.cv_results_
@@ -901,11 +936,12 @@ def test_search_iid_param():
     # create "cv" for splits
     cv = [[mask, ~mask], [~mask, mask]]
     # once with iid=True (default)
-    grid_search = GridSearchCV(SVC(), param_grid={'C': [1, 10]},
-                               cv=cv)
-    random_search = RandomizedSearchCV(SVC(), n_iter=2,
+    grid_search = GridSearchCV(SVC(gamma='auto'), param_grid={'C': [1, 10]},
+                               cv=cv, return_train_score=True)
+    random_search = RandomizedSearchCV(SVC(gamma='auto'), n_iter=2,
                                        param_distributions={'C': [1, 10]},
-                                       cv=cv)
+                                       cv=cv, iid=True,
+                                       return_train_score=True)
     for search in (grid_search, random_search):
         search.fit(X, y)
         assert_true(search.iid or search.iid is None)
@@ -936,7 +972,7 @@ def test_search_iid_param():
         assert_almost_equal(test_mean, expected_test_mean)
         assert_almost_equal(test_std, expected_test_std)
         assert_array_almost_equal(test_cv_scores,
-                                  cross_val_score(SVC(C=1), X,
+                                  cross_val_score(SVC(C=1, gamma='auto'), X,
                                                   y, cv=cv))
 
         # For the train scores, we do not take a weighted mean irrespective of
@@ -945,12 +981,13 @@ def test_search_iid_param():
         assert_almost_equal(train_std, 0)
 
     # once with iid=False
-    grid_search = GridSearchCV(SVC(),
+    grid_search = GridSearchCV(SVC(gamma='auto'),
                                param_grid={'C': [1, 10]},
-                               cv=cv, iid=False)
-    random_search = RandomizedSearchCV(SVC(), n_iter=2,
+                               cv=cv, iid=False, return_train_score=True)
+    random_search = RandomizedSearchCV(SVC(gamma='auto'), n_iter=2,
                                        param_distributions={'C': [1, 10]},
-                                       cv=cv, iid=False)
+                                       cv=cv, iid=False,
+                                       return_train_score=True)
 
     for search in (grid_search, random_search):
         search.fit(X, y)
@@ -1083,6 +1120,7 @@ def compare_refit_methods_when_refit_with_acc(search_multi, search_acc, refit):
         assert_equal(getattr(search_multi, key), getattr(search_acc, key))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_search_cv_results_rank_tie_breaking():
     X, y = make_blobs(n_samples=50, random_state=42)
 
@@ -1090,9 +1128,11 @@ def test_search_cv_results_rank_tie_breaking():
     # which would result in a tie of their mean cv-scores
     param_grid = {'C': [1, 1.001, 0.001]}
 
-    grid_search = GridSearchCV(SVC(gamma="scale"), param_grid=param_grid)
+    grid_search = GridSearchCV(SVC(gamma="scale"), param_grid=param_grid,
+                               return_train_score=True)
     random_search = RandomizedSearchCV(SVC(gamma="scale"), n_iter=3,
-                                       param_distributions=param_grid)
+                                       param_distributions=param_grid,
+                                       return_train_score=True)
 
     for search in (grid_search, random_search):
         search.fit(X, y)
@@ -1112,6 +1152,7 @@ def test_search_cv_results_rank_tie_breaking():
         assert_almost_equal(search.cv_results_['rank_test_score'], [1, 1, 3])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_search_cv_results_none_param():
     X, y = [[1], [2], [3], [4], [5]], [0, 0, 0, 0, 1]
     estimators = (DecisionTreeRegressor(), DecisionTreeClassifier())
@@ -1119,7 +1160,8 @@ def test_search_cv_results_none_param():
     cv = KFold(random_state=0)
 
     for est in estimators:
-        grid_search = GridSearchCV(est, est_parameters, cv=cv).fit(X, y)
+        grid_search = GridSearchCV(est, est_parameters, cv=cv,
+                                   ).fit(X, y)
         assert_array_equal(grid_search.cv_results_['param_random_state'],
                            [0, None])
 
@@ -1152,6 +1194,7 @@ def test_search_cv_timing():
         assert_greater_equal(search.refit_time_, 0)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_correct_score_results():
     # test that correct scores are used
     n_splits = 3
@@ -1215,6 +1258,7 @@ def test_fit_grid_point():
                          {'score': scorer}, verbose=True)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_pickle():
     # Test that a fit search can be pickled
     clf = MockClassifier()
@@ -1232,6 +1276,7 @@ def test_pickle():
                               random_search_pickled.predict(X))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_with_multioutput_data():
     # Test search with multi-output estimator
 
@@ -1277,6 +1322,7 @@ def test_grid_search_with_multioutput_data():
                                               % i][cand_i])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_predict_proba_disabled():
     # Test predict_proba when disabled on estimator.
     X = np.arange(20).reshape(5, -1)
@@ -1286,6 +1332,7 @@ def test_predict_proba_disabled():
     assert_false(hasattr(gs, "predict_proba"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_allows_nans():
     # Test GridSearchCV with SimpleImputer
     X = np.arange(20, dtype=np.float64).reshape(5, -1)
@@ -1314,6 +1361,7 @@ def predict(self, X):
         return np.zeros(X.shape[0])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_failing_classifier():
     # GridSearchCV with on_error != 'raise'
     # Ensures that a warning is raised and score reset where appropriate.
@@ -1361,6 +1409,7 @@ def get_cand_scores(i):
     assert gs.best_index_ != clf.FAILING_PARAMETER
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_failing_classifier_raise():
     # GridSearchCV with on_error == 'raise' raises the error
 
@@ -1412,6 +1461,7 @@ def test_parameters_sampler_replacement():
     assert_equal(len(samples), 7)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_stochastic_gradient_loss_param():
     # Make sure the predict_proba works when loss is specified
     # as one of the parameters in the param_grid.
@@ -1442,6 +1492,7 @@ def test_stochastic_gradient_loss_param():
     assert_false(hasattr(clf, "predict_proba"))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_search_train_scores_set_to_false():
     X = np.arange(6).reshape(6, -1)
     y = [0, 0, 0, 1, 1, 1]
@@ -1452,6 +1503,7 @@ def test_search_train_scores_set_to_false():
     gs.fit(X, y)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_grid_search_cv_splits_consistency():
     # Check if a one time iterable is accepted as a cv parameter.
     n_samples = 100
@@ -1461,12 +1513,13 @@ def test_grid_search_cv_splits_consistency():
     gs = GridSearchCV(LinearSVC(random_state=0),
                       param_grid={'C': [0.1, 0.2, 0.3]},
                       cv=OneTimeSplitter(n_splits=n_splits,
-                                         n_samples=n_samples))
+                                         n_samples=n_samples),
+                      return_train_score=True)
     gs.fit(X, y)
 
     gs2 = GridSearchCV(LinearSVC(random_state=0),
                        param_grid={'C': [0.1, 0.2, 0.3]},
-                       cv=KFold(n_splits=n_splits))
+                       cv=KFold(n_splits=n_splits), return_train_score=True)
     gs2.fit(X, y)
 
     # Give generator as a cv parameter
@@ -1476,13 +1529,14 @@ def test_grid_search_cv_splits_consistency():
     gs3 = GridSearchCV(LinearSVC(random_state=0),
                        param_grid={'C': [0.1, 0.2, 0.3]},
                        cv=KFold(n_splits=n_splits, shuffle=True,
-                                random_state=0).split(X, y))
+                                random_state=0).split(X, y),
+                       return_train_score=True)
     gs3.fit(X, y)
 
     gs4 = GridSearchCV(LinearSVC(random_state=0),
                        param_grid={'C': [0.1, 0.2, 0.3]},
                        cv=KFold(n_splits=n_splits, shuffle=True,
-                                random_state=0))
+                                random_state=0), return_train_score=True)
     gs4.fit(X, y)
 
     def _pop_time_keys(cv_results):
@@ -1510,7 +1564,8 @@ def _pop_time_keys(cv_results):
     # Check consistency of folds across the parameters
     gs = GridSearchCV(LinearSVC(random_state=0),
                       param_grid={'C': [0.1, 0.1, 0.2, 0.2]},
-                      cv=KFold(n_splits=n_splits, shuffle=True))
+                      cv=KFold(n_splits=n_splits, shuffle=True),
+                      return_train_score=True)
     gs.fit(X, y)
 
     # As the first two param settings (C=0.1) and the next two param
@@ -1530,6 +1585,7 @@ def _pop_time_keys(cv_results):
                                   per_param_scores[3])
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_transform_inverse_transform_round_trip():
     clf = MockClassifier()
     grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]}, verbose=3)
diff --git a/sklearn/model_selection/tests/test_split.py b/sklearn/model_selection/tests/test_split.py
index 0071129d8ce7..98a1f808b4d7 100644
--- a/sklearn/model_selection/tests/test_split.py
+++ b/sklearn/model_selection/tests/test_split.py
@@ -473,16 +473,18 @@ def test_shuffle_kfold_stratifiedkfold_reproducibility():
 
     for cv in (kf, skf):
         for data in zip((X, X2), (y, y2)):
-            # Test if the two splits are different
-            # numpy's assert_equal properly compares nested lists
-            try:
-                np.testing.assert_array_equal(list(cv.split(*data)),
-                                              list(cv.split(*data)))
-            except AssertionError:
-                pass
-            else:
-                raise AssertionError("The splits for data, %s, are same even "
-                                     "when random state is not set" % data)
+            # Test if the two splits are different cv
+            for (_, test_a), (_, test_b) in zip(cv.split(*data),
+                                                cv.split(*data)):
+                # cv.split(...) returns an array of tuples, each tuple
+                # consisting of an array with train indices and test indices
+                try:
+                    np.testing.assert_array_equal(test_a, test_b)
+                except AssertionError:
+                    pass
+                else:
+                    raise AssertionError("The splits for data, are same even "
+                                         "when random state is not set")
 
 
 def test_shuffle_stratifiedkfold():
@@ -1004,7 +1006,12 @@ def test_repeated_stratified_kfold_determinstic_split():
 
 def test_train_test_split_errors():
     assert_raises(ValueError, train_test_split)
-    assert_raises(ValueError, train_test_split, range(3), train_size=1.1)
+    with warnings.catch_warnings():
+        # JvR: Currently, a future warning is raised if test_size is not
+        # given. As that is the point of this test, ignore the future warning
+        warnings.filterwarnings("ignore", category=FutureWarning)
+        assert_raises(ValueError, train_test_split, range(3), train_size=1.1)
+
     assert_raises(ValueError, train_test_split, range(3), test_size=0.6,
                   train_size=0.6)
     assert_raises(ValueError, train_test_split, range(3),
@@ -1403,7 +1410,7 @@ def test_nested_cv():
 
     for inner_cv, outer_cv in combinations_with_replacement(cvs, 2):
         gs = GridSearchCV(Ridge(), param_grid={'alpha': [1, .1]},
-                          cv=inner_cv)
+                          cv=inner_cv, error_score='raise', iid=False)
         cross_val_score(gs, X=X, y=y, groups=groups, cv=outer_cv,
                         fit_params={'groups': groups})
 
diff --git a/sklearn/model_selection/tests/test_validation.py b/sklearn/model_selection/tests/test_validation.py
index f2aff6b82bea..f0a6564270b7 100644
--- a/sklearn/model_selection/tests/test_validation.py
+++ b/sklearn/model_selection/tests/test_validation.py
@@ -239,6 +239,8 @@ def get_params(self, deep=False):
 P_sparse = coo_matrix(np.eye(5))
 
 
+@pytest.mark.filterwarnings('ignore: From version 0.22, errors during fit')
+# FIXME issue in error_score parameter
 def test_cross_val_score():
     clf = MockClassifier()
 
@@ -420,9 +422,10 @@ def check_cross_validate_single_metric(clf, X, y, scores):
     for (return_train_score, dict_len) in ((True, 4), (False, 3)):
         # Single metric passed as a string
         if return_train_score:
-            # It must be True by default
+            # It must be True by default - deprecated
             mse_scores_dict = cross_validate(clf, X, y, cv=5,
-                                             scoring='neg_mean_squared_error')
+                                             scoring='neg_mean_squared_error',
+                                             return_train_score=True)
             assert_array_almost_equal(mse_scores_dict['train_score'],
                                       train_mse_scores)
         else:
@@ -436,10 +439,11 @@ def check_cross_validate_single_metric(clf, X, y, scores):
 
         # Single metric passed as a list
         if return_train_score:
-            # It must be True by default
-            r2_scores_dict = cross_validate(clf, X, y, cv=5, scoring=['r2'])
+            # It must be True by default - deprecated
+            r2_scores_dict = cross_validate(clf, X, y, cv=5, scoring=['r2'],
+                                            return_train_score=True)
             assert_array_almost_equal(r2_scores_dict['train_r2'],
-                                      train_r2_scores)
+                                      train_r2_scores, True)
         else:
             r2_scores_dict = cross_validate(clf, X, y, cv=5, scoring=['r2'],
                                             return_train_score=False)
@@ -472,8 +476,9 @@ def check_cross_validate_multi_metric(clf, X, y, scores):
     for return_train_score in (True, False):
         for scoring in all_scoring:
             if return_train_score:
-                # return_train_score must be True by default
-                cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring)
+                # return_train_score must be True by default - deprecated
+                cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring,
+                                            return_train_score=True)
                 assert_array_almost_equal(cv_results['train_r2'],
                                           train_r2_scores)
                 assert_array_almost_equal(
@@ -523,6 +528,7 @@ def test_cross_val_score_predict_groups():
                              cross_val_predict, estimator=clf, X=X, y=y, cv=cv)
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
 def test_cross_val_score_pandas():
     # check cross_val_score doesn't destroy pandas dataframe
     types = [(MockDataFrame, MockDataFrame)]
@@ -947,6 +953,8 @@ def test_cross_val_predict_input_types():
     assert_array_equal(predictions.shape, (150,))
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
+# python3.7 deprecation warnings in pandas via matplotlib :-/
 def test_cross_val_predict_pandas():
     # check cross_val_score doesn't destroy pandas dataframe
     types = [(MockDataFrame, MockDataFrame)]
@@ -1150,6 +1158,8 @@ def test_learning_curve_with_boolean_indices():
                               np.linspace(0.1, 1.0, 10))
 
 
+@pytest.mark.filterwarnings('ignore: From version 0.22, errors during fit')
+# FIXME this is an error in the error_score change!
 def test_learning_curve_with_shuffle():
     # Following test case was designed this way to verify the code
     # changes made in pull request: #7506.
@@ -1319,6 +1329,7 @@ def test_cross_val_predict_with_method():
     check_cross_val_predict_with_method(LogisticRegression())
 
 
+@pytest.mark.filterwarnings('ignore: max_iter and tol parameters')
 def test_cross_val_predict_method_checking():
     # Regression test for issue #9639. Tests that cross_val_predict does not
     # check estimator methods (e.g. predict_proba) before fitting
@@ -1326,6 +1337,7 @@ def test_cross_val_predict_method_checking():
     check_cross_val_predict_with_method(est)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')
 def test_gridsearchcv_cross_val_predict_with_method():
     est = GridSearchCV(LogisticRegression(random_state=42),
                        {'C': [0.1, 1]},
@@ -1421,6 +1433,7 @@ def test_score_memmap():
                 sleep(1.)
 
 
+@pytest.mark.filterwarnings('ignore: Using or importing the ABCs from')
 def test_permutation_test_score_pandas():
     # check permutation_test_score doesn't destroy pandas dataframe
     types = [(MockDataFrame, MockDataFrame)]
@@ -1463,10 +1476,6 @@ def test_fit_and_score():
     assert_warns_message(FitFailedWarning, warning_message, _fit_and_score,
                          *fit_and_score_args, **fit_and_score_kwargs)
 
-    # check if exception is raised, with default error_score argument
-    assert_raise_message(ValueError, "Failing classifier failed as required",
-                         _fit_and_score, *fit_and_score_args)
-
     # check if warning was raised, with default error_score argument
     warning_message = ("From version 0.22, errors during fit will result "
                        "in a cross validation score of NaN by default. Use "
diff --git a/sklearn/multiclass.py b/sklearn/multiclass.py
index 0fc2907fe481..7c84fcf9c6c1 100644
--- a/sklearn/multiclass.py
+++ b/sklearn/multiclass.py
@@ -52,8 +52,8 @@
                                _ovr_decision_function)
 from .utils.metaestimators import _safe_split, if_delegate_has_method
 
-from .externals.joblib import Parallel
-from .externals.joblib import delayed
+from .utils import Parallel
+from .utils import delayed
 from .externals.six.moves import zip as izip
 
 __all__ = [
diff --git a/sklearn/multioutput.py b/sklearn/multioutput.py
index 4d9b9e10f4fb..c2e40d044b2f 100644
--- a/sklearn/multioutput.py
+++ b/sklearn/multioutput.py
@@ -25,7 +25,7 @@
 from .utils.metaestimators import if_delegate_has_method
 from .utils.validation import check_is_fitted, has_fit_parameter
 from .utils.multiclass import check_classification_targets
-from .externals.joblib import Parallel, delayed
+from .utils import Parallel, delayed
 from .externals import six
 
 __all__ = ["MultiOutputRegressor", "MultiOutputClassifier",
diff --git a/sklearn/neighbors/approximate.py b/sklearn/neighbors/approximate.py
index 6a3fd571b321..4a30bd815998 100644
--- a/sklearn/neighbors/approximate.py
+++ b/sklearn/neighbors/approximate.py
@@ -187,17 +187,18 @@ class LSHForest(BaseEstimator, KNeighborsMixin, RadiusNeighborsMixin):
 
       >>> X_train = [[5, 5, 2], [21, 5, 5], [1, 1, 1], [8, 9, 1], [6, 10, 2]]
       >>> X_test = [[9, 1, 6], [3, 1, 10], [7, 10, 3]]
-      >>> lshf = LSHForest(random_state=42)
-      >>> lshf.fit(X_train)  # doctest: +NORMALIZE_WHITESPACE
+      >>> lshf = LSHForest(random_state=42)  # doctest: +SKIP
+      >>> lshf.fit(X_train)  # doctest: +SKIP
       LSHForest(min_hash_match=4, n_candidates=50, n_estimators=10,
                 n_neighbors=5, radius=1.0, radius_cutoff_ratio=0.9,
                 random_state=42)
       >>> distances, indices = lshf.kneighbors(X_test, n_neighbors=2)
-      >>> distances                                        # doctest: +ELLIPSIS
+      ... # doctest: +SKIP
+      >>> distances                                        # doctest: +SKIP
       array([[0.069..., 0.149...],
              [0.229..., 0.481...],
              [0.004..., 0.014...]])
-      >>> indices
+      >>> indices  # doctest: +SKIP
       array([[1, 2],
              [2, 0],
              [4, 0]])
diff --git a/sklearn/neighbors/base.py b/sklearn/neighbors/base.py
index 14810e65b016..b2e42e7bf3a4 100644
--- a/sklearn/neighbors/base.py
+++ b/sklearn/neighbors/base.py
@@ -23,7 +23,7 @@
 from ..utils.multiclass import check_classification_targets
 from ..utils.validation import check_is_fitted
 from ..externals import six
-from ..externals.joblib import Parallel, delayed
+from ..utils import Parallel, delayed
 from ..exceptions import NotFittedError
 from ..exceptions import DataConversionWarning
 
diff --git a/sklearn/neighbors/tests/test_lof.py b/sklearn/neighbors/tests/test_lof.py
index b472ab3d833b..a6fb572b6740 100644
--- a/sklearn/neighbors/tests/test_lof.py
+++ b/sklearn/neighbors/tests/test_lof.py
@@ -12,7 +12,7 @@
 from sklearn.metrics import roc_auc_score
 
 from sklearn.utils import check_random_state
-from sklearn.utils.testing import assert_greater
+from sklearn.utils.testing import assert_greater, ignore_warnings
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_equal
 from sklearn.utils.testing import assert_warns_message, assert_raises
@@ -29,6 +29,8 @@
 iris.target = iris.target[perm]
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_lof():
     # Toy sample (the last two samples are outliers):
     X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [5, 3], [-4, 2]]
@@ -47,6 +49,8 @@ def test_lof():
     assert_array_equal(clf._predict(), 6 * [1] + 2 * [-1])
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_lof_performance():
     # Generate train/test data
     rng = check_random_state(2)
@@ -68,6 +72,8 @@ def test_lof_performance():
     assert_greater(roc_auc_score(y_test, y_pred), .99)
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_lof_values():
     # toy samples:
     X_train = [[1, 1], [1, 2], [2, 1]]
@@ -87,6 +93,8 @@ def test_lof_values():
     assert_array_almost_equal(-clf2._score_samples([[1., 1.]]), [s_1])
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_lof_precomputed(random_state=42):
     """Tests LOF with a distance matrix."""
     # Note: smaller samples may result in spurious test success
@@ -112,6 +120,8 @@ def test_lof_precomputed(random_state=42):
     assert_array_almost_equal(pred_X_Y, pred_D_Y)
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_n_neighbors_attribute():
     X = iris.data
     clf = neighbors.LocalOutlierFactor(n_neighbors=500).fit(X)
@@ -124,6 +134,8 @@ def test_n_neighbors_attribute():
     assert_equal(clf.n_neighbors_, X.shape[0] - 1)
 
 
+@ignore_warnings(category=DeprecationWarning)
+# contamination changed to 'auto' 0.22
 def test_score_samples():
     X_train = [[1, 1], [1, 2], [2, 1]]
     clf1 = neighbors.LocalOutlierFactor(n_neighbors=2,
diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py
index 1e99dd54615a..c92da01244f0 100644
--- a/sklearn/pipeline.py
+++ b/sklearn/pipeline.py
@@ -15,7 +15,7 @@
 from scipy import sparse
 
 from .base import clone, TransformerMixin
-from .externals.joblib import Parallel, delayed
+from .utils import Parallel, delayed
 from .externals import six
 from .utils.metaestimators import if_delegate_has_method
 from .utils import Bunch
diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py
index d51a2b96c47c..1cbe0d09b723 100644
--- a/sklearn/preprocessing/_discretization.py
+++ b/sklearn/preprocessing/_discretization.py
@@ -67,7 +67,7 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):
         will have ``n_bins_[i] == 0``.
 
     bin_edges_ : array of arrays, shape (n_features, )
-        The edges of each bin. Contain arrays of varying shapes (n_bins_, ).
+        The edges of each bin. Contain arrays of varying shapes ``(n_bins_, )``
         Ignored features will have empty arrays.
 
     Examples
diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py
index f3bd4b9ffb63..bd6e10fb6281 100644
--- a/sklearn/preprocessing/_encoders.py
+++ b/sklearn/preprocessing/_encoders.py
@@ -198,24 +198,24 @@ class OneHotEncoder(_BaseEncoder):
         in the training set. Only available when n_values is ``'auto'``.
 
         .. deprecated:: 0.20
-            The `active_features_` attribute was deprecated in version
+            The ``active_features_`` attribute was deprecated in version
             0.20 and will be removed in 0.22.
 
     feature_indices_ : array of shape (n_features,)
         Indices to feature ranges.
         Feature ``i`` in the original data is mapped to features
         from ``feature_indices_[i]`` to ``feature_indices_[i+1]``
-        (and then potentially masked by `active_features_` afterwards)
+        (and then potentially masked by ``active_features_`` afterwards)
 
         .. deprecated:: 0.20
-            The `feature_indices_` attribute was deprecated in version
+            The ``feature_indices_`` attribute was deprecated in version
             0.20 and will be removed in 0.22.
 
     n_values_ : array of shape (n_features,)
         Maximum number of values per feature.
 
         .. deprecated:: 0.20
-            The `n_values_` attribute was deprecated in version
+            The ``n_values_`` attribute was deprecated in version
             0.20 and will be removed in 0.22.
 
     Examples
@@ -240,6 +240,8 @@ class OneHotEncoder(_BaseEncoder):
     >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])
     array([['Male', 1],
            [None, 2]], dtype=object)
+    >>> enc.get_feature_names()
+    array(['x0_Female', 'x0_Male', 'x1_1', 'x1_2', 'x1_3'], dtype=object)
 
     See also
     --------
@@ -269,21 +271,21 @@ def __init__(self, n_values=None, categorical_features=None,
     # Deprecated attributes
 
     @property
-    @deprecated("The 'active_features_' attribute was deprecated in version "
+    @deprecated("The ``active_features_`` attribute was deprecated in version "
                 "0.20 and will be removed 0.22.")
     def active_features_(self):
         check_is_fitted(self, 'categories_')
         return self._active_features_
 
     @property
-    @deprecated("The 'feature_indices_' attribute was deprecated in version "
+    @deprecated("The ``feature_indices_`` attribute was deprecated in version "
                 "0.20 and will be removed 0.22.")
     def feature_indices_(self):
         check_is_fitted(self, 'categories_')
         return self._feature_indices_
 
     @property
-    @deprecated("The 'n_values_' attribute was deprecated in version "
+    @deprecated("The ``n_values_`` attribute was deprecated in version "
                 "0.20 and will be removed 0.22.")
     def n_values_(self):
         check_is_fitted(self, 'categories_')
@@ -639,6 +641,38 @@ def inverse_transform(self, X):
 
         return X_tr
 
+    def get_feature_names(self, input_features=None):
+        """Return feature names for output features.
+
+        Parameters
+        ----------
+        input_features : list of string, length n_features, optional
+            String names for input features if available. By default,
+            "x0", "x1", ... "xn_features" is used.
+
+        Returns
+        -------
+        output_feature_names : array of string, length n_output_features
+
+        """
+        check_is_fitted(self, 'categories_')
+        cats = self.categories_
+        if input_features is None:
+            input_features = ['x%d' % i for i in range(len(cats))]
+        elif(len(input_features) != len(self.categories_)):
+            raise ValueError(
+                "input_features should have length equal to number of "
+                "features ({}), got {}".format(len(self.categories_),
+                                               len(input_features)))
+
+        feature_names = []
+        for i in range(len(cats)):
+            names = [
+                input_features[i] + '_' + six.text_type(t) for t in cats[i]]
+            feature_names.extend(names)
+
+        return np.array(feature_names, dtype=object)
+
 
 class OrdinalEncoder(_BaseEncoder):
     """Encode categorical features as an integer array.
diff --git a/sklearn/preprocessing/tests/test_encoders.py b/sklearn/preprocessing/tests/test_encoders.py
index e655acd20b30..9ec16b85df60 100644
--- a/sklearn/preprocessing/tests/test_encoders.py
+++ b/sklearn/preprocessing/tests/test_encoders.py
@@ -1,3 +1,4 @@
+# -*- coding: utf-8 -*-
 from __future__ import division
 
 import re
@@ -455,6 +456,47 @@ def test_one_hot_encoder_pandas():
     assert_allclose(Xtr, [[1, 0, 1, 0], [0, 1, 0, 1]])
 
 
+def test_one_hot_encoder_feature_names():
+    enc = OneHotEncoder()
+    X = [['Male', 1, 'girl', 2, 3],
+         ['Female', 41, 'girl', 1, 10],
+         ['Male', 51, 'boy', 12, 3],
+         ['Male', 91, 'girl', 21, 30]]
+
+    enc.fit(X)
+    feature_names = enc.get_feature_names()
+    assert isinstance(feature_names, np.ndarray)
+
+    assert_array_equal(['x0_Female', 'x0_Male',
+                        'x1_1', 'x1_41', 'x1_51', 'x1_91',
+                        'x2_boy', 'x2_girl',
+                        'x3_1', 'x3_2', 'x3_12', 'x3_21',
+                        'x4_3',
+                        'x4_10', 'x4_30'], feature_names)
+
+    feature_names2 = enc.get_feature_names(['one', 'two',
+                                            'three', 'four', 'five'])
+
+    assert_array_equal(['one_Female', 'one_Male',
+                        'two_1', 'two_41', 'two_51', 'two_91',
+                        'three_boy', 'three_girl',
+                        'four_1', 'four_2', 'four_12', 'four_21',
+                        'five_3', 'five_10', 'five_30'], feature_names2)
+
+    with pytest.raises(ValueError, match="input_features should have length"):
+        enc.get_feature_names(['one', 'two'])
+
+
+def test_one_hot_encoder_feature_names_unicode():
+    enc = OneHotEncoder()
+    X = np.array([[u'c❤t1', u'dat2']], dtype=object).T
+    enc.fit(X)
+    feature_names = enc.get_feature_names()
+    assert_array_equal([u'x0_c❤t1', u'x0_dat2'], feature_names)
+    feature_names = enc.get_feature_names(input_features=[u'n👍me'])
+    assert_array_equal([u'n👍me_c❤t1', u'n👍me_dat2'], feature_names)
+
+
 @pytest.mark.parametrize("X", [
     [['abc', 2, 55], ['def', 1, 55]],
     np.array([[10, 2, 55], [20, 1, 55]]),
diff --git a/sklearn/preprocessing/tests/test_function_transformer.py b/sklearn/preprocessing/tests/test_function_transformer.py
index 0bd57a859649..464581e5e9c2 100644
--- a/sklearn/preprocessing/tests/test_function_transformer.py
+++ b/sklearn/preprocessing/tests/test_function_transformer.py
@@ -6,6 +6,7 @@
 from sklearn.utils.testing import (assert_equal, assert_array_equal,
                                    assert_allclose_dense_sparse)
 from sklearn.utils.testing import assert_warns_message, assert_no_warnings
+from sklearn.utils.testing import ignore_warnings
 
 
 def _make_func(args_store, kwargs_store, func=lambda X, *a, **k: X):
@@ -25,7 +26,8 @@ def test_delegate_to_func():
     kwargs_store = {}
     X = np.arange(10).reshape((5, 2))
     assert_array_equal(
-        FunctionTransformer(_make_func(args_store, kwargs_store)).transform(X),
+        FunctionTransformer(_make_func(args_store, kwargs_store),
+                            validate=False).transform(X),
         X, 'transform should have returned X unchanged',
     )
 
@@ -53,7 +55,7 @@ def test_delegate_to_func():
         DeprecationWarning, "pass_y is deprecated",
         FunctionTransformer(
             _make_func(args_store, kwargs_store),
-            pass_y=True).transform, X, y)
+            pass_y=True, validate=False).transform, X, y)
 
     assert_array_equal(transformed, X,
                        err_msg='transform should have returned X unchanged')
@@ -75,6 +77,8 @@ def test_delegate_to_func():
     )
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_np_log():
     X = np.arange(10).reshape((5, 2))
 
@@ -85,6 +89,8 @@ def test_np_log():
     )
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_kw_arg():
     X = np.linspace(0, 1, num=10).reshape((5, 2))
 
@@ -95,6 +101,8 @@ def test_kw_arg():
                        np.around(X, decimals=3))
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_kw_arg_update():
     X = np.linspace(0, 1, num=10).reshape((5, 2))
 
@@ -106,6 +114,8 @@ def test_kw_arg_update():
     assert_array_equal(F.transform(X), np.around(X, decimals=1))
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_kw_arg_reset():
     X = np.linspace(0, 1, num=10).reshape((5, 2))
 
@@ -117,6 +127,8 @@ def test_kw_arg_reset():
     assert_array_equal(F.transform(X), np.around(X, decimals=1))
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_inverse_transform():
     X = np.array([1, 4, 9, 16]).reshape((2, 2))
 
@@ -131,6 +143,8 @@ def test_inverse_transform():
     )
 
 
+@ignore_warnings(category=FutureWarning)
+# ignore warning for validate=False 0.22
 def test_check_inverse():
     X_dense = np.array([1, 4, 9, 16], dtype=np.float64).reshape((2, 2))
 
diff --git a/sklearn/svm/classes.py b/sklearn/svm/classes.py
index 4cb23d9cd13f..c595e8a12ea7 100644
--- a/sklearn/svm/classes.py
+++ b/sklearn/svm/classes.py
@@ -116,16 +116,15 @@ class LinearSVC(BaseEstimator, LinearClassifierMixin,
     >>> from sklearn.svm import LinearSVC
     >>> from sklearn.datasets import make_classification
     >>> X, y = make_classification(n_features=4, random_state=0)
-    >>> clf = LinearSVC(random_state=0)
+    >>> clf = LinearSVC(random_state=0, tol=1e-5)
     >>> clf.fit(X, y)
     LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
-         multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
-         verbose=0)
+         multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0)
     >>> print(clf.coef_)
-    [[0.08551385 0.39414796 0.49847831 0.37513797]]
+    [[0.085... 0.394... 0.498... 0.375...]]
     >>> print(clf.intercept_)
-    [0.28418066]
+    [0.284...]
     >>> print(clf.predict([[0, 0, 0, 0]]))
     [1]
 
@@ -329,17 +328,17 @@ class LinearSVR(LinearModel, RegressorMixin):
     >>> from sklearn.svm import LinearSVR
     >>> from sklearn.datasets import make_regression
     >>> X, y = make_regression(n_features=4, random_state=0)
-    >>> regr = LinearSVR(random_state=0)
+    >>> regr = LinearSVR(random_state=0, tol=1e-5)
     >>> regr.fit(X, y)
     LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,
          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,
-         random_state=0, tol=0.0001, verbose=0)
+         random_state=0, tol=1e-05, verbose=0)
     >>> print(regr.coef_)
-    [16.35750999 26.91499923 42.30652207 60.47843124]
+    [16.35... 26.91... 42.30... 60.47...]
     >>> print(regr.intercept_)
-    [-4.29756543]
+    [-4.29...]
     >>> print(regr.predict([[0, 0, 0, 0]]))
-    [-4.29756543]
+    [-4.29...]
 
     See also
     --------
@@ -1010,7 +1009,7 @@ class OneClassSVM(BaseLibSVM, OutlierMixin):
 
     The implementation is based on libsvm.
 
-    Read more in the :ref:`User Guide <svm_outlier_detection>`.
+    Read more in the :ref:`User Guide <outlier_detection>`.
 
     Parameters
     ----------
diff --git a/sklearn/svm/tests/test_svm.py b/sklearn/svm/tests/test_svm.py
index ead2d1cd27fd..6187a08f7b75 100644
--- a/sklearn/svm/tests/test_svm.py
+++ b/sklearn/svm/tests/test_svm.py
@@ -22,7 +22,7 @@
 from sklearn.utils.testing import ignore_warnings, assert_raises
 from sklearn.utils.testing import assert_no_warnings
 from sklearn.exceptions import ConvergenceWarning
-from sklearn.exceptions import NotFittedError
+from sklearn.exceptions import NotFittedError, UndefinedMetricWarning
 from sklearn.multiclass import OneVsRestClassifier
 from sklearn.externals import six
 
@@ -283,7 +283,7 @@ def test_oneclass_decision_function():
 
 def test_oneclass_score_samples():
     X_train = [[1, 1], [1, 2], [2, 1]]
-    clf = svm.OneClassSVM().fit(X_train)
+    clf = svm.OneClassSVM(gamma=1).fit(X_train)
     assert_array_equal(clf.score_samples([[2., 2.]]),
                        clf.decision_function([[2., 2.]]) + clf.offset_)
 
@@ -442,13 +442,15 @@ def test_sample_weights():
     assert_array_almost_equal(dual_coef_no_weight, clf.dual_coef_)
 
 
+@ignore_warnings(category=UndefinedMetricWarning)
 def test_auto_weight():
     # Test class weights for imbalanced data
     from sklearn.linear_model import LogisticRegression
     # We take as dataset the two-dimensional projection of iris so
     # that it is not separable and remove half of predictors from
     # class 1.
-    # We add one to the targets as a non-regression test: class_weight="balanced"
+    # We add one to the targets as a non-regression test:
+    # class_weight="balanced"
     # used to work only when the labels where a range [0..K).
     from sklearn.utils import compute_class_weight
     X, y = iris.data[:, :2], iris.target + 1
diff --git a/sklearn/tests/test_calibration.py b/sklearn/tests/test_calibration.py
index 404c3a797c1d..c99f79bbebd3 100644
--- a/sklearn/tests/test_calibration.py
+++ b/sklearn/tests/test_calibration.py
@@ -2,6 +2,7 @@
 # License: BSD 3 clause
 
 from __future__ import division
+import pytest
 import numpy as np
 from scipy import sparse
 from sklearn.model_selection import LeaveOneOut
@@ -24,7 +25,7 @@
 from sklearn.calibration import calibration_curve
 
 
-@ignore_warnings
+@pytest.mark.filterwarnings('ignore:The default value of n_estimators')
 def test_calibration():
     """Test calibration objects with isotonic and sigmoid"""
     n_samples = 100
diff --git a/sklearn/tests/test_common.py b/sklearn/tests/test_common.py
index 1f4c41ec8285..2cde1ca9a14a 100644
--- a/sklearn/tests/test_common.py
+++ b/sklearn/tests/test_common.py
@@ -110,6 +110,8 @@ def test_no_attributes_set_in_init(name, Estimator):
         check_no_attributes_set_in_init(name, estimator)
 
 
+@ignore_warnings(category=DeprecationWarning)
+# ignore deprecated open(.., 'U') in numpy distutils
 def test_configure():
     # Smoke test the 'configure' step of setup, this tests all the
     # 'configure' functions in the setup.pys in scikit-learn
diff --git a/sklearn/tests/test_discriminant_analysis.py b/sklearn/tests/test_discriminant_analysis.py
index 8eb5da1908ba..6e509949b0a8 100644
--- a/sklearn/tests/test_discriminant_analysis.py
+++ b/sklearn/tests/test_discriminant_analysis.py
@@ -324,9 +324,9 @@ def test_qda_deprecation():
                          "removed in 0.21.", clf.fit, X, y)
 
     # check that covariance_ (and covariances_ with warning) is stored
-    assert_warns_message(DeprecationWarning, "Attribute covariances_ was "
+    assert_warns_message(DeprecationWarning, "Attribute ``covariances_`` was "
                          "deprecated in version 0.19 and will be removed "
-                         "in 0.21. Use covariance_ instead", getattr, clf,
+                         "in 0.21. Use ``covariance_`` instead", getattr, clf,
                          'covariances_')
 
 
diff --git a/sklearn/tests/test_docstring_parameters.py b/sklearn/tests/test_docstring_parameters.py
index 0fada63831c9..69f72d934479 100644
--- a/sklearn/tests/test_docstring_parameters.py
+++ b/sklearn/tests/test_docstring_parameters.py
@@ -27,9 +27,6 @@
 IGNORED_MODULES = (
     'cluster',
     'datasets',
-    'gaussian_process',
-    'linear_model',
-    'ensemble',
     'feature_selection',
     'kernel_approximation',
     'model_selection',
@@ -63,6 +60,9 @@
 ]
 
 
+# numpydoc 0.8.0's docscrape tool raises because of collections.abc under
+# Python 3.7
+@ignore_warnings(category=DeprecationWarning)
 def test_docstring_parameters():
     # Test module docstring formatting
 
diff --git a/sklearn/tests/test_impute.py b/sklearn/tests/test_impute.py
index f5c42f744348..acd9117e9f7d 100644
--- a/sklearn/tests/test_impute.py
+++ b/sklearn/tests/test_impute.py
@@ -1,5 +1,3 @@
-from __future__ import division
-
 import pytest
 
 import numpy as np
@@ -13,9 +11,8 @@
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_false
 
-from sklearn.impute import SimpleImputer, ChainedImputer
-from sklearn.dummy import DummyRegressor
-from sklearn.linear_model import BayesianRidge, ARDRegression
+from sklearn.impute import MissingIndicator
+from sklearn.impute import SimpleImputer
 from sklearn.pipeline import Pipeline
 from sklearn.model_selection import GridSearchCV
 from sklearn import tree
@@ -72,10 +69,6 @@ def test_imputation_shape():
         X_imputed = imputer.fit_transform(X)
         assert X_imputed.shape == (10, 2)
 
-        chained_imputer = ChainedImputer(initial_strategy=strategy)
-        X_imputed = chained_imputer.fit_transform(X)
-        assert X_imputed.shape == (10, 2)
-
 
 @pytest.mark.parametrize("strategy", ["const", 101, None])
 def test_imputation_error_invalid_strategy(strategy):
@@ -97,6 +90,23 @@ def test_imputation_deletion_warning(strategy):
         imputer.fit_transform(X)
 
 
+@pytest.mark.parametrize("strategy", ["mean", "median",
+                                      "most_frequent", "constant"])
+def test_imputation_error_sparse_0(strategy):
+    # check that error are raised when missing_values = 0 and input is sparse
+    X = np.ones((3, 5))
+    X[0] = 0
+    X = sparse.csc_matrix(X)
+
+    imputer = SimpleImputer(strategy=strategy, missing_values=0)
+    with pytest.raises(ValueError, match="Provide a dense array"):
+        imputer.fit(X)
+
+    imputer.fit(X.toarray())
+    with pytest.raises(ValueError, match="Provide a dense array"):
+        imputer.transform(X)
+
+
 def safe_median(arr, *args, **kwargs):
     # np.median([]) raises a TypeError for numpy >= 1.10.1
     length = arr.size if hasattr(arr, 'size') else len(arr)
@@ -123,10 +133,8 @@ def test_imputation_mean_median():
     values[4::2] = - values[4::2]
 
     tests = [("mean", np.nan, lambda z, v, p: safe_mean(np.hstack((z, v)))),
-             ("mean", 0, lambda z, v, p: np.mean(v)),
              ("median", np.nan,
-              lambda z, v, p: safe_median(np.hstack((z, v)))),
-             ("median", 0, lambda z, v, p: np.median(v))]
+              lambda z, v, p: safe_median(np.hstack((z, v))))]
 
     for strategy, test_missing_values, true_value_fun in tests:
         X = np.empty(shape)
@@ -315,7 +323,7 @@ def test_imputation_most_frequent_pandas(dtype):
 @pytest.mark.parametrize("X_data, missing_value", [(1, 0), (1., np.nan)])
 def test_imputation_constant_error_invalid_type(X_data, missing_value):
     # Verify that exceptions are raised on invalid fill_value type
-    X = np.full((3, 5), X_data)
+    X = np.full((3, 5), X_data, dtype=float)
     X[0, 0] = missing_value
 
     with pytest.raises(ValueError, match="imputing numerical"):
@@ -425,16 +433,21 @@ def test_imputation_constant_pandas(dtype):
     assert_array_equal(X_trans, X_true)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_imputation_pipeline_grid_search():
     # Test imputation within a pipeline + gridsearch.
-    pipeline = Pipeline([('imputer', SimpleImputer(missing_values=0)),
-                         ('tree', tree.DecisionTreeRegressor(random_state=0))])
+    X = sparse_random_matrix(100, 100, density=0.10)
+    missing_values = X.data[0]
+
+    pipeline = Pipeline([('imputer',
+                          SimpleImputer(missing_values=missing_values)),
+                         ('tree',
+                          tree.DecisionTreeRegressor(random_state=0))])
 
     parameters = {
         'imputer__strategy': ["mean", "median", "most_frequent"]
     }
 
-    X = sparse_random_matrix(100, 100, density=0.10)
     Y = sparse_random_matrix(100, 1, density=0.10).toarray()
     gs = GridSearchCV(pipeline, parameters)
     gs.fit(X, Y)
@@ -486,222 +499,138 @@ def test_imputation_copy():
     # made, even if copy=False.
 
 
-def test_chained_imputer_rank_one():
-    rng = np.random.RandomState(0)
-    d = 100
-    A = rng.rand(d, 1)
-    B = rng.rand(1, d)
-    X = np.dot(A, B)
-    nan_mask = rng.rand(d, d) < 0.5
-    X_missing = X.copy()
-    X_missing[nan_mask] = np.nan
-
-    imputer = ChainedImputer(n_imputations=5,
-                             n_burn_in=5,
-                             verbose=True,
-                             random_state=rng)
-    X_filled = imputer.fit_transform(X_missing)
-    assert_allclose(X_filled, X, atol=0.001)
-
-
 @pytest.mark.parametrize(
-    "imputation_order",
-    ['random', 'roman', 'ascending', 'descending', 'arabic']
+    "X_fit, X_trans, params, msg_err",
+    [(np.array([[-1, 1], [1, 2]]), np.array([[-1, 1], [1, -1]]),
+      {'features': 'missing-only', 'sparse': 'auto'},
+      'have missing values in transform but have no missing values in fit'),
+     (np.array([[-1, 1], [1, 2]]), np.array([[-1, 1], [1, 2]]),
+      {'features': 'random', 'sparse': 'auto'},
+      "'features' has to be either 'missing-only' or 'all'"),
+     (np.array([[-1, 1], [1, 2]]), np.array([[-1, 1], [1, 2]]),
+      {'features': 'all', 'sparse': 'random'},
+      "'sparse' has to be a boolean or 'auto'")]
 )
-def test_chained_imputer_imputation_order(imputation_order):
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 10
-    X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()
-    X[:, 0] = 1  # this column should not be discarded by ChainedImputer
-
-    imputer = ChainedImputer(missing_values=0,
-                             n_imputations=1,
-                             n_burn_in=1,
-                             n_nearest_features=5,
-                             min_value=0,
-                             max_value=1,
-                             verbose=False,
-                             imputation_order=imputation_order,
-                             random_state=rng)
-    imputer.fit_transform(X)
-    ordered_idx = [i.feat_idx for i in imputer.imputation_sequence_]
-    if imputation_order == 'roman':
-        assert np.all(ordered_idx[:d-1] == np.arange(1, d))
-    elif imputation_order == 'arabic':
-        assert np.all(ordered_idx[:d-1] == np.arange(d-1, 0, -1))
-    elif imputation_order == 'random':
-        ordered_idx_round_1 = ordered_idx[:d-1]
-        ordered_idx_round_2 = ordered_idx[d-1:]
-        assert ordered_idx_round_1 != ordered_idx_round_2
-    elif 'ending' in imputation_order:
-        assert len(ordered_idx) == 2 * (d - 1)
+def test_missing_indicator_error(X_fit, X_trans, params, msg_err):
+    indicator = MissingIndicator(missing_values=-1)
+    indicator.set_params(**params)
+    with pytest.raises(ValueError, match=msg_err):
+        indicator.fit(X_fit).transform(X_trans)
 
 
 @pytest.mark.parametrize(
-    "predictor",
-    [DummyRegressor(), BayesianRidge(), ARDRegression()]
-)
-def test_chained_imputer_predictors(predictor):
-    rng = np.random.RandomState(0)
-
-    n = 100
-    d = 10
-    X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()
-
-    imputer = ChainedImputer(missing_values=0,
-                             n_imputations=1,
-                             n_burn_in=1,
-                             predictor=predictor,
-                             random_state=rng)
-    imputer.fit_transform(X)
-
-    # check that types are correct for predictors
-    hashes = []
-    for triplet in imputer.imputation_sequence_:
-        assert triplet.predictor
-        hashes.append(id(triplet.predictor))
-
-    # check that each predictor is unique
-    assert len(set(hashes)) == len(hashes)
-
-
-def test_chained_imputer_clip():
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 10
-    X = sparse_random_matrix(n, d, density=0.10,
-                             random_state=rng).toarray()
-
-    imputer = ChainedImputer(missing_values=0,
-                             n_imputations=1,
-                             n_burn_in=1,
-                             min_value=0.1,
-                             max_value=0.2,
-                             random_state=rng)
-
-    Xt = imputer.fit_transform(X)
-    assert_allclose(np.min(Xt[X == 0]), 0.1)
-    assert_allclose(np.max(Xt[X == 0]), 0.2)
-    assert_allclose(Xt[X != 0], X[X != 0])
-
-
+    "missing_values, dtype",
+    [(np.nan, np.float64),
+     (0, np.int32),
+     (-1, np.int32)])
 @pytest.mark.parametrize(
-    "strategy",
-    ["mean", "median", "most_frequent"]
-)
-def test_chained_imputer_missing_at_transform(strategy):
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 10
-    X_train = rng.randint(low=0, high=3, size=(n, d))
-    X_test = rng.randint(low=0, high=3, size=(n, d))
-
-    X_train[:, 0] = 1  # definitely no missing values in 0th column
-    X_test[0, 0] = 0  # definitely missing value in 0th column
-
-    imputer = ChainedImputer(missing_values=0,
-                             n_imputations=1,
-                             n_burn_in=1,
-                             initial_strategy=strategy,
-                             random_state=rng).fit(X_train)
-    initial_imputer = SimpleImputer(missing_values=0,
-                                    strategy=strategy).fit(X_train)
-
-    # if there were no missing values at time of fit, then imputer will
-    # only use the initial imputer for that feature at transform
-    assert np.all(imputer.transform(X_test)[:, 0] ==
-                  initial_imputer.transform(X_test)[:, 0])
-
-
-def test_chained_imputer_transform_stochasticity():
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 10
-    X = sparse_random_matrix(n, d, density=0.10,
-                             random_state=rng).toarray()
-
-    imputer = ChainedImputer(missing_values=0,
-                             n_imputations=1,
-                             n_burn_in=1,
-                             random_state=rng)
-    imputer.fit(X)
-
-    X_fitted_1 = imputer.transform(X)
-    X_fitted_2 = imputer.transform(X)
-
-    # sufficient to assert that the means are not the same
-    assert np.mean(X_fitted_1) != pytest.approx(np.mean(X_fitted_2))
+    "arr_type",
+    [np.array, sparse.csc_matrix, sparse.csr_matrix, sparse.coo_matrix,
+     sparse.lil_matrix, sparse.bsr_matrix])
+@pytest.mark.parametrize(
+    "param_features, n_features, features_indices",
+    [('missing-only', 2, np.array([0, 1])),
+     ('all', 3, np.array([0, 1, 2]))])
+def test_missing_indicator_new(missing_values, arr_type, dtype, param_features,
+                               n_features, features_indices):
+    X_fit = np.array([[missing_values, missing_values, 1],
+                      [4, missing_values, 2]])
+    X_trans = np.array([[missing_values, missing_values, 1],
+                        [4, 12, 10]])
+    X_fit_expected = np.array([[1, 1, 0], [0, 1, 0]])
+    X_trans_expected = np.array([[1, 1, 0], [0, 0, 0]])
+
+    # convert the input to the right array format and right dtype
+    X_fit = arr_type(X_fit).astype(dtype)
+    X_trans = arr_type(X_trans).astype(dtype)
+    X_fit_expected = X_fit_expected.astype(dtype)
+    X_trans_expected = X_trans_expected.astype(dtype)
+
+    indicator = MissingIndicator(missing_values=missing_values,
+                                 features=param_features,
+                                 sparse=False)
+    X_fit_mask = indicator.fit_transform(X_fit)
+    X_trans_mask = indicator.transform(X_trans)
+
+    assert X_fit_mask.shape[1] == n_features
+    assert X_trans_mask.shape[1] == n_features
+
+    assert_array_equal(indicator.features_, features_indices)
+    assert_allclose(X_fit_mask, X_fit_expected[:, features_indices])
+    assert_allclose(X_trans_mask, X_trans_expected[:, features_indices])
+
+    assert X_fit_mask.dtype == bool
+    assert X_trans_mask.dtype == bool
+    assert isinstance(X_fit_mask, np.ndarray)
+    assert isinstance(X_trans_mask, np.ndarray)
+
+    indicator.set_params(sparse=True)
+    X_fit_mask_sparse = indicator.fit_transform(X_fit)
+    X_trans_mask_sparse = indicator.transform(X_trans)
+
+    assert X_fit_mask_sparse.dtype == bool
+    assert X_trans_mask_sparse.dtype == bool
+    assert X_fit_mask_sparse.format == 'csc'
+    assert X_trans_mask_sparse.format == 'csc'
+    assert_allclose(X_fit_mask_sparse.toarray(), X_fit_mask)
+    assert_allclose(X_trans_mask_sparse.toarray(), X_trans_mask)
+
+
+@pytest.mark.parametrize("param_sparse", [True, False, 'auto'])
+@pytest.mark.parametrize("missing_values", [np.nan, 0])
+@pytest.mark.parametrize(
+    "arr_type",
+    [np.array, sparse.csc_matrix, sparse.csr_matrix, sparse.coo_matrix])
+def test_missing_indicator_sparse_param(arr_type, missing_values,
+                                        param_sparse):
+    # check the format of the output with different sparse parameter
+    X_fit = np.array([[missing_values, missing_values, 1],
+                      [4, missing_values, 2]])
+    X_trans = np.array([[missing_values, missing_values, 1],
+                        [4, 12, 10]])
+    X_fit = arr_type(X_fit).astype(np.float64)
+    X_trans = arr_type(X_trans).astype(np.float64)
+
+    indicator = MissingIndicator(missing_values=missing_values,
+                                 sparse=param_sparse)
+    X_fit_mask = indicator.fit_transform(X_fit)
+    X_trans_mask = indicator.transform(X_trans)
+
+    if param_sparse is True:
+        assert X_fit_mask.format == 'csc'
+        assert X_trans_mask.format == 'csc'
+    elif param_sparse == 'auto' and missing_values == 0:
+        assert isinstance(X_fit_mask, np.ndarray)
+        assert isinstance(X_trans_mask, np.ndarray)
+    elif param_sparse is False:
+        assert isinstance(X_fit_mask, np.ndarray)
+        assert isinstance(X_trans_mask, np.ndarray)
+    else:
+        if sparse.issparse(X_fit):
+            assert X_fit_mask.format == 'csc'
+            assert X_trans_mask.format == 'csc'
+        else:
+            assert isinstance(X_fit_mask, np.ndarray)
+            assert isinstance(X_trans_mask, np.ndarray)
 
 
-def test_chained_imputer_no_missing():
-    rng = np.random.RandomState(0)
-    X = rng.rand(100, 100)
-    X[:, 0] = np.nan
-    m1 = ChainedImputer(n_imputations=10, random_state=rng)
-    m2 = ChainedImputer(n_imputations=10, random_state=rng)
-    pred1 = m1.fit(X).transform(X)
-    pred2 = m2.fit_transform(X)
-    # should exclude the first column entirely
-    assert_allclose(X[:, 1:], pred1)
-    # fit and fit_transform should both be identical
-    assert_allclose(pred1, pred2)
+@pytest.mark.parametrize("imputer_constructor",
+                         [SimpleImputer])
+@pytest.mark.parametrize(
+    "imputer_missing_values, missing_value, err_msg",
+    [("NaN", np.nan, "Input contains NaN"),
+     ("-1", -1, "types are expected to be both numerical.")])
+def test_inconsistent_dtype_X_missing_values(imputer_constructor,
+                                             imputer_missing_values,
+                                             missing_value,
+                                             err_msg):
+    # regression test for issue #11390. Comparison between incoherent dtype
+    # for X and missing_values was not raising a proper error.
+    rng = np.random.RandomState(42)
+    X = rng.randn(10, 10)
+    X[0, 0] = missing_value
 
+    imputer = imputer_constructor(missing_values=imputer_missing_values)
 
-@pytest.mark.parametrize(
-    "rank",
-    [3, 5]
-)
-def test_chained_imputer_transform_recovery(rank):
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 100
-    A = rng.rand(n, rank)
-    B = rng.rand(rank, d)
-    X_filled = np.dot(A, B)
-    # half is randomly missing
-    nan_mask = rng.rand(n, d) < 0.5
-    X_missing = X_filled.copy()
-    X_missing[nan_mask] = np.nan
-
-    # split up data in half
-    n = n // 2
-    X_train = X_missing[:n]
-    X_test_filled = X_filled[n:]
-    X_test = X_missing[n:]
-
-    imputer = ChainedImputer(n_imputations=10,
-                             n_burn_in=10,
-                             verbose=True,
-                             random_state=rng).fit(X_train)
-    X_test_est = imputer.transform(X_test)
-    assert_allclose(X_test_filled, X_test_est, rtol=1e-5, atol=0.1)
-
-
-def test_chained_imputer_additive_matrix():
-    rng = np.random.RandomState(0)
-    n = 100
-    d = 10
-    A = rng.randn(n, d)
-    B = rng.randn(n, d)
-    X_filled = np.zeros(A.shape)
-    for i in range(d):
-        for j in range(d):
-            X_filled[:, (i+j) % d] += (A[:, i] + B[:, j]) / 2
-    # a quarter is randomly missing
-    nan_mask = rng.rand(n, d) < 0.25
-    X_missing = X_filled.copy()
-    X_missing[nan_mask] = np.nan
-
-    # split up data
-    n = n // 2
-    X_train = X_missing[:n]
-    X_test_filled = X_filled[n:]
-    X_test = X_missing[n:]
-
-    imputer = ChainedImputer(n_imputations=25,
-                             n_burn_in=10,
-                             verbose=True,
-                             random_state=rng).fit(X_train)
-    X_test_est = imputer.transform(X_test)
-    assert_allclose(X_test_filled, X_test_est, atol=0.01)
+    with pytest.raises(ValueError, match=err_msg):
+        imputer.fit_transform(X)
diff --git a/sklearn/tests/test_init.py b/sklearn/tests/test_init.py
index 56dbcaafba2c..75c9dd92129f 100644
--- a/sklearn/tests/test_init.py
+++ b/sklearn/tests/test_init.py
@@ -1,11 +1,18 @@
 # Basic unittests to test functioning of module's top-level
 
-__author__ = 'Yaroslav Halchenko'
-__license__ = 'BSD'
+import subprocess
+
+import pkgutil
 
+import pytest
 
+import sklearn
 from sklearn.utils.testing import assert_equal
 
+__author__ = 'Yaroslav Halchenko'
+__license__ = 'BSD'
+
+
 try:
     from sklearn import *  # noqa
     _top_import_error = None
@@ -18,3 +25,37 @@ def test_import_skl():
     # "import *" is discouraged outside of the module level, hence we
     # rely on setting up the variable above
     assert_equal(_top_import_error, None)
+
+
+def test_import_sklearn_no_warnings():
+    # Test that importing scikit-learn main modules doesn't raise any warnings.
+
+    try:
+        pkgs = pkgutil.iter_modules(path=sklearn.__path__, prefix='sklearn.')
+        import_modules = '; '.join(['import ' + modname
+                                    for _, modname, _ in pkgs
+                                    if (not modname.startswith('_') and
+                                        # add deprecated top level modules
+                                        # below to ignore them
+                                        modname not in [])])
+
+        message = subprocess.check_output(['python', '-Wdefault',
+                                           '-c', import_modules],
+                                          stderr=subprocess.STDOUT)
+        message = message.decode("utf-8")
+        message = '\n'.join([line for line in message.splitlines()
+                             if not (
+                                     # ignore ImportWarning due to Cython
+                                     "ImportWarning" in line or
+                                     # ignore DeprecationWarning due to pytest
+                                     "pytest" in line or
+                                     # ignore DeprecationWarnings due to
+                                     # numpy.oldnumeric
+                                     "oldnumeric" in line
+                                     )])
+        assert 'Warning' not in message
+        assert 'Error' not in message
+
+    except Exception as e:
+        pytest.skip('soft-failed test_import_sklearn_no_warnings.\n'
+                    ' %s, \n %s' % (e, message))
diff --git a/sklearn/tests/test_multiclass.py b/sklearn/tests/test_multiclass.py
index 78a1fd617ccf..010d1fcd92c8 100644
--- a/sklearn/tests/test_multiclass.py
+++ b/sklearn/tests/test_multiclass.py
@@ -1,3 +1,5 @@
+import pytest
+
 import numpy as np
 import scipy.sparse as sp
 
@@ -329,6 +331,7 @@ def test_ovr_multilabel_dataset():
                             decimal=2)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_ovr_multilabel_predict_proba():
     base_clf = MultinomialNB(alpha=1)
     for au in (False, True):
@@ -421,6 +424,7 @@ def test_ovr_single_label_decision_function():
                        clf.predict(X_test))
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_ovr_gridsearch():
     ovr = OneVsRestClassifier(LinearSVC(random_state=0))
     Cs = [0.1, 0.5, 0.8]
@@ -597,6 +601,7 @@ def test_ovo_decision_function():
         assert_greater(len(np.unique(decisions[:, class_idx])), 146)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_ovo_gridsearch():
     ovo = OneVsOneClassifier(LinearSVC(random_state=0))
     Cs = [0.1, 0.5, 0.8]
@@ -691,6 +696,7 @@ def test_ecoc_fit_predict():
     assert_equal(len(ecoc.estimators_), n_classes * 2)
 
 
+@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22
 def test_ecoc_gridsearch():
     ecoc = OutputCodeClassifier(LinearSVC(random_state=0),
                                 random_state=0)
diff --git a/sklearn/tests/test_multioutput.py b/sklearn/tests/test_multioutput.py
index 717d680fa6fd..83e3794d7887 100644
--- a/sklearn/tests/test_multioutput.py
+++ b/sklearn/tests/test_multioutput.py
@@ -18,7 +18,7 @@
 from sklearn.datasets import make_classification
 from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier
 from sklearn.exceptions import NotFittedError
-from sklearn.externals.joblib import cpu_count
+from sklearn.utils import cpu_count
 from sklearn.linear_model import Lasso
 from sklearn.linear_model import LogisticRegression
 from sklearn.linear_model import Ridge
diff --git a/sklearn/tests/test_pipeline.py b/sklearn/tests/test_pipeline.py
index beb4be61d0b0..c79f9d0e1f73 100644
--- a/sklearn/tests/test_pipeline.py
+++ b/sklearn/tests/test_pipeline.py
@@ -33,7 +33,7 @@
 from sklearn.datasets import load_iris
 from sklearn.preprocessing import StandardScaler
 from sklearn.feature_extraction.text import CountVectorizer
-from sklearn.externals.joblib import Memory
+from sklearn.utils import Memory
 
 
 JUNK_FOOD_DOCS = (
@@ -908,7 +908,7 @@ def test_pipeline_wrong_memory():
                             ('svc', SVC())], memory=memory)
     assert_raises_regex(ValueError, "'memory' should be None, a string or"
                         " have the same interface as "
-                        "sklearn.externals.joblib.Memory."
+                        "sklearn.utils.Memory."
                         " Got memory='1' instead.", cached_pipe.fit, X, y)
 
 
@@ -931,7 +931,7 @@ def test_pipeline_with_cache_attribute():
                     memory=dummy)
     assert_raises_regex(ValueError, "'memory' should be None, a string or"
                         " have the same interface as "
-                        "sklearn.externals.joblib.Memory."
+                        "sklearn.utils.Memory."
                         " Got memory='{}' instead.".format(dummy), pipe.fit, X)
 
 
diff --git a/sklearn/tests/test_site_joblib.py b/sklearn/tests/test_site_joblib.py
new file mode 100644
index 000000000000..7ceb80a28166
--- /dev/null
+++ b/sklearn/tests/test_site_joblib.py
@@ -0,0 +1,42 @@
+import os
+from sklearn.externals import joblib as joblib_vendored
+from sklearn.utils import Parallel, delayed, Memory, parallel_backend
+
+if os.environ.get('SKLEARN_SITE_JOBLIB', False):
+    import joblib as joblib_site
+else:
+    joblib_site = None
+
+
+def test_old_pickle(tmpdir):
+    # Check that a pickle that references sklearn.external.joblib can load
+    f = tmpdir.join('foo.pkl')
+    f.write(b'\x80\x02csklearn.externals.joblib.numpy_pickle\nNumpyArrayWrappe'
+            b'r\nq\x00)\x81q\x01}q\x02(U\x05dtypeq\x03cnumpy\ndtype\nq\x04U'
+            b'\x02i8q\x05K\x00K\x01\x87q\x06Rq\x07(K\x03U\x01<q\x08NNNJ\xff'
+            b'\xff\xff\xffJ\xff\xff\xff\xffK\x00tq\tbU\x05shapeq\nK\x01\x85q'
+            b'\x0bU\x05orderq\x0cU\x01Cq\rU\x08subclassq\x0ecnumpy\nndarray\nq'
+            b'\x0fU\nallow_mmapq\x10\x88ub\x01\x00\x00\x00\x00\x00\x00\x00.',
+            mode='wb')
+
+    joblib_vendored.load(str(f))
+
+
+def test_site_joblib_dispatch():
+    if os.environ.get('SKLEARN_SITE_JOBLIB', False):
+        assert Parallel is joblib_site.Parallel
+        assert delayed is joblib_site.delayed
+        assert parallel_backend is joblib_site.parallel_backend
+        assert Memory is joblib_site.Memory
+
+        assert joblib_vendored.Parallel is not joblib_site.Parallel
+        assert joblib_vendored.delayed is not joblib_site.delayed
+        assert joblib_vendored.parallel_backend is not \
+            joblib_site.parallel_backend
+        assert joblib_vendored.Memory is not joblib_site.Memory
+
+    else:
+        assert Parallel is joblib_vendored.Parallel
+        assert delayed is joblib_vendored.delayed
+        assert parallel_backend is joblib_vendored.parallel_backend
+        assert Memory is joblib_vendored.Memory
diff --git a/sklearn/tree/_criterion.pyx b/sklearn/tree/_criterion.pyx
index f47aa73e6e79..a2b362334de5 100644
--- a/sklearn/tree/_criterion.pyx
+++ b/sklearn/tree/_criterion.pyx
@@ -842,7 +842,7 @@ cdef class RegressionCriterion(Criterion):
         #           sum_left[x] +  sum_right[x] = sum_total[x]
         # and that sum_total is known, we are going to update
         # sum_left from the direction that require the least amount
-        # of computations, i.e. from pos to new_pos or from end to new_po.
+        # of computations, i.e. from pos to new_pos or from end to new_pos.
 
         if (new_pos - pos) <= (end - new_pos):
             for p in range(pos, new_pos):
@@ -1238,9 +1238,8 @@ cdef class MAE(RegressionCriterion):
         cdef SIZE_t* samples = self.samples
         cdef SIZE_t i, p, k
         cdef DOUBLE_t y_ik
-        cdef DOUBLE_t w_y_ik
-
-        cdef double impurity = 0.0
+        cdef DOUBLE_t w = 1.0
+        cdef DOUBLE_t impurity = 0.0
 
         for k in range(self.n_outputs):
             for p in range(self.start, self.end):
@@ -1248,11 +1247,15 @@ cdef class MAE(RegressionCriterion):
 
                 y_ik = y[i * self.y_stride + k]
 
-                impurity += <double> fabs((<double> y_ik) - <double> self.node_medians[k])
+                if sample_weight != NULL:
+                    w = sample_weight[i]
+
+                impurity += fabs(y_ik - self.node_medians[k]) * w
+
         return impurity / (self.weighted_n_node_samples * self.n_outputs)
 
-    cdef void children_impurity(self, double* impurity_left,
-                                double* impurity_right) nogil:
+    cdef void children_impurity(self, double* p_impurity_left,
+                                double* p_impurity_right) nogil:
         """Evaluate the impurity in children nodes, i.e. the impurity of the
            left child (samples[start:pos]) and the impurity the right child
            (samples[pos:end]).
@@ -1269,13 +1272,13 @@ cdef class MAE(RegressionCriterion):
         cdef SIZE_t i, p, k
         cdef DOUBLE_t y_ik
         cdef DOUBLE_t median
+        cdef DOUBLE_t w = 1.0
+        cdef DOUBLE_t impurity_left = 0.0
+        cdef DOUBLE_t impurity_right = 0.0
 
         cdef void** left_child = <void**> self.left_child.data
         cdef void** right_child = <void**> self.right_child.data
 
-        impurity_left[0] = 0.0
-        impurity_right[0] = 0.0
-
         for k in range(self.n_outputs):
             median = (<WeightedMedianCalculator> left_child[k]).get_median()
             for p in range(start, pos):
@@ -1283,9 +1286,12 @@ cdef class MAE(RegressionCriterion):
 
                 y_ik = y[i * self.y_stride + k]
 
-                impurity_left[0] += <double>fabs((<double> y_ik) -
-                                                 <double> median)
-        impurity_left[0] /= <double>((self.weighted_n_left) * self.n_outputs)
+                if sample_weight != NULL:
+                    w = sample_weight[i]
+
+                impurity_left += fabs(y_ik - median) * w
+        p_impurity_left[0] = impurity_left / (self.weighted_n_left * 
+                                              self.n_outputs)
 
         for k in range(self.n_outputs):
             median = (<WeightedMedianCalculator> right_child[k]).get_median()
@@ -1294,10 +1300,12 @@ cdef class MAE(RegressionCriterion):
 
                 y_ik = y[i * self.y_stride + k]
 
-                impurity_right[0] += <double>fabs((<double> y_ik) -
-                                                  <double> median)
-        impurity_right[0] /= <double>((self.weighted_n_right) *
-                                      self.n_outputs)
+                if sample_weight != NULL:
+                    w = sample_weight[i]
+
+                impurity_right += fabs(y_ik - median) * w
+        p_impurity_right[0] = impurity_right / (self.weighted_n_right * 
+                                                self.n_outputs)
 
 
 cdef class FriedmanMSE(MSE):
diff --git a/sklearn/tree/tests/test_tree.py b/sklearn/tree/tests/test_tree.py
index bb117d8a2986..508819e23947 100644
--- a/sklearn/tree/tests/test_tree.py
+++ b/sklearn/tree/tests/test_tree.py
@@ -18,6 +18,7 @@
 from sklearn.metrics import accuracy_score
 from sklearn.metrics import mean_squared_error
 
+from sklearn.utils.testing import assert_allclose
 from sklearn.utils.testing import assert_array_equal
 from sklearn.utils.testing import assert_array_almost_equal
 from sklearn.utils.testing import assert_almost_equal
@@ -1693,19 +1694,101 @@ def test_no_sparse_y_support(name):
 
 
 def test_mae():
-    # check MAE criterion produces correct results
-    # on small toy dataset
+    """Check MAE criterion produces correct results on small toy dataset:
+
+    ------------------
+    | X | y | weight |
+    ------------------
+    | 3 | 3 |  0.1   |
+    | 5 | 3 |  0.3   |
+    | 8 | 4 |  1.0   |
+    | 3 | 6 |  0.6   |
+    | 5 | 7 |  0.3   |
+    ------------------
+    |sum wt:|  2.3   |
+    ------------------
+
+    Because we are dealing with sample weights, we cannot find the median by
+    simply choosing/averaging the centre value(s), instead we consider the
+    median where 50% of the cumulative weight is found (in a y sorted data set)
+    . Therefore with regards to this test data, the cumulative weight is >= 50%
+    when y = 4.  Therefore:
+    Median = 4
+
+    For all the samples, we can get the total error by summing:
+    Absolute(Median - y) * weight
+
+    I.e., total error = (Absolute(4 - 3) * 0.1)
+                      + (Absolute(4 - 3) * 0.3)
+                      + (Absolute(4 - 4) * 1.0)
+                      + (Absolute(4 - 6) * 0.6)
+                      + (Absolute(4 - 7) * 0.3)
+                      = 2.5
+
+    Impurity = Total error / total weight
+             = 2.5 / 2.3
+             = 1.08695652173913
+             ------------------
+
+    From this root node, the next best split is between X values of 3 and 5.
+    Thus, we have left and right child nodes:
+
+    LEFT                    RIGHT
+    ------------------      ------------------
+    | X | y | weight |      | X | y | weight |
+    ------------------      ------------------
+    | 3 | 3 |  0.1   |      | 5 | 3 |  0.3   |
+    | 3 | 6 |  0.6   |      | 8 | 4 |  1.0   |
+    ------------------      | 5 | 7 |  0.3   |
+    |sum wt:|  0.7   |      ------------------
+    ------------------      |sum wt:|  1.6   |
+                            ------------------
+
+    Impurity is found in the same way:
+    Left node Median = 6
+    Total error = (Absolute(6 - 3) * 0.1)
+                + (Absolute(6 - 6) * 0.6)
+                = 0.3
+
+    Left Impurity = Total error / total weight
+            = 0.3 / 0.7
+            = 0.428571428571429
+            -------------------
+
+    Likewise for Right node:
+    Right node Median = 4
+    Total error = (Absolute(4 - 3) * 0.3)
+                + (Absolute(4 - 4) * 1.0)
+                + (Absolute(4 - 7) * 0.3)
+                = 1.2
+
+    Right Impurity = Total error / total weight
+            = 1.2 / 1.6
+            = 0.75
+            ------
+    """
     dt_mae = DecisionTreeRegressor(random_state=0, criterion="mae",
                                    max_leaf_nodes=2)
-    dt_mae.fit([[3], [5], [3], [8], [5]], [6, 7, 3, 4, 3])
-    assert_array_equal(dt_mae.tree_.impurity, [1.4, 1.5, 4.0/3.0])
-    assert_array_equal(dt_mae.tree_.value.flat, [4, 4.5, 4.0])
 
-    dt_mae.fit([[3], [5], [3], [8], [5]], [6, 7, 3, 4, 3],
-               [0.6, 0.3, 0.1, 1.0, 0.3])
-    assert_array_equal(dt_mae.tree_.impurity, [7.0/2.3, 3.0/0.7, 4.0/1.6])
+    # Test MAE where sample weights are non-uniform (as illustrated above):
+    dt_mae.fit(X=[[3], [5], [3], [8], [5]], y=[6, 7, 3, 4, 3],
+               sample_weight=[0.6, 0.3, 0.1, 1.0, 0.3])
+    assert_allclose(dt_mae.tree_.impurity, [2.5 / 2.3, 0.3 / 0.7, 1.2 / 1.6])
     assert_array_equal(dt_mae.tree_.value.flat, [4.0, 6.0, 4.0])
 
+    # Test MAE where all sample weights are uniform:
+    dt_mae.fit(X=[[3], [5], [3], [8], [5]], y=[6, 7, 3, 4, 3],
+               sample_weight=np.ones(5))
+    assert_array_equal(dt_mae.tree_.impurity, [1.4, 1.5, 4.0 / 3.0])
+    assert_array_equal(dt_mae.tree_.value.flat, [4, 4.5, 4.0])
+
+    # Test MAE where a `sample_weight` is not explicitly provided.
+    # This is equivalent to providing uniform sample weights, though
+    # the internal logic is different:
+    dt_mae.fit(X=[[3], [5], [3], [8], [5]], y=[6, 7, 3, 4, 3])
+    assert_array_equal(dt_mae.tree_.impurity, [1.4, 1.5, 4.0 / 3.0])
+    assert_array_equal(dt_mae.tree_.value.flat, [4, 4.5, 4.0])
+
 
 def test_criterion_copy():
     # Let's check whether copy of our criterion has the same type
diff --git a/sklearn/utils/__init__.py b/sklearn/utils/__init__.py
index bb1f383505fe..50963341f8ed 100644
--- a/sklearn/utils/__init__.py
+++ b/sklearn/utils/__init__.py
@@ -1,7 +1,7 @@
 """
 The :mod:`sklearn.utils` module includes various utilities.
 """
-from collections import Sequence
+
 import numbers
 
 import numpy as np
@@ -15,8 +15,10 @@
                          check_consistent_length, check_X_y, indexable,
                          check_symmetric)
 from .class_weight import compute_class_weight, compute_sample_weight
-from ..externals.joblib import cpu_count
+from ._joblib import cpu_count, Parallel, Memory, delayed
+from ._joblib import parallel_backend
 from ..exceptions import DataConversionWarning
+from ..utils.fixes import _Sequence as Sequence
 from .deprecation import deprecated
 from .. import get_config
 
@@ -26,7 +28,8 @@
            "compute_class_weight", "compute_sample_weight",
            "column_or_1d", "safe_indexing",
            "check_consistent_length", "check_X_y", 'indexable',
-           "check_symmetric", "indices_to_mask", "deprecated"]
+           "check_symmetric", "indices_to_mask", "deprecated",
+           "cpu_count", "Parallel", "Memory", "delayed", "parallel_backend"]
 
 
 class Bunch(dict):
diff --git a/sklearn/externals/joblib.py b/sklearn/utils/_joblib.py
similarity index 53%
rename from sklearn/externals/joblib.py
rename to sklearn/utils/_joblib.py
index 3bd6ae73b875..c4aa319396d4 100644
--- a/sklearn/externals/joblib.py
+++ b/sklearn/utils/_joblib.py
@@ -5,11 +5,12 @@
 
 # An environment variable to use the site joblib
 if _os.environ.get('SKLEARN_SITE_JOBLIB', False):
-    from joblib import *
+    from joblib import __all__
+    from joblib import *  # noqa
     from joblib import __version__
     from joblib import logger
 else:
-    from ._joblib import *
-    from ._joblib import __version__
-    from ._joblib import logger
-
+    from ..externals.joblib import __all__   # noqa
+    from ..externals.joblib import *  # noqa
+    from ..externals.joblib import __version__  # noqa
+    from ..externals.joblib import logger  # noqa
diff --git a/sklearn/utils/_unittest_backport.py b/sklearn/utils/_unittest_backport.py
index 919217f67e3c..a7cfe267280e 100644
--- a/sklearn/utils/_unittest_backport.py
+++ b/sklearn/utils/_unittest_backport.py
@@ -149,7 +149,7 @@ def __exit__(self, exc_type, exc_value, tb):
 
 
 class TestCase(unittest.TestCase):
-    longMessage = False
+    longMessage = True
     failureException = AssertionError
 
     def _formatMessage(self, msg, standardMsg):
diff --git a/sklearn/utils/estimator_checks.py b/sklearn/utils/estimator_checks.py
index 02d91ee80791..ab09229c358c 100644
--- a/sklearn/utils/estimator_checks.py
+++ b/sklearn/utils/estimator_checks.py
@@ -14,7 +14,7 @@
 from scipy.stats import rankdata
 
 from sklearn.externals.six.moves import zip
-from sklearn.externals.joblib import hash, Memory
+from sklearn.utils._joblib import hash, Memory
 from sklearn.utils.testing import assert_raises, _get_args
 from sklearn.utils.testing import assert_raises_regex
 from sklearn.utils.testing import assert_raise_message
@@ -51,7 +51,6 @@
 from sklearn.svm.base import BaseLibSVM
 from sklearn.linear_model.stochastic_gradient import BaseSGD
 from sklearn.pipeline import make_pipeline
-from sklearn.exceptions import ConvergenceWarning
 from sklearn.exceptions import DataConversionWarning
 from sklearn.exceptions import SkipTestWarning
 from sklearn.model_selection import train_test_split
@@ -78,7 +77,7 @@
                 'RANSACRegressor', 'RadiusNeighborsRegressor',
                 'RandomForestRegressor', 'Ridge', 'RidgeCV']
 
-ALLOW_NAN = ['Imputer', 'SimpleImputer', 'ChainedImputer',
+ALLOW_NAN = ['Imputer', 'SimpleImputer', 'MissingIndicator',
              'MaxAbsScaler', 'MinMaxScaler', 'RobustScaler', 'StandardScaler',
              'PowerTransformer', 'QuantileTransformer']
 
@@ -89,6 +88,7 @@ def _yield_non_meta_checks(name, estimator):
     yield check_dtype_object
     yield check_sample_weights_pandas_series
     yield check_sample_weights_list
+    yield check_sample_weights_invariance
     yield check_estimators_fit_returns_self
     yield partial(check_estimators_fit_returns_self, readonly_memmap=True)
     yield check_complex_data
@@ -262,6 +262,7 @@ def _yield_all_checks(name, estimator):
     yield check_fit2d_1feature
     yield check_fit1d
     yield check_get_params_invariance
+    yield check_set_params
     yield check_dict_unchanged
     yield check_dont_overwrite_parameters
 
@@ -341,7 +342,13 @@ def set_checking_parameters(estimator):
         estimator.set_params(n_resampling=5)
     if "n_estimators" in params:
         # especially gradient boosting with default 100
-        estimator.set_params(n_estimators=min(5, estimator.n_estimators))
+        # FIXME: The default number of trees was changed and is set to 'warn'
+        # for some of the ensemble methods. We need to catch this case to avoid
+        # an error during the comparison. To be reverted in 0.22.
+        if estimator.n_estimators == 'warn':
+            estimator.set_params(n_estimators=5)
+        else:
+            estimator.set_params(n_estimators=min(5, estimator.n_estimators))
     if "max_trials" in params:
         # RANSAC
         estimator.set_params(max_trials=10)
@@ -554,6 +561,40 @@ def check_sample_weights_list(name, estimator_orig):
         estimator.fit(X, y, sample_weight=sample_weight)
 
 
+@ignore_warnings(category=(DeprecationWarning, FutureWarning))
+def check_sample_weights_invariance(name, estimator_orig):
+    # check that the estimators yield same results for
+    # unit weights and no weights
+    if (has_fit_parameter(estimator_orig, "sample_weight") and
+            not (hasattr(estimator_orig, "_pairwise")
+                 and estimator_orig._pairwise)):
+        # We skip pairwise because the data is not pairwise
+
+        estimator1 = clone(estimator_orig)
+        estimator2 = clone(estimator_orig)
+        set_random_state(estimator1, random_state=0)
+        set_random_state(estimator2, random_state=0)
+
+        X = np.array([[1, 3], [1, 3], [1, 3], [1, 3],
+                      [2, 1], [2, 1], [2, 1], [2, 1],
+                      [3, 3], [3, 3], [3, 3], [3, 3],
+                      [4, 1], [4, 1], [4, 1], [4, 1]], dtype=np.dtype('float'))
+        y = np.array([1, 1, 1, 1, 2, 2, 2, 2,
+                      1, 1, 1, 1, 2, 2, 2, 2], dtype=np.dtype('int'))
+
+        estimator1.fit(X, y=y, sample_weight=np.ones(shape=len(y)))
+        estimator2.fit(X, y=y, sample_weight=None)
+
+        for method in ["predict", "transform"]:
+            if hasattr(estimator_orig, method):
+                X_pred1 = getattr(estimator1, method)(X)
+                X_pred2 = getattr(estimator2, method)(X)
+                assert_allclose(X_pred1, X_pred2,
+                                err_msg="For %s sample_weight=None is not"
+                                        " equivalent to sample_weight=ones"
+                                        % name)
+
+
 @ignore_warnings(category=(DeprecationWarning, FutureWarning, UserWarning))
 def check_dtype_object(name, estimator_orig):
     # check that estimators treat dtype object as numeric if possible
@@ -1167,6 +1208,13 @@ def check_estimators_pickle(name, estimator_orig):
         X += 1
     X = pairwise_estimator_convert_X(X, estimator_orig, kernel=rbf_kernel)
 
+    # include NaN values when the estimator should deal with them
+    if name in ALLOW_NAN:
+        # set randomly 10 elements to np.nan
+        rng = np.random.RandomState(42)
+        mask = rng.choice(X.size, 10, replace=False)
+        X.reshape(-1)[mask] = np.nan
+
     estimator = clone(estimator_orig)
 
     # some estimators only take multioutputs
@@ -1175,17 +1223,17 @@ def check_estimators_pickle(name, estimator_orig):
     set_random_state(estimator)
     estimator.fit(X, y)
 
-    result = dict()
-    for method in check_methods:
-        if hasattr(estimator, method):
-            result[method] = getattr(estimator, method)(X)
-
     # pickle and unpickle!
     pickled_estimator = pickle.dumps(estimator)
     if estimator.__module__.startswith('sklearn.'):
         assert_true(b"version" in pickled_estimator)
     unpickled_estimator = pickle.loads(pickled_estimator)
 
+    result = dict()
+    for method in check_methods:
+        if hasattr(estimator, method):
+            result[method] = getattr(estimator, method)(X)
+
     for method in result:
         unpickled_result = getattr(unpickled_estimator, method)(X)
         assert_allclose_dense_sparse(result[method], unpickled_result)
@@ -2174,6 +2222,59 @@ def transform(self, X):
                     shallow_params.items()))
 
 
+@ignore_warnings(category=(DeprecationWarning, FutureWarning))
+def check_set_params(name, estimator_orig):
+    # Check that get_params() returns the same thing
+    # before and after set_params() with some fuzz
+    estimator = clone(estimator_orig)
+
+    orig_params = estimator.get_params(deep=False)
+    msg = ("get_params result does not match what was passed to set_params")
+
+    estimator.set_params(**orig_params)
+    curr_params = estimator.get_params(deep=False)
+    assert_equal(set(orig_params.keys()), set(curr_params.keys()), msg)
+    for k, v in curr_params.items():
+        assert orig_params[k] is v, msg
+
+    # some fuzz values
+    test_values = [-np.inf, np.inf, None]
+
+    test_params = deepcopy(orig_params)
+    for param_name in orig_params.keys():
+        default_value = orig_params[param_name]
+        for value in test_values:
+            test_params[param_name] = value
+            try:
+                estimator.set_params(**test_params)
+            except (TypeError, ValueError) as e:
+                e_type = e.__class__.__name__
+                # Exception occurred, possibly parameter validation
+                warnings.warn("{} occurred during set_params. "
+                              "It is recommended to delay parameter "
+                              "validation until fit.".format(e_type))
+
+                change_warning_msg = "Estimator's parameters changed after " \
+                                     "set_params raised {}".format(e_type)
+                params_before_exception = curr_params
+                curr_params = estimator.get_params(deep=False)
+                try:
+                    assert_equal(set(params_before_exception.keys()),
+                                 set(curr_params.keys()))
+                    for k, v in curr_params.items():
+                        assert params_before_exception[k] is v
+                except AssertionError:
+                    warnings.warn(change_warning_msg)
+            else:
+                curr_params = estimator.get_params(deep=False)
+                assert_equal(set(test_params.keys()),
+                             set(curr_params.keys()),
+                             msg)
+                for k, v in curr_params.items():
+                    assert test_params[k] is v, msg
+        test_params[param_name] = default_value
+
+
 @ignore_warnings(category=(DeprecationWarning, FutureWarning))
 def check_classifiers_regression_target(name, estimator_orig):
     # Check if classifier throws an exception when fed regression targets
diff --git a/sklearn/utils/extmath.py b/sklearn/utils/extmath.py
index 218733145a0d..68a93a2a9120 100644
--- a/sklearn/utils/extmath.py
+++ b/sklearn/utils/extmath.py
@@ -367,7 +367,7 @@ def logsumexp(arr, axis=0):
     >>> a = np.arange(10)
     >>> np.log(np.sum(np.exp(a)))
     9.458...
-    >>> logsumexp(a)
+    >>> logsumexp(a)  # doctest: +SKIP
     9.458...
     """
     return scipy_logsumexp(arr, axis)
diff --git a/sklearn/utils/fixes.py b/sklearn/utils/fixes.py
index 748670e4dd9a..12ac3ae8e55e 100644
--- a/sklearn/utils/fixes.py
+++ b/sklearn/utils/fixes.py
@@ -310,3 +310,16 @@ def _object_dtype_isnan(X):
 else:
     def _object_dtype_isnan(X):
         return np.frompyfunc(lambda x: x != x, 1, 1)(X).astype(bool)
+
+
+# To be removed once this fix is included in six
+try:
+    from collections.abc import Sequence as _Sequence  # noqa
+    from collections.abc import Iterable as _Iterable  # noqa
+    from collections.abc import Mapping as _Mapping  # noqa
+    from collections.abc import Sized as _Sized  # noqa
+except ImportError:  # python <3.3
+    from collections import Sequence as _Sequence  # noqa
+    from collections import Iterable as _Iterable  # noqa
+    from collections import Mapping as _Mapping  # noqa
+    from collections import Sized as _Sized  # noqa
diff --git a/sklearn/utils/multiclass.py b/sklearn/utils/multiclass.py
index 4adefd4ff04f..f4d28ec227ba 100644
--- a/sklearn/utils/multiclass.py
+++ b/sklearn/utils/multiclass.py
@@ -7,7 +7,6 @@
 
 """
 from __future__ import division
-from collections import Sequence
 from itertools import chain
 
 from scipy.sparse import issparse
@@ -18,10 +17,10 @@
 import numpy as np
 
 from ..externals.six import string_types
+from ..utils.fixes import _Sequence as Sequence
 from .validation import check_array
 
 
-
 def _unique_multiclass(y):
     if hasattr(y, '__array__'):
         return np.unique(np.asarray(y))
diff --git a/sklearn/utils/testing.py b/sklearn/utils/testing.py
index c67a314e2fc5..bfae5d4662b1 100644
--- a/sklearn/utils/testing.py
+++ b/sklearn/utils/testing.py
@@ -275,6 +275,8 @@ def ignore_warnings(obj=None, category=Warning):
 
     Parameters
     ----------
+    obj : callable or None
+        callable where you want to ignore the warnings.
     category : warning class, defaults to Warning.
         The category to filter. If Warning, all categories will be muted.
 
@@ -290,7 +292,17 @@ def ignore_warnings(obj=None, category=Warning):
     >>> ignore_warnings(nasty_warn)()
     42
     """
-    if callable(obj):
+    if isinstance(obj, type) and issubclass(obj, Warning):
+        # Avoid common pitfall of passing category as the first positional
+        # argument which result in the test not being run
+        warning_name = obj.__name__
+        raise ValueError(
+            "'obj' should be a callable where you want to ignore warnings. "
+            "You passed a warning class instead: 'obj={warning_name}'. "
+            "If you want to pass a warning class to ignore_warnings, "
+            "you should use 'category={warning_name}'".format(
+                warning_name=warning_name))
+    elif callable(obj):
         return _IgnoreWarnings(category=category)(obj)
     else:
         return _IgnoreWarnings(category=category)
diff --git a/sklearn/utils/tests/test_estimator_checks.py b/sklearn/utils/tests/test_estimator_checks.py
index 9b4a9c4f87c1..bf8412b3e527 100644
--- a/sklearn/utils/tests/test_estimator_checks.py
+++ b/sklearn/utils/tests/test_estimator_checks.py
@@ -10,7 +10,8 @@
 from sklearn.base import BaseEstimator, ClassifierMixin
 from sklearn.utils import deprecated
 from sklearn.utils.testing import (assert_raises_regex, assert_true,
-                                   assert_equal, ignore_warnings)
+                                   assert_equal, ignore_warnings,
+                                   assert_warns)
 from sklearn.utils.estimator_checks import check_estimator
 from sklearn.utils.estimator_checks import set_random_state
 from sklearn.utils.estimator_checks import set_checking_parameters
@@ -86,6 +87,61 @@ def fit(self, X, y=None):
         return self
 
 
+class RaisesErrorInSetParams(BaseEstimator):
+    def __init__(self, p=0):
+        self.p = p
+
+    def set_params(self, **kwargs):
+        if 'p' in kwargs:
+            p = kwargs.pop('p')
+            if p < 0:
+                raise ValueError("p can't be less than 0")
+            self.p = p
+        return super(RaisesErrorInSetParams, self).set_params(**kwargs)
+
+    def fit(self, X, y=None):
+        X, y = check_X_y(X, y)
+        return self
+
+
+class ModifiesValueInsteadOfRaisingError(BaseEstimator):
+    def __init__(self, p=0):
+        self.p = p
+
+    def set_params(self, **kwargs):
+        if 'p' in kwargs:
+            p = kwargs.pop('p')
+            if p < 0:
+                p = 0
+            self.p = p
+        return super(ModifiesValueInsteadOfRaisingError,
+                     self).set_params(**kwargs)
+
+    def fit(self, X, y=None):
+        X, y = check_X_y(X, y)
+        return self
+
+
+class ModifiesAnotherValue(BaseEstimator):
+    def __init__(self, a=0, b='method1'):
+        self.a = a
+        self.b = b
+
+    def set_params(self, **kwargs):
+        if 'a' in kwargs:
+            a = kwargs.pop('a')
+            self.a = a
+            if a is None:
+                kwargs.pop('b')
+                self.b = 'method2'
+        return super(ModifiesAnotherValue,
+                     self).set_params(**kwargs)
+
+    def fit(self, X, y=None):
+        X, y = check_X_y(X, y)
+        return self
+
+
 class NoCheckinPredict(BaseBadClassifier):
     def fit(self, X, y):
         X, y = check_X_y(X, y)
@@ -219,6 +275,13 @@ def test_check_estimator():
     msg = "it does not implement a 'get_params' methods"
     assert_raises_regex(TypeError, msg, check_estimator, object)
     assert_raises_regex(TypeError, msg, check_estimator, object())
+    # check that values returned by get_params match set_params
+    msg = "get_params result does not match what was passed to set_params"
+    assert_raises_regex(AssertionError, msg, check_estimator,
+                        ModifiesValueInsteadOfRaisingError())
+    assert_warns(UserWarning, check_estimator, RaisesErrorInSetParams())
+    assert_raises_regex(AssertionError, msg, check_estimator,
+                        ModifiesAnotherValue())
     # check that we have a fit method
     msg = "object has no attribute 'fit'"
     assert_raises_regex(AttributeError, msg, check_estimator, BaseEstimator)
@@ -317,25 +380,25 @@ def test_check_estimator_clones():
     for Estimator in [GaussianMixture, LinearRegression,
                       RandomForestClassifier, NMF, SGDClassifier,
                       MiniBatchKMeans]:
-        with ignore_warnings(category=FutureWarning):
+        with ignore_warnings(category=(FutureWarning, DeprecationWarning)):
             # when 'est = SGDClassifier()'
             est = Estimator()
-        set_checking_parameters(est)
-        set_random_state(est)
-        # without fitting
-        old_hash = joblib.hash(est)
-        check_estimator(est)
+            set_checking_parameters(est)
+            set_random_state(est)
+            # without fitting
+            old_hash = joblib.hash(est)
+            check_estimator(est)
         assert_equal(old_hash, joblib.hash(est))
 
-        with ignore_warnings(category=FutureWarning):
+        with ignore_warnings(category=(FutureWarning, DeprecationWarning)):
             # when 'est = SGDClassifier()'
             est = Estimator()
-        set_checking_parameters(est)
-        set_random_state(est)
-        # with fitting
-        est.fit(iris.data + 10, iris.target)
-        old_hash = joblib.hash(est)
-        check_estimator(est)
+            set_checking_parameters(est)
+            set_random_state(est)
+            # with fitting
+            est.fit(iris.data + 10, iris.target)
+            old_hash = joblib.hash(est)
+            check_estimator(est)
         assert_equal(old_hash, joblib.hash(est))
 
 
diff --git a/sklearn/utils/tests/test_testing.py b/sklearn/utils/tests/test_testing.py
index eb9512f177ed..729b5ef81c68 100644
--- a/sklearn/utils/tests/test_testing.py
+++ b/sklearn/utils/tests/test_testing.py
@@ -8,6 +8,8 @@
 
 from scipy import sparse
 
+import pytest
+
 from sklearn.utils.deprecation import deprecated
 from sklearn.utils.metaestimators import if_delegate_has_method
 from sklearn.utils.testing import (
@@ -210,6 +212,20 @@ def context_manager_no_user_multiple_warning():
     assert_warns(UserWarning, context_manager_no_deprecation_multiple_warning)
     assert_warns(DeprecationWarning, context_manager_no_user_multiple_warning)
 
+    # Check that passing warning class as first positional argument
+    warning_class = UserWarning
+    match = "'obj' should be a callable.+you should use 'category=UserWarning'"
+
+    with pytest.raises(ValueError, match=match):
+        silence_warnings_func = ignore_warnings(warning_class)(
+            _warning_function)
+        silence_warnings_func()
+
+    with pytest.raises(ValueError, match=match):
+        @ignore_warnings(warning_class)
+        def test():
+            pass
+
 
 class TestWarns(unittest.TestCase):
     def test_warn(self):
diff --git a/sklearn/utils/tests/test_validation.py b/sklearn/utils/tests/test_validation.py
index deec9a50179b..b0401142642a 100644
--- a/sklearn/utils/tests/test_validation.py
+++ b/sklearn/utils/tests/test_validation.py
@@ -291,40 +291,17 @@ def test_check_array():
     assert_true(isinstance(result, np.ndarray))
 
     # deprecation warning if string-like array with dtype="numeric"
-    X_str = [['a', 'b'], ['c', 'd']]
-    assert_warns_message(
-        FutureWarning,
-        "arrays of strings will be interpreted as decimal numbers if "
-        "parameter 'dtype' is 'numeric'. It is recommended that you convert "
-        "the array to type np.float64 before passing it to check_array.",
-        check_array, X_str, "numeric")
-    assert_warns_message(
-        FutureWarning,
-        "arrays of strings will be interpreted as decimal numbers if "
-        "parameter 'dtype' is 'numeric'. It is recommended that you convert "
-        "the array to type np.float64 before passing it to check_array.",
-        check_array, np.array(X_str, dtype='U'), "numeric")
-    assert_warns_message(
-        FutureWarning,
-        "arrays of strings will be interpreted as decimal numbers if "
-        "parameter 'dtype' is 'numeric'. It is recommended that you convert "
-        "the array to type np.float64 before passing it to check_array.",
-        check_array, np.array(X_str, dtype='S'), "numeric")
+    expected_warn_regex = r"converted to decimal numbers if dtype='numeric'"
+    X_str = [['11', '12'], ['13', 'xx']]
+    for X in [X_str, np.array(X_str, dtype='U'), np.array(X_str, dtype='S')]:
+        with pytest.warns(FutureWarning, match=expected_warn_regex):
+            check_array(X, dtype="numeric")
 
     # deprecation warning if byte-like array with dtype="numeric"
     X_bytes = [[b'a', b'b'], [b'c', b'd']]
-    assert_warns_message(
-        FutureWarning,
-        "arrays of strings will be interpreted as decimal numbers if "
-        "parameter 'dtype' is 'numeric'. It is recommended that you convert "
-        "the array to type np.float64 before passing it to check_array.",
-        check_array, X_bytes, "numeric")
-    assert_warns_message(
-        FutureWarning,
-        "arrays of strings will be interpreted as decimal numbers if "
-        "parameter 'dtype' is 'numeric'. It is recommended that you convert "
-        "the array to type np.float64 before passing it to check_array.",
-        check_array, np.array(X_bytes, dtype='V1'), "numeric")
+    for X in [X_bytes, np.array(X_bytes, dtype='V1')]:
+        with pytest.warns(FutureWarning, match=expected_warn_regex):
+            check_array(X, dtype="numeric")
 
 
 def test_check_array_pandas_dtype_object_conversion():
@@ -436,8 +413,9 @@ def test_check_array_accept_sparse_type_exception():
            "Use X.toarray() to convert to a dense numpy array.")
     assert_raise_message(TypeError, msg,
                          check_array, X_csr, accept_sparse=False)
-    assert_raise_message(TypeError, msg,
-                         check_array, X_csr, accept_sparse=None)
+    with pytest.warns(DeprecationWarning):
+        assert_raise_message(TypeError, msg,
+                             check_array, X_csr, accept_sparse=None)
 
     msg = ("Parameter 'accept_sparse' should be a string, "
            "boolean or list of strings. You provided 'accept_sparse={}'.")
@@ -765,12 +743,12 @@ def test_check_memory():
     assert memory is dummy
     assert_raises_regex(ValueError, "'memory' should be None, a string or"
                         " have the same interface as "
-                        "sklearn.externals.joblib.Memory."
+                        "sklearn.utils.Memory."
                         " Got memory='1' instead.", check_memory, 1)
     dummy = WrongDummyMemory()
     assert_raises_regex(ValueError, "'memory' should be None, a string or"
                         " have the same interface as "
-                        "sklearn.externals.joblib.Memory. Got memory='{}' "
+                        "sklearn.utils.Memory. Got memory='{}' "
                         "instead.".format(dummy), check_memory, dummy)
 
 
diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py
index a000d935624c..01d258c3f97b 100644
--- a/sklearn/utils/validation.py
+++ b/sklearn/utils/validation.py
@@ -24,7 +24,7 @@
 from ..exceptions import NonBLASDotWarning
 from ..exceptions import NotFittedError
 from ..exceptions import DataConversionWarning
-from ..externals.joblib import Memory
+from ..utils._joblib import Memory
 
 
 FLOAT_DTYPES = (np.float64, np.float32, np.float16)
@@ -183,7 +183,7 @@ def check_memory(memory):
     """Check that ``memory`` is joblib.Memory-like.
 
     joblib.Memory-like means that ``memory`` can be converted into a
-    sklearn.externals.joblib.Memory instance (typically a str denoting the
+    sklearn.utils.Memory instance (typically a str denoting the
     ``cachedir``) or has the same interface (has a ``cache`` method).
 
     Parameters
@@ -204,7 +204,7 @@ def check_memory(memory):
         memory = Memory(cachedir=memory, verbose=0)
     elif not hasattr(memory, 'cache'):
         raise ValueError("'memory' should be None, a string or have the same"
-                         " interface as sklearn.externals.joblib.Memory."
+                         " interface as sklearn.utils.Memory."
                          " Got memory='{}' instead.".format(memory))
     return memory
 
@@ -546,10 +546,12 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,
         # in the future np.flexible dtypes will be handled like object dtypes
         if dtype_numeric and np.issubdtype(array.dtype, np.flexible):
             warnings.warn(
-                "Beginning in version 0.22, arrays of strings will be "
-                "interpreted as decimal numbers if parameter 'dtype' is "
-                "'numeric'. It is recommended that you convert the array to "
-                "type np.float64 before passing it to check_array.",
+                "Beginning in version 0.22, arrays of bytes/strings will be "
+                "converted to decimal numbers if dtype='numeric'. "
+                "It is recommended that you convert the array to "
+                "a float dtype before using it in scikit-learn, "
+                "for example by using "
+                "your_array = your_array.astype(np.float64).",
                 FutureWarning)
 
         # make sure we actually converted to numeric:
