diff --git a/doc/release/1.11.2-notes.rst b/doc/release/1.11.2-notes.rst
index 99fa8946c7b..f15e732e52e 100644
--- a/doc/release/1.11.2-notes.rst
+++ b/doc/release/1.11.2-notes.rst
@@ -5,12 +5,12 @@ Numpy 1.11.2 supports Python 2.6 - 2.7 and 3.2 - 3.5. It fixes bugs and
 regressions found in Numpy 1.11.1 and includes several build related
 improvements. Wheels for Linux, Windows, and OS X can be found on PyPI.
 
-Fixes Merged
-============
+Pull Requests Merged
+====================
 
-Fixes overridden by later merges are omitted.
+Fixes overridden by later merges and release notes updates are omitted.
 
-- #7736 BUG: many functions silently drop `keepdims` kwarg.
+- #7736 BUG: many functions silently drop 'keepdims' kwarg.
 - #7738 ENH: add extra kwargs and update doc of many MA methods.
 - #7778 DOC: Update Numpy 1.11.1 release notes.
 - #7793 BUG: MaskedArray.count treats negative axes incorrectly.
@@ -31,3 +31,5 @@ Fixes overridden by later merges are omitted.
 - #7954 BUG: Use keyword arguments to initialize Extension base class.
 - #7955 BUG: Make sure numpy globals keep identity after reload.
 - #7972 BUG: MSVCCompiler grows 'lib' & 'include' env strings exponentially.
+- #8005 BLD: Remove __NUMPY_SETUP__ from builtins at end of setup.py.
+- #8010 MAINT: Remove leftover imp module imports.
diff --git a/doc/release/1.12.0-notes.rst b/doc/release/1.12.0-notes.rst
index f7f3b4e555e..dbd4c3ac652 100644
--- a/doc/release/1.12.0-notes.rst
+++ b/doc/release/1.12.0-notes.rst
@@ -180,10 +180,10 @@ Add a hook in ``numpy/__init__.py`` to import a ``numpy/_distributor_init.py``
 file that will remain empty (bar a docstring) in the standard numpy source,
 but that can be overwritten by people making binary distributions of numpy.
 
-New nanfunctions ``nancumsum`` and ``nancumprod`` added
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-Nanfunctions ``nancumsum`` and ``nancumprod`` have been added to
-compute ``cumsum`` and ``cumprod`` by ignoring nans.
+New nanfunctions ``nancov``, ``nancumsum``, and ``nancumprod`` added
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Nanfunctions ``nancov``, ``nancumsum``, and ``nancumprod`` have been added to
+compute ``cov``, ``cumsum``, and ``cumprod`` by ignoring nans.
 
 ``np.interp`` can now interpolate complex values
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
diff --git a/doc/source/reference/routines.statistics.rst b/doc/source/reference/routines.statistics.rst
index d359541aa62..cfc1425bcbc 100644
--- a/doc/source/reference/routines.statistics.rst
+++ b/doc/source/reference/routines.statistics.rst
@@ -43,6 +43,7 @@ Correlating
    corrcoef
    correlate
    cov
+   nancov
 
 Histograms
 ----------
diff --git a/doc/source/user/c-info.ufunc-tutorial.rst b/doc/source/user/c-info.ufunc-tutorial.rst
index ab97846a85f..f064fbcc949 100644
--- a/doc/source/user/c-info.ufunc-tutorial.rst
+++ b/doc/source/user/c-info.ufunc-tutorial.rst
@@ -70,7 +70,7 @@ Example Non-ufunc extension
 .. index::
    pair: ufunc; adding new
 
-For comparison and general edificaiton of the reader we provide
+For comparison and general edification of the reader we provide
 a simple implementation of a C extension of logit that uses no
 numpy.
 
@@ -278,7 +278,7 @@ the primary thing that must be changed to create your own ufunc.
          * In this code we only define the ufunc for
          * a single dtype. The computations that must
          * be replaced to create a ufunc for
-         * a different funciton are marked with BEGIN
+         * a different function are marked with BEGIN
          * and END.
          *
          * Details explaining the Python-C API can be found under
@@ -480,7 +480,7 @@ the primary thing that must be changed to create your own ufunc.
          * of these functions must be modified when you
          * create your own ufunc. The computations that must
          * be replaced to create a ufunc for
-         * a different funciton are marked with BEGIN
+         * a different function are marked with BEGIN
          * and END.
          *
          * Details explaining the Python-C API can be found under
diff --git a/numpy/core/setup.py b/numpy/core/setup.py
index bec35848042..0b055dba460 100644
--- a/numpy/core/setup.py
+++ b/numpy/core/setup.py
@@ -1,6 +1,5 @@
 from __future__ import division, print_function
 
-import imp
 import os
 import sys
 import pickle
diff --git a/numpy/distutils/fcompiler/gnu.py b/numpy/distutils/fcompiler/gnu.py
index fd49db49216..1de658afb2f 100644
--- a/numpy/distutils/fcompiler/gnu.py
+++ b/numpy/distutils/fcompiler/gnu.py
@@ -364,7 +364,7 @@ def _can_target(cmd, arch):
     """Return true if the architecture supports the -arch flag"""
     newcmd = cmd[:]
     fid, filename = tempfile.mkstemp(suffix=".f")
-    fid.close()
+    os.close(fid)
     try:
         d = os.path.dirname(filename)
         output = os.path.splitext(filename)[0] + ".o"
diff --git a/numpy/lib/nanfunctions.py b/numpy/lib/nanfunctions.py
index 7f7aea9bc04..352be0a546a 100644
--- a/numpy/lib/nanfunctions.py
+++ b/numpy/lib/nanfunctions.py
@@ -17,6 +17,7 @@
 - `nanstd` -- standard deviation of non-NaN values
 - `nanmedian` -- median of non-NaN values
 - `nanpercentile` -- qth percentile of non-NaN values
+- `nancov` -- covariance matrix of non-Nan values
 
 """
 from __future__ import division, absolute_import, print_function
@@ -29,7 +30,7 @@
 __all__ = [
     'nansum', 'nanmax', 'nanmin', 'nanargmax', 'nanargmin', 'nanmean',
     'nanmedian', 'nanpercentile', 'nanvar', 'nanstd', 'nanprod',
-    'nancumsum', 'nancumprod'
+    'nancumsum', 'nancumprod', 'nancov'
     ]
 
 
@@ -1425,3 +1426,243 @@ def nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue):
     else:
         std = var.dtype.type(np.sqrt(var))
     return std
+
+
+def nancov(m, y=None, rowvar=1, ddof=1, fweights=None, aweights=None,
+           pairwise=False):
+    """
+    Estimate a covariance matrix, given data, ignoring observations containing
+    NaN values.
+
+    Covariance indicates the level to which two variables vary together.
+    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,
+    then the covariance matrix element :math:`C_{ij}` is the covariance of
+    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance
+    of :math:`x_i`.
+
+    Parameters
+    ----------
+    m : array_like
+        A 1-D or 2-D array containing multiple variables and observations.
+        Each row of `m` represents a variable, and each column a single
+        observation of all those variables. Also see `rowvar` below.
+    y : array_like, optional
+        An additional set of variables and observations. `y` has the same
+        form as that of `m`.
+    rowvar : int, optional
+        If `rowvar` is non-zero (default), then each row represents a
+        variable, with observations in the columns. Otherwise, the relationship
+        is transposed: each column represents a variable, while the rows
+        contain observations.
+    ddof : int, optional
+        Normalization is by ``(N - ddof)``, where ``N`` is
+        the number of observations. The default value is ``1``.
+    fweights : array_like, int, optional
+        1-D array of integer freguency weights; the number of times each
+        observation vector should be repeated.
+    aweights : array_like, optional
+        1-D array of observation vector weights. These relative weights are
+        typically large for observations considered "important" and smaller for
+        observations considered less "important". If ``ddof=0`` the array of
+        weights can be used to assign probabilities to observation vectors.
+    pairwise : bool, optional
+        If ``False`` then a NaN value causes that observation to be eliminated
+        across all variables.  If ``True`` then each pair of variables is
+        compared separately.  Observations with NaN values in the pair are
+        removed, but do not affect other pairs.  The returned covariance matrix
+        may no longer be positive semi-definite in this case.  False is
+        equivalent to the ``na.or.complete`` use flag for cov in R, while
+        ``True`` is equivalent to ``pairwise.complete.obs``.
+
+    Returns
+    -------
+    out : ndarray
+        The covariance matrix of the variables.
+
+    See Also
+    --------
+    corrcoef : Normalized covariance matrix
+
+    Examples
+    --------
+    Consider two variables, :math:`x_0` and :math:`x_1`, which
+    correlate perfectly, but in opposite directions:
+
+    >>> x = np.array([[0, 2], [1, 1], [np.nan, 1], [2, 0]]).T
+    >>> x
+    array([[0, 1, nan, 2],
+           [2, 1,   1, 0]])
+
+    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance
+    matrix shows this clearly:
+
+    >>> np.nancov(x)
+    array([[ 1., -1.],
+           [-1.,  1.]])
+
+    Note that element :math:`C_{0,1}`, which shows the correlation between
+    :math:`x_0` and :math:`x_1`, is negative.
+
+    Further, note how `x` and `y` are combined:
+
+    >>> x = [-2.1, -1,  np.nan, 4.3]
+    >>> y = [3,  1.1,  1, 0.12]
+    >>> X = np.vstack((x,y))
+    >>> print np.nancov(X)
+    [[ 11.71        -4.286     ]
+     [ -4.286        2.14413333]]
+    >>> print np.nancov(x, y)
+    [[ 11.71        -4.286     ]
+     [ -4.286        2.14413333]]
+    >>> print np.nancov(x)
+    11.71
+
+    Finally it can be seen how the pairwise option handles nan values
+    differently than when when the pairwise option is disabled (default).
+
+    >>> X = np.array([[ 1.,  2.,     10., np.nan,   5.],
+    ...               [ 4., 10.,     13., np.nan,   8.],
+    ...               [-2., -4., np.nan, np.nan, -10.]])
+    >>> np.nancov(X)
+    array([[  4.33333333,   2.66666667,  -8.66666667],
+           [  2.66666667,   9.33333333,  -5.33333333],
+           [ -8.66666667,  -5.33333333,  17.33333333]])
+    >>> np.nancov(X, pairwise=True)
+    array([[ 16.33333333,  12.16666667,  -8.66666667],
+           [ 12.16666667,  14.25      ,  -5.33333333],
+           [ -8.66666667,  -5.33333333,  17.33333333]])
+    """
+    # Check inputs
+    if ddof is not None and ddof != int(ddof):
+        raise ValueError(
+            "ddof must be integer")
+
+    m = np.asarray(m)
+    if m.ndim > 2:
+        raise ValueError("m has more than 2 dimensions")
+
+    if y is None:
+        dtype = np.result_type(m, np.float64)
+    else:
+        y = np.asarray(y)
+        if y.ndim > 2:
+            raise ValueError("y has more than 2 dimensions")
+        dtype = np.result_type(m, y, np.float64)
+    X = np.array(m, ndmin=2, dtype=dtype)
+
+    if X.shape[0] == 1:
+        rowvar = 1
+    if rowvar:
+        axis = 0
+    else:
+        axis = 1
+
+    if y is not None:
+        y = np.array(y, copy=False, ndmin=2, dtype=dtype)
+        X = np.concatenate((X, y), axis)
+
+    if axis:
+        n = X.shape[0]
+    else:
+        n = X.shape[1]
+
+    # Get the product of frequencies and weights
+    if fweights is not None:
+        fweights = np.asarray(fweights, dtype=np.float64)
+        if not np.all(fweights == np.around(fweights)):
+            raise TypeError(
+                "fweights must be integer")
+        if fweights.ndim > 1:
+            raise RuntimeError(
+                "cannot handle multidimensional fweights")
+        if fweights.shape[0] != n:
+            raise RuntimeError(
+                "incompatible numbers of samples and fweights")
+        if any(fweights < 0):
+            raise ValueError(
+                "fweights cannot be negative")
+    if aweights is not None:
+        aweights = np.asarray(aweights, dtype=np.float64)
+        if aweights.ndim > 1:
+            raise RuntimeError(
+                "cannot handle multidimensional aweights")
+        if aweights.shape[0] != n:
+            raise RuntimeError(
+                "incompatible numbers of samples and aweights")
+        if any(aweights < 0):
+            raise ValueError(
+                "aweights cannot be negative")
+
+    if pairwise:
+        w = None
+        if fweights is not None:
+            w = fweights
+        if aweights is not None:
+            if w is None:
+                w = aweights
+            else:
+                w *= aweights
+
+        nan_vals = np.isnan(X)
+        if axis:
+            one_array = np.ones(X.T.shape)
+            one_array[nan_vals.T] = np.nan
+        else:
+            one_array = np.ones(X.shape)
+            one_array[nan_vals] = np.nan
+        # each pair may cause a unique mean for the variable, so we create
+        # pair_array which has the correctly nan-ed values.
+        if axis:
+            pair_array = X[:, None, :].swapaxes(0, 2) * one_array[None, :, :]
+        else:
+            pair_array = X[:, None, :] * one_array[None, :, :]
+
+        if w is None:
+            pair_means = nanmean(pair_array, axis=2)
+            pair_w_sum = nansum(~np.isnan(pair_array), axis=2)
+        else:
+            pair_w = w[None, None, :] * ~np.isnan(pair_array)
+            pair_w_sum = np.nansum(pair_w, axis=2)
+            pair_means = nansum(w[None, None, :] * pair_array,
+                                axis=2) / pair_w_sum
+        pair_array -= pair_means[:, :, None]
+
+        if w is None:
+            dotted = pair_array * pair_array.swapaxes(0, 1).conj()
+        else:
+            dotted = pair_array * \
+                (w[None, None, :] * pair_array).swapaxes(0, 1).conj()
+
+        c = nansum(dotted, axis=2)
+
+        if aweights is None:
+            fact = pair_w_sum - ddof
+        else:
+            ddof_weight = nansum(aweights[None, None, :] * pair_w, axis=2)
+            fact = pair_w_sum - ddof * ddof_weight / pair_w_sum
+
+        if np.any(fact <= 0):
+            warnings.warn("Degrees of freedom <= 0 for a slice",
+                          RuntimeWarning, stacklevel=2)
+            fact[fact <= 0] = 0.0
+
+        c *= 1. / fact.astype(np.float64)
+        return c
+    else:
+        # "Complete" version for handling nans where a nan value in any
+        # variable causes the observation to be removed from all variables.
+
+        # Find observations with nans
+        nan_obvs = np.any(np.isnan(X), axis=axis)
+
+        if fweights is not None:
+            fweights = fweights[~nan_obvs]
+        if aweights is not None:
+            aweights = aweights[~nan_obvs]
+
+        if axis:
+            X_nonan = X[~nan_obvs, :]
+        else:
+            X_nonan = X[:, ~nan_obvs]
+        return np.cov(X_nonan, rowvar=rowvar, ddof=ddof, fweights=fweights,
+                      aweights=aweights)
diff --git a/numpy/lib/tests/test_nanfunctions.py b/numpy/lib/tests/test_nanfunctions.py
index 06c0953b5df..8607db4ab38 100644
--- a/numpy/lib/tests/test_nanfunctions.py
+++ b/numpy/lib/tests/test_nanfunctions.py
@@ -5,7 +5,8 @@
 import numpy as np
 from numpy.testing import (
     run_module_suite, TestCase, assert_, assert_equal, assert_almost_equal,
-    assert_no_warnings, assert_raises, assert_array_equal, suppress_warnings
+    assert_no_warnings, assert_raises, assert_array_equal, suppress_warnings,
+    assert_warns, assert_allclose
     )
 
 
@@ -842,5 +843,86 @@ def test_multiple_percentiles(self):
         assert_equal(np.nanpercentile(megamat, perc, axis=(1, 2)).shape, (2, 3, 6))
 
 
+class TestNanFunctions_Cov(TestCase):
+    x = np.array([[1, 2, 10, 3]])
+    y = np.array([[0, 1, np.nan, 0]])
+    X = np.vstack((x, y))
+    X_no_nan_complete = X[:, (0, 1, 3)]
+
+    fweights = np.array([1, 2, 3, 1])
+    aweights = np.array([0.9, 1, 0.8, 1.1])
+    mask = ~np.isnan(y).reshape(-1,)
+    fweights_no_nan_complete = fweights[mask]
+    aweights_no_nan_complete = aweights[mask]
+
+    def test_basic(self):
+        assert_equal(np.nancov(self.X), np.cov(self.X_no_nan_complete))
+        assert_equal(np.nancov(self.X.T, rowvar=0),
+                     np.cov(self.X_no_nan_complete))
+
+    def test_xy(self):
+        assert_equal(np.nancov(self.x, self.y),
+                     np.cov(self.X_no_nan_complete))
+
+    def test_complex(self):
+        x = np.array([[1, 2, 10, 3], [1j, 2j, np.nan, 3j]])
+        assert_allclose(np.nancov(x), np.array([[1., -1.j], [1.j, 1.]]))
+
+    def test_weights(self):
+        val = np.nancov(self.X,
+                        fweights=self.fweights,
+                        aweights=self.aweights)
+        nonan_val = np.cov(self.X_no_nan_complete,
+                           fweights=self.fweights_no_nan_complete,
+                           aweights=self.aweights_no_nan_complete)
+        assert_equal(val, nonan_val)
+
+    def test_empty(self):
+        with warnings.catch_warnings(record=True):
+            warnings.simplefilter('always', RuntimeWarning)
+            assert_array_equal(np.nancov(np.array([])), np.nan)
+            assert_array_equal(np.nancov(np.array([]).reshape(0, 2)),
+                               np.array([]).reshape(0, 0))
+            assert_array_equal(np.nancov(np.array([]).reshape(2, 0)),
+                               np.array([[np.nan, np.nan], [np.nan, np.nan]]))
+
+    def test_wrong_ddof(self):
+        x = np.array([[0, 2], [np.nan, 1], [2, 0]]).T
+        with warnings.catch_warnings(record=True) as w:
+            warnings.simplefilter('always')
+            assert_(np.isinf(np.nancov(x, ddof=3)).all())
+            assert_(len(w) == 2)
+            # Degree of freedom <= 0
+            assert_(issubclass(w[0].category, RuntimeWarning))
+            # Divide by zero error
+            assert_(issubclass(w[1].category, RuntimeWarning))
+
+    def test_pairwise(self):
+        x = np.array([[ 1.,  2.,     10., np.nan,   5.],
+                      [ 4., 10.,     13., np.nan,   8.],
+                      [-2., -4., np.nan, np.nan, -10.]])
+        fweights = np.array([1, 2, 3, 1, 1])
+        aweights = np.array([0.9, 1.0, 0.8, 1.1, 1.0])
+        val_weight = np.zeros((3, 3))
+        val = np.zeros((3, 3))
+        for ii in range(3):
+            for jj in range(ii, 3):
+                val[ii, jj] = np.nancov(x[ii, :], x[jj, :])[0, 1]
+                val[jj, ii] = val[ii, jj]
+                val_weight[ii, jj] = np.nancov(x[ii, :], x[jj, :],
+                                               fweights=fweights,
+                                               aweights=aweights)[0, 1]
+                val_weight[jj, ii] = val_weight[ii, jj]
+        assert_allclose(val, np.nancov(x, pairwise=True))
+        assert_allclose(val_weight, np.nancov(x,
+                        fweights=fweights,
+                        aweights=aweights,
+                        pairwise=True))
+        assert_allclose(val_weight, np.nancov(x.T,
+                        rowvar=0,
+                        fweights=fweights,
+                        aweights=aweights,
+                        pairwise=True))
+
 if __name__ == "__main__":
     run_module_suite()
diff --git a/numpy/ma/core.py b/numpy/ma/core.py
index 1bf41b3d812..f83e2adcc36 100644
--- a/numpy/ma/core.py
+++ b/numpy/ma/core.py
@@ -26,6 +26,11 @@
 import warnings
 from functools import reduce
 
+if sys.version_info[0] >= 3:
+    import builtins
+else:
+    import __builtin__ as builtins
+
 import numpy as np
 import numpy.core.umath as umath
 import numpy.core.numerictypes as ntypes
@@ -4356,13 +4361,15 @@ def count(self, axis=None, keepdims=np._NoValue):
                     raise ValueError("'axis' entry is out of bounds")
                 return 1
             elif axis is None:
+                if kwargs.get('keepdims', False):
+                    return np.array(self.size, dtype=np.intp, ndmin=self.ndim)
                 return self.size
 
             axes = axis if isinstance(axis, tuple) else (axis,)
             axes = tuple(a if a >= 0 else self.ndim + a for a in axes)
             if len(axes) != len(set(axes)):
                 raise ValueError("duplicate value in 'axis'")
-            if np.any([a < 0 or a >= self.ndim for a in axes]):
+            if builtins.any(a < 0 or a >= self.ndim for a in axes):
                 raise ValueError("'axis' entry is out of bounds")
             items = 1
             for ax in axes:
@@ -4373,7 +4380,8 @@ def count(self, axis=None, keepdims=np._NoValue):
                 for a in axes:
                     out_dims[a] = 1
             else:
-                out_dims = [d for n,d in enumerate(self.shape) if n not in axes]
+                out_dims = [d for n, d in enumerate(self.shape)
+                            if n not in axes]
             # make sure to return a 0-d array if axis is supplied
             return np.full(out_dims, items, dtype=np.intp)
 
diff --git a/numpy/ma/extras.py b/numpy/ma/extras.py
index a05ea476b9d..0d5c73e7e46 100644
--- a/numpy/ma/extras.py
+++ b/numpy/ma/extras.py
@@ -708,34 +708,37 @@ def _median(a, axis=None, out=None, overwrite_input=False):
             asorted = a
     else:
         asorted = sort(a, axis=axis)
+
     if axis is None:
         axis = 0
     elif axis < 0:
-        axis += a.ndim
+        axis += asorted.ndim
 
     if asorted.ndim == 1:
         idx, odd = divmod(count(asorted), 2)
-        return asorted[idx - (not odd) : idx + 1].mean()
+        return asorted[idx + odd - 1 : idx + 1].mean(out=out)
 
-    counts = asorted.shape[axis] - (asorted.mask).sum(axis=axis)
+    counts = count(asorted, axis=axis)
     h = counts // 2
+
     # create indexing mesh grid for all but reduced axis
     axes_grid = [np.arange(x) for i, x in enumerate(asorted.shape)
                  if i != axis]
     ind = np.meshgrid(*axes_grid, sparse=True, indexing='ij')
+
     # insert indices of low and high median
     ind.insert(axis, h - 1)
     low = asorted[tuple(ind)]
     low._sharedmask = False
     ind[axis] = h
     high = asorted[tuple(ind)]
+
     # duplicate high if odd number of elements so mean does nothing
     odd = counts % 2 == 1
-    if asorted.ndim == 1:
-        if odd:
-            low = high
-    else:
-        low[odd] = high[odd]
+    if asorted.ndim > 1:
+        np.copyto(low, high, where=odd)
+    elif odd:
+        low = high
 
     if np.issubdtype(asorted.dtype, np.inexact):
         # avoid inf / x = masked
diff --git a/numpy/ma/tests/test_core.py b/numpy/ma/tests/test_core.py
index 7cac90628bf..338a6d0dc9d 100644
--- a/numpy/ma/tests/test_core.py
+++ b/numpy/ma/tests/test_core.py
@@ -4364,6 +4364,7 @@ def test_count(self):
         assert_equal(count(a, axis=1), 3*ones((2,4)))
         assert_equal(count(a, axis=(0,1)), 6*ones((4,)))
         assert_equal(count(a, keepdims=True), 24*ones((1,1,1)))
+        assert_equal(np.ndim(count(a, keepdims=True)), 3)
         assert_equal(count(a, axis=1, keepdims=True), 3*ones((2,1,4)))
         assert_equal(count(a, axis=(0,1), keepdims=True), 6*ones((1,1,4)))
         assert_equal(count(a, axis=-2), 3*ones((2,4)))
diff --git a/numpy/ma/tests/test_extras.py b/numpy/ma/tests/test_extras.py
index 6d56d4dc6c9..27fac3d635a 100644
--- a/numpy/ma/tests/test_extras.py
+++ b/numpy/ma/tests/test_extras.py
@@ -10,6 +10,7 @@
 from __future__ import division, absolute_import, print_function
 
 import warnings
+import itertools
 
 import numpy as np
 from numpy.testing import (
@@ -684,6 +685,37 @@ def test_docstring_examples(self):
         assert_equal(ma_x.shape, (2,), "shape mismatch")
         assert_(type(ma_x) is MaskedArray)
 
+    def test_axis_argument_errors(self):
+        msg = "mask = %s, ndim = %s, axis = %s, overwrite_input = %s"
+        for ndmin in range(5):
+            for mask in [False, True]:
+                x = array(1, ndmin=ndmin, mask=mask)
+
+                # Valid axis values should not raise exception
+                args = itertools.product(range(-ndmin, ndmin), [False, True])
+                for axis, over in args:
+                    try:
+                        np.ma.median(x, axis=axis, overwrite_input=over)
+                    except:
+                        raise AssertionError(msg % (mask, ndmin, axis, over))
+
+                # Invalid axis values should raise exception
+                args = itertools.product([-(ndmin + 1), ndmin], [False, True])
+                for axis, over in args:
+                    try:
+                        np.ma.median(x, axis=axis, overwrite_input=over)
+                    except IndexError:
+                        pass
+                    else:
+                        raise AssertionError(msg % (mask, ndmin, axis, over))
+
+    def test_masked_0d(self):
+        # Check values
+        x = array(1, mask=False)
+        assert_equal(np.ma.median(x), 1)
+        x = array(1, mask=True)
+        assert_equal(np.ma.median(x), np.ma.masked)
+
     def test_masked_1d(self):
         x = array(np.arange(5), mask=True)
         assert_equal(np.ma.median(x), np.ma.masked)
diff --git a/runtests.py b/runtests.py
index 9008950e9c0..7be76e46de6 100755
--- a/runtests.py
+++ b/runtests.py
@@ -60,7 +60,6 @@
 import shutil
 import subprocess
 import time
-import imp
 from argparse import ArgumentParser, REMAINDER
 
 ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__)))
diff --git a/setup.py b/setup.py
index 981746ff941..66499245159 100755
--- a/setup.py
+++ b/setup.py
@@ -388,3 +388,8 @@ def setup_package():
 
 if __name__ == '__main__':
     setup_package()
+    # This may avoid problems where numpy is installed via ``*_requires`` by
+    # setuptools, the global namespace isn't reset properly, and then numpy is
+    # imported later (which will then fail to load numpy extension modules).
+    # See gh-7956 for details
+    del builtins.__NUMPY_SETUP__
